2022-12-12 02:22:41.473643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.482070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.488248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.493878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.499177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.511715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.518055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.529797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.586390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.587398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.588288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.589221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.590454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.591537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.592832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.594592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.595589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.595648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.597250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.597350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.598644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.599010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.600261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.600749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.601843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.602340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.603328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.604030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.604790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.605863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.606293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.607930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.608816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.609956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.610858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.611879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.612862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.613845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.614775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.615722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.620042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.620979: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 02:22:41.621763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.622765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.623016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.624460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.624728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.626229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.626404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.627733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.628039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.629163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.629602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.630658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.631048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.632228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.632268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.634060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.634166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.636068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.636670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.638223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.639800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.641310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.643043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.645384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.646065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.647791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.648726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.648828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.650268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.651391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.651589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.652012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.653642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.653666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.653730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.654296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.663980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.664016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.664304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.665869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.667492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.667708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.668102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.668520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.670060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.670633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.671186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.671574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.676325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.679190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.695924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.706411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.707456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.708447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.708944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.709018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.709547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.709591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.711020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.713601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.713858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.714039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.714085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.714127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.715871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.719209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.719358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.719485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.719616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.720207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.722672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.722800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.722895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.723703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.726098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.726142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.726182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.726936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.729573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.729605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.729647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.730691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.732600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.732733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.732777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.733542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.735630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.735670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.735752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.736633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.738438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.738478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.738560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.739520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.741702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.741742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.741780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.742698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.744613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.744656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.744697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.745791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.747565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.747656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.747712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.749506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.750389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.750429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.750567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.752573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.753176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.753259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.753395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.755381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.755918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.756000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.756184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.756445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.759068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.760085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.760516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.760600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.760869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.761908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.762276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.762763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.764321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.764408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.764980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.765779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.765945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.766167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.767105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.768522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.768675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.769368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.770670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.770755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.770908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.771537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.772910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.773113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.773941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.775096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.775217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.775240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.775936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.777621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.777737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.778506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.779683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.779964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.780432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.781658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.781871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.782329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.783544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.783706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.784157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.784494: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 02:22:41.785356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.786119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.786157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.787087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.787232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.787654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.789117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.789854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.789950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.790843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.790925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.791330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.794415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.794670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.794808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.795666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.796988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.797131: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 02:22:41.797135: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 02:22:41.797135: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 02:22:41.797479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.797482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.798975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.799875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.800670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.800709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.801912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.802703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.803546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.803659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.805572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.806324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.806552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.808039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.808373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.808440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.808856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.809663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.810050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.812056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.812696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.812883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.813164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.814282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.815244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.816194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.816680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.816855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.817026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.818215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.819544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.849092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.851035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.851190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.853830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.855597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.855749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.858434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.860049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.860283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.863751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.865261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.865503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.868214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.870950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.871210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.872847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.879972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.881022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.883600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.885287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.887329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.888988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.889181: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 02:22:41.900660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.919713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.921690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.924704: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 02:22:41.926807: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 02:22:41.936084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.936982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.938081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.946510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.947057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.950903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:41.951704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:42.895983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:42.897179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:42.898323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:42.899534: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 02:22:42.899596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 02:22:42.917768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:42.919233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:42.920328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:42.921544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:42.922644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:42.923738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 02:22:42.970824: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:42.971053: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.031778: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-12 02:22:43.176756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.177378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.177896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.178371: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 02:22:43.178425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 02:22:43.195883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.196521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.197018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.197804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.198412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.198903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 02:22:43.201029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.202045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.202988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.204328: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 02:22:43.204392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 02:22:43.214634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.215778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.216997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.218113: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 02:22:43.218172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 02:22:43.221668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.222831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.222960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.224783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.224929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.226609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.226704: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 02:22:43.226751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 02:22:43.229148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.230791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.231893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 02:22:43.235688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.236935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.237899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.238971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.240490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.241459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 02:22:43.244387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.245943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.247033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.248235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.249477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.250523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 02:22:43.255404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.256717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.257688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.258821: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 02:22:43.258873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 02:22:43.274296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.274705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.276013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.276471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.276582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.277740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.278596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.278629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.279902: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 02:22:43.279983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 02:22:43.280617: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 02:22:43.280636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.280678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 02:22:43.282005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.282575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.283062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 02:22:43.287462: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.287625: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.289422: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-12 02:22:43.295588: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.295761: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.297587: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-12 02:22:43.298648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.298721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.298737: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.298886: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.300121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.300134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.300683: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-12 02:22:43.301352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.301356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.302757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.302775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.303884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.303926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 02:22:43.304929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 02:22:43.304969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 02:22:43.320670: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.320883: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.322930: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
2022-12-12 02:22:43.330713: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.330892: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.332707: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-12 02:22:43.351094: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.351291: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.351706: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.351888: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 02:22:43.352944: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-12 02:22:43.353652: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
[HCTR][02:22:44.607][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][02:22:44.615][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][02:22:44.616][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][02:22:44.617][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][02:22:44.617][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][02:22:44.617][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][02:22:44.639][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][02:22:44.641][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:01,  1.56s/it]warmup run: 1it [00:01,  1.53s/it]warmup run: 100it [00:01, 83.57it/s]warmup run: 1it [00:01,  1.58s/it]warmup run: 1it [00:01,  1.57s/it]warmup run: 1it [00:01,  1.52s/it]warmup run: 1it [00:01,  1.52s/it]warmup run: 95it [00:01, 80.69it/s]warmup run: 200it [00:01, 181.44it/s]warmup run: 94it [00:01, 77.62it/s]warmup run: 1it [00:01,  1.53s/it]warmup run: 96it [00:01, 79.58it/s]warmup run: 1it [00:01,  1.54s/it]warmup run: 94it [00:01, 80.70it/s]warmup run: 96it [00:01, 82.02it/s]warmup run: 195it [00:01, 180.29it/s]warmup run: 301it [00:01, 290.84it/s]warmup run: 189it [00:01, 169.91it/s]warmup run: 96it [00:01, 81.60it/s]warmup run: 192it [00:01, 172.99it/s]warmup run: 99it [00:01, 83.87it/s]warmup run: 188it [00:01, 174.76it/s]warmup run: 195it [00:01, 180.90it/s]warmup run: 295it [00:01, 290.15it/s]warmup run: 400it [00:01, 401.84it/s]warmup run: 286it [00:01, 274.58it/s]warmup run: 194it [00:01, 179.04it/s]warmup run: 288it [00:01, 276.61it/s]warmup run: 200it [00:01, 184.03it/s]warmup run: 288it [00:01, 286.21it/s]warmup run: 294it [00:01, 289.51it/s]warmup run: 395it [00:01, 404.24it/s]warmup run: 499it [00:02, 510.55it/s]warmup run: 384it [00:01, 385.86it/s]warmup run: 294it [00:01, 288.99it/s]warmup run: 387it [00:01, 389.13it/s]warmup run: 300it [00:01, 292.92it/s]warmup run: 385it [00:01, 396.76it/s]warmup run: 392it [00:01, 400.79it/s]warmup run: 497it [00:02, 518.84it/s]warmup run: 598it [00:02, 610.63it/s]warmup run: 484it [00:02, 498.78it/s]warmup run: 395it [00:01, 404.51it/s]warmup run: 485it [00:02, 497.47it/s]warmup run: 401it [00:01, 407.37it/s]warmup run: 483it [00:02, 505.36it/s]warmup run: 491it [00:02, 510.68it/s]warmup run: 600it [00:02, 625.68it/s]warmup run: 697it [00:02, 697.41it/s]warmup run: 584it [00:02, 602.96it/s]warmup run: 497it [00:02, 518.51it/s]warmup run: 582it [00:02, 594.66it/s]warmup run: 501it [00:02, 517.47it/s]warmup run: 578it [00:02, 598.40it/s]warmup run: 591it [00:02, 612.91it/s]warmup run: 702it [00:02, 715.91it/s]warmup run: 797it [00:02, 771.03it/s]warmup run: 682it [00:02, 688.55it/s]warmup run: 599it [00:02, 622.83it/s]warmup run: 678it [00:02, 676.86it/s]warmup run: 604it [00:02, 624.62it/s]warmup run: 674it [00:02, 681.37it/s]warmup run: 690it [00:02, 699.33it/s]warmup run: 804it [00:02, 791.00it/s]warmup run: 897it [00:02, 830.58it/s]warmup run: 780it [00:02, 759.11it/s]warmup run: 704it [00:02, 720.05it/s]warmup run: 773it [00:02, 743.74it/s]warmup run: 707it [00:02, 716.95it/s]warmup run: 770it [00:02, 749.96it/s]warmup run: 788it [00:02, 767.28it/s]warmup run: 904it [00:02, 845.25it/s]warmup run: 996it [00:02, 868.00it/s]warmup run: 877it [00:02, 812.23it/s]warmup run: 810it [00:02, 803.35it/s]warmup run: 867it [00:02, 794.25it/s]warmup run: 809it [00:02, 791.43it/s]warmup run: 865it [00:02, 799.94it/s]warmup run: 885it [00:02, 817.81it/s]warmup run: 1006it [00:02, 890.91it/s]warmup run: 1094it [00:02, 890.62it/s]warmup run: 975it [00:02, 857.53it/s]warmup run: 914it [00:02, 863.23it/s]warmup run: 961it [00:02, 832.90it/s]warmup run: 909it [00:02, 844.24it/s]warmup run: 959it [00:02, 837.25it/s]warmup run: 982it [00:02, 855.18it/s]warmup run: 1107it [00:02, 917.70it/s]warmup run: 1191it [00:02, 911.07it/s]warmup run: 1073it [00:02, 891.20it/s]warmup run: 1016it [00:02, 898.67it/s]warmup run: 1055it [00:02, 859.92it/s]warmup run: 1009it [00:02, 876.93it/s]warmup run: 1054it [00:02, 868.47it/s]warmup run: 1078it [00:02, 882.46it/s]warmup run: 1207it [00:02, 936.86it/s]warmup run: 1292it [00:02, 937.10it/s]warmup run: 1171it [00:02, 914.37it/s]warmup run: 1117it [00:02, 926.90it/s]warmup run: 1150it [00:02, 885.37it/s]warmup run: 1108it [00:02, 896.53it/s]warmup run: 1153it [00:02, 902.17it/s]warmup run: 1174it [00:02, 903.73it/s]warmup run: 1310it [00:02, 961.57it/s]warmup run: 1393it [00:02, 957.65it/s]warmup run: 1270it [00:02, 934.44it/s]warmup run: 1218it [00:02, 948.56it/s]warmup run: 1253it [00:02, 925.44it/s]warmup run: 1206it [00:02, 914.78it/s]warmup run: 1250it [00:02, 920.88it/s]warmup run: 1270it [00:02, 916.54it/s]warmup run: 1413it [00:02, 981.34it/s]warmup run: 1495it [00:03, 975.68it/s]warmup run: 1368it [00:02, 946.54it/s]warmup run: 1319it [00:02, 962.17it/s]warmup run: 1356it [00:02, 955.23it/s]warmup run: 1303it [00:02, 927.93it/s]warmup run: 1367it [00:02, 931.01it/s]warmup run: 1346it [00:02, 915.88it/s]warmup run: 1515it [00:03, 991.74it/s]warmup run: 1598it [00:03, 990.23it/s]warmup run: 1466it [00:03, 955.23it/s]warmup run: 1421it [00:02, 976.27it/s]warmup run: 1460it [00:03, 977.59it/s]warmup run: 1402it [00:02, 945.40it/s]warmup run: 1466it [00:03, 946.15it/s]warmup run: 1442it [00:03, 925.85it/s]warmup run: 1701it [00:03, 1001.80it/s]warmup run: 1617it [00:03, 990.69it/s]warmup run: 1564it [00:03, 960.07it/s]warmup run: 1523it [00:03, 989.01it/s]warmup run: 1562it [00:03, 989.23it/s]warmup run: 1500it [00:03, 952.59it/s]warmup run: 1564it [00:03, 955.60it/s]warmup run: 1538it [00:03, 933.78it/s]warmup run: 1718it [00:03, 991.22it/s]warmup run: 1803it [00:03, 998.25it/s] warmup run: 1662it [00:03, 963.21it/s]warmup run: 1625it [00:03, 996.28it/s]warmup run: 1666it [00:03, 1001.48it/s]warmup run: 1599it [00:03, 961.96it/s]warmup run: 1661it [00:03, 956.05it/s]warmup run: 1634it [00:03, 938.90it/s]warmup run: 1819it [00:03, 990.64it/s]warmup run: 1904it [00:03, 994.21it/s]warmup run: 1760it [00:03, 963.87it/s]warmup run: 1728it [00:03, 1005.50it/s]warmup run: 1768it [00:03, 1004.90it/s]warmup run: 1697it [00:03, 956.39it/s]warmup run: 1730it [00:03, 942.94it/s]warmup run: 1758it [00:03, 955.54it/s]warmup run: 1919it [00:03, 988.78it/s]warmup run: 2004it [00:03, 986.86it/s]warmup run: 1858it [00:03, 965.85it/s]warmup run: 1831it [00:03, 1012.23it/s]warmup run: 1870it [00:03, 999.74it/s] warmup run: 1794it [00:03, 950.24it/s]warmup run: 1826it [00:03, 946.82it/s]warmup run: 1856it [00:03, 961.92it/s]warmup run: 2021it [00:03, 996.19it/s]warmup run: 2122it [00:03, 1042.05it/s]warmup run: 1957it [00:03, 970.17it/s]warmup run: 1935it [00:03, 1018.86it/s]warmup run: 1971it [00:03, 1002.71it/s]warmup run: 1891it [00:03, 953.55it/s]warmup run: 1956it [00:03, 971.76it/s]warmup run: 1922it [00:03, 948.05it/s]warmup run: 2139it [00:03, 1050.03it/s]warmup run: 2240it [00:03, 1080.54it/s]warmup run: 2064it [00:03, 998.95it/s]warmup run: 2046it [00:03, 1043.96it/s]warmup run: 2088it [00:03, 1050.05it/s]warmup run: 1990it [00:03, 963.83it/s]warmup run: 2065it [00:03, 1006.60it/s]warmup run: 2022it [00:03, 962.12it/s]warmup run: 2256it [00:03, 1084.39it/s]warmup run: 2359it [00:03, 1112.96it/s]warmup run: 2182it [00:03, 1052.60it/s]warmup run: 2169it [00:03, 1098.43it/s]warmup run: 2211it [00:03, 1101.38it/s]warmup run: 2108it [00:03, 1026.60it/s]warmup run: 2184it [00:03, 1059.75it/s]warmup run: 2144it [00:03, 1036.53it/s]warmup run: 2374it [00:03, 1110.67it/s]warmup run: 2479it [00:03, 1138.44it/s]warmup run: 2301it [00:03, 1092.98it/s]warmup run: 2292it [00:03, 1136.85it/s]warmup run: 2334it [00:03, 1137.63it/s]warmup run: 2229it [00:03, 1080.06it/s]warmup run: 2303it [00:03, 1097.73it/s]warmup run: 2265it [00:03, 1087.91it/s]warmup run: 2492it [00:03, 1130.49it/s]warmup run: 2600it [00:04, 1159.36it/s]warmup run: 2421it [00:03, 1122.22it/s]warmup run: 2415it [00:03, 1162.67it/s]warmup run: 2457it [00:03, 1162.81it/s]warmup run: 2350it [00:03, 1117.93it/s]warmup run: 2422it [00:03, 1123.65it/s]warmup run: 2386it [00:03, 1123.78it/s]warmup run: 2610it [00:04, 1142.57it/s]warmup run: 2721it [00:04, 1172.62it/s]warmup run: 2540it [00:04, 1141.76it/s]warmup run: 2538it [00:03, 1181.02it/s]warmup run: 2580it [00:04, 1180.69it/s]warmup run: 2471it [00:03, 1144.20it/s]warmup run: 2507it [00:04, 1149.19it/s]warmup run: 2541it [00:04, 1141.26it/s]warmup run: 2726it [00:04, 1145.61it/s]warmup run: 2844it [00:04, 1188.55it/s]warmup run: 2658it [00:04, 1152.45it/s]warmup run: 2660it [00:04, 1191.78it/s]warmup run: 2702it [00:04, 1190.68it/s]warmup run: 2593it [00:04, 1166.17it/s]warmup run: 2628it [00:04, 1166.73it/s]warmup run: 2659it [00:04, 1151.76it/s]warmup run: 2843it [00:04, 1150.87it/s]warmup run: 2966it [00:04, 1196.52it/s]warmup run: 2776it [00:04, 1157.88it/s]warmup run: 2784it [00:04, 1203.53it/s]warmup run: 2825it [00:04, 1200.29it/s]warmup run: 3000it [00:04, 678.88it/s] warmup run: 2715it [00:04, 1179.87it/s]warmup run: 2747it [00:04, 1173.22it/s]warmup run: 2778it [00:04, 1163.09it/s]warmup run: 2960it [00:04, 1153.60it/s]warmup run: 2893it [00:04, 1160.08it/s]warmup run: 2907it [00:04, 1210.16it/s]warmup run: 2948it [00:04, 1206.74it/s]warmup run: 3000it [00:04, 682.17it/s] warmup run: 3000it [00:04, 675.32it/s] warmup run: 2836it [00:04, 1187.33it/s]warmup run: 2866it [00:04, 1177.97it/s]warmup run: 2898it [00:04, 1171.32it/s]warmup run: 3000it [00:04, 692.44it/s] warmup run: 3000it [00:04, 667.78it/s] warmup run: 2958it [00:04, 1195.13it/s]warmup run: 3000it [00:04, 676.03it/s] warmup run: 2984it [00:04, 1171.78it/s]warmup run: 3000it [00:04, 673.13it/s] warmup run: 3000it [00:04, 680.33it/s] 



warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|         | 161/3000 [00:00<00:01, 1608.44it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1673.59it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1624.60it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1642.67it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1635.24it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1613.01it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1640.59it/s]warmup should be done:   5%|         | 159/3000 [00:00<00:01, 1580.21it/s]warmup should be done:  11%|         | 324/3000 [00:00<00:01, 1617.64it/s]warmup should be done:  11%|         | 331/3000 [00:00<00:01, 1651.03it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1658.36it/s]warmup should be done:  11%|         | 324/3000 [00:00<00:01, 1614.08it/s]warmup should be done:  11%|         | 336/3000 [00:00<00:01, 1671.68it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1642.12it/s]warmup should be done:  11%|         | 319/3000 [00:00<00:01, 1590.07it/s]warmup should be done:  11%|         | 326/3000 [00:00<00:01, 1604.86it/s]warmup should be done:  16%|        | 486/3000 [00:00<00:01, 1615.96it/s]warmup should be done:  17%|        | 499/3000 [00:00<00:01, 1661.70it/s]warmup should be done:  17%|        | 497/3000 [00:00<00:01, 1649.32it/s]warmup should be done:  17%|        | 504/3000 [00:00<00:01, 1670.28it/s]warmup should be done:  16%|        | 479/3000 [00:00<00:01, 1588.26it/s]warmup should be done:  16%|        | 486/3000 [00:00<00:01, 1609.04it/s]warmup should be done:  16%|        | 495/3000 [00:00<00:01, 1638.43it/s]warmup should be done:  16%|        | 488/3000 [00:00<00:01, 1610.46it/s]warmup should be done:  22%|       | 662/3000 [00:00<00:01, 1647.51it/s]warmup should be done:  21%|       | 639/3000 [00:00<00:01, 1591.30it/s]warmup should be done:  22%|       | 672/3000 [00:00<00:01, 1668.27it/s]warmup should be done:  22%|       | 659/3000 [00:00<00:01, 1635.57it/s]warmup should be done:  22%|       | 647/3000 [00:00<00:01, 1605.70it/s]warmup should be done:  22%|       | 650/3000 [00:00<00:01, 1613.09it/s]warmup should be done:  22%|       | 648/3000 [00:00<00:01, 1431.03it/s]warmup should be done:  22%|       | 666/3000 [00:00<00:01, 1468.24it/s]warmup should be done:  28%|       | 827/3000 [00:00<00:01, 1644.66it/s]warmup should be done:  27%|       | 800/3000 [00:00<00:01, 1595.34it/s]warmup should be done:  28%|       | 839/3000 [00:00<00:01, 1666.24it/s]warmup should be done:  27%|       | 823/3000 [00:00<00:01, 1633.74it/s]warmup should be done:  27%|       | 808/3000 [00:00<00:01, 1601.22it/s]warmup should be done:  27%|       | 812/3000 [00:00<00:01, 1607.31it/s]warmup should be done:  27%|       | 807/3000 [00:00<00:01, 1483.27it/s]warmup should be done:  28%|       | 833/3000 [00:00<00:01, 1533.73it/s]warmup should be done:  32%|      | 961/3000 [00:00<00:01, 1597.65it/s]warmup should be done:  34%|      | 1006/3000 [00:00<00:01, 1664.15it/s]warmup should be done:  33%|      | 992/3000 [00:00<00:01, 1639.18it/s]warmup should be done:  33%|      | 987/3000 [00:00<00:01, 1628.59it/s]warmup should be done:  32%|      | 969/3000 [00:00<00:01, 1594.13it/s]warmup should be done:  32%|      | 973/3000 [00:00<00:01, 1602.49it/s]warmup should be done:  32%|      | 965/3000 [00:00<00:01, 1513.36it/s]warmup should be done:  33%|      | 999/3000 [00:00<00:01, 1571.23it/s]warmup should be done:  37%|      | 1121/3000 [00:00<00:01, 1596.06it/s]warmup should be done:  39%|      | 1156/3000 [00:00<00:01, 1638.54it/s]warmup should be done:  38%|      | 1150/3000 [00:00<00:01, 1628.50it/s]warmup should be done:  39%|      | 1173/3000 [00:00<00:01, 1657.76it/s]warmup should be done:  38%|      | 1134/3000 [00:00<00:01, 1604.87it/s]warmup should be done:  38%|      | 1129/3000 [00:00<00:01, 1593.06it/s]warmup should be done:  37%|      | 1124/3000 [00:00<00:01, 1535.52it/s]warmup should be done:  39%|      | 1159/3000 [00:00<00:01, 1577.94it/s]warmup should be done:  43%|     | 1281/3000 [00:00<00:01, 1592.24it/s]warmup should be done:  44%|     | 1314/3000 [00:00<00:01, 1628.98it/s]warmup should be done:  43%|     | 1295/3000 [00:00<00:01, 1606.44it/s]warmup should be done:  43%|     | 1289/3000 [00:00<00:01, 1592.83it/s]warmup should be done:  45%|     | 1339/3000 [00:00<00:01, 1647.92it/s]warmup should be done:  44%|     | 1320/3000 [00:00<00:01, 1506.93it/s]warmup should be done:  43%|     | 1283/3000 [00:00<00:01, 1551.40it/s]warmup should be done:  44%|     | 1319/3000 [00:00<00:01, 1433.61it/s]warmup should be done:  48%|     | 1441/3000 [00:00<00:00, 1590.90it/s]warmup should be done:  49%|     | 1477/3000 [00:00<00:00, 1628.24it/s]warmup should be done:  48%|     | 1449/3000 [00:00<00:00, 1592.30it/s]warmup should be done:  49%|     | 1456/3000 [00:00<00:00, 1589.76it/s]warmup should be done:  50%|     | 1504/3000 [00:00<00:00, 1624.66it/s]warmup should be done:  48%|     | 1442/3000 [00:00<00:00, 1562.11it/s]warmup should be done:  49%|     | 1473/3000 [00:00<00:01, 1493.02it/s]warmup should be done:  49%|     | 1480/3000 [00:00<00:01, 1482.84it/s]warmup should be done:  55%|    | 1640/3000 [00:01<00:00, 1625.87it/s]warmup should be done:  53%|    | 1601/3000 [00:01<00:00, 1586.46it/s]warmup should be done:  54%|    | 1609/3000 [00:01<00:00, 1593.42it/s]warmup should be done:  54%|    | 1617/3000 [00:01<00:00, 1593.80it/s]warmup should be done:  56%|    | 1667/3000 [00:01<00:00, 1610.03it/s]warmup should be done:  53%|    | 1601/3000 [00:01<00:00, 1569.40it/s]warmup should be done:  55%|    | 1635/3000 [00:01<00:00, 1529.81it/s]warmup should be done:  55%|    | 1643/3000 [00:01<00:00, 1522.95it/s]warmup should be done:  60%|    | 1803/3000 [00:01<00:00, 1622.24it/s]warmup should be done:  59%|    | 1770/3000 [00:01<00:00, 1597.75it/s]warmup should be done:  59%|    | 1760/3000 [00:01<00:00, 1582.42it/s]warmup should be done:  59%|    | 1778/3000 [00:01<00:00, 1597.85it/s]warmup should be done:  61%|    | 1829/3000 [00:01<00:00, 1602.66it/s]warmup should be done:  59%|    | 1760/3000 [00:01<00:00, 1574.61it/s]warmup should be done:  60%|    | 1799/3000 [00:01<00:00, 1561.17it/s]warmup should be done:  60%|    | 1806/3000 [00:01<00:00, 1552.85it/s]warmup should be done:  66%|   | 1966/3000 [00:01<00:00, 1621.50it/s]warmup should be done:  64%|   | 1931/3000 [00:01<00:00, 1599.43it/s]warmup should be done:  64%|   | 1919/3000 [00:01<00:00, 1579.34it/s]warmup should be done:  65%|   | 1939/3000 [00:01<00:00, 1599.03it/s]warmup should be done:  66%|   | 1990/3000 [00:01<00:00, 1603.17it/s]warmup should be done:  64%|   | 1919/3000 [00:01<00:00, 1577.71it/s]warmup should be done:  65%|   | 1963/3000 [00:01<00:00, 1583.26it/s]warmup should be done:  66%|   | 1969/3000 [00:01<00:00, 1574.19it/s]warmup should be done:  71%|   | 2129/3000 [00:01<00:00, 1622.42it/s]warmup should be done:  70%|   | 2091/3000 [00:01<00:00, 1598.95it/s]warmup should be done:  69%|   | 2077/3000 [00:01<00:00, 1577.25it/s]warmup should be done:  70%|   | 2100/3000 [00:01<00:00, 1599.54it/s]warmup should be done:  72%|  | 2151/3000 [00:01<00:00, 1601.10it/s]warmup should be done:  69%|   | 2079/3000 [00:01<00:00, 1583.20it/s]warmup should be done:  71%|   | 2127/3000 [00:01<00:00, 1599.93it/s]warmup should be done:  71%|   | 2132/3000 [00:01<00:00, 1587.90it/s]warmup should be done:  76%|  | 2292/3000 [00:01<00:00, 1620.63it/s]warmup should be done:  75%|  | 2251/3000 [00:01<00:00, 1595.83it/s]warmup should be done:  74%|  | 2235/3000 [00:01<00:00, 1572.95it/s]warmup should be done:  75%|  | 2260/3000 [00:01<00:00, 1595.74it/s]warmup should be done:  77%|  | 2312/3000 [00:01<00:00, 1599.11it/s]warmup should be done:  75%|  | 2240/3000 [00:01<00:00, 1590.19it/s]warmup should be done:  76%|  | 2293/3000 [00:01<00:00, 1614.98it/s]warmup should be done:  76%|  | 2294/3000 [00:01<00:00, 1596.12it/s]warmup should be done:  80%|  | 2411/3000 [00:01<00:00, 1596.41it/s]warmup should be done:  82%| | 2455/3000 [00:01<00:00, 1620.83it/s]warmup should be done:  80%|  | 2393/3000 [00:01<00:00, 1572.95it/s]warmup should be done:  81%|  | 2420/3000 [00:01<00:00, 1595.79it/s]warmup should be done:  82%| | 2472/3000 [00:01<00:00, 1592.74it/s]warmup should be done:  80%|  | 2402/3000 [00:01<00:00, 1598.50it/s]warmup should be done:  82%| | 2455/3000 [00:01<00:00, 1615.10it/s]warmup should be done:  82%| | 2457/3000 [00:01<00:00, 1603.70it/s]warmup should be done:  86%| | 2572/3000 [00:01<00:00, 1599.71it/s]warmup should be done:  87%| | 2618/3000 [00:01<00:00, 1622.91it/s]warmup should be done:  85%| | 2551/3000 [00:01<00:00, 1572.23it/s]warmup should be done:  86%| | 2580/3000 [00:01<00:00, 1596.68it/s]warmup should be done:  88%| | 2632/3000 [00:01<00:00, 1591.48it/s]warmup should be done:  85%| | 2564/3000 [00:01<00:00, 1603.60it/s]warmup should be done:  87%| | 2621/3000 [00:01<00:00, 1627.27it/s]warmup should be done:  87%| | 2620/3000 [00:01<00:00, 1609.09it/s]warmup should be done:  91%| | 2734/3000 [00:01<00:00, 1603.25it/s]warmup should be done:  93%|| 2782/3000 [00:01<00:00, 1625.08it/s]warmup should be done:  90%| | 2709/3000 [00:01<00:00, 1571.50it/s]warmup should be done:  91%|| 2741/3000 [00:01<00:00, 1598.51it/s]warmup should be done:  93%|| 2792/3000 [00:01<00:00, 1591.20it/s]warmup should be done:  91%| | 2726/3000 [00:01<00:00, 1606.55it/s]warmup should be done:  93%|| 2787/3000 [00:01<00:00, 1635.38it/s]warmup should be done:  93%|| 2782/3000 [00:01<00:00, 1612.20it/s]warmup should be done:  97%|| 2897/3000 [00:01<00:00, 1610.28it/s]warmup should be done:  98%|| 2947/3000 [00:01<00:00, 1630.09it/s]warmup should be done:  97%|| 2903/3000 [00:01<00:00, 1604.73it/s]warmup should be done:  96%|| 2868/3000 [00:01<00:00, 1574.41it/s]warmup should be done:  98%|| 2953/3000 [00:01<00:00, 1595.30it/s]warmup should be done:  96%|| 2889/3000 [00:01<00:00, 1611.79it/s]warmup should be done:  98%|| 2954/3000 [00:01<00:00, 1644.42it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1627.49it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1619.80it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1606.08it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1602.09it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1601.49it/s]warmup should be done:  98%|| 2947/3000 [00:01<00:00, 1623.32it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1581.65it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1573.49it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1573.32it/s]



warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1658.38it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1658.25it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1655.36it/s]warmup should be done:   5%|         | 150/3000 [00:00<00:01, 1495.90it/s]warmup should be done:   5%|         | 161/3000 [00:00<00:01, 1606.83it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1614.80it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1675.26it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1650.38it/s]warmup should be done:  11%|         | 333/3000 [00:00<00:01, 1663.94it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1658.00it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1653.59it/s]warmup should be done:  11%|         | 319/3000 [00:00<00:01, 1605.05it/s]warmup should be done:  11%|         | 322/3000 [00:00<00:01, 1603.06it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1653.87it/s]warmup should be done:  11%|         | 336/3000 [00:00<00:01, 1668.77it/s]warmup should be done:  11%|         | 324/3000 [00:00<00:01, 1589.78it/s]warmup should be done:  17%|        | 502/3000 [00:00<00:01, 1675.73it/s]warmup should be done:  17%|        | 502/3000 [00:00<00:01, 1671.85it/s]warmup should be done:  17%|        | 498/3000 [00:00<00:01, 1655.75it/s]warmup should be done:  16%|        | 487/3000 [00:00<00:01, 1638.43it/s]warmup should be done:  17%|        | 499/3000 [00:00<00:01, 1658.34it/s]warmup should be done:  16%|        | 485/3000 [00:00<00:01, 1611.36it/s]warmup should be done:  17%|        | 503/3000 [00:00<00:01, 1667.86it/s]warmup should be done:  16%|        | 484/3000 [00:00<00:01, 1586.79it/s]warmup should be done:  22%|       | 672/3000 [00:00<00:01, 1681.55it/s]warmup should be done:  22%|       | 673/3000 [00:00<00:01, 1685.85it/s]warmup should be done:  22%|       | 665/3000 [00:00<00:01, 1657.81it/s]warmup should be done:  22%|       | 665/3000 [00:00<00:01, 1658.75it/s]warmup should be done:  22%|       | 654/3000 [00:00<00:01, 1647.15it/s]warmup should be done:  22%|       | 671/3000 [00:00<00:01, 1671.60it/s]warmup should be done:  22%|       | 647/3000 [00:00<00:01, 1610.66it/s]warmup should be done:  22%|       | 647/3000 [00:00<00:01, 1601.04it/s]warmup should be done:  28%|       | 843/3000 [00:00<00:01, 1690.17it/s]warmup should be done:  28%|       | 844/3000 [00:00<00:01, 1692.49it/s]warmup should be done:  28%|       | 831/3000 [00:00<00:01, 1655.84it/s]warmup should be done:  27%|       | 823/3000 [00:00<00:01, 1660.31it/s]warmup should be done:  28%|       | 839/3000 [00:00<00:01, 1673.47it/s]warmup should be done:  27%|       | 810/3000 [00:00<00:01, 1615.97it/s]warmup should be done:  28%|       | 831/3000 [00:00<00:01, 1652.46it/s]warmup should be done:  27%|       | 810/3000 [00:00<00:01, 1609.35it/s]warmup should be done:  34%|      | 1014/3000 [00:00<00:01, 1694.14it/s]warmup should be done:  34%|      | 1015/3000 [00:00<00:01, 1696.90it/s]warmup should be done:  33%|      | 992/3000 [00:00<00:01, 1670.04it/s]warmup should be done:  33%|      | 997/3000 [00:00<00:01, 1654.00it/s]warmup should be done:  34%|      | 1007/3000 [00:00<00:01, 1670.38it/s]warmup should be done:  32%|      | 974/3000 [00:00<00:01, 1620.84it/s]warmup should be done:  33%|      | 997/3000 [00:00<00:01, 1649.86it/s]warmup should be done:  32%|      | 972/3000 [00:00<00:01, 1612.87it/s]warmup should be done:  39%|      | 1184/3000 [00:00<00:01, 1693.94it/s]warmup should be done:  40%|      | 1186/3000 [00:00<00:01, 1700.28it/s]warmup should be done:  39%|      | 1161/3000 [00:00<00:01, 1675.32it/s]warmup should be done:  38%|      | 1137/3000 [00:00<00:01, 1623.69it/s]warmup should be done:  39%|      | 1175/3000 [00:00<00:01, 1670.02it/s]warmup should be done:  39%|      | 1163/3000 [00:00<00:01, 1648.83it/s]warmup should be done:  39%|      | 1163/3000 [00:00<00:01, 1651.24it/s]warmup should be done:  38%|      | 1135/3000 [00:00<00:01, 1617.49it/s]warmup should be done:  45%|     | 1355/3000 [00:00<00:00, 1697.57it/s]warmup should be done:  45%|     | 1358/3000 [00:00<00:00, 1704.23it/s]warmup should be done:  44%|     | 1329/3000 [00:00<00:00, 1675.78it/s]warmup should be done:  45%|     | 1343/3000 [00:00<00:00, 1672.46it/s]warmup should be done:  43%|     | 1300/3000 [00:00<00:01, 1621.26it/s]warmup should be done:  44%|     | 1328/3000 [00:00<00:01, 1645.60it/s]warmup should be done:  44%|     | 1329/3000 [00:00<00:01, 1649.72it/s]warmup should be done:  43%|     | 1297/3000 [00:00<00:01, 1615.73it/s]warmup should be done:  51%|     | 1529/3000 [00:00<00:00, 1705.38it/s]warmup should be done:  50%|     | 1498/3000 [00:00<00:00, 1678.92it/s]warmup should be done:  51%|     | 1526/3000 [00:00<00:00, 1698.67it/s]warmup should be done:  49%|     | 1464/3000 [00:00<00:00, 1625.59it/s]warmup should be done:  50%|     | 1511/3000 [00:00<00:00, 1669.99it/s]warmup should be done:  50%|     | 1495/3000 [00:00<00:00, 1652.42it/s]warmup should be done:  50%|     | 1493/3000 [00:00<00:00, 1645.54it/s]warmup should be done:  49%|     | 1461/3000 [00:00<00:00, 1620.38it/s]warmup should be done:  57%|    | 1700/3000 [00:01<00:00, 1706.58it/s]warmup should be done:  57%|    | 1696/3000 [00:01<00:00, 1698.72it/s]warmup should be done:  56%|    | 1667/3000 [00:01<00:00, 1681.20it/s]warmup should be done:  54%|    | 1628/3000 [00:01<00:00, 1628.52it/s]warmup should be done:  55%|    | 1658/3000 [00:01<00:00, 1646.81it/s]warmup should be done:  56%|    | 1679/3000 [00:01<00:00, 1671.89it/s]warmup should be done:  55%|    | 1662/3000 [00:01<00:00, 1655.69it/s]warmup should be done:  54%|    | 1625/3000 [00:01<00:00, 1623.58it/s]warmup should be done:  61%|    | 1836/3000 [00:01<00:00, 1682.31it/s]warmup should be done:  62%|   | 1867/3000 [00:01<00:00, 1699.76it/s]warmup should be done:  62%|   | 1871/3000 [00:01<00:00, 1703.10it/s]warmup should be done:  60%|    | 1791/3000 [00:01<00:00, 1628.03it/s]warmup should be done:  61%|    | 1823/3000 [00:01<00:00, 1647.35it/s]warmup should be done:  62%|   | 1847/3000 [00:01<00:00, 1671.21it/s]warmup should be done:  61%|    | 1829/3000 [00:01<00:00, 1658.24it/s]warmup should be done:  60%|    | 1788/3000 [00:01<00:00, 1624.14it/s]warmup should be done:  68%|   | 2037/3000 [00:01<00:00, 1699.43it/s]warmup should be done:  68%|   | 2042/3000 [00:01<00:00, 1704.78it/s]warmup should be done:  67%|   | 2005/3000 [00:01<00:00, 1680.99it/s]warmup should be done:  65%|   | 1954/3000 [00:01<00:00, 1626.00it/s]warmup should be done:  66%|   | 1988/3000 [00:01<00:00, 1644.46it/s]warmup should be done:  66%|   | 1995/3000 [00:01<00:00, 1657.61it/s]warmup should be done:  67%|   | 2015/3000 [00:01<00:00, 1668.94it/s]warmup should be done:  65%|   | 1951/3000 [00:01<00:00, 1622.81it/s]warmup should be done:  74%|  | 2207/3000 [00:01<00:00, 1697.91it/s]warmup should be done:  74%|  | 2213/3000 [00:01<00:00, 1702.38it/s]warmup should be done:  72%|  | 2174/3000 [00:01<00:00, 1675.58it/s]warmup should be done:  71%|   | 2117/3000 [00:01<00:00, 1625.51it/s]warmup should be done:  72%|  | 2154/3000 [00:01<00:00, 1646.99it/s]warmup should be done:  72%|  | 2161/3000 [00:01<00:00, 1655.99it/s]warmup should be done:  73%|  | 2182/3000 [00:01<00:00, 1667.39it/s]warmup should be done:  70%|   | 2114/3000 [00:01<00:00, 1615.96it/s]warmup should be done:  79%|  | 2377/3000 [00:01<00:00, 1698.03it/s]warmup should be done:  79%|  | 2384/3000 [00:01<00:00, 1701.67it/s]warmup should be done:  76%|  | 2280/3000 [00:01<00:00, 1625.35it/s]warmup should be done:  77%|  | 2320/3000 [00:01<00:00, 1649.92it/s]warmup should be done:  78%|  | 2328/3000 [00:01<00:00, 1658.99it/s]warmup should be done:  78%|  | 2342/3000 [00:01<00:00, 1669.48it/s]warmup should be done:  78%|  | 2350/3000 [00:01<00:00, 1668.38it/s]warmup should be done:  76%|  | 2276/3000 [00:01<00:00, 1604.40it/s]warmup should be done:  85%| | 2548/3000 [00:01<00:00, 1700.78it/s]warmup should be done:  85%| | 2555/3000 [00:01<00:00, 1703.49it/s]warmup should be done:  83%| | 2497/3000 [00:01<00:00, 1668.09it/s]warmup should be done:  81%| | 2443/3000 [00:01<00:00, 1622.68it/s]warmup should be done:  83%| | 2485/3000 [00:01<00:00, 1646.13it/s]warmup should be done:  84%| | 2511/3000 [00:01<00:00, 1673.66it/s]warmup should be done:  84%| | 2518/3000 [00:01<00:00, 1670.22it/s]warmup should be done:  81%|  | 2437/3000 [00:01<00:00, 1592.26it/s]warmup should be done:  91%| | 2719/3000 [00:01<00:00, 1702.79it/s]warmup should be done:  89%| | 2666/3000 [00:01<00:00, 1672.19it/s]warmup should be done:  88%| | 2651/3000 [00:01<00:00, 1647.98it/s]warmup should be done:  91%| | 2726/3000 [00:01<00:00, 1692.50it/s]warmup should be done:  87%| | 2606/3000 [00:01<00:00, 1620.70it/s]warmup should be done:  90%| | 2686/3000 [00:01<00:00, 1669.42it/s]warmup should be done:  89%| | 2679/3000 [00:01<00:00, 1642.10it/s]warmup should be done:  87%| | 2600/3000 [00:01<00:00, 1600.63it/s]warmup should be done:  96%|| 2890/3000 [00:01<00:00, 1698.38it/s]warmup should be done:  94%|| 2835/3000 [00:01<00:00, 1676.24it/s]warmup should be done:  94%|| 2817/3000 [00:01<00:00, 1651.27it/s]warmup should be done:  97%|| 2897/3000 [00:01<00:00, 1696.26it/s]warmup should be done:  92%|| 2770/3000 [00:01<00:00, 1624.66it/s]warmup should be done:  95%|| 2854/3000 [00:01<00:00, 1670.76it/s]warmup should be done:  95%|| 2844/3000 [00:01<00:00, 1640.65it/s]warmup should be done:  92%|| 2763/3000 [00:01<00:00, 1609.08it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1696.46it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1694.24it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1670.70it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1661.90it/s]warmup should be done:  99%|| 2984/3000 [00:01<00:00, 1654.97it/s]warmup should be done:  98%|| 2933/3000 [00:01<00:00, 1626.21it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1657.89it/s]warmup should be done:  98%|| 2926/3000 [00:01<00:00, 1614.22it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1650.20it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1622.07it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1610.98it/s]2022-12-12 02:24:20.582535: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f568382cc20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 02:24:20.582595: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 02:24:20.597374: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f56838310c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 02:24:20.597437: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 02:24:20.598327: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f567f835140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 02:24:20.598370: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 02:24:20.634861: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f5677795f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 02:24:20.634936: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 02:24:20.670843: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f568382cb40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 02:24:20.670928: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 02:24:21.048367: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f39cc030ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 02:24:21.048441: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 02:24:21.068105: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f56778318e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 02:24:21.068173: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 02:24:21.134519: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f5683831eb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 02:24:21.134591: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 02:24:22.807115: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 02:24:22.894198: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 02:24:22.926392: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 02:24:22.933488: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 02:24:22.995368: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 02:24:23.323029: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 02:24:23.361438: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 02:24:23.430424: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 02:24:25.650677: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 02:24:25.732455: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 02:24:25.879767: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 02:24:25.883252: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 02:24:25.936328: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 02:24:26.222534: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 02:24:26.261633: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 02:24:26.319332: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][02:24:54.240][ERROR][RK0][main]: replica 7 reaches 1000, calling init pre replica
[HCTR][02:24:54.240][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][02:24:54.250][ERROR][RK0][main]: coll ps creation done
[HCTR][02:24:54.250][ERROR][RK0][main]: replica 7 waits for coll ps creation barrier
[HCTR][02:24:54.298][ERROR][RK0][tid #140009919194880]: replica 6 reaches 1000, calling init pre replica
[HCTR][02:24:54.298][ERROR][RK0][tid #140009919194880]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][02:24:54.304][ERROR][RK0][tid #140009919194880]: coll ps creation done
[HCTR][02:24:54.304][ERROR][RK0][tid #140009919194880]: replica 6 waits for coll ps creation barrier
[HCTR][02:24:54.333][ERROR][RK0][tid #140010456065792]: replica 5 reaches 1000, calling init pre replica
[HCTR][02:24:54.333][ERROR][RK0][tid #140010456065792]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][02:24:54.338][ERROR][RK0][tid #140010456065792]: coll ps creation done
[HCTR][02:24:54.338][ERROR][RK0][tid #140010456065792]: replica 5 waits for coll ps creation barrier
[HCTR][02:24:54.347][ERROR][RK0][tid #140010187630336]: replica 1 reaches 1000, calling init pre replica
[HCTR][02:24:54.347][ERROR][RK0][tid #140010187630336]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][02:24:54.352][ERROR][RK0][tid #140010187630336]: coll ps creation done
[HCTR][02:24:54.352][ERROR][RK0][tid #140010187630336]: replica 1 waits for coll ps creation barrier
[HCTR][02:24:54.368][ERROR][RK0][main]: replica 2 reaches 1000, calling init pre replica
[HCTR][02:24:54.368][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][02:24:54.373][ERROR][RK0][main]: coll ps creation done
[HCTR][02:24:54.373][ERROR][RK0][main]: replica 2 waits for coll ps creation barrier
[HCTR][02:24:54.376][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][02:24:54.376][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][02:24:54.385][ERROR][RK0][main]: coll ps creation done
[HCTR][02:24:54.385][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][02:24:54.402][ERROR][RK0][main]: replica 4 reaches 1000, calling init pre replica
[HCTR][02:24:54.402][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][02:24:54.410][ERROR][RK0][main]: coll ps creation done
[HCTR][02:24:54.410][ERROR][RK0][main]: replica 4 waits for coll ps creation barrier
[HCTR][02:24:54.436][ERROR][RK0][tid #140010858718976]: replica 0 reaches 1000, calling init pre replica
[HCTR][02:24:54.436][ERROR][RK0][tid #140010858718976]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][02:24:54.441][ERROR][RK0][tid #140010858718976]: coll ps creation done
[HCTR][02:24:54.441][ERROR][RK0][tid #140010858718976]: replica 0 waits for coll ps creation barrier
[HCTR][02:24:54.441][ERROR][RK0][tid #140010858718976]: replica 0 preparing frequency
[HCTR][02:24:55.291][ERROR][RK0][tid #140010858718976]: replica 0 preparing frequency done
[HCTR][02:24:55.328][ERROR][RK0][tid #140010858718976]: replica 0 calling init per replica
[HCTR][02:24:55.328][ERROR][RK0][main]: replica 4 calling init per replica
[HCTR][02:24:55.328][ERROR][RK0][main]: replica 2 calling init per replica
[HCTR][02:24:55.328][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][02:24:55.328][ERROR][RK0][main]: replica 7 calling init per replica
[HCTR][02:24:55.328][ERROR][RK0][tid #140010456065792]: replica 5 calling init per replica
[HCTR][02:24:55.328][ERROR][RK0][tid #140010187630336]: replica 1 calling init per replica
[HCTR][02:24:55.328][ERROR][RK0][tid #140009919194880]: replica 6 calling init per replica
[HCTR][02:24:55.328][ERROR][RK0][tid #140010858718976]: Calling build_v2
[HCTR][02:24:55.328][ERROR][RK0][main]: Calling build_v2
[HCTR][02:24:55.328][ERROR][RK0][main]: Calling build_v2
[HCTR][02:24:55.328][ERROR][RK0][main]: Calling build_v2
[HCTR][02:24:55.328][ERROR][RK0][main]: Calling build_v2
[HCTR][02:24:55.328][ERROR][RK0][tid #140010456065792]: Calling build_v2
[HCTR][02:24:55.328][ERROR][RK0][tid #140010187630336]: Calling build_v2
[HCTR][02:24:55.328][ERROR][RK0][tid #140010858718976]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][02:24:55.328][ERROR][RK0][tid #140010456065792]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][02:24:55.328][ERROR][RK0][tid #140009919194880]: Calling build_v2
[HCTR][02:24:55.328][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][02:24:55.328][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][02:24:55.328][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][02:24:55.328][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][02:24:55.328][ERROR][RK0][tid #140010187630336]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][02:24:55.328][ERROR][RK0][tid #140009919194880]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[2022-12-12 02:24:55.332266: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[[2022-12-12 02:24:55.332344: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:2022-12-12 02:24:55196.[] 332323assigning 0 to cpu: 
2022-12-12 02:24:55E. 332369/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: :E[178 [] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 02:24:552022-12-12 02:24:55v100x8, slow pcie:..[
178332420332453] : 2022-12-12 02:24:55[: v100x8, slow pcieE[.2022-12-12 02:24:55E
 332468. 2022-12-12 02:24:55/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: 332513/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[.:[E: :2022-12-12 02:24:552022-12-12 02:24:55332514178 E212..: ] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc ] 332565332560Ev100x8, slow pcie:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8: :  
178:
2022-12-12 02:24:55EE/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 196[.  :v100x8, slow pcie] [2022-12-12 02:24:55332604/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc178
assigning 0 to cpu2022-12-12 02:24:55.: ::] 
.[332687E196178v100x8, slow pcie3327072022-12-12 02:24:55:  ] ] 
: .E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccassigning 0 to cpuv100x8, slow pcie[E332755[ :

2022-12-12 02:24:55 : 2022-12-12 02:24:55/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc178./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[E.:] 332826:2022-12-12 02:24:55 332830196v100x8, slow pcie: [213./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: ] 
E2022-12-12 02:24:55] [332876:Eassigning 0 to cpu .remote time is 8.684212022-12-12 02:24:55: 196 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc332916
.E] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:: 332968 [assigning 0 to cpu:212E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 02:24:55
[196]  E:.2022-12-12 02:24:55] build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc 196333019.assigning 0 to cpu
:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] : [333045
212:assigning 0 to cpuE[2022-12-12 02:24:55: ] 196
 2022-12-12 02:24:55.Ebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.333112 
assigning 0 to cpu2022-12-12 02:24:55:333137: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
.[214[: E:3331792022-12-12 02:24:55] 2022-12-12 02:24:55E 212: .cpu time is 97.0588. /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] E333228
[333231/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8 : 2022-12-12 02:24:55: :212
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE.E213] : 333290 [] build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8212/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 02:24:55remote time is 8.68421
] :E:[.
build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8212 2132022-12-12 02:24:55333360
] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] .: build asymm link desc with 8X Tesla V100-SXM2-32GB out of 82022-12-12 02:24:55:remote time is 8.68421[333415E
.212
2022-12-12 02:24:55:  333432] [.E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[: build asymm link desc with 8X Tesla V100-SXM2-32GB out of 82022-12-12 02:24:55333456 :2022-12-12 02:24:55E
.: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc213. 333494E:] [333500/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:  213remote time is 8.684212022-12-12 02:24:55: :E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 
.E214 :remote time is 8.68421333576 [] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc213
: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 02:24:55cpu time is 97.0588:] E[:.
213remote time is 8.68421 2022-12-12 02:24:55214333637] 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.[] : remote time is 8.68421:3336732022-12-12 02:24:55cpu time is 97.0588E
213: [.
 ] E2022-12-12 02:24:55333737/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421 .: :
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc333780E214::  [] 214E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 02:24:55cpu time is 97.0588]  :.
cpu time is 97.0588/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc214333834
:] : 214cpu time is 97.0588E] 
 cpu time is 97.0588/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
:214] cpu time is 97.0588
[2022-12-12 02:26:14.412536: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-12 02:26:14.452535: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-12 02:26:14.452607: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 10000000
[2022-12-12 02:26:14.584060: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-12 02:26:14.584152: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-12 02:26:14.603086: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-12 02:26:14.603120: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-12 02:26:14.604466: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.605449: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.606309: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.618299: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 2 solved
[2022-12-12 02:26:14.618361: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 2 initing device 2
[2022-12-12 02:26:14.618486: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 4 solved
[2022-12-12 02:26:14.618543: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 4 initing device 4
[2022-12-12 02:26:14.[6186832022-12-12 02:26:14: .E618699 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.ccE: 202/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc] :[2025 solved2022-12-12 02:26:14] 
.6 solved618751
: [E2022-12-12 02:26:14 [./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 02:26:14618775:.: 1980618784E] :  eager alloc mem 381.47 MBE/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc
 :/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc205:] 205worker 0 thread 5 initing device 5] 
worker 0 thread 6 initing device 6
[2022-12-12 02:26:14.618932: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14[.2022-12-12 02:26:14619217.: 619224E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980:] 1980eager alloc mem 381.47 MB] 
eager alloc mem 381.47 MB
[2022-12-12 02:26:14.621634: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.621738: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.621796: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.621847: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.622650: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 3 solved
[2022-12-12 02:26:14.622738: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 3 initing device 3
[2022-12-12 02:26:14.623213: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.624947: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.624999: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.625107: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.625246: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.626685: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[[2022-12-12 02:26:142022-12-12 02:26:14..628253628253: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::202202] ] 7 solved1 solved

[[2022-12-12 02:26:142022-12-12 02:26:14..628329628329: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::205205] ] worker 0 thread 7 initing device 7worker 0 thread 1 initing device 1

[2022-12-12 02:26:14.628676: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[[2022-12-12 02:26:142022-12-12 02:26:14..628841628841: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 381.47 MBeager alloc mem 381.47 MB

[2022-12-12 02:26:14.631153: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.631215: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.632725: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.632779: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 02:26:14.684515: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 02:26:14.684913: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 02:26:14.690540: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 02:26:14.690641: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 02:26:14.690690: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 02:26:14.691548: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 38.53 MB
[2022-12-12 02:26:14.692140: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:14.693190: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:14.693292: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 02:26:14.693962: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 02:26:14.694002: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 4.77 GB
[2022-12-12 02:26:14[[[.[2022-12-12 02:26:142022-12-12 02:26:142022-12-12 02:26:147080202022-12-12 02:26:14...: .708060708054708054E708063: : :  : EEE/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE   : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:::] :198019801980eager alloc mem 2.00 Bytes1980
] ] ] ] eager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes



[2022-12-12 02:26:14.[[7084752022-12-12 02:26:14[2022-12-12 02:26:14[: .2022-12-12 02:26:14.2022-12-12 02:26:14E708480.708480. : 708486: 708488/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: E: : E E1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu ] :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 1024.00 Bytes1980:1980:
] 1980] 1980eager alloc mem 1024.00 Bytes] eager alloc mem 1024.00 Bytes] 
eager alloc mem 1024.00 Bytes
eager alloc mem 1024.00 Bytes

[2022-12-12 02:26:14.715125: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 02:26:14.715216: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 02:26:14eager release cuda mem 2.
715224: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 02:26:14.715279: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000[
[2022-12-12 02:26:142022-12-12 02:26:14..715288715301: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 2eager release cuda mem 1024

[2022-12-12 02:26:14[.2022-12-12 02:26:14715353[.: 2022-12-12 02:26:14715375E.:  715380E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:  :E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638 :] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638eager release cuda mem 1024:] 
638eager release cuda mem 400000000] 
eager release cuda mem 2
[2022-12-12 02:26:14.715462[: 2022-12-12 02:26:14E. 715469/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 2:
638] eager release cuda mem 400000000
[[2022-12-12 02:26:142022-12-12 02:26:14..715524715512: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 400000000eager release cuda mem 1024

[2022-12-12 02:26:14.715600: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 02:26:14.715651: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 02:26:14.716953: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 38.53 MB
[2022-12-12 02:26:14.717459: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 38.53 MB
[2022-12-12 02:26:14.717963: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 38.53 MB
[2022-12-12 02:26:14.718471: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 38.53 MB
[2022-12-12 02:26:14.718984: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 38.53 MB
[2022-12-12 02:26:14.720305: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:14.720343: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:14.720396: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:14.720471: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:14.720543: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:14.721302: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:14.721343: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:14.[7213872022-12-12 02:26:14: .E721390 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager alloc mem 25.25 KB638
[] 2022-12-12 02:26:14eager release cuda mem 625663.
721428: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 25.25 KB2022-12-12 02:26:14
.721456: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:14.721499: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[[2022-12-12 02:26:142022-12-12 02:26:14..721541721539: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::1980638] ] eager alloc mem 25.25 KBeager release cuda mem 625663

[2022-12-12 02:26:14.721648: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 02:26:14.722077: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 02:26:14.722109[: 2022-12-12 02:26:14E. 722117/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 25855:
1980] eager alloc mem 4.77 GB
[2022-12-12 02:26:14.[7221652022-12-12 02:26:14: .E722170 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager alloc mem 4.77 GB638
] eager release cuda mem 25855
[[2022-12-12 02:26:142022-12-12 02:26:14..722237722238: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::1980638] ] eager alloc mem 4.77 GBeager release cuda mem 25855

[2022-12-12 02:26:14.722301: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 02:26:14eager alloc mem 4.77 GB.
722316: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 02:26:14.722363: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 4.77 GB
[2022-12-12 02:26:14.743925: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 02:26:14.744018: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 02:26:14.744268: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 02:26:14.744334: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 02:26:14.758317: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 02:26:14.[7584012022-12-12 02:26:14: .E758402 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 2638
] eager release cuda mem 1024
[2022-12-12 02:26:14.[7584732022-12-12 02:26:14: .E758478 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 400000000638
] eager release cuda mem 2
[2022-12-12 02:26:14.758544: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 02:26:14.759498: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 38.53 MB
[2022-12-12 02:26:14.760076: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 38.53 MB
[2022-12-12 02:26:14.760838: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:14.760930: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:14.761881: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:14.761916: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:14.762013: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 02:26:141980.] 762030eager alloc mem 25.25 KB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 02:26:14.762734: [E2022-12-12 02:26:14 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc762748:: 638E]  eager release cuda mem 25855/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 25855
[2022-12-12 02:26:14.762804[: 2022-12-12 02:26:14E. 762812/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: :E1980 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 4.77 GB:
1980] eager alloc mem 4.77 GB
[[[[[[[2022-12-12 02:26:152022-12-12 02:26:15[2022-12-12 02:26:152022-12-12 02:26:152022-12-12 02:26:152022-12-12 02:26:152022-12-12 02:26:15..2022-12-12 02:26:15...688297..688293688293.688294688293: 688287688301: : 688316: : E: : EE: EE EE  E  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::1980::19801980:19801980] 19801980] ] 1980] ] eager alloc mem 611.00 KB] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KB] eager alloc mem 611.00 KBeager alloc mem 611.00 KB
eager alloc mem 611.00 KBeager alloc mem 611.00 KB

eager alloc mem 611.00 KB




[2022-12-12 02:26:15[.[2022-12-12 02:26:15[689398[2022-12-12 02:26:15.[2022-12-12 02:26:15[: 2022-12-12 02:26:15.689403[2022-12-12 02:26:15.2022-12-12 02:26:15E.689405: 2022-12-12 02:26:15.689408. 689410: E.689413: 689415/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: E 689424: E: :E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: E E638 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663:638] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638:
638] eager release cuda mem 625663:638] 638] eager release cuda mem 625663
638] eager release cuda mem 625663] eager release cuda mem 625663
] eager release cuda mem 625663
eager release cuda mem 625663
eager release cuda mem 625663

[
2022-12-12 02:26:15.689668: E[ 2022-12-12 02:26:15/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.:6896931980: ] [Eeager alloc mem 611.00 KB[2022-12-12 02:26:15 
2022-12-12 02:26:15.[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.6897082022-12-12 02:26:15[[:689712: [.2022-12-12 02:26:152022-12-12 02:26:151980: E2022-12-12 02:26:15689724..] E .: 689730689732eager alloc mem 611.00 KB /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu689739E: : 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::  EE:1980E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu  1980]  :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980::eager alloc mem 611.00 KB
:] 19801980
1980eager alloc mem 611.00 KB] ] ] 
eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB


[2022-12-12 02:26:15.690455: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.690525: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.690560: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.690622: [E2022-12-12 02:26:15 .[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc6906322022-12-12 02:26:15:: .638E690639] [ : eager release cuda mem 6256632022-12-12 02:26:15/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE
[.[:[ 2022-12-12 02:26:156906592022-12-12 02:26:1519802022-12-12 02:26:15/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.: .] .:690678E690672eager alloc mem 611.00 KB[690677638:  : 
2022-12-12 02:26:15: ] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE.Eeager release cuda mem 625663 : 690727 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:] :E:638eager release cuda mem 625663638 638] 
] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] eager release cuda mem 625663[eager release cuda mem 625663:eager release cuda mem 625663
2022-12-12 02:26:15
1980
.] 690849eager alloc mem 611.00 KB: 
[E2022-12-12 02:26:15 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu690897:: 1980E]  eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[
:2022-12-12 02:26:15[[1980.2022-12-12 02:26:152022-12-12 02:26:15] 690923..eager alloc mem 611.00 KB: 690934690930
E: :  EE/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu  :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980::] 19801980eager alloc mem 611.00 KB] ] 
eager alloc mem 611.00 KBeager alloc mem 611.00 KB

[2022-12-12 02:26:15.691276: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.691349: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.691493: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.691564: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.691627: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.691662: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15[.2022-12-12 02:26:15691708.: 691711E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu [:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 02:26:151980:.] 638691734eager alloc mem 611.00 KB] : 
eager release cuda mem 625663E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.691798[: 2022-12-12 02:26:15[E[.2022-12-12 02:26:15 2022-12-12 02:26:15691807./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.: 691810:691814E: 638:  E] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc eager release cuda mem 625663 :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638::] 6381980eager release cuda mem 625663] ] 
eager release cuda mem 625663eager alloc mem 611.00 KB

[2022-12-12 02:26:15.691961: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.691997: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 02:26:15:.1980692008] : eager alloc mem 611.00 KBE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.692096: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.692164: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.692315: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.692384: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.692492: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 02:26:15] .eager release cuda mem 625663692508
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.692568: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:[19802022-12-12 02:26:15] .eager alloc mem 611.00 KB692584
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.692692: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663[
2022-12-12 02:26:15.692715: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15[.2022-12-12 02:26:15692776[.: 2022-12-12 02:26:15[692781E.2022-12-12 02:26:15:  692787.E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: 692792 :E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc1980 E:] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 638eager alloc mem 611.00 KB:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] 
1980:eager release cuda mem 625663] 638
eager alloc mem 611.00 KB] [
eager release cuda mem 6256632022-12-12 02:26:15
.692918: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.692964: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.692987: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 02:26:15eager alloc mem 611.00 KB.
693007: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.693135: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.693206: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.693327: E[ 2022-12-12 02:26:15/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:693339638: ] Eeager release cuda mem 625663 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.693409: [E2022-12-12 02:26:15 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu693418:: 1980E]  eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.693627: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.693658: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.693695: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 611.00 KB2022-12-12 02:26:15
.693714[: 2022-12-12 02:26:15E. 693725/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 625663[:
2022-12-12 02:26:151980[.] 2022-12-12 02:26:15693753eager alloc mem 611.00 KB.: 
693770E[:  2022-12-12 02:26:15E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc. :693812/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638: :] E638eager release cuda mem 625663 ] 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 625663:
1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.693935[: 2022-12-12 02:26:15E. 693943[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: 2022-12-12 02:26:15:E.1980 693960] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: eager alloc mem 611.00 KB:E
1980 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager alloc mem 611.00 KB:
638] eager release cuda mem 625663
[2022-12-12 02:26:15.694091: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15[.2022-12-12 02:26:15694177.: 694181E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 625663] 
eager release cuda mem 625663
[[2022-12-12 02:26:152022-12-12 02:26:15..694266694268: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KB

[2022-12-12 02:26:15.694451: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.694518: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 611.00 KB2022-12-12 02:26:15
.694536: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.694606: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.694635: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.694701: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 02:26:15.694752: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 02:26:15638.] 694766eager release cuda mem 625663: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.694830: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 02:26:15[:.2022-12-12 02:26:15638694839.] : 694844eager release cuda mem 40400000E: 
 E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638:] 1980eager release cuda mem 625663] 
eager alloc mem 611.00 KB
[2022-12-12 02:26:15.694957: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 40400000
[2022-12-12 02:26:15.[6950352022-12-12 02:26:15: .E695040 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 625663638
] eager release cuda mem 625663
[2022-12-12 02:26:15.[6950902022-12-12 02:26:15: .E695096 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 40400000638
] eager release cuda mem 40400000
[2022-12-12 02:26:15.695272: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.695310: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 40400000
[2022-12-12 02:26:15.695355: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.695394: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 40400000
[2022-12-12 02:26:15.695449: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.695486: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 40400000
[2022-12-12 02:26:15.695677: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 02:26:15.695717: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 40400000
[2022-12-12 02:26:15.695853: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 10000000 / 100000000 nodes ( 10.00 %~10.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 90000000 / 100000000 nodes ( 90.00 %) | 4.77 GB | 1.06702 secs 
[2022-12-12 02:26:15.695970: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 10000000 / 100000000 nodes ( 10.00 %~10.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 90000000 / 100000000 nodes ( 90.00 %) | 4.77 GB | 1.07675 secs 
[2022-12-12 02:26:15.696614: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 10000000 / 100000000 nodes ( 10.00 %~10.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 90000000 / 100000000 nodes ( 90.00 %) | 4.77 GB | 1.07787 secs 
[2022-12-12 02:26:15.696730: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 10000000 / 100000000 nodes ( 10.00 %~10.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 90000000 / 100000000 nodes ( 90.00 %) | 4.77 GB | 1.07353 secs 
[2022-12-12 02:26:15.697471: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 10000000 / 100000000 nodes ( 10.00 %~10.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 90000000 / 100000000 nodes ( 90.00 %) | 4.77 GB | 1.06864 secs 
[2022-12-12 02:26:15.697910: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 10000000 / 100000000 nodes ( 10.00 %~10.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 90000000 / 100000000 nodes ( 90.00 %) | 4.77 GB | 1.09345 secs 
[2022-12-12 02:26:15.698343: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 10000000 / 100000000 nodes ( 10.00 %~10.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 90000000 / 100000000 nodes ( 90.00 %) | 4.77 GB | 1.07913 secs 
[2022-12-12 02:26:15.698792: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 10000000 / 100000000 nodes ( 10.00 %~10.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 90000000 / 100000000 nodes ( 90.00 %) | 4.77 GB | 1.07987 secs 
[HCTR][02:26:15.698][ERROR][RK0][tid #140010456065792]: replica 5 calling init per replica done, doing barrier
[HCTR][02:26:15.698][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier
[HCTR][02:26:15.698][ERROR][RK0][tid #140010858718976]: replica 0 calling init per replica done, doing barrier
[HCTR][02:26:15.698][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier
[HCTR][02:26:15.698][ERROR][RK0][tid #140010187630336]: replica 1 calling init per replica done, doing barrier
[HCTR][02:26:15.698][ERROR][RK0][tid #140009919194880]: replica 6 calling init per replica done, doing barrier
[HCTR][02:26:15.698][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][02:26:15.698][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier
[HCTR][02:26:15.698][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier done
[HCTR][02:26:15.698][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier done
[HCTR][02:26:15.698][ERROR][RK0][tid #140009919194880]: replica 6 calling init per replica done, doing barrier done
[HCTR][02:26:15.698][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][02:26:15.698][ERROR][RK0][tid #140010456065792]: replica 5 calling init per replica done, doing barrier done
[HCTR][02:26:15.698][ERROR][RK0][tid #140010187630336]: replica 1 calling init per replica done, doing barrier done
[HCTR][02:26:15.698][ERROR][RK0][tid #140010858718976]: replica 0 calling init per replica done, doing barrier done
[HCTR][02:26:15.698][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier done
[HCTR][02:26:15.699][ERROR][RK0][main]: init per replica done
[HCTR][02:26:15.699][ERROR][RK0][tid #140010456065792]: init per replica done
[HCTR][02:26:15.699][ERROR][RK0][tid #140010187630336]: init per replica done
[HCTR][02:26:15.699][ERROR][RK0][main]: init per replica done
[HCTR][02:26:15.699][ERROR][RK0][tid #140009919194880]: init per replica done
[HCTR][02:26:15.699][ERROR][RK0][main]: init per replica done
[HCTR][02:26:15.699][ERROR][RK0][main]: init per replica done
[HCTR][02:26:15.701][ERROR][RK0][tid #140010858718976]: init per replica done








