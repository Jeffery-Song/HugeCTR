2022-12-11 19:20:46.055861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.065289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.071744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.075859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.083219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.095104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.102694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.106752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.156877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.167391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.175178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.184814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.187922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.188532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.190367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.190369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.191763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.191880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.193193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.193394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.194712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.195212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.196439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.197361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.197958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.198886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.199337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.200407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.200872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.202162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.203119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.204141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.205878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.207004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.207926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.208843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.209773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.210692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.211619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.212657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.217458: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:20:46.221711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.223688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.224321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.225459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.226437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.226573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.228336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.228928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.229134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.229664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.231735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.232484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.232634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.232897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.233081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.235429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.236594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.236918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.237040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.237298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.238880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.240320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.240647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.240822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.241248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.242620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.244064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.244372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.244534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.245091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.247234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.247728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.248037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.248219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.248816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.250723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.250861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.251473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.251783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.252549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.253891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.254425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.254822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.255090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.255784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.256858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.257674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.258327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.258796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.259544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.260413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.261351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.261743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.262534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.263549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.277108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.278866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.279509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.280140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.280891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.281759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.290882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.296749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.301971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.305375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.307606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.317504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.318358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.318733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.318778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.318873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.318904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.322153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.322703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.322901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.322979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.323035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.323075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.326670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.328010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.328153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.328252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.328308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.328344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.331407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.331912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.332118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.332165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.332360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.332401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.335531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.336152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.336267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.336432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.336478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.336613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.340064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.340529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.340669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.340830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.340926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.340965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.344799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.345042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.345145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.345174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.345222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.345272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.348457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.348924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.349073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.349104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.349156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.349253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.352394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.352789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.352971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.352992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.353041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.353135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.357194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.357986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.358150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.358244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.358308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.358372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.359828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.362325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.362823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.363064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.363067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.363173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.363321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.364704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.367374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.367929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.368185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.368228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.368278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.368390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.369740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.371905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.372584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.372858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.372888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.373027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.373122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.374302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.376550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.377445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.377732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.377790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.378008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.378062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.379474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.381408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.382109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.382491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.382534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.382685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.383926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.386710: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:20:46.387413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.388121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.388304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.388315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.388393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.388903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.391431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.392305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.392344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.392395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.392617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.392932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.395748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.396116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.396969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.397211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.397280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.397751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.397745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.400491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.400769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.401556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.401711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.401811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.402152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.402430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.405063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.405944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.406960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.407002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.407304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.407612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.408397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.411367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.412205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.412242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.412522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.412640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.413443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.416212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.416801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.416874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.417095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.417108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.418284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.421022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.421394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.421937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.421970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.422096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.423233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.426790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.429965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.430119: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:20:46.430682: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:20:46.430683: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:20:46.430683: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:20:46.431712: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:20:46.432543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.434683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.436948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.439528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.439571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.440256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.440424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.440454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.441076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.444368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.444573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.445683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.445721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.445886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.446755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.448807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.448908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.450445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.450580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.450672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.451595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.517431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.522476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.533226: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:20:46.541954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.547088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:46.553156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.549087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.549886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.550585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.551315: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:20:47.551370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-11 19:20:47.569581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.570236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.571098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.571700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.572221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.572694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-11 19:20:47.617244: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.617442: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.643806: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-11 19:20:47.783527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.786195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.787092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.787590: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:20:47.787646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-11 19:20:47.805604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.806422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.807447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.808481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.809018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.809494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-11 19:20:47.873346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.873962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.874494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.874968: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:20:47.875022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-11 19:20:47.885068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.885699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.886228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.886717: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:20:47.886774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-11 19:20:47.887534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.888104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.888634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.889102: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:20:47.889145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-11 19:20:47.892891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.893531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.894038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.895037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.895589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.896058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-11 19:20:47.897505: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.897695: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.897698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.898321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.898940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.899492: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-11 19:20:47.899978: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:20:47.900047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-11 19:20:47.900686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.901283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.901800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.902277: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:20:47.902330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-11 19:20:47.904789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.905404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.905908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.906477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.906870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.906995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.908133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-11 19:20:47.908189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.908745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.909332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.909851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.910333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-11 19:20:47.917370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.918017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.918541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.919117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.919728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.920216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-11 19:20:47.920797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.921395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.921896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.922462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.922968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.923453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-11 19:20:47.932504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.933092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.933626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.934096: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:20:47.934147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-11 19:20:47.951635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.952258: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.952318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.952453: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.952832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.953423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.953958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:20:47.954253: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-11 19:20:47.954435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-11 19:20:47.955349: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.955485: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.957372: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-11 19:20:47.964340: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.964507: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.966593: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-11 19:20:47.967803: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.967957: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.971830: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-11 19:20:47.992110: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.992305: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.994112: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
2022-12-11 19:20:47.999760: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:47.999908: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:20:48.001649: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
[HCTR][19:20:49.263][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:20:49.263][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:20:49.263][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:20:49.263][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:20:49.263][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:20:49.263][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:20:49.288][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:20:49.288][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:00,  2.65it/s]warmup run: 1it [00:00,  2.59it/s]warmup run: 1it [00:00,  2.58it/s]warmup run: 1it [00:00,  2.59it/s]warmup run: 1it [00:00,  2.39it/s]warmup run: 61it [00:00, 166.85it/s]warmup run: 70it [00:00, 187.35it/s]warmup run: 65it [00:00, 174.07it/s]warmup run: 62it [00:00, 165.60it/s]warmup run: 64it [00:00, 161.55it/s]warmup run: 109it [00:00, 254.69it/s]warmup run: 109it [00:00, 249.62it/s]warmup run: 127it [00:00, 292.33it/s]warmup run: 119it [00:00, 274.66it/s]warmup run: 118it [00:00, 261.00it/s]warmup run: 161it [00:00, 329.76it/s]warmup run: 157it [00:00, 314.37it/s]warmup run: 184it [00:00, 370.30it/s]warmup run: 173it [00:00, 348.55it/s]warmup run: 173it [00:00, 339.00it/s]warmup run: 212it [00:00, 381.42it/s]warmup run: 206it [00:00, 363.83it/s]warmup run: 241it [00:00, 426.82it/s]warmup run: 223it [00:00, 390.45it/s]warmup run: 229it [00:00, 399.45it/s]warmup run: 262it [00:00, 415.19it/s]warmup run: 297it [00:00, 464.71it/s]warmup run: 255it [00:00, 398.99it/s]warmup run: 272it [00:00, 418.32it/s]warmup run: 283it [00:00, 439.46it/s]warmup run: 314it [00:00, 444.46it/s]warmup run: 354it [00:00, 494.61it/s]warmup run: 305it [00:00, 428.09it/s]warmup run: 322it [00:00, 440.00it/s]warmup run: 335it [00:01, 458.81it/s]warmup run: 372it [00:01, 482.92it/s]warmup run: 411it [00:01, 515.33it/s]warmup run: 358it [00:01, 456.35it/s]warmup run: 374it [00:01, 462.59it/s]warmup run: 388it [00:01, 479.36it/s]warmup run: 429it [00:01, 508.62it/s]warmup run: 409it [00:01, 471.30it/s]warmup run: 467it [00:01, 521.00it/s]warmup run: 424it [00:01, 464.03it/s]warmup run: 442it [00:01, 494.58it/s]warmup run: 486it [00:01, 525.01it/s]warmup run: 460it [00:01, 481.94it/s]warmup run: 522it [00:01, 524.19it/s]warmup run: 473it [00:01, 455.31it/s]warmup run: 495it [00:01, 504.54it/s]warmup run: 1it [00:01,  1.38s/it]warmup run: 1it [00:01,  1.38s/it]warmup run: 544it [00:01, 538.72it/s]warmup run: 513it [00:01, 494.57it/s]warmup run: 578it [00:01, 532.16it/s]warmup run: 521it [00:01, 452.90it/s]warmup run: 1it [00:01,  1.42s/it]warmup run: 548it [00:01, 511.68it/s]warmup run: 100it [00:01, 93.46it/s]warmup run: 91it [00:01, 84.85it/s]warmup run: 600it [00:01, 542.84it/s]warmup run: 568it [00:01, 508.51it/s]warmup run: 633it [00:01, 535.28it/s]warmup run: 569it [00:01, 458.15it/s]warmup run: 94it [00:01, 85.70it/s]warmup run: 601it [00:01, 515.92it/s]warmup run: 199it [00:01, 199.22it/s]warmup run: 182it [00:01, 182.01it/s]warmup run: 656it [00:01, 545.77it/s]warmup run: 623it [00:01, 518.24it/s]warmup run: 688it [00:01, 533.31it/s]warmup run: 617it [00:01, 461.75it/s]warmup run: 186it [00:01, 182.04it/s]warmup run: 654it [00:01, 518.50it/s]warmup run: 298it [00:01, 313.18it/s]warmup run: 272it [00:01, 285.18it/s]warmup run: 712it [00:01, 542.98it/s]warmup run: 679it [00:01, 530.57it/s]warmup run: 742it [00:01, 532.37it/s]warmup run: 665it [00:01, 465.27it/s]warmup run: 279it [00:01, 287.73it/s]warmup run: 707it [00:01, 516.46it/s]warmup run: 396it [00:01, 426.83it/s]warmup run: 361it [00:01, 388.10it/s]warmup run: 736it [00:01, 539.68it/s]warmup run: 767it [00:01, 528.71it/s]warmup run: 796it [00:01, 530.42it/s]warmup run: 374it [00:01, 398.53it/s]warmup run: 715it [00:01, 473.56it/s]warmup run: 761it [00:01, 521.10it/s]warmup run: 493it [00:01, 533.16it/s]warmup run: 446it [00:01, 477.58it/s]warmup run: 792it [00:01, 545.00it/s]warmup run: 821it [00:01, 519.48it/s]warmup run: 850it [00:01, 533.17it/s]warmup run: 469it [00:01, 504.64it/s]warmup run: 764it [00:01, 476.95it/s]warmup run: 816it [00:01, 527.79it/s]warmup run: 593it [00:01, 634.12it/s]warmup run: 534it [00:01, 564.80it/s]warmup run: 849it [00:02, 551.33it/s]warmup run: 907it [00:02, 541.35it/s]warmup run: 874it [00:02, 507.51it/s]warmup run: 559it [00:02, 589.16it/s]warmup run: 814it [00:02, 482.99it/s]warmup run: 874it [00:02, 541.79it/s]warmup run: 693it [00:02, 720.53it/s]warmup run: 629it [00:02, 655.38it/s]warmup run: 905it [00:02, 545.68it/s]warmup run: 931it [00:02, 523.66it/s]warmup run: 962it [00:02, 524.87it/s]warmup run: 650it [00:02, 664.29it/s]warmup run: 863it [00:02, 484.13it/s]warmup run: 932it [00:02, 550.14it/s]warmup run: 793it [00:02, 789.87it/s]warmup run: 721it [00:02, 721.01it/s]warmup run: 960it [00:02, 546.08it/s]warmup run: 988it [00:02, 536.39it/s]warmup run: 741it [00:02, 724.94it/s]warmup run: 916it [00:02, 497.25it/s]warmup run: 1015it [00:02, 515.47it/s]warmup run: 990it [00:02, 556.66it/s]warmup run: 891it [00:02, 835.36it/s]warmup run: 810it [00:02, 756.78it/s]warmup run: 1015it [00:02, 545.87it/s]warmup run: 1043it [00:02, 539.80it/s]warmup run: 970it [00:02, 509.61it/s]warmup run: 833it [00:02, 773.91it/s]warmup run: 1067it [00:02, 511.52it/s]warmup run: 1048it [00:02, 560.81it/s]warmup run: 993it [00:02, 883.89it/s]warmup run: 898it [00:02, 789.75it/s]warmup run: 1070it [00:02, 541.47it/s]warmup run: 1024it [00:02, 517.50it/s]warmup run: 1098it [00:02, 523.14it/s]warmup run: 923it [00:02, 786.76it/s]warmup run: 1119it [00:02, 503.95it/s]warmup run: 1106it [00:02, 565.61it/s]warmup run: 989it [00:02, 822.14it/s]warmup run: 1092it [00:02, 891.59it/s]warmup run: 1125it [00:02, 539.72it/s]warmup run: 1076it [00:02, 511.33it/s]warmup run: 1151it [00:02, 519.31it/s]warmup run: 1011it [00:02, 802.68it/s]warmup run: 1170it [00:02, 497.63it/s]warmup run: 1163it [00:02, 560.72it/s]warmup run: 1083it [00:02, 854.22it/s]warmup run: 1188it [00:02, 899.33it/s]warmup run: 1181it [00:02, 543.03it/s]warmup run: 1207it [00:02, 530.84it/s]warmup run: 1128it [00:02, 508.87it/s]warmup run: 1111it [00:02, 855.36it/s]warmup run: 1224it [00:02, 508.96it/s]warmup run: 1220it [00:02, 550.79it/s]warmup run: 1174it [00:02, 868.06it/s]warmup run: 1289it [00:02, 930.21it/s]warmup run: 1236it [00:02, 541.66it/s]warmup run: 1263it [00:02, 538.39it/s]warmup run: 1180it [00:02, 510.89it/s]warmup run: 1209it [00:02, 888.45it/s]warmup run: 1282it [00:02, 528.69it/s]warmup run: 1276it [00:02, 530.86it/s]warmup run: 1266it [00:02, 881.33it/s]warmup run: 1390it [00:02, 948.90it/s]warmup run: 1291it [00:02, 540.61it/s]warmup run: 1320it [00:02, 546.48it/s]warmup run: 1232it [00:02, 513.34it/s]warmup run: 1340it [00:02, 540.94it/s]warmup run: 1302it [00:02, 868.20it/s]warmup run: 1330it [00:02, 520.77it/s]warmup run: 1349it [00:02, 550.34it/s]warmup run: 1377it [00:02, 552.80it/s]warmup run: 1284it [00:02, 506.56it/s]warmup run: 1397it [00:02, 549.35it/s]warmup run: 1488it [00:02, 797.18it/s]warmup run: 1357it [00:02, 686.55it/s]warmup run: 1383it [00:02, 500.44it/s]warmup run: 1406it [00:03, 555.40it/s]warmup run: 1392it [00:03, 735.76it/s]warmup run: 1433it [00:03, 542.77it/s]warmup run: 1335it [00:03, 500.36it/s]warmup run: 1455it [00:03, 556.53it/s]warmup run: 1434it [00:03, 491.66it/s]warmup run: 1574it [00:03, 721.23it/s]warmup run: 1462it [00:03, 549.99it/s]warmup run: 1490it [00:03, 549.61it/s]warmup run: 1386it [00:03, 498.90it/s]warmup run: 1513it [00:03, 562.82it/s]warmup run: 1434it [00:03, 612.44it/s]warmup run: 1471it [00:03, 669.56it/s]warmup run: 1484it [00:03, 483.09it/s]warmup run: 1518it [00:03, 544.61it/s]warmup run: 1546it [00:03, 545.25it/s]warmup run: 1570it [00:03, 564.75it/s]warmup run: 1652it [00:03, 671.43it/s]warmup run: 1436it [00:03, 484.02it/s]warmup run: 1502it [00:03, 567.46it/s]warmup run: 1543it [00:03, 631.45it/s]warmup run: 1533it [00:03, 473.16it/s]warmup run: 1574it [00:03, 546.94it/s]warmup run: 1601it [00:03, 546.35it/s]warmup run: 1627it [00:03, 564.51it/s]warmup run: 1485it [00:03, 476.04it/s]warmup run: 1723it [00:03, 635.34it/s]warmup run: 1581it [00:03, 473.36it/s]warmup run: 1630it [00:03, 549.67it/s]warmup run: 1564it [00:03, 542.77it/s]warmup run: 1610it [00:03, 600.85it/s]warmup run: 1657it [00:03, 547.80it/s]warmup run: 1684it [00:03, 564.95it/s]warmup run: 1533it [00:03, 476.64it/s]warmup run: 1789it [00:03, 601.95it/s]warmup run: 1631it [00:03, 479.97it/s]warmup run: 1685it [00:03, 529.42it/s]warmup run: 1622it [00:03, 532.44it/s]warmup run: 1742it [00:03, 566.86it/s]warmup run: 1712it [00:03, 540.70it/s]warmup run: 1673it [00:03, 566.63it/s]warmup run: 1582it [00:03, 479.71it/s]warmup run: 1686it [00:03, 499.75it/s]warmup run: 1851it [00:03, 578.93it/s]warmup run: 1739it [00:03, 513.05it/s]warmup run: 1800it [00:03, 567.87it/s]warmup run: 1769it [00:03, 548.89it/s]warmup run: 1678it [00:03, 524.49it/s]warmup run: 1633it [00:03, 488.23it/s]warmup run: 1732it [00:03, 541.35it/s]warmup run: 1737it [00:03, 502.01it/s]warmup run: 1910it [00:03, 562.01it/s]warmup run: 1858it [00:03, 569.97it/s]warmup run: 1824it [00:03, 546.22it/s]warmup run: 1791it [00:03, 507.59it/s]warmup run: 1732it [00:03, 519.07it/s]warmup run: 1682it [00:03, 488.15it/s]warmup run: 1787it [00:03, 526.01it/s]warmup run: 1792it [00:03, 515.02it/s]warmup run: 1967it [00:03, 549.57it/s]warmup run: 1916it [00:03, 569.14it/s]warmup run: 1881it [00:03, 550.25it/s]warmup run: 1842it [00:03, 501.41it/s]warmup run: 1785it [00:03, 515.98it/s]warmup run: 1731it [00:03, 484.24it/s]warmup run: 1841it [00:03, 511.23it/s]warmup run: 1850it [00:03, 532.51it/s]warmup run: 1974it [00:03, 570.11it/s]warmup run: 1939it [00:03, 558.11it/s]warmup run: 2023it [00:03, 539.34it/s]warmup run: 1899it [00:03, 518.75it/s]warmup run: 1838it [00:03, 512.44it/s]warmup run: 1780it [00:03, 480.55it/s]warmup run: 1893it [00:04, 503.53it/s]warmup run: 1907it [00:04, 542.08it/s]warmup run: 2003it [00:04, 581.12it/s]warmup run: 2032it [00:04, 569.11it/s]warmup run: 1956it [00:04, 533.32it/s]warmup run: 2078it [00:04, 534.85it/s]warmup run: 1894it [00:04, 523.77it/s]warmup run: 1834it [00:04, 497.56it/s]warmup run: 1944it [00:04, 500.15it/s]warmup run: 1964it [00:04, 548.30it/s]warmup run: 2063it [00:04, 586.44it/s]warmup run: 2089it [00:04, 568.07it/s]warmup run: 2012it [00:04, 538.33it/s]warmup run: 2133it [00:04, 537.52it/s]warmup run: 1949it [00:04, 530.58it/s]warmup run: 1889it [00:04, 512.89it/s]warmup run: 2021it [00:04, 552.31it/s]warmup run: 1995it [00:04, 488.03it/s]warmup run: 2146it [00:04, 562.41it/s]warmup run: 2067it [00:04, 541.51it/s]warmup run: 2191it [00:04, 547.80it/s]warmup run: 2122it [00:04, 568.53it/s]warmup run: 2004it [00:04, 534.35it/s]warmup run: 1947it [00:04, 530.78it/s]warmup run: 2079it [00:04, 558.06it/s]warmup run: 2044it [00:04, 477.66it/s]warmup run: 2204it [00:04, 567.59it/s]warmup run: 2122it [00:04, 542.94it/s]warmup run: 2248it [00:04, 552.65it/s]warmup run: 2002it [00:04, 534.26it/s]warmup run: 2058it [00:04, 530.14it/s]warmup run: 2179it [00:04, 539.16it/s]warmup run: 2136it [00:04, 560.91it/s]warmup run: 2092it [00:04, 475.87it/s]warmup run: 2177it [00:04, 544.61it/s]warmup run: 2261it [00:04, 562.74it/s]warmup run: 2305it [00:04, 555.18it/s]warmup run: 2114it [00:04, 538.33it/s]warmup run: 2057it [00:04, 535.75it/s]warmup run: 2234it [00:04, 524.96it/s]warmup run: 2194it [00:04, 563.75it/s]warmup run: 2140it [00:04, 475.39it/s]warmup run: 2234it [00:04, 550.05it/s]warmup run: 2363it [00:04, 561.82it/s]warmup run: 2318it [00:04, 547.80it/s]warmup run: 2168it [00:04, 536.92it/s]warmup run: 2111it [00:04, 535.28it/s]warmup run: 2287it [00:04, 520.05it/s]warmup run: 2252it [00:04, 565.85it/s]warmup run: 2188it [00:04, 472.57it/s]warmup run: 2291it [00:04, 553.97it/s]warmup run: 2421it [00:04, 565.56it/s]warmup run: 2166it [00:04, 538.64it/s]warmup run: 2373it [00:04, 537.32it/s]warmup run: 2222it [00:04, 528.00it/s]warmup run: 2340it [00:04, 518.90it/s]warmup run: 2310it [00:04, 567.44it/s]warmup run: 2240it [00:04, 485.38it/s]warmup run: 2348it [00:04, 558.64it/s]warmup run: 2478it [00:04, 563.92it/s]warmup run: 2220it [00:04, 535.58it/s]warmup run: 2430it [00:04, 544.13it/s]warmup run: 2275it [00:04, 517.72it/s]warmup run: 2394it [00:04, 523.65it/s]warmup run: 2368it [00:04, 570.27it/s]warmup run: 2295it [00:04, 503.40it/s]warmup run: 2405it [00:04, 561.08it/s]warmup run: 2536it [00:04, 565.73it/s]warmup run: 2274it [00:04, 528.44it/s]warmup run: 2487it [00:04, 549.06it/s]warmup run: 2327it [00:04, 497.74it/s]warmup run: 2448it [00:04, 527.52it/s]warmup run: 2426it [00:04, 567.32it/s]warmup run: 2348it [00:04, 510.64it/s]warmup run: 2462it [00:04, 562.51it/s]warmup run: 2593it [00:04, 560.68it/s]warmup run: 2542it [00:04, 547.32it/s]warmup run: 2327it [00:04, 523.26it/s]warmup run: 2501it [00:05, 525.49it/s]warmup run: 2377it [00:05, 492.00it/s]warmup run: 2483it [00:05, 567.35it/s]warmup run: 2402it [00:05, 517.17it/s]warmup run: 2520it [00:05, 564.89it/s]warmup run: 2598it [00:05, 549.66it/s]warmup run: 2383it [00:05, 532.63it/s]warmup run: 2650it [00:05, 533.06it/s]warmup run: 2427it [00:05, 489.70it/s]warmup run: 2554it [00:05, 510.25it/s]warmup run: 2540it [00:05, 556.51it/s]warmup run: 2457it [00:05, 525.52it/s]warmup run: 2577it [00:05, 563.29it/s]warmup run: 2438it [00:05, 535.78it/s]warmup run: 2478it [00:05, 494.02it/s]warmup run: 2606it [00:05, 508.90it/s]warmup run: 2513it [00:05, 533.65it/s]warmup run: 2596it [00:05, 542.28it/s]warmup run: 2634it [00:05, 559.08it/s]warmup run: 2492it [00:05, 533.78it/s]warmup run: 2530it [00:05, 500.08it/s]warmup run: 2567it [00:05, 533.69it/s]warmup run: 2653it [00:05, 359.99it/s]warmup run: 2704it [00:05, 350.59it/s]warmup run: 2546it [00:05, 528.16it/s]warmup run: 2583it [00:05, 507.83it/s]warmup run: 2621it [00:05, 525.51it/s]warmup run: 2705it [00:05, 394.52it/s]warmup run: 2761it [00:05, 395.85it/s]warmup run: 2599it [00:05, 526.93it/s]warmup run: 2657it [00:05, 328.16it/s]warmup run: 2636it [00:05, 512.88it/s]warmup run: 2674it [00:05, 525.10it/s]warmup run: 2651it [00:05, 340.52it/s]warmup run: 2761it [00:05, 432.96it/s]warmup run: 2690it [00:05, 356.67it/s]warmup run: 2813it [00:05, 424.50it/s]warmup run: 2715it [00:05, 380.20it/s]warmup run: 2701it [00:05, 372.98it/s]warmup run: 2745it [00:05, 397.48it/s]warmup run: 2818it [00:05, 465.48it/s]warmup run: 2865it [00:05, 447.84it/s]warmup run: 2772it [00:05, 423.64it/s]warmup run: 2751it [00:05, 401.23it/s]warmup run: 2801it [00:05, 433.50it/s]warmup run: 2876it [00:05, 493.48it/s]warmup run: 2915it [00:05, 457.94it/s]warmup run: 2688it [00:05, 324.70it/s]warmup run: 2830it [00:05, 460.71it/s]warmup run: 2652it [00:05, 308.31it/s]warmup run: 2801it [00:05, 423.85it/s]warmup run: 2727it [00:05, 324.81it/s]warmup run: 2857it [00:05, 462.88it/s]warmup run: 2934it [00:05, 515.20it/s]warmup run: 2970it [00:05, 481.71it/s]warmup run: 2738it [00:05, 361.48it/s]warmup run: 2888it [00:05, 489.77it/s]warmup run: 2704it [00:05, 349.45it/s]warmup run: 3000it [00:05, 503.67it/s]warmup run: 2851it [00:05, 443.17it/s]warmup run: 2773it [00:05, 351.40it/s]warmup run: 2991it [00:05, 530.02it/s]warmup run: 2910it [00:05, 479.31it/s]warmup run: 3000it [00:06, 499.47it/s]warmup run: 2789it [00:06, 394.36it/s]warmup run: 2945it [00:06, 509.17it/s]warmup run: 2752it [00:06, 377.68it/s]warmup run: 2902it [00:06, 460.85it/s]warmup run: 2824it [00:06, 386.00it/s]warmup run: 2963it [00:06, 492.08it/s]warmup run: 2847it [00:06, 438.88it/s]warmup run: 3000it [00:06, 489.09it/s]warmup run: 2804it [00:06, 411.53it/s]warmup run: 3000it [00:06, 486.68it/s]warmup run: 2955it [00:06, 478.54it/s]warmup run: 2878it [00:06, 423.15it/s]warmup run: 2904it [00:06, 471.20it/s]warmup run: 2858it [00:06, 442.11it/s]warmup run: 3000it [00:06, 479.26it/s]warmup run: 2931it [00:06, 450.55it/s]warmup run: 2961it [00:06, 497.10it/s]warmup run: 2911it [00:06, 464.61it/s]warmup run: 2986it [00:06, 476.54it/s]warmup run: 3000it [00:06, 468.39it/s]warmup run: 3000it [00:06, 468.19it/s]warmup run: 2968it [00:06, 491.24it/s]warmup run: 3000it [00:06, 460.06it/s]

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1659.24it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1669.20it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1658.97it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1647.14it/s]warmup should be done:   6%|         | 170/3000 [00:00<00:01, 1691.48it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1673.39it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1670.78it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1671.93it/s]warmup should be done:  11%|         | 336/3000 [00:00<00:01, 1682.17it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1657.30it/s]warmup should be done:  11%|         | 337/3000 [00:00<00:01, 1683.50it/s]warmup should be done:  11%|         | 331/3000 [00:00<00:01, 1651.49it/s]warmup should be done:  11%|         | 337/3000 [00:00<00:01, 1680.97it/s]warmup should be done:  11%|         | 337/3000 [00:00<00:01, 1680.45it/s]warmup should be done:  11%|         | 337/3000 [00:00<00:01, 1680.00it/s]warmup should be done:  11%|        | 340/3000 [00:00<00:01, 1689.29it/s]warmup should be done:  17%|        | 506/3000 [00:00<00:01, 1688.05it/s]warmup should be done:  17%|        | 500/3000 [00:00<00:01, 1664.69it/s]warmup should be done:  17%|        | 497/3000 [00:00<00:01, 1653.75it/s]warmup should be done:  17%|        | 506/3000 [00:00<00:01, 1683.59it/s]warmup should be done:  17%|        | 506/3000 [00:00<00:01, 1681.13it/s]warmup should be done:  17%|        | 506/3000 [00:00<00:01, 1678.59it/s]warmup should be done:  17%|        | 506/3000 [00:00<00:01, 1677.12it/s]warmup should be done:  17%|        | 509/3000 [00:00<00:01, 1672.19it/s]warmup should be done:  22%|       | 675/3000 [00:00<00:01, 1686.30it/s]warmup should be done:  22%|       | 667/3000 [00:00<00:01, 1665.09it/s]warmup should be done:  22%|       | 675/3000 [00:00<00:01, 1685.30it/s]warmup should be done:  22%|       | 663/3000 [00:00<00:01, 1654.02it/s]warmup should be done:  22%|       | 675/3000 [00:00<00:01, 1683.34it/s]warmup should be done:  22%|       | 675/3000 [00:00<00:01, 1680.22it/s]warmup should be done:  22%|       | 674/3000 [00:00<00:01, 1668.67it/s]warmup should be done:  23%|       | 677/3000 [00:00<00:01, 1637.30it/s]warmup should be done:  28%|       | 844/3000 [00:00<00:01, 1681.43it/s]warmup should be done:  28%|       | 829/3000 [00:00<00:01, 1649.50it/s]warmup should be done:  28%|       | 844/3000 [00:00<00:01, 1679.56it/s]warmup should be done:  28%|       | 834/3000 [00:00<00:01, 1658.35it/s]warmup should be done:  28%|       | 844/3000 [00:00<00:01, 1676.61it/s]warmup should be done:  28%|       | 844/3000 [00:00<00:01, 1677.58it/s]warmup should be done:  28%|       | 841/3000 [00:00<00:01, 1657.31it/s]warmup should be done:  28%|       | 841/3000 [00:00<00:01, 1631.25it/s]warmup should be done:  34%|      | 1013/3000 [00:00<00:01, 1679.71it/s]warmup should be done:  33%|      | 994/3000 [00:00<00:01, 1646.39it/s]warmup should be done:  34%|      | 1012/3000 [00:00<00:01, 1675.37it/s]warmup should be done:  33%|      | 1000/3000 [00:00<00:01, 1654.50it/s]warmup should be done:  34%|      | 1012/3000 [00:00<00:01, 1673.41it/s]warmup should be done:  34%|      | 1012/3000 [00:00<00:01, 1667.94it/s]warmup should be done:  34%|      | 1007/3000 [00:00<00:01, 1650.79it/s]warmup should be done:  34%|      | 1007/3000 [00:00<00:01, 1637.73it/s]warmup should be done:  39%|      | 1181/3000 [00:00<00:01, 1679.23it/s]warmup should be done:  39%|      | 1159/3000 [00:00<00:01, 1645.43it/s]warmup should be done:  39%|      | 1180/3000 [00:00<00:01, 1671.66it/s]warmup should be done:  39%|      | 1166/3000 [00:00<00:01, 1651.65it/s]warmup should be done:  39%|      | 1180/3000 [00:00<00:01, 1669.58it/s]warmup should be done:  39%|      | 1179/3000 [00:00<00:01, 1661.94it/s]warmup should be done:  39%|      | 1173/3000 [00:00<00:01, 1645.47it/s]warmup should be done:  39%|      | 1175/3000 [00:00<00:01, 1648.57it/s]warmup should be done:  44%|     | 1324/3000 [00:00<00:01, 1645.08it/s]warmup should be done:  45%|     | 1347/3000 [00:00<00:00, 1668.58it/s]warmup should be done:  44%|     | 1332/3000 [00:00<00:01, 1648.17it/s]warmup should be done:  45%|     | 1349/3000 [00:00<00:00, 1667.02it/s]warmup should be done:  45%|     | 1348/3000 [00:00<00:00, 1667.12it/s]warmup should be done:  45%|     | 1347/3000 [00:00<00:00, 1666.47it/s]warmup should be done:  45%|     | 1338/3000 [00:00<00:01, 1640.34it/s]warmup should be done:  45%|     | 1341/3000 [00:00<00:01, 1651.37it/s]warmup should be done:  50%|     | 1489/3000 [00:00<00:00, 1643.85it/s]warmup should be done:  50%|     | 1514/3000 [00:00<00:00, 1668.97it/s]warmup should be done:  50%|     | 1498/3000 [00:00<00:00, 1649.07it/s]warmup should be done:  51%|     | 1516/3000 [00:00<00:00, 1668.74it/s]warmup should be done:  51%|     | 1516/3000 [00:00<00:00, 1672.41it/s]warmup should be done:  51%|     | 1516/3000 [00:00<00:00, 1656.33it/s]warmup should be done:  50%|     | 1503/3000 [00:00<00:00, 1638.26it/s]warmup should be done:  50%|     | 1507/3000 [00:00<00:00, 1652.76it/s]warmup should be done:  56%|    | 1681/3000 [00:01<00:00, 1668.82it/s]warmup should be done:  55%|    | 1663/3000 [00:01<00:00, 1648.31it/s]warmup should be done:  56%|    | 1684/3000 [00:01<00:00, 1670.55it/s]warmup should be done:  55%|    | 1654/3000 [00:01<00:00, 1634.38it/s]warmup should be done:  56%|    | 1685/3000 [00:01<00:00, 1675.00it/s]warmup should be done:  56%|    | 1684/3000 [00:01<00:00, 1660.64it/s]warmup should be done:  56%|    | 1667/3000 [00:01<00:00, 1638.18it/s]warmup should be done:  56%|    | 1673/3000 [00:01<00:00, 1650.92it/s]warmup should be done:  62%|   | 1848/3000 [00:01<00:00, 1667.38it/s]warmup should be done:  61%|    | 1828/3000 [00:01<00:00, 1648.13it/s]warmup should be done:  61%|    | 1821/3000 [00:01<00:00, 1643.39it/s]warmup should be done:  62%|   | 1854/3000 [00:01<00:00, 1677.66it/s]warmup should be done:  62%|   | 1852/3000 [00:01<00:00, 1668.04it/s]warmup should be done:  62%|   | 1852/3000 [00:01<00:00, 1664.22it/s]warmup should be done:  61%|    | 1833/3000 [00:01<00:00, 1642.20it/s]warmup should be done:  61%|   | 1839/3000 [00:01<00:00, 1647.36it/s]warmup should be done:  67%|   | 2016/3000 [00:01<00:00, 1668.29it/s]warmup should be done:  66%|   | 1994/3000 [00:01<00:00, 1651.01it/s]warmup should be done:  67%|   | 2023/3000 [00:01<00:00, 1680.59it/s]warmup should be done:  66%|   | 1989/3000 [00:01<00:00, 1652.83it/s]warmup should be done:  67%|   | 2020/3000 [00:01<00:00, 1669.73it/s]warmup should be done:  67%|   | 2022/3000 [00:01<00:00, 1672.54it/s]warmup should be done:  67%|   | 1998/3000 [00:01<00:00, 1643.91it/s]warmup should be done:  67%|   | 2005/3000 [00:01<00:00, 1651.13it/s]warmup should be done:  72%|  | 2160/3000 [00:01<00:00, 1653.10it/s]warmup should be done:  73%|  | 2184/3000 [00:01<00:00, 1669.59it/s]warmup should be done:  73%|  | 2192/3000 [00:01<00:00, 1683.17it/s]warmup should be done:  72%|  | 2159/3000 [00:01<00:00, 1664.75it/s]warmup should be done:  73%|  | 2188/3000 [00:01<00:00, 1671.35it/s]warmup should be done:  73%|  | 2192/3000 [00:01<00:00, 1678.60it/s]warmup should be done:  72%|  | 2164/3000 [00:01<00:00, 1645.84it/s]warmup should be done:  72%|  | 2172/3000 [00:01<00:00, 1654.20it/s]warmup should be done:  78%|  | 2327/3000 [00:01<00:00, 1655.53it/s]warmup should be done:  78%|  | 2353/3000 [00:01<00:00, 1673.21it/s]warmup should be done:  78%|  | 2328/3000 [00:01<00:00, 1671.76it/s]warmup should be done:  79%|  | 2361/3000 [00:01<00:00, 1681.60it/s]warmup should be done:  79%|  | 2356/3000 [00:01<00:00, 1668.13it/s]warmup should be done:  79%|  | 2361/3000 [00:01<00:00, 1681.67it/s]warmup should be done:  78%|  | 2329/3000 [00:01<00:00, 1646.56it/s]warmup should be done:  78%|  | 2338/3000 [00:01<00:00, 1655.75it/s]warmup should be done:  83%| | 2495/3000 [00:01<00:00, 1662.62it/s]warmup should be done:  83%| | 2497/3000 [00:01<00:00, 1674.44it/s]warmup should be done:  84%| | 2521/3000 [00:01<00:00, 1667.61it/s]warmup should be done:  84%| | 2530/3000 [00:01<00:00, 1676.57it/s]warmup should be done:  84%| | 2524/3000 [00:01<00:00, 1669.60it/s]warmup should be done:  84%| | 2530/3000 [00:01<00:00, 1684.02it/s]warmup should be done:  83%| | 2495/3000 [00:01<00:00, 1649.45it/s]warmup should be done:  83%| | 2504/3000 [00:01<00:00, 1654.02it/s]warmup should be done:  89%| | 2663/3000 [00:01<00:00, 1667.55it/s]warmup should be done:  89%| | 2665/3000 [00:01<00:00, 1675.55it/s]warmup should be done:  90%| | 2698/3000 [00:01<00:00, 1676.28it/s]warmup should be done:  90%| | 2692/3000 [00:01<00:00, 1670.72it/s]warmup should be done:  90%| | 2699/3000 [00:01<00:00, 1679.08it/s]warmup should be done:  89%| | 2661/3000 [00:01<00:00, 1651.14it/s]warmup should be done:  90%| | 2688/3000 [00:01<00:00, 1649.48it/s]warmup should be done:  89%| | 2670/3000 [00:01<00:00, 1653.23it/s]warmup should be done:  94%|| 2831/3000 [00:01<00:00, 1670.70it/s]warmup should be done:  94%|| 2833/3000 [00:01<00:00, 1667.71it/s]warmup should be done:  96%|| 2866/3000 [00:01<00:00, 1672.03it/s]warmup should be done:  95%|| 2860/3000 [00:01<00:00, 1667.67it/s]warmup should be done:  94%|| 2827/3000 [00:01<00:00, 1653.23it/s]warmup should be done:  96%|| 2867/3000 [00:01<00:00, 1668.51it/s]warmup should be done:  95%|| 2853/3000 [00:01<00:00, 1632.22it/s]warmup should be done:  95%|| 2836/3000 [00:01<00:00, 1652.13it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1675.39it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1672.96it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1671.54it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1675.99it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1659.78it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1658.13it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1658.22it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1652.64it/s]warmup should be done: 100%|| 2993/3000 [00:01<00:00, 1478.30it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1613.61it/s]





warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 172/3000 [00:00<00:01, 1719.74it/s]warmup should be done:   6%|         | 172/3000 [00:00<00:01, 1718.23it/s]warmup should be done:   6%|         | 172/3000 [00:00<00:01, 1716.47it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1647.27it/s]warmup should be done:   6%|         | 171/3000 [00:00<00:01, 1704.84it/s]warmup should be done:   6%|         | 171/3000 [00:00<00:01, 1705.48it/s]warmup should be done:   5%|         | 142/3000 [00:00<00:02, 1414.68it/s]warmup should be done:   6%|         | 173/3000 [00:00<00:01, 1720.52it/s]warmup should be done:  12%|        | 346/3000 [00:00<00:01, 1728.88it/s]warmup should be done:  12%|        | 346/3000 [00:00<00:01, 1728.84it/s]warmup should be done:  11%|        | 343/3000 [00:00<00:01, 1712.29it/s]warmup should be done:  11%|        | 344/3000 [00:00<00:01, 1719.08it/s]warmup should be done:  11%|        | 340/3000 [00:00<00:01, 1705.73it/s]warmup should be done:  11%|        | 344/3000 [00:00<00:01, 1714.76it/s]warmup should be done:  11%|         | 317/3000 [00:00<00:01, 1610.39it/s]warmup should be done:  12%|        | 346/3000 [00:00<00:01, 1725.68it/s]warmup should be done:  17%|        | 514/3000 [00:00<00:01, 1719.46it/s]warmup should be done:  17%|        | 520/3000 [00:00<00:01, 1731.07it/s]warmup should be done:  17%|        | 520/3000 [00:00<00:01, 1730.94it/s]warmup should be done:  16%|        | 492/3000 [00:00<00:01, 1672.35it/s]warmup should be done:  17%|        | 517/3000 [00:00<00:01, 1721.59it/s]warmup should be done:  17%|        | 519/3000 [00:00<00:01, 1724.91it/s]warmup should be done:  17%|        | 516/3000 [00:00<00:01, 1716.27it/s]warmup should be done:  17%|        | 516/3000 [00:00<00:01, 1709.48it/s]warmup should be done:  22%|       | 667/3000 [00:00<00:01, 1699.56it/s]warmup should be done:  23%|       | 694/3000 [00:00<00:01, 1729.48it/s]warmup should be done:  23%|       | 687/3000 [00:00<00:01, 1708.55it/s]warmup should be done:  23%|       | 694/3000 [00:00<00:01, 1728.01it/s]warmup should be done:  23%|       | 690/3000 [00:00<00:01, 1717.73it/s]warmup should be done:  23%|       | 686/3000 [00:00<00:01, 1710.59it/s]warmup should be done:  23%|       | 692/3000 [00:00<00:01, 1718.20it/s]warmup should be done:  23%|       | 688/3000 [00:00<00:01, 1707.27it/s]warmup should be done:  29%|       | 867/3000 [00:00<00:01, 1728.76it/s]warmup should be done:  28%|       | 842/3000 [00:00<00:01, 1715.12it/s]warmup should be done:  29%|       | 862/3000 [00:00<00:01, 1720.74it/s]warmup should be done:  29%|       | 862/3000 [00:00<00:01, 1713.43it/s]warmup should be done:  29%|       | 860/3000 [00:00<00:01, 1709.38it/s]warmup should be done:  29%|       | 858/3000 [00:00<00:01, 1706.58it/s]warmup should be done:  29%|       | 864/3000 [00:00<00:01, 1708.83it/s]warmup should be done:  29%|       | 867/3000 [00:00<00:01, 1712.61it/s]warmup should be done:  35%|      | 1040/3000 [00:00<00:01, 1728.66it/s]warmup should be done:  34%|      | 1017/3000 [00:00<00:01, 1726.52it/s]warmup should be done:  35%|      | 1036/3000 [00:00<00:01, 1725.37it/s]warmup should be done:  34%|      | 1035/3000 [00:00<00:01, 1716.29it/s]warmup should be done:  34%|      | 1033/3000 [00:00<00:01, 1713.76it/s]warmup should be done:  34%|      | 1035/3000 [00:00<00:01, 1725.15it/s]warmup should be done:  35%|      | 1038/3000 [00:00<00:01, 1717.89it/s]warmup should be done:  35%|      | 1039/3000 [00:00<00:01, 1706.61it/s]warmup should be done:  40%|      | 1215/3000 [00:00<00:01, 1733.67it/s]warmup should be done:  40%|      | 1190/3000 [00:00<00:01, 1724.70it/s]warmup should be done:  40%|      | 1212/3000 [00:00<00:01, 1734.72it/s]warmup should be done:  40%|      | 1208/3000 [00:00<00:01, 1718.04it/s]warmup should be done:  40%|      | 1206/3000 [00:00<00:01, 1717.11it/s]warmup should be done:  40%|      | 1210/3000 [00:00<00:01, 1732.50it/s]warmup should be done:  40%|      | 1212/3000 [00:00<00:01, 1722.64it/s]warmup should be done:  40%|      | 1210/3000 [00:00<00:01, 1703.09it/s]warmup should be done:  46%|     | 1391/3000 [00:00<00:00, 1741.23it/s]warmup should be done:  45%|     | 1363/3000 [00:00<00:00, 1725.99it/s]warmup should be done:  46%|     | 1390/3000 [00:00<00:00, 1746.55it/s]warmup should be done:  46%|     | 1380/3000 [00:00<00:00, 1722.73it/s]warmup should be done:  46%|     | 1382/3000 [00:00<00:00, 1722.24it/s]warmup should be done:  46%|     | 1386/3000 [00:00<00:00, 1739.79it/s]warmup should be done:  46%|     | 1387/3000 [00:00<00:00, 1729.10it/s]warmup should be done:  46%|     | 1381/3000 [00:00<00:00, 1701.13it/s]warmup should be done:  52%|    | 1566/3000 [00:00<00:00, 1743.65it/s]warmup should be done:  51%|     | 1536/3000 [00:00<00:00, 1726.04it/s]warmup should be done:  52%|    | 1567/3000 [00:00<00:00, 1752.74it/s]warmup should be done:  52%|    | 1553/3000 [00:00<00:00, 1724.08it/s]warmup should be done:  52%|    | 1561/3000 [00:00<00:00, 1742.26it/s]warmup should be done:  52%|    | 1555/3000 [00:00<00:00, 1723.21it/s]warmup should be done:  52%|    | 1561/3000 [00:00<00:00, 1731.57it/s]warmup should be done:  52%|    | 1552/3000 [00:00<00:00, 1700.02it/s]warmup should be done:  58%|    | 1741/3000 [00:01<00:00, 1743.05it/s]warmup should be done:  57%|    | 1709/3000 [00:01<00:00, 1725.90it/s]warmup should be done:  58%|    | 1744/3000 [00:01<00:00, 1755.12it/s]warmup should be done:  58%|    | 1736/3000 [00:01<00:00, 1744.33it/s]warmup should be done:  58%|    | 1726/3000 [00:01<00:00, 1724.95it/s]warmup should be done:  58%|    | 1729/3000 [00:01<00:00, 1725.65it/s]warmup should be done:  58%|    | 1735/3000 [00:01<00:00, 1732.93it/s]warmup should be done:  57%|    | 1723/3000 [00:01<00:00, 1698.55it/s]warmup should be done:  63%|   | 1883/3000 [00:01<00:00, 1728.22it/s]warmup should be done:  64%|   | 1917/3000 [00:01<00:00, 1745.45it/s]warmup should be done:  64%|   | 1921/3000 [00:01<00:00, 1757.45it/s]warmup should be done:  63%|   | 1899/3000 [00:01<00:00, 1725.49it/s]warmup should be done:  64%|   | 1911/3000 [00:01<00:00, 1742.00it/s]warmup should be done:  64%|   | 1909/3000 [00:01<00:00, 1734.82it/s]warmup should be done:  63%|   | 1902/3000 [00:01<00:00, 1722.85it/s]warmup should be done:  63%|   | 1894/3000 [00:01<00:00, 1699.53it/s]warmup should be done:  69%|   | 2057/3000 [00:01<00:00, 1730.36it/s]warmup should be done:  70%|   | 2093/3000 [00:01<00:00, 1747.75it/s]warmup should be done:  69%|   | 2072/3000 [00:01<00:00, 1725.64it/s]warmup should be done:  70%|   | 2098/3000 [00:01<00:00, 1758.34it/s]warmup should be done:  69%|   | 2083/3000 [00:01<00:00, 1733.94it/s]warmup should be done:  70%|   | 2086/3000 [00:01<00:00, 1739.74it/s]warmup should be done:  69%|   | 2075/3000 [00:01<00:00, 1710.87it/s]warmup should be done:  69%|   | 2064/3000 [00:01<00:00, 1697.68it/s]warmup should be done:  76%|  | 2269/3000 [00:01<00:00, 1748.98it/s]warmup should be done:  74%|  | 2231/3000 [00:01<00:00, 1729.46it/s]warmup should be done:  76%|  | 2274/3000 [00:01<00:00, 1757.42it/s]warmup should be done:  75%|  | 2245/3000 [00:01<00:00, 1724.38it/s]warmup should be done:  75%|  | 2260/3000 [00:01<00:00, 1736.44it/s]warmup should be done:  75%|  | 2257/3000 [00:01<00:00, 1728.44it/s]warmup should be done:  74%|  | 2234/3000 [00:01<00:00, 1695.85it/s]warmup should be done:  75%|  | 2247/3000 [00:01<00:00, 1700.11it/s]warmup should be done:  80%|  | 2404/3000 [00:01<00:00, 1729.03it/s]warmup should be done:  82%| | 2445/3000 [00:01<00:00, 1749.85it/s]warmup should be done:  81%|  | 2418/3000 [00:01<00:00, 1723.03it/s]warmup should be done:  82%| | 2450/3000 [00:01<00:00, 1747.06it/s]warmup should be done:  81%|  | 2433/3000 [00:01<00:00, 1737.26it/s]warmup should be done:  81%|  | 2434/3000 [00:01<00:00, 1733.18it/s]warmup should be done:  80%|  | 2404/3000 [00:01<00:00, 1695.27it/s]warmup should be done:  81%|  | 2418/3000 [00:01<00:00, 1693.31it/s]warmup should be done:  86%| | 2577/3000 [00:01<00:00, 1728.45it/s]warmup should be done:  87%| | 2621/3000 [00:01<00:00, 1751.17it/s]warmup should be done:  87%| | 2607/3000 [00:01<00:00, 1737.26it/s]warmup should be done:  86%| | 2591/3000 [00:01<00:00, 1711.96it/s]warmup should be done:  87%| | 2608/3000 [00:01<00:00, 1726.79it/s]warmup should be done:  88%| | 2625/3000 [00:01<00:00, 1737.57it/s]warmup should be done:  86%| | 2574/3000 [00:01<00:00, 1695.85it/s]warmup should be done:  86%| | 2588/3000 [00:01<00:00, 1689.22it/s]warmup should be done:  92%|| 2752/3000 [00:01<00:00, 1732.71it/s]warmup should be done:  93%|| 2797/3000 [00:01<00:00, 1752.03it/s]warmup should be done:  93%|| 2781/3000 [00:01<00:00, 1737.25it/s]warmup should be done:  92%|| 2765/3000 [00:01<00:00, 1717.43it/s]warmup should be done:  93%|| 2782/3000 [00:01<00:00, 1729.57it/s]warmup should be done:  93%|| 2799/3000 [00:01<00:00, 1737.26it/s]warmup should be done:  92%|| 2745/3000 [00:01<00:00, 1698.36it/s]warmup should be done:  92%|| 2757/3000 [00:01<00:00, 1688.90it/s]warmup should be done:  99%|| 2973/3000 [00:01<00:00, 1751.46it/s]warmup should be done:  98%|| 2926/3000 [00:01<00:00, 1727.50it/s]warmup should be done:  99%|| 2956/3000 [00:01<00:00, 1739.31it/s]warmup should be done:  99%|| 2956/3000 [00:01<00:00, 1731.84it/s]warmup should be done:  98%|| 2939/3000 [00:01<00:00, 1721.36it/s]warmup should be done:  99%|| 2973/3000 [00:01<00:00, 1737.18it/s]warmup should be done:  97%|| 2916/3000 [00:01<00:00, 1699.20it/s]warmup should be done:  98%|| 2926/3000 [00:01<00:00, 1687.37it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1742.71it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1738.69it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1730.55it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1729.14it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1719.15it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1714.66it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1705.76it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1703.17it/s]2022-12-11 19:21:54.548144: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2776fa30c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:21:54.548202: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:21:54.621462: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:21:54.693364: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f276ef04e50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:21:54.693420: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:21:54.705243: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f277ec26d30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:21:54.705307: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:21:54.750504: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f277efa2e70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:21:54.750561: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:21:54.785164: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:21:54.788018: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:21:54.810493: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:21:55.224167: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f277ac27060 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:21:55.224231: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:21:55.249932: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f277ef7eba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:21:55.250001: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:21:55.250076: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f277ac27340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:21:55.250123: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:21:55.251971: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2782c22c10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:21:55.252033: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:21:55.307287: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:21:55.324644: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:21:55.336697: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:21:55.369660: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:21:56.427622: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:21:56.550836: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:21:56.571694: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:21:56.572422: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:21:56.800181: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:21:56.847119: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:21:56.853034: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:21:56.923702: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][19:22:17.412][ERROR][RK0][main]: replica 0 reaches 1000, calling init pre replica
[HCTR][19:22:17.412][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy coll_cache_asymm_link
[HCTR][19:22:17.423][ERROR][RK0][main]: coll ps creation done
[HCTR][19:22:17.423][ERROR][RK0][main]: replica 0 waits for coll ps creation barrier
[HCTR][19:22:17.490][ERROR][RK0][main]: replica 6 reaches 1000, calling init pre replica
[HCTR][19:22:17.490][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy coll_cache_asymm_link
[HCTR][19:22:17.509][ERROR][RK0][main]: coll ps creation done
[HCTR][19:22:17.510][ERROR][RK0][main]: replica 6 waits for coll ps creation barrier
[HCTR][19:22:17.547][ERROR][RK0][tid #139808013801216]: replica 2 reaches 1000, calling init pre replica
[HCTR][19:22:17.547][ERROR][RK0][tid #139808013801216]: coll ps creation, with 8 devices, using policy coll_cache_asymm_link
[HCTR][19:22:17.556][ERROR][RK0][main]: replica 1 reaches 1000, calling init pre replica
[HCTR][19:22:17.556][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy coll_cache_asymm_link
[HCTR][19:22:17.562][ERROR][RK0][main]: coll ps creation done
[HCTR][19:22:17.562][ERROR][RK0][main]: replica 1 waits for coll ps creation barrier
[HCTR][19:22:17.567][ERROR][RK0][tid #139808013801216]: coll ps creation done
[HCTR][19:22:17.567][ERROR][RK0][tid #139808013801216]: replica 2 waits for coll ps creation barrier
[HCTR][19:22:17.579][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][19:22:17.579][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy coll_cache_asymm_link
[HCTR][19:22:17.584][ERROR][RK0][tid #139808013801216]: replica 4 reaches 1000, calling init pre replica
[HCTR][19:22:17.585][ERROR][RK0][tid #139808013801216]: coll ps creation, with 8 devices, using policy coll_cache_asymm_link
[HCTR][19:22:17.589][ERROR][RK0][main]: coll ps creation done
[HCTR][19:22:17.589][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][19:22:17.590][ERROR][RK0][tid #139808013801216]: coll ps creation done
[HCTR][19:22:17.590][ERROR][RK0][tid #139808013801216]: replica 4 waits for coll ps creation barrier
[HCTR][19:22:17.606][ERROR][RK0][tid #139807879583488]: replica 7 reaches 1000, calling init pre replica
[HCTR][19:22:17.606][ERROR][RK0][tid #139807879583488]: coll ps creation, with 8 devices, using policy coll_cache_asymm_link
[HCTR][19:22:17.615][ERROR][RK0][tid #139807879583488]: coll ps creation done
[HCTR][19:22:17.615][ERROR][RK0][tid #139807879583488]: replica 7 waits for coll ps creation barrier
[HCTR][19:22:17.637][ERROR][RK0][main]: replica 5 reaches 1000, calling init pre replica
[HCTR][19:22:17.637][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy coll_cache_asymm_link
[HCTR][19:22:17.645][ERROR][RK0][main]: coll ps creation done
[HCTR][19:22:17.645][ERROR][RK0][main]: replica 5 waits for coll ps creation barrier
[HCTR][19:22:17.645][ERROR][RK0][main]: replica 0 preparing frequency
[HCTR][19:22:24.746][ERROR][RK0][main]: replica 0 preparing frequency done
[HCTR][19:22:24.779][ERROR][RK0][main]: replica 0 calling init per replica
[HCTR][19:22:24.779][ERROR][RK0][tid #139808013801216]: replica 4 calling init per replica
[HCTR][19:22:24.779][ERROR][RK0][main]: replica 1 calling init per replica
[HCTR][19:22:24.779][ERROR][RK0][main]: replica 5 calling init per replica
[HCTR][19:22:24.779][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][19:22:24.779][ERROR][RK0][tid #139808013801216]: replica 2 calling init per replica
[HCTR][19:22:24.780][ERROR][RK0][tid #139807879583488]: replica 7 calling init per replica
[HCTR][19:22:24.780][ERROR][RK0][main]: replica 6 calling init per replica
[HCTR][19:22:24.780][ERROR][RK0][main]: Calling build_v2
[HCTR][19:22:24.780][ERROR][RK0][tid #139808013801216]: Calling build_v2
[HCTR][19:22:24.780][ERROR][RK0][main]: Calling build_v2
[HCTR][19:22:24.780][ERROR][RK0][main]: Calling build_v2
[HCTR][19:22:24.780][ERROR][RK0][main]: Calling build_v2
[HCTR][19:22:24.780][ERROR][RK0][tid #139808013801216]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:22:24.780][ERROR][RK0][tid #139808013801216]: Calling build_v2
[HCTR][19:22:24.780][ERROR][RK0][tid #139807879583488]: Calling build_v2
[HCTR][19:22:24.780][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:22:24.780][ERROR][RK0][main]: Calling build_v2
[HCTR][19:22:24.780][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:22:24.780][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:22:24.780][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:22:24.780][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:22:24.780][ERROR][RK0][tid #139808013801216]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:22:24.780][ERROR][RK0][tid #139807879583488]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[[[[[2022-12-11 19:22:242022-12-11 19:22:24.2022-12-11 19:22:24[.2022-12-11 19:22:24780211[2022-12-11 19:22:24.[780198.: 2022-12-11 19:22:24.780204: 2022-12-11 19:22:24780208E.780215: E.2022-12-11 19:22:24:  780231: E 780231.E/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc: 780252 :E /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc:E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc136 /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc:136 E:] /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc:136] /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc 136using concurrent impl MPS:136] using concurrent impl MPS:/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc] 
136] using concurrent impl MPS
136:using concurrent impl MPS] using concurrent impl MPS
] 136
using concurrent impl MPS
using concurrent impl MPS] 

using concurrent impl MPS
[2022-12-11 19:22:24.784366: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[2022-12-11 19:22:24.784403: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-11 19:22:24:.196784410] : assigning 8 to cpuE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[2022-12-11 19:22:24.[7844572022-12-11 19:22:24: .E784456 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[E:2022-12-11 19:22:24 196./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 784478:assigning 8 to cpu: 178
[E] 2022-12-11 19:22:24 v100x8, slow pcie./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
784500:: 212E[]  2022-12-11 19:22:24build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.
[:[7845342022-12-11 19:22:241782022-12-11 19:22:24: .] .E[784547v100x8, slow pcie784544 2022-12-11 19:22:24: 
: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.EE[:784570[  2022-12-11 19:22:24196: 2022-12-11 19:22:24/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.] E.::784590assigning 8 to cpu 784598212178: 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: ] [] E:Ebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 82022-12-11 19:22:24v100x8, slow pcie 213 
[.
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[2022-12-11 19:22:24784640:[remote time is 8.68421[:2022-12-11 19:22:24.: 1782022-12-11 19:22:24
2022-12-11 19:22:24196.784683E] ..] [784702:  v100x8, slow pcie784714784718assigning 8 to cpu2022-12-11 19:22:24: E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
: : 
.E :EE[784763 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc178  2022-12-11 19:22:24: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.[E:178v100x8, slow pcie::7848202022-12-11 19:22:24 212] 
213196: ./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] v100x8, slow pcie] ] E[784856:build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8
remote time is 8.68421assigning 8 to cpu 2022-12-11 19:22:24: 214


[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.E] 2022-12-11 19:22:24[[:784914 cpu time is 97.0588.2022-12-11 19:22:242022-12-11 19:22:24196[: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
784956..] 2022-12-11 19:22:24E:: 784979784981assigning 8 to cpu. 212E: : 
785007/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc]  EE: :build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc  E196
:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc ] [196::[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccassigning 8 to cpu2022-12-11 19:22:24] assigning 8 to cpu
2142132022-12-11 19:22:24:
.] ] .212785148cpu time is 97.0588remote time is 8.68421785161] : 
[
: build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E2022-12-11 19:22:24[E
 [.2022-12-11 19:22:24 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-11 19:22:24785235[./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:.: 2022-12-11 19:22:24785260:212785259E.: 213] :  785282E] build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:  remote time is 8.68421
 :E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc212 :[:] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2142022-12-11 19:22:24212build asymm link desc with 8X Tesla V100-SXM2-32GB out of 82022-12-11 19:22:24:] .] 
.213cpu time is 97.0588785383build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8785393] 
: 
[: remote time is 8.68421E2022-12-11 19:22:24E
[ . 2022-12-11 19:22:24[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc785456/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.2022-12-11 19:22:24:: :785481.213E214: 785498]  ] E: remote time is 8.68421/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cccpu time is 97.0588 E
:
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc 213[:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 2022-12-11 19:22:24213:remote time is 8.68421.] 214
785622remote time is 8.68421] : [
cpu time is 97.0588E2022-12-11 19:22:24
[ .2022-12-11 19:22:24/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc785693.:: 785714214E: ]  Ecpu time is 97.0588/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc 
:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc214:] 214cpu time is 97.0588] 
cpu time is 97.0588
[2022-12-11 19:24:08.548104: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-11 19:24:08.929762: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 3.29 GB
[2022-12-11 19:24:08.929885: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 3.29 GB
[2022-12-11 19:24:08.930952: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:74] mapping nid to rank...
[2022-12-11 19:24:09.652842: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:91] counting slots...
[2022-12-11 19:24:11.384796: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:105] Final num slot is 2
[2022-12-11 19:24:11.384893: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:109] counting blocks...
[2022-12-11 19:25:44.380440: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:118] Final num block is 1001
[2022-12-11 19:25:44.380536: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:123] counting freq and density...
[2022-12-11 19:25:58.299159: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:154] averaging freq and density...
[2022-12-11 19:25:58.299282: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:155] 1001
[2022-12-11 19:25:58.321004: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-11 19:25:58.321083: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:354] constructing optimal solver, device=8, stream=1
1001 blocks, 8 devices
[2022-12-11 19:25:58.637789: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:527] Add Var...
[2022-12-11 19:25:58.667926: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:545] Capacity...
[2022-12-11 19:25:58.670036: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:548] Connect CPU...
[2022-12-11 19:25:58.690860: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:550] Connect Access To Storage...
[2022-12-11 19:25:59.207010: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:554] Time...
[2022-12-11 19:26:04. 56287: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:569] Coll Cache init block placement array
[2022-12-11 19:26:04. 63664: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:645] Coll Cache init block placement array done
[2022-12-11 19:26:04. 65340: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:647] Coll Cache model reset done
[2022-12-11 19:26:04.110858: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-11 19:26:04.110961: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-11 19:26:04.110995: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-11 19:26:04.111026: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-11 19:26:04.111572: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:26:04.111683: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.115779: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.119699: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.244407: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 5 solved
[2022-12-11 19:26:04.244515: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 5 initing device 5
[2022-12-11 19:26:04.244947: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:26:04.245010: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.245096: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 4 solved
[2022-12-11 19:26:04.245180: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 4 initing device 4
[2022-12-11 19:26:04.245581: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:26:04.245627: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.246465: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 1 solved
[2022-12-11 19:26:04.246524: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 1 initing device 1
[2022-12-11 19:26:04.246914: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:26:04.246963: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.247007: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 6 solved
[2022-12-11 19:26:04.247064: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 6 initing device 6
[2022-12-11 19:26:04.247443: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:26:04.247485: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.247561: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 2 solved
[2022-12-11 19:26:04.247613: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 2 initing device 2
[2022-12-11 19:26:04.247996: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:26:04.248037: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.250247: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 3 solved
[2022-12-11 19:26:04.250300: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 3 initing device 3
[2022-12-11 19:26:04.250673: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:26:04.250713: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.250852: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 7 solved
[2022-12-11 19:26:04.250904: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 7 initing device 7
[2022-12-11 19:26:04.251289: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:26:04.251330: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.271631: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.271912: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.272024: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.272090: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.272190: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.275871: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.275961: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.302765: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.303037: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.303120: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.303206: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.303306: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.306964: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.307043: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:26:04.772024: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1001.00 Bytes
[2022-12-11 19:26:04.772220: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1855] using empty feat=27
[2022-12-11 19:26:04.789793: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1001
[2022-12-11 19:26:04.789936: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:26:04.794224: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:26:04.795033: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:04.802334: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:04.802732: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 131.33 MB
[2022-12-11 19:26:04.897558: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:26:04.902187: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:26:04.902248: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.46 GB
[[[[2022-12-11 19:26:052022-12-11 19:26:052022-12-11 19:26:052022-12-11 19:26:05... 15777. 15785 15785: :  15785: EE: E  E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:19801980:1980] ] 1980] eager alloc mem 1001.00 Byteseager alloc mem 1001.00 Bytes] eager alloc mem 1001.00 Bytes

eager alloc mem 1001.00 Bytes

[[[2022-12-11 19:26:05[2022-12-11 19:26:052022-12-11 19:26:05.2022-12-11 19:26:05.. 16057. 16057 16062:  16061: : W: WW W  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::1855:18551855] 1855] ] using empty feat=27] using empty feat=27using empty feat=27
using empty feat=27


[2022-12-11 19:26:05. 21712: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1001.00 Bytes
[[2022-12-11 19:26:052022-12-11 19:26:05.. 21775 21775: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 1001.00 Byteseager alloc mem 1001.00 Bytes

[2022-12-11 19:26:05. 21877: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1855] using empty feat=27
[[2022-12-11 19:26:052022-12-11 19:26:05.. 21953 21954: : WW  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::18551855] ] using empty feat=27using empty feat=27

[2022-12-11 19:26:05. 34069: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1001
[2022-12-11 19:26:05[.2022-12-11 19:26:05 34137.:  34159E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 1001] 
eager release cuda mem 3531098340
[[2022-12-11 19:26:052022-12-11 19:26:05.. 34225 34238: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 1001eager release cuda mem 3531098340

[2022-12-11 19:26:05. 34302[: 2022-12-11 19:26:05E.  34324/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 1001:
638] eager release cuda mem 3531098340
[2022-12-11 19:26:05. 34392: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:26:05. 38830: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:26:05. 39419: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1001
[2022-12-11 19:26:05. 39504: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-11 19:26:05:.638 39502] : eager release cuda mem 3531098340E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1001
[2022-12-11 19:26:05. 39592[: 2022-12-11 19:26:05E.  39585/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 3531098340:
638] eager release cuda mem 1001
[2022-12-11 19:26:05. 39679: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:26:05. 42833: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:26:05. 47223: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:26:05. 51489: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:26:05. 56349: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:26:05. 60237: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:26:05. 64144: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:26:05. 64484: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:05. 65047: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:05. 65364: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:05. 65684: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:05. 66345: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:05. 66515: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:05. 66616: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:05. 73353: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:05. 73581: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:05. 73638: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 131.44 MB
[2022-12-11 19:26:05. 73858: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 94.29 MB
[2022-12-11 19:26:05. 73903: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:05. 74149: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:05. 74188: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 131.44 MB
[2022-12-11 19:26:05. 74432: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 121.34 MB
[2022-12-11 19:26:05. 74456: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:05[.2022-12-11 19:26:05 74486.:  74495E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 5518079] 
eager release cuda mem 5518079
[2022-12-11 19:26:05. 74980: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 77.56 MB
[2022-12-11 19:26:05. 75045: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 117.86 MB
[2022-12-11 19:26:05. 75112: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 131.44 MB
[2022-12-11 19:26:05.127087: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:26:05.132848: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:26:05.132898: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 9.74 GB
[2022-12-11 19:26:05.136318: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:26:05.140848: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:26:05.140899: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 11.83 GB
[2022-12-11 19:26:05.151366: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:26:05.154350: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:26:05.155895: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:26:05.155942: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.77 GB
[2022-12-11 19:26:05.157869: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:26:05.158843: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:26:05.158893: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 15.21 GB
[2022-12-11 19:26:05.160149: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:26:05.162375: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:26:05.162422: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.47 GB
[2022-12-11 19:26:05.162741: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:26:05.164657: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:26:05.164702: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.47 GB
[2022-12-11 19:26:05.167263: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:26:05.167310: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.47 GB
[[[[[[[[2022-12-11 19:26:082022-12-11 19:26:082022-12-11 19:26:082022-12-11 19:26:082022-12-11 19:26:082022-12-11 19:26:082022-12-11 19:26:082022-12-11 19:26:08........242669242674242671242673242672242672242668242679: : : : : : : : EEEEEEEE        /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::::::19261926192619261926192619261926] ] Device 4 init p2p of link 5] ] ] ] ] ] Device 0 init p2p of link 3
Device 6 init p2p of link 0Device 1 init p2p of link 7Device 3 init p2p of link 2Device 2 init p2p of link 1Device 5 init p2p of link 6Device 7 init p2p of link 4






[[[2022-12-11 19:26:08[[2022-12-11 19:26:08[2022-12-11 19:26:08[.2022-12-11 19:26:08[2022-12-11 19:26:08.2022-12-11 19:26:08.2022-12-11 19:26:08243222.2022-12-11 19:26:08.243226.243225.: 243227.243228: 243230: 243233E: 243241: E: E:  E: E E E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980:1980:] 1980:1980] 1980] 1980eager alloc mem 5.26 MB] 1980] eager alloc mem 5.26 MB] eager alloc mem 5.26 MB] 
eager alloc mem 5.26 MB] eager alloc mem 5.26 MB
eager alloc mem 5.26 MB
eager alloc mem 5.26 MB
eager alloc mem 5.26 MB



[2022-12-11 19:26:08.255251: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[[2022-12-11 19:26:08[2022-12-11 19:26:08.2022-12-11 19:26:08.[255357.2553622022-12-11 19:26:08: 255366: .E: E255377 E : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: 638:638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] 638] :eager release cuda mem 5518079eager release cuda mem 5518079] 638

eager release cuda mem 5518079] 
eager release cuda mem 5518079
[2022-12-11 19:26:08[.2022-12-11 19:26:08255504.: 255513E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 5518079] 
eager release cuda mem 5518079
[2022-12-11 19:26:08.255614: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.274187: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 0 init p2p of link 6
[2022-12-11 19:26:08.274341: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.274623: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 1 init p2p of link 2
[2022-12-11 19:26:08.274779: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.275208: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 5 init p2p of link 4
[2022-12-11 19:26:08.275341: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.275812: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 4 init p2p of link 7
[2022-12-11 19:26:08.275988: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.277074: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 6 init p2p of link 5
[2022-12-11 19:26:08.277227: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.278845: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 7 init p2p of link 1
[2022-12-11 19:26:08.278983: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.279376: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 3 init p2p of link 0
[2022-12-11 19:26:08.279539: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.279627: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 2 init p2p of link 3
[2022-12-11 19:26:08.279783: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.282995: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.283057: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[[2022-12-11 19:26:082022-12-11 19:26:08..283198283202: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 5518079eager release cuda mem 5518079

[2022-12-11 19:26:08.283743: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.285462: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[[2022-12-11 19:26:082022-12-11 19:26:08..286308286314: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 5518079eager release cuda mem 5518079

[2022-12-11 19:26:08.301743: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 4 init p2p of link 2
[2022-12-11 19:26:08.301859[: 2022-12-11 19:26:08E. 301880/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: :E1926 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuDevice 1 init p2p of link 3:
1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.302003: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.302874: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 2 init p2p of link 0
[2022-12-11 19:26:08.303004: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.304442: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 0 init p2p of link 1
[2022-12-11 19:26:08.304577: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.305208: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 3 init p2p of link 5
[2022-12-11 19:26:08.305344: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.305440: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 5 init p2p of link 7
[2022-12-11 19:26:08.305563: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.305892: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 6 init p2p of link 4
[2022-12-11 19:26:08.306020: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.309550: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 7 init p2p of link 6
[[2022-12-11 19:26:082022-12-11 19:26:08..309624309628: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638[638] 2022-12-11 19:26:08] eager release cuda mem 5518079.eager release cuda mem 5518079
309674
: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-11 19:26:08:.1980309712] : eager alloc mem 5.26 MBE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.311075: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.312000: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.312106: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.312528: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.317947: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.327822: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 1 init p2p of link 0
[2022-12-11 19:26:08.327945: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.331571: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 3 init p2p of link 1
[2022-12-11 19:26:08.331696: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.332413: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 5 init p2p of link 3
[2022-12-11 19:26:08.332528: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.336246: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 6 init p2p of link 7[
2022-12-11 19:26:08.336274: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 2 init p2p of link 4
[2022-12-11 19:26:08.336374: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.336402: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.338102: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.339409: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.339505: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.339634: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 0 init p2p of link 2
[[2022-12-11 19:26:082022-12-11 19:26:08..339757339773: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19261980] ] Device 7 init p2p of link 5eager alloc mem 5.26 MB

[2022-12-11 19:26:08.339934: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.343124: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.343200: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.346825: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 4 init p2p of link 6
[2022-12-11 19:26:08.346958: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:26:08.348918: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.349325: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.351758: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:26:08.354424: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: coll_cache_asymm_link) | local 34456688 / 882774585 nodes ( 3.90 %~4.00 %) | remote 26483220 / 882774585 nodes ( 3.00 %) | cpu 821834677 / 882774585 nodes ( 93.10 %) | 16.47 GB | 4.10747 secs 
[2022-12-11 19:26:08.355790: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:26:08.356104: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:26:08.356259: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:26:08.358471: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: coll_cache_asymm_link) | local 31808366 / 882774585 nodes ( 3.60 %~4.00 %) | remote 29131542 / 882774585 nodes ( 3.30 %) | cpu 821834677 / 882774585 nodes ( 93.10 %) | 15.21 GB | 4.11044 secs 
[2022-12-11 19:26:08.358935: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-11 19:26:08:.638358957] : eager release cuda mem 144775028E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: coll_cache_asymm_link) | local 30897090 / 882774585 nodes ( 3.50 %~4.00 %) | remote 30042818 / 882774585 nodes ( 3.40 %) | cpu 821834677 / 882774585 nodes ( 93.10 %) | 14.77 GB | 4.11148 secs 
[2022-12-11 19:26:08.363212: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: coll_cache_asymm_link) | local 34456688 / 882774585 nodes ( 3.90 %~4.00 %) | remote 26483220 / 882774585 nodes ( 3.00 %) | cpu 821834677 / 882774585 nodes ( 93.10 %) | 16.47 GB | 4.11822 secs 
[2022-12-11 19:26:08.364787: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:26:08.368349: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: coll_cache_asymm_link) | local 24717672 / 882774585 nodes ( 2.80 %~4.00 %) | remote 36222236 / 882774585 nodes ( 4.10 %) | cpu 821834677 / 882774585 nodes ( 93.10 %) | 11.83 GB | 4.11764 secs 
[2022-12-11 19:26:08.373956: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:26:08.374736: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:26:08.376680: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: coll_cache_asymm_link) | local 34456688 / 882774585 nodes ( 3.90 %~4.00 %) | remote 26483220 / 882774585 nodes ( 3.00 %) | cpu 821834677 / 882774585 nodes ( 93.10 %) | 16.47 GB | 4.13106 secs 
[2022-12-11 19:26:08.377783: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: coll_cache_asymm_link) | local 20332304 / 882774585 nodes ( 2.30 %~4.00 %) | remote 40607604 / 882774585 nodes ( 4.60 %) | cpu 821834677 / 882774585 nodes ( 93.10 %) | 9.74 GB | 4.12646 secs 
[2022-12-11 19:26:08.382795: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:26:08.411318: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: coll_cache_asymm_link) | local 34428186 / 882774585 nodes ( 3.90 %~4.00 %) | remote 26511722 / 882774585 nodes ( 3.00 %) | cpu 821834677 / 882774585 nodes ( 93.10 %) | 16.46 GB | 4.2997 secs 
[2022-12-11 19:26:08.434888: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 27.37 GB
[2022-12-11 19:26:09.864781: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 27.63 GB
[2022-12-11 19:26:09.866610: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 27.63 GB
[2022-12-11 19:26:09.867312: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 27.63 GB
[2022-12-11 19:26:11.338568: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 27.90 GB
[2022-12-11 19:26:11.338770: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 27.90 GB
[2022-12-11 19:26:11.339973: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 27.90 GB
[2022-12-11 19:26:12.343662: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 28.11 GB
[2022-12-11 19:26:12.345520: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 28.11 GB
[2022-12-11 19:26:12.346473: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 28.11 GB
[2022-12-11 19:26:13.753581: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 28.33 GB
[2022-12-11 19:26:13.754161: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 28.33 GB
[2022-12-11 19:26:13.754924: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 28.33 GB
[2022-12-11 19:26:15.625573: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 28.78 GB
[2022-12-11 19:26:15.626543: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 28.78 GB
[2022-12-11 19:26:15.631922: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 28.78 GB
[2022-12-11 19:26:17.642289: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 28.99 GB
[2022-12-11 19:26:17.643527: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 28.99 GB
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier
[HCTR][19:26:18.807][ERROR][RK0][tid #139807879583488]: replica 7 calling init per replica done, doing barrier
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier
[HCTR][19:26:18.807][ERROR][RK0][tid #139808013801216]: replica 2 calling init per replica done, doing barrier
[HCTR][19:26:18.807][ERROR][RK0][tid #139808013801216]: replica 4 calling init per replica done, doing barrier
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][19:26:18.807][ERROR][RK0][tid #139807879583488]: replica 7 calling init per replica done, doing barrier done
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier done
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier done
[HCTR][19:26:18.807][ERROR][RK0][tid #139808013801216]: replica 2 calling init per replica done, doing barrier done
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][19:26:18.807][ERROR][RK0][tid #139808013801216]: replica 4 calling init per replica done, doing barrier done
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier done
[HCTR][19:26:18.807][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier done
[HCTR][19:26:18.807][ERROR][RK0][tid #139807879583488]: init per replica done
[HCTR][19:26:18.807][ERROR][RK0][tid #139808013801216]: init per replica done
[HCTR][19:26:18.807][ERROR][RK0][tid #139808013801216]: init per replica done
[HCTR][19:26:18.807][ERROR][RK0][main]: init per replica done
[HCTR][19:26:18.807][ERROR][RK0][main]: init per replica done
[HCTR][19:26:18.807][ERROR][RK0][main]: init per replica done
[HCTR][19:26:18.807][ERROR][RK0][main]: init per replica done
[HCTR][19:26:18.827][ERROR][RK0][main]: init per replica done








