2022-12-12 03:42:38.198694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.205070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.212465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.219101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.223724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.236070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.242738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.248490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.303088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.312315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.314206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.318231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.318325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.319930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.319988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.321724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.321834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.323241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.323582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.324581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.325220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.325967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.326952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.327441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.328705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.329176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.330739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.332267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.333294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.334330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.335310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.336332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.338188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.339345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.340346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.341360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.342311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.343278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.344281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.345299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.350294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.350778: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:42:38.351705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.353372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.353931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.354729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.355631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.356379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.357228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.358084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.358814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.359917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.359936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.360254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.361980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.362093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.362222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.363888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.364423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.365944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.371827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.374247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.374322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.374336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.377312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.377642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.377778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.378125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.380535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.381087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.381350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.381857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.382370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.383638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.384023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.384444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.384967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.385477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.386967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.388754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.389223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.389800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.390336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.391053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.392161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.392510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.393187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.393848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.394192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.395835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.408386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.410556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.429131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.430102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.430713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.430739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.432951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.433431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.433963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.434880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.435111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.435252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.437745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.437880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.440244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.440454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.440542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.442874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.443023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.444463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.445222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.446329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.446371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.447429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.449278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.449360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.450303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.451830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.451903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.452797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.454161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.454247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.454929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.456317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.456356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.457261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.458419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.458458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.460288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.460745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.460785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.462546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.462855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.462896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.464924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.465062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.465154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.467107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.467412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.467507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.469321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.469529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.469662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.471484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.471622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.471758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.474043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.474920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.474925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.475610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.477094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.477210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.477304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.479380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.479515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.479533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.481493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.481779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.481906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.481922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.482525: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:42:38.484230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.484751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.484782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.484794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.486777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.487289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.487626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.487704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.488928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.489629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.490303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.490862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.491569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.491646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.491825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.492966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.494249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.494914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.495636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.496304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.496317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.496516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.497699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.498726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.500326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.501167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.501212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.502079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.502799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.503878: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:42:38.503963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.504475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.505156: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:42:38.505219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.506199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.507210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.507981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.508619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.509433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.510992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.511642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.512255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.512805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.513080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.514138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.514575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.515424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.516538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.517251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.517649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.518838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.519227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.520063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.521149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.522079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.522394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.523610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.523939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.525146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.525992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.527117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.529722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.530627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.531379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.532930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.563906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.564777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.565585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.566636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.569316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.569324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.570035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.571752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.574130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.574555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.575121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.577910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.578666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.580645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.580997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.585669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.586025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.586723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.586803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.591552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.591731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.592317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.593269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.625055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.625745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.626623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.627062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.629872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.630640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.631710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.632163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.634596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.635630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.637345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.638446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.653206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.655218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.655504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.657472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.658037: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:42:38.659169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.659318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.667466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.693963: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:42:38.702719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.722338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.722624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.725846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.726711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.729160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.729301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.731838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.733100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.735340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.738925: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:42:38.747450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.748980: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:42:38.753260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.757384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.759486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.762601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:38.767601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.634428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.635040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.635580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.636051: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:42:39.636107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 03:42:39.654456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.655249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.655776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.656589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.657291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.657777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 03:42:39.703912: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:39.704112: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:39.771819: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-12 03:42:39.850903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.851537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.852183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.852663: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:42:39.852715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 03:42:39.870431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.871058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.871588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.872149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.872868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.873331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 03:42:39.898148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.898570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.899213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.899592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.900431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.900543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.901277: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:42:39.901333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 03:42:39.901391: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:42:39.901443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 03:42:39.919421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.919421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.920551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.920582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.921591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.921707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.922689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.922772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.924059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.924316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.925062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 03:42:39.925176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 03:42:39.957164: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:39.957379: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:39.959196: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-12 03:42:39.970208: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:39.970383: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:39.972249: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-12 03:42:39.973795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.974518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.975185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.975729: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:42:39.975781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 03:42:39.993283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.993797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.993836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.993947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.994233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.995828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.995884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.996156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.996333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.997833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.998012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.998110: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:42:39.998164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 03:42:39.998364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.999814: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:42:39.999830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:39.999866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 03:42:39.999985: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:42:40.000031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 03:42:40.000812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.001278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 03:42:40.015700: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.015914: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.016861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.017527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.017594: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
2022-12-12 03:42:40.018032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.018047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.018156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.019655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.019711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.019798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.021183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.021218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.021308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.022674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 03:42:40.022899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.022938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.024017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.024063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:42:40.025051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 03:42:40.025097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 03:42:40.046535: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.046748: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.048594: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-12 03:42:40.068623: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.068815: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.069808: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.069981: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.070555: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-12 03:42:40.070807: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.070948: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:42:40.071784: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-12 03:42:40.072734: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
[HCTR][03:42:41.329][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:42:41.329][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:42:41.329][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:42:41.331][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:42:41.331][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:42:41.331][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:42:41.374][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:42:41.374][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:01,  1.53s/it]warmup run: 1it [00:01,  1.51s/it]warmup run: 1it [00:01,  1.50s/it]warmup run: 1it [00:01,  1.52s/it]warmup run: 100it [00:01, 85.32it/s]warmup run: 1it [00:01,  1.56s/it]warmup run: 103it [00:01, 88.84it/s]warmup run: 100it [00:01, 86.56it/s]warmup run: 94it [00:01, 80.41it/s]warmup run: 1it [00:01,  1.50s/it]warmup run: 201it [00:01, 185.87it/s]warmup run: 99it [00:01, 82.89it/s]warmup run: 205it [00:01, 191.23it/s]warmup run: 201it [00:01, 188.32it/s]warmup run: 1it [00:01,  1.48s/it]warmup run: 189it [00:01, 175.26it/s]warmup run: 98it [00:01, 84.83it/s]warmup run: 300it [00:01, 293.90it/s]warmup run: 1it [00:01,  1.48s/it]warmup run: 195it [00:01, 176.68it/s]warmup run: 306it [00:01, 302.39it/s]warmup run: 300it [00:01, 297.21it/s]warmup run: 97it [00:01, 84.86it/s]warmup run: 283it [00:01, 278.14it/s]warmup run: 197it [00:01, 184.58it/s]warmup run: 396it [00:01, 401.16it/s]warmup run: 100it [00:01, 87.87it/s]warmup run: 294it [00:01, 284.39it/s]warmup run: 408it [00:01, 418.37it/s]warmup run: 396it [00:01, 405.00it/s]warmup run: 196it [00:01, 185.53it/s]warmup run: 380it [00:01, 389.79it/s]warmup run: 297it [00:01, 295.41it/s]warmup run: 493it [00:02, 506.68it/s]warmup run: 200it [00:01, 189.86it/s]warmup run: 392it [00:01, 394.66it/s]warmup run: 511it [00:02, 533.18it/s]warmup run: 492it [00:02, 509.05it/s]warmup run: 296it [00:01, 297.19it/s]warmup run: 480it [00:02, 504.05it/s]warmup run: 394it [00:01, 404.83it/s]warmup run: 592it [00:02, 608.14it/s]warmup run: 300it [00:01, 301.33it/s]warmup run: 485it [00:02, 493.26it/s]warmup run: 615it [00:02, 640.23it/s]warmup run: 591it [00:02, 610.83it/s]warmup run: 396it [00:01, 412.18it/s]warmup run: 582it [00:02, 612.12it/s]warmup run: 493it [00:02, 513.94it/s]warmup run: 690it [00:02, 693.90it/s]warmup run: 401it [00:01, 417.68it/s]warmup run: 580it [00:02, 587.95it/s]warmup run: 717it [00:02, 727.83it/s]warmup run: 688it [00:02, 693.09it/s]warmup run: 496it [00:01, 522.96it/s]warmup run: 685it [00:02, 708.80it/s]warmup run: 593it [00:02, 616.05it/s]warmup run: 789it [00:02, 765.70it/s]warmup run: 502it [00:01, 530.24it/s]warmup run: 674it [00:02, 668.38it/s]warmup run: 820it [00:02, 802.57it/s]warmup run: 785it [00:02, 760.84it/s]warmup run: 598it [00:02, 628.68it/s]warmup run: 789it [00:02, 789.39it/s]warmup run: 691it [00:02, 700.37it/s]warmup run: 888it [00:02, 823.31it/s]warmup run: 604it [00:02, 634.70it/s]warmup run: 769it [00:02, 736.30it/s]warmup run: 922it [00:02, 859.11it/s]warmup run: 881it [00:02, 811.41it/s]warmup run: 700it [00:02, 719.81it/s]warmup run: 891it [00:02, 849.07it/s]warmup run: 792it [00:02, 775.57it/s]warmup run: 986it [00:02, 865.79it/s]warmup run: 706it [00:02, 723.98it/s]warmup run: 871it [00:02, 809.01it/s]warmup run: 1023it [00:02, 892.21it/s]warmup run: 977it [00:02, 846.70it/s]warmup run: 802it [00:02, 794.16it/s]warmup run: 994it [00:02, 896.51it/s]warmup run: 891it [00:02, 829.65it/s]warmup run: 1084it [00:02, 895.54it/s]warmup run: 807it [00:02, 794.40it/s]warmup run: 971it [00:02, 858.98it/s]warmup run: 1123it [00:02, 919.92it/s]warmup run: 1072it [00:02, 871.84it/s]warmup run: 902it [00:02, 842.23it/s]warmup run: 1098it [00:02, 936.18it/s]warmup run: 990it [00:02, 872.45it/s]warmup run: 1183it [00:02, 920.96it/s]warmup run: 910it [00:02, 855.42it/s]warmup run: 1074it [00:02, 904.77it/s]warmup run: 1227it [00:02, 953.34it/s]warmup run: 1167it [00:02, 890.22it/s]warmup run: 1002it [00:02, 884.89it/s]warmup run: 1200it [00:02, 957.00it/s]warmup run: 1088it [00:02, 900.06it/s]warmup run: 1281it [00:02, 935.80it/s]warmup run: 1013it [00:02, 900.75it/s]warmup run: 1174it [00:02, 930.91it/s]warmup run: 1330it [00:02, 975.03it/s]warmup run: 1267it [00:02, 920.74it/s]warmup run: 1104it [00:02, 920.31it/s]warmup run: 1302it [00:02, 973.57it/s]warmup run: 1186it [00:02, 920.23it/s]warmup run: 1384it [00:02, 961.33it/s]warmup run: 1115it [00:02, 933.62it/s]warmup run: 1273it [00:02, 945.52it/s]warmup run: 1432it [00:02, 986.69it/s]warmup run: 1363it [00:02, 925.94it/s]warmup run: 1207it [00:02, 949.65it/s]warmup run: 1404it [00:02, 982.69it/s]warmup run: 1284it [00:02, 935.30it/s]warmup run: 1486it [00:03, 977.99it/s]warmup run: 1217it [00:02, 957.78it/s]warmup run: 1374it [00:02, 962.35it/s]warmup run: 1536it [00:03, 1000.82it/s]warmup run: 1464it [00:03, 950.15it/s]warmup run: 1309it [00:02, 968.29it/s]warmup run: 1506it [00:03, 988.82it/s]warmup run: 1383it [00:02, 950.83it/s]warmup run: 1319it [00:02, 975.76it/s]warmup run: 1586it [00:03, 975.10it/s]warmup run: 1475it [00:03, 975.75it/s]warmup run: 1640it [00:03, 1009.79it/s]warmup run: 1564it [00:03, 963.89it/s]warmup run: 1411it [00:02, 982.03it/s]warmup run: 1608it [00:03, 997.04it/s]warmup run: 1481it [00:03, 958.72it/s]warmup run: 1422it [00:02, 989.64it/s]warmup run: 1685it [00:03, 970.39it/s]warmup run: 1577it [00:03, 986.60it/s]warmup run: 1743it [00:03, 1006.48it/s]warmup run: 1664it [00:03, 972.45it/s]warmup run: 1512it [00:02, 982.00it/s]warmup run: 1710it [00:03, 1001.15it/s]warmup run: 1579it [00:03, 961.03it/s]warmup run: 1525it [00:02, 1000.10it/s]warmup run: 1784it [00:03, 967.81it/s]warmup run: 1678it [00:03, 979.27it/s]warmup run: 1848it [00:03, 1016.68it/s]warmup run: 1763it [00:03, 971.65it/s]warmup run: 1613it [00:03, 977.30it/s]warmup run: 1812it [00:03, 1003.70it/s]warmup run: 1677it [00:03, 962.00it/s]warmup run: 1629it [00:03, 1010.30it/s]warmup run: 1882it [00:03, 960.38it/s]warmup run: 1777it [00:03, 980.70it/s]warmup run: 1952it [00:03, 1022.55it/s]warmup run: 1862it [00:03, 975.81it/s]warmup run: 1713it [00:03, 972.37it/s]warmup run: 1914it [00:03, 1002.78it/s]warmup run: 1775it [00:03, 959.08it/s]warmup run: 1732it [00:03, 1014.44it/s]warmup run: 1979it [00:03, 959.63it/s]warmup run: 1880it [00:03, 994.78it/s]warmup run: 2064it [00:03, 1051.13it/s]warmup run: 1962it [00:03, 982.67it/s]warmup run: 1812it [00:03, 962.99it/s]warmup run: 2018it [00:03, 1011.45it/s]warmup run: 1873it [00:03, 964.15it/s]warmup run: 1836it [00:03, 1020.69it/s]warmup run: 2089it [00:03, 999.86it/s]warmup run: 1982it [00:03, 1002.24it/s]warmup run: 2185it [00:03, 1095.99it/s]warmup run: 2075it [00:03, 1025.75it/s]warmup run: 1909it [00:03, 955.64it/s]warmup run: 2136it [00:03, 1059.87it/s]warmup run: 1971it [00:03, 966.32it/s]warmup run: 1940it [00:03, 1025.49it/s]warmup run: 2204it [00:03, 1043.84it/s]warmup run: 2097it [00:03, 1043.94it/s]warmup run: 2305it [00:03, 1126.94it/s]warmup run: 2196it [00:03, 1079.95it/s]warmup run: 2255it [00:03, 1096.95it/s]warmup run: 2006it [00:03, 947.67it/s]warmup run: 2083it [00:03, 1009.79it/s]warmup run: 2049it [00:03, 1044.67it/s]warmup run: 2321it [00:03, 1078.59it/s]warmup run: 2215it [00:03, 1084.34it/s]warmup run: 2426it [00:03, 1149.11it/s]warmup run: 2318it [00:03, 1119.12it/s]warmup run: 2375it [00:03, 1125.03it/s]warmup run: 2122it [00:03, 1009.55it/s]warmup run: 2202it [00:03, 1061.16it/s]warmup run: 2169it [00:03, 1088.55it/s]warmup run: 2438it [00:03, 1105.60it/s]warmup run: 2333it [00:03, 1112.26it/s]warmup run: 2546it [00:03, 1163.51it/s]warmup run: 2439it [00:03, 1145.59it/s]warmup run: 2496it [00:03, 1147.81it/s]warmup run: 2238it [00:03, 1053.24it/s]warmup run: 2321it [00:03, 1097.76it/s]warmup run: 2289it [00:03, 1119.40it/s]warmup run: 2556it [00:04, 1126.03it/s]warmup run: 2451it [00:03, 1132.40it/s]warmup run: 2665it [00:04, 1169.71it/s]warmup run: 2561it [00:04, 1165.57it/s]warmup run: 2616it [00:04, 1162.57it/s]warmup run: 2354it [00:03, 1083.51it/s]warmup run: 2440it [00:03, 1124.12it/s]warmup run: 2408it [00:03, 1139.85it/s]warmup run: 2672it [00:04, 1135.77it/s]warmup run: 2569it [00:04, 1145.92it/s]warmup run: 2785it [00:04, 1178.59it/s]warmup run: 2682it [00:04, 1176.40it/s]warmup run: 2735it [00:04, 1169.53it/s]warmup run: 2470it [00:03, 1105.18it/s]warmup run: 2559it [00:04, 1141.08it/s]warmup run: 2527it [00:03, 1152.13it/s]warmup run: 2790it [00:04, 1146.13it/s]warmup run: 2686it [00:04, 1151.61it/s]warmup run: 2905it [00:04, 1184.70it/s]warmup run: 2803it [00:04, 1185.62it/s]warmup run: 2855it [00:04, 1178.37it/s]warmup run: 2587it [00:04, 1121.59it/s]warmup run: 2676it [00:04, 1149.21it/s]warmup run: 2645it [00:03, 1157.91it/s]warmup run: 2907it [00:04, 1151.94it/s]warmup run: 3000it [00:04, 696.03it/s] warmup run: 2803it [00:04, 1154.38it/s]warmup run: 2924it [00:04, 1192.28it/s]warmup run: 2975it [00:04, 1182.20it/s]warmup run: 2703it [00:04, 1131.97it/s]warmup run: 2791it [00:04, 1148.03it/s]warmup run: 3000it [00:04, 675.79it/s] warmup run: 2763it [00:04, 1163.84it/s]warmup run: 3000it [00:04, 686.81it/s] warmup run: 2919it [00:04, 1155.16it/s]warmup run: 3000it [00:04, 683.21it/s] warmup run: 2819it [00:04, 1138.55it/s]warmup run: 2910it [00:04, 1159.85it/s]warmup run: 2880it [00:04, 1165.36it/s]warmup run: 3000it [00:04, 673.88it/s] warmup run: 3000it [00:04, 681.11it/s] warmup run: 2937it [00:04, 1149.13it/s]warmup run: 2997it [00:04, 1160.66it/s]warmup run: 3000it [00:04, 697.87it/s] warmup run: 3000it [00:04, 684.77it/s] 
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]





warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|         | 160/3000 [00:00<00:01, 1596.97it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1637.34it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1618.15it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1614.01it/s]warmup should be done:   5%|         | 161/3000 [00:00<00:01, 1604.45it/s]warmup should be done:   5%|         | 158/3000 [00:00<00:01, 1574.61it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1620.49it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1613.53it/s]warmup should be done:  11%|         | 321/3000 [00:00<00:01, 1603.99it/s]warmup should be done:  11%|         | 326/3000 [00:00<00:01, 1630.04it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1646.12it/s]warmup should be done:  11%|         | 324/3000 [00:00<00:01, 1616.39it/s]warmup should be done:  11%|         | 326/3000 [00:00<00:01, 1623.26it/s]warmup should be done:  11%|         | 325/3000 [00:00<00:01, 1620.26it/s]warmup should be done:  11%|         | 326/3000 [00:00<00:01, 1623.69it/s]warmup should be done:  11%|         | 318/3000 [00:00<00:01, 1584.20it/s]warmup should be done:  16%|        | 490/3000 [00:00<00:01, 1630.13it/s]warmup should be done:  16%|        | 486/3000 [00:00<00:01, 1614.69it/s]warmup should be done:  16%|        | 495/3000 [00:00<00:01, 1643.22it/s]warmup should be done:  16%|        | 482/3000 [00:00<00:01, 1595.33it/s]warmup should be done:  16%|        | 489/3000 [00:00<00:01, 1620.20it/s]warmup should be done:  16%|        | 489/3000 [00:00<00:01, 1618.22it/s]warmup should be done:  16%|        | 477/3000 [00:00<00:01, 1580.05it/s]warmup should be done:  16%|        | 488/3000 [00:00<00:01, 1615.75it/s]warmup should be done:  22%|       | 654/3000 [00:00<00:01, 1629.06it/s]warmup should be done:  22%|       | 648/3000 [00:00<00:01, 1612.49it/s]warmup should be done:  22%|       | 660/3000 [00:00<00:01, 1639.93it/s]warmup should be done:  21%|       | 643/3000 [00:00<00:01, 1597.51it/s]warmup should be done:  22%|       | 651/3000 [00:00<00:01, 1614.97it/s]warmup should be done:  22%|       | 652/3000 [00:00<00:01, 1618.64it/s]warmup should be done:  22%|       | 650/3000 [00:00<00:01, 1612.36it/s]warmup should be done:  21%|        | 636/3000 [00:00<00:01, 1575.21it/s]warmup should be done:  27%|       | 817/3000 [00:00<00:01, 1628.85it/s]warmup should be done:  27%|       | 810/3000 [00:00<00:01, 1612.04it/s]warmup should be done:  27%|       | 803/3000 [00:00<00:01, 1598.35it/s]warmup should be done:  27%|       | 816/3000 [00:00<00:01, 1625.72it/s]warmup should be done:  27%|       | 824/3000 [00:00<00:01, 1633.53it/s]warmup should be done:  27%|       | 813/3000 [00:00<00:01, 1608.90it/s]warmup should be done:  27%|       | 812/3000 [00:00<00:01, 1606.07it/s]warmup should be done:  26%|       | 794/3000 [00:00<00:01, 1558.01it/s]warmup should be done:  33%|      | 980/3000 [00:00<00:01, 1624.25it/s]warmup should be done:  32%|      | 963/3000 [00:00<00:01, 1593.97it/s]warmup should be done:  33%|      | 979/3000 [00:00<00:01, 1622.92it/s]warmup should be done:  32%|      | 972/3000 [00:00<00:01, 1608.05it/s]warmup should be done:  32%|      | 974/3000 [00:00<00:01, 1604.93it/s]warmup should be done:  32%|      | 973/3000 [00:00<00:01, 1600.12it/s]warmup should be done:  33%|      | 988/3000 [00:00<00:01, 1621.01it/s]warmup should be done:  32%|      | 952/3000 [00:00<00:01, 1564.01it/s]warmup should be done:  38%|      | 1143/3000 [00:00<00:01, 1624.70it/s]warmup should be done:  37%|      | 1124/3000 [00:00<00:01, 1596.01it/s]warmup should be done:  38%|      | 1133/3000 [00:00<00:01, 1606.61it/s]warmup should be done:  38%|      | 1143/3000 [00:00<00:01, 1625.20it/s]warmup should be done:  38%|      | 1135/3000 [00:00<00:01, 1601.73it/s]warmup should be done:  38%|      | 1134/3000 [00:00<00:01, 1600.41it/s]warmup should be done:  38%|      | 1151/3000 [00:00<00:01, 1617.58it/s]warmup should be done:  37%|      | 1109/3000 [00:00<00:01, 1564.14it/s]warmup should be done:  44%|     | 1306/3000 [00:00<00:01, 1623.98it/s]warmup should be done:  44%|     | 1306/3000 [00:00<00:01, 1625.44it/s]warmup should be done:  43%|     | 1294/3000 [00:00<00:01, 1604.92it/s]warmup should be done:  43%|     | 1284/3000 [00:00<00:01, 1589.31it/s]warmup should be done:  43%|     | 1296/3000 [00:00<00:01, 1601.47it/s]warmup should be done:  43%|     | 1295/3000 [00:00<00:01, 1599.02it/s]warmup should be done:  44%|     | 1313/3000 [00:00<00:01, 1616.31it/s]warmup should be done:  42%|     | 1266/3000 [00:00<00:01, 1563.33it/s]warmup should be done:  49%|     | 1469/3000 [00:00<00:00, 1623.28it/s]warmup should be done:  48%|     | 1455/3000 [00:00<00:00, 1604.45it/s]warmup should be done:  49%|     | 1470/3000 [00:00<00:00, 1627.16it/s]warmup should be done:  48%|     | 1443/3000 [00:00<00:00, 1588.03it/s]warmup should be done:  49%|     | 1457/3000 [00:00<00:00, 1600.51it/s]warmup should be done:  48%|     | 1455/3000 [00:00<00:00, 1597.90it/s]warmup should be done:  47%|     | 1423/3000 [00:00<00:01, 1562.38it/s]warmup should be done:  49%|     | 1475/3000 [00:00<00:00, 1612.08it/s]warmup should be done:  54%|    | 1632/3000 [00:01<00:00, 1619.96it/s]warmup should be done:  54%|    | 1618/3000 [00:01<00:00, 1610.64it/s]warmup should be done:  54%|    | 1634/3000 [00:01<00:00, 1628.70it/s]warmup should be done:  53%|    | 1602/3000 [00:01<00:00, 1586.49it/s]warmup should be done:  54%|    | 1618/3000 [00:01<00:00, 1600.43it/s]warmup should be done:  54%|    | 1615/3000 [00:01<00:00, 1598.29it/s]warmup should be done:  53%|    | 1580/3000 [00:01<00:00, 1563.01it/s]warmup should be done:  55%|    | 1637/3000 [00:01<00:00, 1607.52it/s]warmup should be done:  60%|    | 1797/3000 [00:01<00:00, 1628.53it/s]warmup should be done:  59%|    | 1783/3000 [00:01<00:00, 1620.45it/s]warmup should be done:  59%|    | 1762/3000 [00:01<00:00, 1589.77it/s]warmup should be done:  60%|    | 1794/3000 [00:01<00:00, 1610.41it/s]warmup should be done:  59%|    | 1779/3000 [00:01<00:00, 1600.32it/s]warmup should be done:  59%|    | 1775/3000 [00:01<00:00, 1593.14it/s]warmup should be done:  58%|    | 1737/3000 [00:01<00:00, 1562.44it/s]warmup should be done:  60%|    | 1798/3000 [00:01<00:00, 1605.02it/s]warmup should be done:  65%|   | 1960/3000 [00:01<00:00, 1627.43it/s]warmup should be done:  65%|   | 1948/3000 [00:01<00:00, 1626.96it/s]warmup should be done:  64%|   | 1922/3000 [00:01<00:00, 1591.43it/s]warmup should be done:  65%|   | 1940/3000 [00:01<00:00, 1600.64it/s]warmup should be done:  65%|   | 1956/3000 [00:01<00:00, 1600.66it/s]warmup should be done:  63%|   | 1894/3000 [00:01<00:00, 1562.10it/s]warmup should be done:  64%|   | 1935/3000 [00:01<00:00, 1588.68it/s]warmup should be done:  65%|   | 1959/3000 [00:01<00:00, 1602.54it/s]warmup should be done:  71%|   | 2123/3000 [00:01<00:00, 1625.93it/s]warmup should be done:  70%|   | 2113/3000 [00:01<00:00, 1631.20it/s]warmup should be done:  69%|   | 2082/3000 [00:01<00:00, 1586.44it/s]warmup should be done:  70%|   | 2101/3000 [00:01<00:00, 1600.34it/s]warmup should be done:  70%|   | 2094/3000 [00:01<00:00, 1584.84it/s]warmup should be done:  68%|   | 2051/3000 [00:01<00:00, 1559.89it/s]warmup should be done:  71%|   | 2117/3000 [00:01<00:00, 1592.92it/s]warmup should be done:  71%|   | 2120/3000 [00:01<00:00, 1599.84it/s]warmup should be done:  76%|  | 2286/3000 [00:01<00:00, 1624.83it/s]warmup should be done:  76%|  | 2277/3000 [00:01<00:00, 1632.08it/s]warmup should be done:  75%|  | 2241/3000 [00:01<00:00, 1586.44it/s]warmup should be done:  75%|  | 2262/3000 [00:01<00:00, 1600.64it/s]warmup should be done:  74%|  | 2208/3000 [00:01<00:00, 1561.03it/s]warmup should be done:  75%|  | 2253/3000 [00:01<00:00, 1581.52it/s]warmup should be done:  76%|  | 2280/3000 [00:01<00:00, 1596.51it/s]warmup should be done:  76%|  | 2277/3000 [00:01<00:00, 1586.95it/s]warmup should be done:  82%| | 2450/3000 [00:01<00:00, 1626.48it/s]warmup should be done:  81%| | 2442/3000 [00:01<00:00, 1635.89it/s]warmup should be done:  80%|  | 2401/3000 [00:01<00:00, 1589.13it/s]warmup should be done:  81%|  | 2423/3000 [00:01<00:00, 1598.56it/s]warmup should be done:  79%|  | 2365/3000 [00:01<00:00, 1558.70it/s]warmup should be done:  80%|  | 2412/3000 [00:01<00:00, 1581.44it/s]warmup should be done:  81%| | 2440/3000 [00:01<00:00, 1596.86it/s]warmup should be done:  81%|  | 2436/3000 [00:01<00:00, 1585.40it/s]warmup should be done:  87%| | 2613/3000 [00:01<00:00, 1627.19it/s]warmup should be done:  87%| | 2607/3000 [00:01<00:00, 1637.98it/s]warmup should be done:  85%| | 2560/3000 [00:01<00:00, 1589.35it/s]warmup should be done:  86%| | 2584/3000 [00:01<00:00, 1599.50it/s]warmup should be done:  84%| | 2522/3000 [00:01<00:00, 1560.35it/s]warmup should be done:  86%| | 2571/3000 [00:01<00:00, 1581.20it/s]warmup should be done:  87%| | 2600/3000 [00:01<00:00, 1596.47it/s]warmup should be done:  86%| | 2595/3000 [00:01<00:00, 1584.06it/s]warmup should be done:  93%|| 2776/3000 [00:01<00:00, 1627.42it/s]warmup should be done:  92%|| 2771/3000 [00:01<00:00, 1637.44it/s]warmup should be done:  91%| | 2720/3000 [00:01<00:00, 1591.61it/s]warmup should be done:  92%|| 2745/3000 [00:01<00:00, 1599.73it/s]warmup should be done:  89%| | 2679/3000 [00:01<00:00, 1561.61it/s]warmup should be done:  91%| | 2730/3000 [00:01<00:00, 1580.87it/s]warmup should be done:  92%|| 2760/3000 [00:01<00:00, 1596.14it/s]warmup should be done:  92%|| 2754/3000 [00:01<00:00, 1583.24it/s]warmup should be done:  98%|| 2941/3000 [00:01<00:00, 1631.78it/s]warmup should be done:  98%|| 2937/3000 [00:01<00:00, 1642.16it/s]warmup should be done:  96%|| 2880/3000 [00:01<00:00, 1590.13it/s]warmup should be done:  97%|| 2907/3000 [00:01<00:00, 1604.99it/s]warmup should be done:  95%|| 2836/3000 [00:01<00:00, 1564.07it/s]warmup should be done:  97%|| 2922/3000 [00:01<00:00, 1602.72it/s]warmup should be done:  96%|| 2890/3000 [00:01<00:00, 1584.02it/s]warmup should be done:  97%|| 2914/3000 [00:01<00:00, 1586.60it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1626.68it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1620.93it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1610.26it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1604.76it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1604.22it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1592.66it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1592.44it/s]warmup should be done: 100%|| 2996/3000 [00:01<00:00, 1573.42it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1565.58it/s]




warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1648.81it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1614.44it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1644.72it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1664.70it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1645.02it/s]warmup should be done:   6%|         | 169/3000 [00:00<00:01, 1682.55it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1621.90it/s]warmup should be done:   5%|         | 160/3000 [00:00<00:01, 1592.00it/s]warmup should be done:  11%|         | 324/3000 [00:00<00:01, 1617.36it/s]warmup should be done:  11%|         | 331/3000 [00:00<00:01, 1652.01it/s]warmup should be done:  11%|         | 335/3000 [00:00<00:01, 1672.47it/s]warmup should be done:  11%|         | 331/3000 [00:00<00:01, 1651.01it/s]warmup should be done:  11%|        | 338/3000 [00:00<00:01, 1683.74it/s]warmup should be done:  11%|         | 323/3000 [00:00<00:01, 1612.52it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1642.68it/s]warmup should be done:  11%|         | 327/3000 [00:00<00:01, 1628.67it/s]warmup should be done:  16%|        | 486/3000 [00:00<00:01, 1617.59it/s]warmup should be done:  17%|        | 497/3000 [00:00<00:01, 1654.04it/s]warmup should be done:  17%|        | 504/3000 [00:00<00:01, 1678.22it/s]warmup should be done:  16%|        | 491/3000 [00:00<00:01, 1633.53it/s]warmup should be done:  17%|        | 498/3000 [00:00<00:01, 1656.12it/s]warmup should be done:  17%|        | 496/3000 [00:00<00:01, 1647.41it/s]warmup should be done:  16%|        | 487/3000 [00:00<00:01, 1620.82it/s]warmup should be done:  17%|        | 508/3000 [00:00<00:01, 1686.62it/s]warmup should be done:  22%|       | 672/3000 [00:00<00:01, 1678.45it/s]warmup should be done:  22%|       | 648/3000 [00:00<00:01, 1614.70it/s]warmup should be done:  22%|       | 663/3000 [00:00<00:01, 1653.39it/s]warmup should be done:  22%|       | 655/3000 [00:00<00:01, 1632.38it/s]warmup should be done:  22%|       | 662/3000 [00:00<00:01, 1650.23it/s]warmup should be done:  23%|       | 678/3000 [00:00<00:01, 1689.03it/s]warmup should be done:  22%|       | 664/3000 [00:00<00:01, 1652.50it/s]warmup should be done:  22%|       | 650/3000 [00:00<00:01, 1619.24it/s]warmup should be done:  28%|       | 840/3000 [00:00<00:01, 1677.26it/s]warmup should be done:  28%|       | 829/3000 [00:00<00:01, 1655.03it/s]warmup should be done:  28%|       | 828/3000 [00:00<00:01, 1652.74it/s]warmup should be done:  27%|       | 810/3000 [00:00<00:01, 1612.10it/s]warmup should be done:  27%|       | 819/3000 [00:00<00:01, 1630.99it/s]warmup should be done:  28%|       | 848/3000 [00:00<00:01, 1689.38it/s]warmup should be done:  27%|       | 814/3000 [00:00<00:01, 1624.37it/s]warmup should be done:  28%|       | 830/3000 [00:00<00:01, 1650.15it/s]warmup should be done:  34%|      | 1008/3000 [00:00<00:01, 1677.23it/s]warmup should be done:  33%|      | 996/3000 [00:00<00:01, 1657.69it/s]warmup should be done:  32%|      | 972/3000 [00:00<00:01, 1614.43it/s]warmup should be done:  33%|      | 994/3000 [00:00<00:01, 1654.36it/s]warmup should be done:  33%|      | 983/3000 [00:00<00:01, 1633.51it/s]warmup should be done:  33%|      | 978/3000 [00:00<00:01, 1629.38it/s]warmup should be done:  34%|      | 1018/3000 [00:00<00:01, 1690.02it/s]warmup should be done:  33%|      | 999/3000 [00:00<00:01, 1661.26it/s]warmup should be done:  39%|      | 1176/3000 [00:00<00:01, 1676.77it/s]warmup should be done:  39%|      | 1162/3000 [00:00<00:01, 1657.96it/s]warmup should be done:  38%|      | 1134/3000 [00:00<00:01, 1616.11it/s]warmup should be done:  39%|      | 1160/3000 [00:00<00:01, 1653.68it/s]warmup should be done:  38%|      | 1142/3000 [00:00<00:01, 1632.47it/s]warmup should be done:  38%|      | 1148/3000 [00:00<00:01, 1635.71it/s]warmup should be done:  40%|      | 1188/3000 [00:00<00:01, 1689.99it/s]warmup should be done:  39%|      | 1167/3000 [00:00<00:01, 1665.43it/s]warmup should be done:  45%|     | 1345/3000 [00:00<00:00, 1677.99it/s]warmup should be done:  44%|     | 1328/3000 [00:00<00:01, 1655.70it/s]warmup should be done:  44%|     | 1326/3000 [00:00<00:01, 1651.26it/s]warmup should be done:  43%|     | 1296/3000 [00:00<00:01, 1610.42it/s]warmup should be done:  44%|     | 1306/3000 [00:00<00:01, 1630.10it/s]warmup should be done:  45%|     | 1358/3000 [00:00<00:00, 1691.41it/s]warmup should be done:  44%|     | 1312/3000 [00:00<00:01, 1629.05it/s]warmup should be done:  44%|     | 1334/3000 [00:00<00:01, 1644.44it/s]warmup should be done:  50%|     | 1513/3000 [00:00<00:00, 1678.02it/s]warmup should be done:  50%|     | 1494/3000 [00:00<00:00, 1656.27it/s]warmup should be done:  49%|     | 1458/3000 [00:00<00:00, 1613.16it/s]warmup should be done:  50%|     | 1492/3000 [00:00<00:00, 1651.49it/s]warmup should be done:  51%|     | 1528/3000 [00:00<00:00, 1691.06it/s]warmup should be done:  49%|     | 1476/3000 [00:00<00:00, 1631.66it/s]warmup should be done:  49%|     | 1470/3000 [00:00<00:00, 1626.61it/s]warmup should be done:  50%|     | 1499/3000 [00:00<00:00, 1629.59it/s]warmup should be done:  55%|    | 1660/3000 [00:01<00:00, 1657.38it/s]warmup should be done:  56%|    | 1682/3000 [00:01<00:00, 1678.98it/s]warmup should be done:  54%|    | 1621/3000 [00:01<00:00, 1615.31it/s]warmup should be done:  55%|    | 1659/3000 [00:01<00:00, 1654.44it/s]warmup should be done:  57%|    | 1698/3000 [00:01<00:00, 1691.53it/s]warmup should be done:  54%|    | 1633/3000 [00:01<00:00, 1626.95it/s]warmup should be done:  55%|    | 1641/3000 [00:01<00:00, 1634.49it/s]warmup should be done:  56%|    | 1665/3000 [00:01<00:00, 1637.45it/s]warmup should be done:  61%|    | 1827/3000 [00:01<00:00, 1658.64it/s]warmup should be done:  62%|   | 1851/3000 [00:01<00:00, 1679.78it/s]warmup should be done:  61%|    | 1825/3000 [00:01<00:00, 1655.80it/s]warmup should be done:  59%|    | 1783/3000 [00:01<00:00, 1613.07it/s]warmup should be done:  62%|   | 1868/3000 [00:01<00:00, 1692.47it/s]warmup should be done:  60%|    | 1796/3000 [00:01<00:00, 1625.56it/s]warmup should be done:  60%|    | 1805/3000 [00:01<00:00, 1632.68it/s]warmup should be done:  61%|    | 1831/3000 [00:01<00:00, 1643.17it/s]warmup should be done:  67%|   | 2019/3000 [00:01<00:00, 1679.70it/s]warmup should be done:  66%|   | 1993/3000 [00:01<00:00, 1656.33it/s]warmup should be done:  66%|   | 1991/3000 [00:01<00:00, 1654.14it/s]warmup should be done:  65%|   | 1945/3000 [00:01<00:00, 1611.77it/s]warmup should be done:  68%|   | 2038/3000 [00:01<00:00, 1692.42it/s]warmup should be done:  65%|   | 1959/3000 [00:01<00:00, 1626.24it/s]warmup should be done:  66%|   | 1969/3000 [00:01<00:00, 1631.37it/s]warmup should be done:  67%|   | 1998/3000 [00:01<00:00, 1651.15it/s]warmup should be done:  73%|  | 2187/3000 [00:01<00:00, 1678.12it/s]warmup should be done:  72%|  | 2159/3000 [00:01<00:00, 1654.61it/s]warmup should be done:  72%|  | 2157/3000 [00:01<00:00, 1653.40it/s]warmup should be done:  70%|   | 2107/3000 [00:01<00:00, 1613.91it/s]warmup should be done:  71%|   | 2123/3000 [00:01<00:00, 1629.97it/s]warmup should be done:  74%|  | 2208/3000 [00:01<00:00, 1691.03it/s]warmup should be done:  71%|   | 2133/3000 [00:01<00:00, 1632.29it/s]warmup should be done:  72%|  | 2166/3000 [00:01<00:00, 1658.12it/s]warmup should be done:  79%|  | 2356/3000 [00:01<00:00, 1679.00it/s]warmup should be done:  78%|  | 2325/3000 [00:01<00:00, 1655.45it/s]warmup should be done:  77%|  | 2323/3000 [00:01<00:00, 1654.99it/s]warmup should be done:  76%|  | 2269/3000 [00:01<00:00, 1614.22it/s]warmup should be done:  76%|  | 2286/3000 [00:01<00:00, 1626.55it/s]warmup should be done:  79%|  | 2378/3000 [00:01<00:00, 1690.15it/s]warmup should be done:  77%|  | 2297/3000 [00:01<00:00, 1633.82it/s]warmup should be done:  78%|  | 2335/3000 [00:01<00:00, 1664.71it/s]warmup should be done:  84%| | 2525/3000 [00:01<00:00, 1679.92it/s]warmup should be done:  83%| | 2492/3000 [00:01<00:00, 1656.95it/s]warmup should be done:  83%| | 2489/3000 [00:01<00:00, 1655.06it/s]warmup should be done:  81%|  | 2431/3000 [00:01<00:00, 1611.92it/s]warmup should be done:  82%| | 2449/3000 [00:01<00:00, 1625.41it/s]warmup should be done:  85%| | 2548/3000 [00:01<00:00, 1690.71it/s]warmup should be done:  82%| | 2461/3000 [00:01<00:00, 1632.44it/s]warmup should be done:  83%| | 2503/3000 [00:01<00:00, 1668.89it/s]warmup should be done:  90%| | 2693/3000 [00:01<00:00, 1679.76it/s]warmup should be done:  89%| | 2658/3000 [00:01<00:00, 1655.80it/s]warmup should be done:  88%| | 2655/3000 [00:01<00:00, 1652.63it/s]warmup should be done:  87%| | 2612/3000 [00:01<00:00, 1626.30it/s]warmup should be done:  86%| | 2593/3000 [00:01<00:00, 1611.43it/s]warmup should be done:  91%| | 2718/3000 [00:01<00:00, 1692.77it/s]warmup should be done:  88%| | 2625/3000 [00:01<00:00, 1629.59it/s]warmup should be done:  89%| | 2670/3000 [00:01<00:00, 1669.00it/s]warmup should be done:  95%|| 2861/3000 [00:01<00:00, 1678.12it/s]warmup should be done:  94%|| 2824/3000 [00:01<00:00, 1656.26it/s]warmup should be done:  94%|| 2821/3000 [00:01<00:00, 1652.44it/s]warmup should be done:  93%|| 2777/3000 [00:01<00:00, 1630.38it/s]warmup should be done:  92%|| 2756/3000 [00:01<00:00, 1614.41it/s]warmup should be done:  96%|| 2888/3000 [00:01<00:00, 1692.76it/s]warmup should be done:  93%|| 2789/3000 [00:01<00:00, 1631.46it/s]warmup should be done:  95%|| 2837/3000 [00:01<00:00, 1668.66it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1690.67it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1678.06it/s]warmup should be done: 100%|| 2991/3000 [00:01<00:00, 1657.77it/s]warmup should be done: 100%|| 2987/3000 [00:01<00:00, 1653.81it/s]warmup should be done:  97%|| 2918/3000 [00:01<00:00, 1614.92it/s]warmup should be done:  98%|| 2942/3000 [00:01<00:00, 1633.52it/s]warmup should be done:  98%|| 2953/3000 [00:01<00:00, 1633.47it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1657.66it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1655.93it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1652.50it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1631.85it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1626.94it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1613.64it/s]2022-12-12 03:44:15.688884: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f51d002fff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:44:15.688952: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:44:16.745875: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f52200300f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:44:16.745939: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:44:16.760522: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f526802cc60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:44:16.760579: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:44:16.874862: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f6faf8304e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:44:16.874928: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:44:17.099357: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f52680288a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:44:17.099428: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:44:17.229698: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f520002d1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:44:17.229768: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:44:17.246933: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f6fabf93110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:44:17.246997: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:44:17.248687: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f6fb782c400 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:44:17.248763: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:44:17.888691: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:44:19.023723: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:44:19.075190: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:44:19.183289: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:44:19.434970: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:44:19.511870: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:44:19.518755: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:44:19.557840: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:44:20.756096: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:44:21.935671: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:44:21.948925: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:44:22.132774: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:44:22.333261: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:44:22.383601: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:44:22.398645: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:44:22.452755: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][03:44:48.332][ERROR][RK0][main]: replica 6 reaches 1000, calling init pre replica
[HCTR][03:44:48.332][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:44:48.338][ERROR][RK0][main]: coll ps creation done
[HCTR][03:44:48.338][ERROR][RK0][main]: replica 6 waits for coll ps creation barrier
[HCTR][03:44:48.404][ERROR][RK0][main]: replica 7 reaches 1000, calling init pre replica
[HCTR][03:44:48.404][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:44:48.412][ERROR][RK0][main]: coll ps creation done
[HCTR][03:44:48.412][ERROR][RK0][main]: replica 7 waits for coll ps creation barrier
[HCTR][03:44:48.445][ERROR][RK0][main]: replica 4 reaches 1000, calling init pre replica
[HCTR][03:44:48.445][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:44:48.450][ERROR][RK0][main]: coll ps creation done
[HCTR][03:44:48.450][ERROR][RK0][main]: replica 4 waits for coll ps creation barrier
[HCTR][03:44:48.457][ERROR][RK0][main]: replica 1 reaches 1000, calling init pre replica
[HCTR][03:44:48.458][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:44:48.463][ERROR][RK0][main]: coll ps creation done
[HCTR][03:44:48.463][ERROR][RK0][main]: replica 1 waits for coll ps creation barrier
[HCTR][03:44:48.463][ERROR][RK0][tid #140118467798784]: replica 5 reaches 1000, calling init pre replica
[HCTR][03:44:48.463][ERROR][RK0][tid #140118467798784]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:44:48.463][ERROR][RK0][main]: replica 0 reaches 1000, calling init pre replica
[HCTR][03:44:48.464][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:44:48.467][ERROR][RK0][main]: replica 2 reaches 1000, calling init pre replica
[HCTR][03:44:48.467][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:44:48.467][ERROR][RK0][main]: coll ps creation done
[HCTR][03:44:48.467][ERROR][RK0][main]: replica 0 waits for coll ps creation barrier
[HCTR][03:44:48.468][ERROR][RK0][tid #140118467798784]: coll ps creation done
[HCTR][03:44:48.468][ERROR][RK0][tid #140118467798784]: replica 5 waits for coll ps creation barrier
[HCTR][03:44:48.470][ERROR][RK0][tid #140118526514944]: replica 3 reaches 1000, calling init pre replica
[HCTR][03:44:48.470][ERROR][RK0][tid #140118526514944]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:44:48.472][ERROR][RK0][main]: coll ps creation done
[HCTR][03:44:48.472][ERROR][RK0][main]: replica 2 waits for coll ps creation barrier
[HCTR][03:44:48.477][ERROR][RK0][tid #140118526514944]: coll ps creation done
[HCTR][03:44:48.477][ERROR][RK0][tid #140118526514944]: replica 3 waits for coll ps creation barrier
[HCTR][03:44:48.477][ERROR][RK0][main]: replica 0 preparing frequency
[HCTR][03:44:49.361][ERROR][RK0][main]: replica 0 preparing frequency done
[HCTR][03:44:49.407][ERROR][RK0][main]: replica 0 calling init per replica
[HCTR][03:44:49.407][ERROR][RK0][tid #140118526514944]: replica 3 calling init per replica
[HCTR][03:44:49.407][ERROR][RK0][main]: replica 2 calling init per replica
[HCTR][03:44:49.407][ERROR][RK0][main]: replica 1 calling init per replica
[HCTR][03:44:49.407][ERROR][RK0][main]: replica 6 calling init per replica
[HCTR][03:44:49.407][ERROR][RK0][main]: replica 7 calling init per replica
[HCTR][03:44:49.407][ERROR][RK0][main]: replica 4 calling init per replica
[HCTR][03:44:49.407][ERROR][RK0][tid #140118467798784]: replica 5 calling init per replica
[HCTR][03:44:49.407][ERROR][RK0][main]: Calling build_v2
[HCTR][03:44:49.407][ERROR][RK0][tid #140118526514944]: Calling build_v2
[HCTR][03:44:49.407][ERROR][RK0][main]: Calling build_v2
[HCTR][03:44:49.407][ERROR][RK0][main]: Calling build_v2
[HCTR][03:44:49.407][ERROR][RK0][main]: Calling build_v2
[HCTR][03:44:49.407][ERROR][RK0][main]: Calling build_v2
[HCTR][03:44:49.407][ERROR][RK0][main]: Calling build_v2
[HCTR][03:44:49.407][ERROR][RK0][tid #140118467798784]: Calling build_v2
[HCTR][03:44:49.407][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:44:49.407][ERROR][RK0][tid #140118526514944]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:44:49.407][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:44:49.407][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:44:49.407][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:44:49.407][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:44:49.407][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:44:49.407][ERROR][RK0][tid #140118467798784]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[[[[[[2022-12-12 03:44:492022-12-12 03:44:492022-12-12 03:44:492022-12-12 03:44:49[.2022-12-12 03:44:49..2022-12-12 03:44:49.4073492022-12-12 03:44:49.407354407346.407346: .407345: : 407361: [E407361: EE: E : 2022-12-12 03:44:49E  E /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.ccE. /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc: 407441/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc::/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc:136/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc: :136136:136] :E136] ] 136] using concurrent impl MPS136 ] using concurrent impl MPSusing concurrent impl MPS] using concurrent impl MPS
] /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.ccusing concurrent impl MPS

using concurrent impl MPS
using concurrent impl MPS:


136] using concurrent impl MPS
[2022-12-12 03:44:49.411798: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[2022-12-12 03:44:49.411835: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] [assigning 8 to cpu2022-12-12 03:44:49
.411847: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[2022-12-12 03:44:49.411888: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] assigning 8 to cpu[
[2022-12-12 03:44:492022-12-12 03:44:49..411896411912: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc::[178[2122022-12-12 03:44:49] 2022-12-12 03:44:49] .v100x8, slow pcie.build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8411943
411939
: : [EE2022-12-12 03:44:49  .[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc411979[2022-12-12 03:44:49::: 2022-12-12 03:44:49.212178E.411983] ]  411994: build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8v100x8, slow pcie/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: E

:E [[196 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 03:44:49[2022-12-12 03:44:49] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:.2022-12-12 03:44:49.assigning 8 to cpu:178412050.[412038
213] : v100x8, slow pcie4120562022-12-12 03:44:49: ] E
: .Eremote time is 8.68421 E412084[ 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc [: [2022-12-12 03:44:49/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[2022-12-12 03:44:49E2022-12-12 03:44:49.:196:2022-12-12 03:44:49. .412140178] 213.412145/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc412158: ] assigning 8 to cpu] 412171: :: Ev100x8, slow pcie
remote time is 8.68421: E178E 

E ]  /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[[v100x8, slow pcie/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 03:44:49:2022-12-12 03:44:492022-12-12 03:44:49
:196:[.178..212] 2142022-12-12 03:44:49412319] 412322412324] assigning 8 to cpu] .: v100x8, slow pcie: : build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8
cpu time is 97.0588412384E
EE

:    [E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 03:44:49 :[2022-12-12 03:44:49::./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc1962022-12-12 03:44:49.214212412465:] .412475] ] : 196assigning 8 to cpu412489: cpu time is 97.0588build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E] 
: E

 assigning 8 to cpuE /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
[ /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:2022-12-12 03:44:49/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196.:213] 412614[212] assigning 8 to cpu: 2022-12-12 03:44:49] remote time is 8.68421
E[.build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8
 2022-12-12 03:44:49412643
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.[: :412671[2022-12-12 03:44:49E213: 2022-12-12 03:44:49.[ ] E.4127042022-12-12 03:44:49/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421 412720: .:
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: E412737212:E[ : ] 212 2022-12-12 03:44:49/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccEbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.: 
build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8:412828214/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
213: ] :[] Ecpu time is 97.0588212[2022-12-12 03:44:49remote time is 8.68421 
] 2022-12-12 03:44:49.
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8.[412907:
4129242022-12-12 03:44:49: 214: .E] [E412971 cpu time is 97.05882022-12-12 03:44:49 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE:413002: 213: 213/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] E] :remote time is 8.68421 remote time is 8.68421214
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
] :[cpu time is 97.0588[2132022-12-12 03:44:49
2022-12-12 03:44:49] ..remote time is 8.68421413148413155
: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[::2022-12-12 03:44:49214214.] ] 413221cpu time is 97.0588cpu time is 97.0588: 

E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:214] cpu time is 97.0588
[2022-12-12 03:46:08. 12044: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-12 03:46:08. 52190: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-12 03:46:08. 52257: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 15000000
[2022-12-12 03:46:08.162788: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-12 03:46:08.162876: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-12 03:46:08.307274: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-12 03:46:08.307339: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-12 03:46:08.307806: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.308653: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.309299: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.322408: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 4 solved
[2022-12-12 03:46:08.322471: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 4 initing device 4
[2022-12-12 03:46:08.322569: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 2 solved
[2022-12-12 03:46:08.322651: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 2 initing device 2
[2022-12-12 03:46:08.322872: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.323017: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 1 solved
[2022-12-12 03:46:08.323072: [E2022-12-12 03:46:08 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc323076:: 205E]  worker 0 thread 1 initing device 1/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.323168: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 3 solved
[2022-12-12 03:46:08.323220: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 3 initing device 3
[2022-12-12 03:46:08.323300: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 7 solved
[2022-12-12 03:46:08.323361: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 7 initing device 7
[2022-12-12 03:46:08.323500: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.323587: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.323752: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.323902: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 5 solved
[2022-12-12 03:46:08.323982: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 5 initing device 5
[2022-12-12 03:46:08.324508: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.326417: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 6 solved
[2022-12-12 03:46:08.326498: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 6 initing device 6
[2022-12-12 03:46:08.326535: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.326955: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.327062: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.327515: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.327659: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.327720: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.329095: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.331464: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.331806: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.331949: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.332465: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.332547: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.332610: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.333108: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:46:08.336823: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[[2022-12-12 03:46:082022-12-12 03:46:08..413907413907: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes

[[2022-12-12 03:46:082022-12-12 03:46:08..414297414299: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 1024.00 Byteseager alloc mem 1024.00 Bytes

[2022-12-12 03:46:08.414533: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 03:46:08.414844: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 03:46:08.414881: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 03:46:08.415198: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 03:46:08.419846: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 03:46:08.419923: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 03:46:08.419969: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:46:08.420172: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 03:46:08.420243: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 03:46:08] .eager release cuda mem 2420244
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 03:46:08.420299: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 4000000002022-12-12 03:46:08
.420318: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 03:46:08.420367: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:46:08.420436: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 03:46:08.420500: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 03:46:08.420547: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:46:08.420771: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[[2022-12-12 03:46:082022-12-12 03:46:08[..4212032022-12-12 03:46:08421203: .: E421247E :  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: :1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980] :] eager alloc mem 2.00 Bytes1980eager alloc mem 2.00 Bytes
] 
eager alloc mem 2.00 Bytes
[[2022-12-12 03:46:08[2022-12-12 03:46:08.2022-12-12 03:46:08.421584.421584: 421589: E: E E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980:1980] 1980] eager alloc mem 1024.00 Bytes] eager alloc mem 1024.00 Bytes
eager alloc mem 1024.00 Bytes

[2022-12-12 03:46:08.421867: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:46:08.422389: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:46:08.422892: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:46:08.423365: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:08.423835: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:08.423871: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:08.424401: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:08.424490: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:46:08.424863: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:08.424894: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:08.424948: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:46:08.424977: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:46:08.425156: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:46:08.425196: [E2022-12-12 03:46:08 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu425195:: 1980E]  eager alloc mem 7.15 GB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:08.425618: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:46:08.425644: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 03:46:08:.638425657] : eager release cuda mem 25855E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[2022-12-12 03:46:08.425701: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[2022-12-12 03:46:08.426233: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:08.426316: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:46:08.426986: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:46:08.426994: [E2022-12-12 03:46:08 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc427028:: 638E]  eager release cuda mem 1024/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
[:2022-12-12 03:46:081980.] 427064eager alloc mem 7.15 GB[: 
2022-12-12 03:46:08E. 427107/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:eager release cuda mem 1024638
] eager release cuda mem 2
[[2022-12-12 03:46:082022-12-12 03:46:08[..2022-12-12 03:46:08427170427189.: : 427193EE:   E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc ::/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638638:] ] 638eager release cuda mem 1024eager release cuda mem 2] 

eager release cuda mem 400000000
[2022-12-12 03:46:08[.2022-12-12 03:46:08427278.: 427280E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 400000000] 
eager release cuda mem 2
[2022-12-12 03:46:08.427345: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:46:08.443455: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 03:46:08.443759: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 03:46:08.459443: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:46:08.459954: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:46:08.460460: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:46:08.462617: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 03:46:08.462692: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 03:46:08.462735: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:46:08.468363: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:08.468440: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:08.468743: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:08.469299: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:46:08.469382: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:08.[4694672022-12-12 03:46:08: .E469470 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager alloc mem 25.25 KB638
] eager release cuda mem 625663
[2022-12-12 03:46:08.469578: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:46:08.469773: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:08.469863: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:46:08.470103: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:08.470154: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:46:08.470196: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[2022-12-12 03:46:08.470246: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:46:08.470286: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[2022-12-12 03:46:08.470535: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:46:08.470576: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[2022-12-12 03:46:08.471125: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:08.471228: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:46:08.471900: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:46:08.471941: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[[[[[[[[2022-12-12 03:46:092022-12-12 03:46:092022-12-12 03:46:092022-12-12 03:46:092022-12-12 03:46:092022-12-12 03:46:092022-12-12 03:46:092022-12-12 03:46:09........937206937206937206937206937222937206937206937208: : : : : : : : EEEEEEEE        /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:::::::1980] :198019801980198019801980eager alloc mem 611.00 KB1980] ] ] ] ] ] 
] eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB






[2022-12-12 03:46:09.938449: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 6256632022-12-12 03:46:09
.938471: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[2022-12-12 03:46:09[:2022-12-12 03:46:09[[.2022-12-12 03:46:09638[.2022-12-12 03:46:092022-12-12 03:46:09938486.] 2022-12-12 03:46:09[938493..: 938504eager release cuda mem 625663.2022-12-12 03:46:09: 938500938501E: 
938510.E: :  E: 938538 EE/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc  :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc E:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc 638::] 6382022-12-12 03:46:09:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] 638638eager release cuda mem 625663] .638:eager release cuda mem 625663] ] 
eager release cuda mem 625663938649] 1980
eager release cuda mem 625663eager release cuda mem 625663
: eager release cuda mem 625663] 

E
eager alloc mem 611.00 KB 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.938777: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:[19802022-12-12 03:46:09] [[.eager alloc mem 611.00 KB[2022-12-12 03:46:092022-12-12 03:46:09[938794
2022-12-12 03:46:09..2022-12-12 03:46:09: .938802938811.E938813: : 938818 : EE: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE  E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :19801980:eager alloc mem 611.00 KB1980] ] 1980
] eager alloc mem 611.00 KBeager alloc mem 611.00 KB] eager alloc mem 611.00 KB

eager alloc mem 611.00 KB

[2022-12-12 03:46:09.939501[: 2022-12-12 03:46:09E. 939509/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663:
638] eager release cuda mem 625663
[2022-12-12 03:46:09.939569: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] [2022-12-12 03:46:09eager release cuda mem 6256632022-12-12 03:46:09.
.939591939597: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KB

[2022-12-12 03:46:09.939674: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.939700: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[638[2022-12-12 03:46:09] [2022-12-12 03:46:09.[eager release cuda mem 6256632022-12-12 03:46:09.9397172022-12-12 03:46:09
.939723: .939728: E939735: E : E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 03:46:09:638] :.638] eager release cuda mem 625663638939821] eager release cuda mem 625663
] : eager release cuda mem 625663
eager release cuda mem 625663E

 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.939934: [E[2022-12-12 03:46:09 2022-12-12 03:46:09[./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.2022-12-12 03:46:09939946:939955.: 1980: 939961E] E:  eager alloc mem 611.00 KB E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu ::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu19801980:] ] 1980eager alloc mem 611.00 KBeager alloc mem 611.00 KB] 

eager alloc mem 611.00 KB
[[2022-12-12 03:46:092022-12-12 03:46:09..940391940394: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] [] eager release cuda mem 6256632022-12-12 03:46:09eager release cuda mem 625663
.
940428: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:09[.2022-12-12 03:46:09940500.: 940504E:  E[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 2022-12-12 03:46:09:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.1980:940523] 1980: eager alloc mem 611.00 KB] E
eager alloc mem 611.00 KB
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.940656: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:09.940730: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.940775: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[[2022-12-12 03:46:092022-12-12 03:46:09..940829940831: [[: E2022-12-12 03:46:092022-12-12 03:46:09E .. /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc940843940847/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:: : :638EE638]   ] eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 625663
::
6381980] ] eager release cuda mem 625663eager alloc mem 611.00 KB

[2022-12-12 03:46:09.940997: [E2022-12-12 03:46:09 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu941007:: 1980E]  eager alloc mem 611.00 KB[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
2022-12-12 03:46:09:.1980941030] : eager alloc mem 611.00 KBE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.[9413192022-12-12 03:46:09: .E[941324 2022-12-12 03:46:09: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.E:941332 638: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] E:eager release cuda mem 625663 638
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 625663638
] eager release cuda mem 625663
[2022-12-12 03:46:09.941451: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 03:46:09eager alloc mem 611.00 KB.[
941471[2022-12-12 03:46:09: 2022-12-12 03:46:09.E.941478 941484: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: E:E 1980 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:eager alloc mem 611.00 KB:1980
638] ] eager alloc mem 611.00 KBeager release cuda mem 625663

[2022-12-12 03:46:09.941656: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.941713: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[[2022-12-12 03:46:092022-12-12 03:46:09..941780941783: : EE [ /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 03:46:09/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:.:[63894180319802022-12-12 03:46:09] : ] .eager release cuda mem 625663Eeager alloc mem 611.00 KB941819
 
: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 625663638
] [eager release cuda mem 6256632022-12-12 03:46:09
.941909: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.941956: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 611.00 KB2022-12-12 03:46:09
.941973: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.942216: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:09.942284: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.942319: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 03:46:09] .eager release cuda mem 625663942335
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:09[.2022-12-12 03:46:09942405.: 942408[E: 2022-12-12 03:46:09 E./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 942421:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: 1980:E] 638 eager alloc mem 611.00 KB] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
eager release cuda mem 625663:
1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.942559: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.942608: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[[2022-12-12 03:46:092022-12-12 03:46:09..942677942679: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::6381980] [] eager release cuda mem 6256632022-12-12 03:46:09eager alloc mem 611.00 KB
.
942714: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 03:46:09:.638942737] : eager release cuda mem 625663E
[ 2022-12-12 03:46:09/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:942773638: ] Eeager release cuda mem 625663 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 03:46:091980.] 942820eager alloc mem 611.00 KB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.942864: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.943032: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:09.943099: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.943232: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 03:46:09] .eager release cuda mem 625663943248
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[[2022-12-12 03:46:092022-12-12 03:46:09..943321943320[: : 2022-12-12 03:46:09EE.  943337/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: ::E1980638 ] ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 611.00 KBeager release cuda mem 625663:

1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.943460: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 03:46:09] .eager release cuda mem 625663943475
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.943546: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 611.00 KB2022-12-12 03:46:09
.943566[: 2022-12-12 03:46:09E. 943578/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663:
638] [eager release cuda mem 6256632022-12-12 03:46:09
.943627: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:09.943676: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 03:46:091980.] 943694eager alloc mem 611.00 KB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 03:46:091980.] 943718eager alloc mem 611.00 KB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:46:09.943856: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:46:09.943895: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 60400000
[2022-12-12 03:46:09.944153[: 2022-12-12 03:46:09E. 944160/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663:
638] eager release cuda mem 625663
[2022-12-12 03:46:09.944237[: [2022-12-12 03:46:09E2022-12-12 03:46:09. .944244/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc944247: :: E638E ] [ /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 604000002022-12-12 03:46:09/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:
.:638944305638[] : ] 2022-12-12 03:46:09eager release cuda mem 60400000Eeager release cuda mem 625663.
 
944352/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638[ ] 2022-12-12 03:46:09/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[eager release cuda mem 625663.:2022-12-12 03:46:09
9444181793.: ] 944440E[[Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62129 secs :  2022-12-12 03:46:092022-12-12 03:46:09
[E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc..2022-12-12 03:46:09 :944473944476./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638: : 944494:] EE: E 638eager release cuda mem 60400000  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:eager release cuda mem 625663::638
638638] ] ] [eager release cuda mem 625663eager release cuda mem 60400000eager release cuda mem 6256632022-12-12 03:46:09


.944667: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[638[2022-12-12 03:46:09] 2022-12-12 03:46:09.eager release cuda mem 60400000.944702
944706: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 60400000eager release cuda mem 60400000

[2022-12-12 03:46:09.945234: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62149 secs 
[2022-12-12 03:46:09.945507: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62201 secs 
[2022-12-12 03:46:09.946355: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62186 secs 
[2022-12-12 03:46:09.946827: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62396 secs 
[2022-12-12 03:46:09.946984: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.61993 secs 
[2022-12-12 03:46:09.947454: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62387 secs 
[2022-12-12 03:46:09.948148: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.64036 secs 
[2022-12-12 03:46:09.949157: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 13.79 GB
[2022-12-12 03:46:11.289643: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 14.05 GB
[2022-12-12 03:46:11.290354: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 14.05 GB
[2022-12-12 03:46:11.292435: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 14.05 GB
[2022-12-12 03:46:12.786423: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 14.32 GB
[2022-12-12 03:46:12.787336: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 14.32 GB
[2022-12-12 03:46:12.792382: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 14.32 GB
[2022-12-12 03:46:14.  3768: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 14.53 GB
[2022-12-12 03:46:14.  3892: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 14.53 GB
[2022-12-12 03:46:14.  4171: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 14.53 GB
[2022-12-12 03:46:16.240764: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 14.75 GB
[2022-12-12 03:46:16.241599: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 14.75 GB
[2022-12-12 03:46:16.242447: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 14.75 GB
[2022-12-12 03:46:17.720867: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 15.20 GB
[2022-12-12 03:46:17.721559: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 15.20 GB
[2022-12-12 03:46:17.722748: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 15.20 GB
[2022-12-12 03:46:18.948278: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 15.40 GB
[2022-12-12 03:46:18.948430: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 15.40 GB
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier
[HCTR][03:46:18.985][ERROR][RK0][tid #140118467798784]: replica 5 calling init per replica done, doing barrier
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier
[HCTR][03:46:18.985][ERROR][RK0][tid #140118526514944]: replica 3 calling init per replica done, doing barrier
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier done
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier done
[HCTR][03:46:18.985][ERROR][RK0][tid #140118467798784]: replica 5 calling init per replica done, doing barrier done
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier done
[HCTR][03:46:18.985][ERROR][RK0][main]: init per replica done
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier done
[HCTR][03:46:18.985][ERROR][RK0][tid #140118526514944]: replica 3 calling init per replica done, doing barrier done
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier done
[HCTR][03:46:18.985][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier done
[HCTR][03:46:18.985][ERROR][RK0][main]: init per replica done
[HCTR][03:46:18.985][ERROR][RK0][main]: init per replica done
[HCTR][03:46:18.985][ERROR][RK0][tid #140118467798784]: init per replica done
[HCTR][03:46:18.985][ERROR][RK0][main]: init per replica done
[HCTR][03:46:18.985][ERROR][RK0][tid #140118526514944]: init per replica done
[HCTR][03:46:18.985][ERROR][RK0][main]: init per replica done
[HCTR][03:46:18.988][ERROR][RK0][main]: init per replica done
[HCTR][03:46:18.991][ERROR][RK0][main]: 6 allocated 3276800 at 0x7f71a2120000
[HCTR][03:46:18.991][ERROR][RK0][main]: 4 allocated 3276800 at 0x7f71a0120000
[HCTR][03:46:18.991][ERROR][RK0][main]: 6 allocated 6553600 at 0x7f71a2600000
[HCTR][03:46:18.991][ERROR][RK0][main]: 4 allocated 6553600 at 0x7f71a0600000
[HCTR][03:46:18.991][ERROR][RK0][main]: 6 allocated 3276800 at 0x7f71a2c40000
[HCTR][03:46:18.991][ERROR][RK0][main]: 4 allocated 3276800 at 0x7f71a0c40000
[HCTR][03:46:18.991][ERROR][RK0][main]: 6 allocated 6553600 at 0x7f71a2f60000
[HCTR][03:46:18.991][ERROR][RK0][main]: 4 allocated 6553600 at 0x7f71a0f60000
[HCTR][03:46:18.991][ERROR][RK0][main]: 3 allocated 3276800 at 0x7f71a2120000
[HCTR][03:46:18.991][ERROR][RK0][main]: 3 allocated 6553600 at 0x7f71a2600000
[HCTR][03:46:18.991][ERROR][RK0][main]: 7 allocated 3276800 at 0x7f71a2120000
[HCTR][03:46:18.991][ERROR][RK0][main]: 3 allocated 3276800 at 0x7f71a2c40000
[HCTR][03:46:18.991][ERROR][RK0][main]: 7 allocated 6553600 at 0x7f71a2600000
[HCTR][03:46:18.991][ERROR][RK0][main]: 3 allocated 6553600 at 0x7f71a2f60000
[HCTR][03:46:18.991][ERROR][RK0][main]: 7 allocated 3276800 at 0x7f71a2c40000
[HCTR][03:46:18.991][ERROR][RK0][main]: 7 allocated 6553600 at 0x7f71a2f60000
[HCTR][03:46:18.991][ERROR][RK0][tid #140118467798784]: 5 allocated 3276800 at 0x7f71a2120000
[HCTR][03:46:18.991][ERROR][RK0][tid #140118467798784]: 5 allocated 6553600 at 0x7f71a2600000
[HCTR][03:46:18.991][ERROR][RK0][tid #140118467798784]: 5 allocated 3276800 at 0x7f71a2c40000
[HCTR][03:46:18.991][ERROR][RK0][tid #140118467798784]: 5 allocated 6553600 at 0x7f71a2f60000
[HCTR][03:46:18.991][ERROR][RK0][main]: 1 allocated 3276800 at 0x7f71a2120000
[HCTR][03:46:18.991][ERROR][RK0][main]: 1 allocated 6553600 at 0x7f71a2600000
[HCTR][03:46:18.991][ERROR][RK0][main]: 1 allocated 3276800 at 0x7f71a2c40000
[HCTR][03:46:18.991][ERROR][RK0][main]: 1 allocated 6553600 at 0x7f71a2f60000
[HCTR][03:46:18.991][ERROR][RK0][tid #140117922535168]: 2 allocated 3276800 at 0x7f71a2120000
[HCTR][03:46:18.991][ERROR][RK0][tid #140117922535168]: 2 allocated 6553600 at 0x7f71a2600000
[HCTR][03:46:18.991][ERROR][RK0][tid #140117922535168]: 2 allocated 3276800 at 0x7f71a2c40000
[HCTR][03:46:18.991][ERROR][RK0][tid #140117922535168]: 2 allocated 6553600 at 0x7f71a2f60000
[HCTR][03:46:18.994][ERROR][RK0][tid #140118065145600]: 0 allocated 3276800 at 0x7f71a4720000
[HCTR][03:46:18.994][ERROR][RK0][tid #140118065145600]: 0 allocated 6553600 at 0x7f71a4c00000
[HCTR][03:46:18.994][ERROR][RK0][tid #140118065145600]: 0 allocated 3276800 at 0x7f71a590e800
[HCTR][03:46:18.994][ERROR][RK0][tid #140118065145600]: 0 allocated 6553600 at 0x7f71a5c2e800








