2022-12-12 01:52:02.459933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.467953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.475601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.479364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.485039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.491406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.504779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.509998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.559951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.570538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.574063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.583200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.586300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.586759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.587485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.588453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.589135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.590284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.590706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.592011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.592197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.593417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.593517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.594858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.594912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.596293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.596389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.597647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.597959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.598936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.600158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.601072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.602759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.603865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.604756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.605669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.606994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.608704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.609388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.609949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.610960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.611269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.612448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.613451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.614364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.615524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.616639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.616834: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:52:02.617643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.626325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.626392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.629013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.629060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.630589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.631640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.631738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.632485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.633398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.634610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.635695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.636800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.638003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.639343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.640185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.640208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.641594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.642921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.643456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.643999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.644067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.644664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.645269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.647190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.647617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.648359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.648492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.649338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.649813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.651343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.651400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.652508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.652808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.653566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.655355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.655456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.656406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.656654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.657339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.658519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.658787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.659719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.660632: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.661344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.662309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.662530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.663366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.663753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.664866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.665191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.672878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.673149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.675344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.676513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.676556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.677390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.678704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.679481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.697893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.705016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.705287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.714616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.715762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.715809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.715869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.715906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.718000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.719006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.719795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.719828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.719947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.719977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.722219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.722964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.724025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.725138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.725191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.725358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.725382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.728347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.728849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.729887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.730732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.730778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.731436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.731509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.733657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.734081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.735809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.736462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.736488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.736626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.736842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.738798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.739343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.741778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.742379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.742462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.742751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.743061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.744790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.746251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.746379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.747219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.747322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.747458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.748071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.749657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.751996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.752057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.752496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.752587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.752698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.753214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.754614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.756603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.756610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.757085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.757195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.757242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.757804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.759525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.761431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.761651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.762022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.762080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.762602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.763404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.765252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.767004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.767119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.767444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.767536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.767899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.768513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.770421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.772364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.772550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.772907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.773204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.773586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.773784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.775156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.777022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.777186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.777526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.778138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.778591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.778720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.779963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.782426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.782648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.782802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.783169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.783722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.784033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.785277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.787476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.787762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.788020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.788504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.788708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.789844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.791460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.791749: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:52:02.792569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.792677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.792793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.793650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.793847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.795333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.796570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.796736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.797137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.797705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.797884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.800710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.800791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.800836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.801176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.801255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.802146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.803383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.805129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.805481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.805556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.805889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.806120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.806858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.808438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.810108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.810307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.810641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.810853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.811623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.813224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.814611: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:52:02.814719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.815221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.815339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.815970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.817326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.818968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.819361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.819669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.821013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.821267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.822837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.823199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.823228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.823616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.825741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.826055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.828058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.828329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.830073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.831145: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:52:02.831262: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:52:02.831589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.831826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.833195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.833529: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:52:02.838064: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:52:02.839457: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:52:02.840144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.840450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.842660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.843471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.843985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.846879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.847021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.848079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.848538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.849213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.852791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.853044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.853248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.858054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:02.858098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:03.942969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:03.943634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:03.944235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:03.944870: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:52:03.944930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 01:52:03.962614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:03.963274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:03.963786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:03.964372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:03.964891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:03.965752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 01:52:04.012602: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.012798: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.063648: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-12 01:52:04.140321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.141243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.141929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.142391: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:52:04.142448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 01:52:04.160144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.160770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.161281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.161868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.162608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.163092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 01:52:04.172090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.172689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.173222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.173682: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:52:04.173735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 01:52:04.191145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.191773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.192294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.193079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.193593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.194671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 01:52:04.224141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.224748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.225276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.225734: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:52:04.225786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 01:52:04.237637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.238267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.238788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.239265: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:52:04.239322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 01:52:04.242672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.243773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.244320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.244898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.245403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.245867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 01:52:04.249279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.249348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.249802: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.249985: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.250389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.250542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.251255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.251721: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-12 01:52:04.252385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.252717: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:52:04.252769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 01:52:04.253219: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:52:04.253269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 01:52:04.256459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.257095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.257598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.258181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.258691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.259172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 01:52:04.261574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.262199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.262717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.263202: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:52:04.263259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 01:52:04.270351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.270433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.271581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.271587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.272742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.272849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.273766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.273985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.274680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.275010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.275660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 01:52:04.275864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 01:52:04.280293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.280906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.281408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.281985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.282492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:52:04.282964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 01:52:04.292330: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.292545: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.292559: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.292738: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.294268: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-12 01:52:04.294477: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
2022-12-12 01:52:04.304891: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.305055: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.306706: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-12 01:52:04.321817: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.322021: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.323165: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.323293: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.323798: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-12 01:52:04.324997: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-12 01:52:04.329843: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.329986: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:52:04.331762: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
[HCTR][01:52:05.588][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:52:05.589][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:52:05.589][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:52:05.590][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:52:05.591][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:52:05.591][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:52:05.597][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:52:05.597][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:01,  1.52s/it]warmup run: 1it [00:01,  1.51s/it]warmup run: 1it [00:01,  1.54s/it]warmup run: 1it [00:01,  1.54s/it]warmup run: 1it [00:01,  1.55s/it]warmup run: 1it [00:01,  1.53s/it]warmup run: 1it [00:01,  1.53s/it]warmup run: 92it [00:01, 78.89it/s]warmup run: 100it [00:01, 86.14it/s]warmup run: 92it [00:01, 77.88it/s]warmup run: 103it [00:01, 87.14it/s]warmup run: 96it [00:01, 80.95it/s]warmup run: 96it [00:01, 81.59it/s]warmup run: 100it [00:01, 85.27it/s]warmup run: 184it [00:01, 170.77it/s]warmup run: 200it [00:01, 186.39it/s]warmup run: 1it [00:01,  1.48s/it]warmup run: 181it [00:01, 165.67it/s]warmup run: 205it [00:01, 187.96it/s]warmup run: 194it [00:01, 177.86it/s]warmup run: 192it [00:01, 176.87it/s]warmup run: 198it [00:01, 182.68it/s]warmup run: 276it [00:01, 271.74it/s]warmup run: 300it [00:01, 296.40it/s]warmup run: 98it [00:01, 85.90it/s]warmup run: 272it [00:01, 265.14it/s]warmup run: 307it [00:01, 299.10it/s]warmup run: 292it [00:01, 284.70it/s]warmup run: 289it [00:01, 283.03it/s]warmup run: 298it [00:01, 292.54it/s]warmup run: 368it [00:01, 375.92it/s]warmup run: 400it [00:01, 410.44it/s]warmup run: 196it [00:01, 185.48it/s]warmup run: 364it [00:01, 369.82it/s]warmup run: 407it [00:01, 410.75it/s]warmup run: 389it [00:01, 393.99it/s]warmup run: 387it [00:01, 394.70it/s]warmup run: 398it [00:01, 406.28it/s]warmup run: 460it [00:02, 477.67it/s]warmup run: 500it [00:02, 521.11it/s]warmup run: 293it [00:01, 293.19it/s]warmup run: 456it [00:02, 472.19it/s]warmup run: 506it [00:02, 517.70it/s]warmup run: 486it [00:02, 500.76it/s]warmup run: 484it [00:02, 501.88it/s]warmup run: 498it [00:02, 517.02it/s]warmup run: 553it [00:02, 572.40it/s]warmup run: 601it [00:02, 624.46it/s]warmup run: 391it [00:01, 405.50it/s]warmup run: 550it [00:02, 569.30it/s]warmup run: 607it [00:02, 620.85it/s]warmup run: 584it [00:02, 600.89it/s]warmup run: 582it [00:02, 602.31it/s]warmup run: 599it [00:02, 620.52it/s]warmup run: 646it [00:02, 655.10it/s]warmup run: 702it [00:02, 713.50it/s]warmup run: 489it [00:01, 514.04it/s]warmup run: 645it [00:02, 655.87it/s]warmup run: 709it [00:02, 711.42it/s]warmup run: 683it [00:02, 690.07it/s]warmup run: 681it [00:02, 691.80it/s]warmup run: 701it [00:02, 712.53it/s]warmup run: 741it [00:02, 726.65it/s]warmup run: 803it [00:02, 786.38it/s]warmup run: 589it [00:02, 616.88it/s]warmup run: 739it [00:02, 725.81it/s]warmup run: 811it [00:02, 786.77it/s]warmup run: 782it [00:02, 762.86it/s]warmup run: 779it [00:02, 763.09it/s]warmup run: 802it [00:02, 785.36it/s]warmup run: 834it [00:02, 777.94it/s]warmup run: 904it [00:02, 843.87it/s]warmup run: 690it [00:02, 708.44it/s]warmup run: 832it [00:02, 778.30it/s]warmup run: 914it [00:02, 848.16it/s]warmup run: 881it [00:02, 820.95it/s]warmup run: 877it [00:02, 818.43it/s]warmup run: 904it [00:02, 844.64it/s]warmup run: 928it [00:02, 820.55it/s]warmup run: 1006it [00:02, 889.74it/s]warmup run: 791it [00:02, 782.94it/s]warmup run: 926it [00:02, 821.31it/s]warmup run: 1014it [00:02, 878.52it/s]warmup run: 979it [00:02, 863.24it/s]warmup run: 974it [00:02, 856.24it/s]warmup run: 1005it [00:02, 888.61it/s]warmup run: 1021it [00:02, 850.58it/s]warmup run: 1107it [00:02, 923.28it/s]warmup run: 890it [00:02, 835.37it/s]warmup run: 1019it [00:02, 844.05it/s]warmup run: 1116it [00:02, 917.42it/s]warmup run: 1077it [00:02, 890.71it/s]warmup run: 1071it [00:02, 885.30it/s]warmup run: 1106it [00:02, 922.18it/s]warmup run: 1115it [00:02, 875.15it/s]warmup run: 1209it [00:02, 950.77it/s]warmup run: 988it [00:02, 873.22it/s]warmup run: 1115it [00:02, 876.41it/s]warmup run: 1218it [00:02, 944.51it/s]warmup run: 1174it [00:02, 912.00it/s]warmup run: 1168it [00:02, 908.39it/s]warmup run: 1208it [00:02, 948.45it/s]warmup run: 1209it [00:02, 893.42it/s]warmup run: 1310it [00:02, 953.19it/s]warmup run: 1086it [00:02, 900.83it/s]warmup run: 1211it [00:02, 900.22it/s]warmup run: 1319it [00:02, 957.98it/s]warmup run: 1271it [00:02, 927.97it/s]warmup run: 1266it [00:02, 926.95it/s]warmup run: 1310it [00:02, 968.61it/s]warmup run: 1303it [00:02, 903.16it/s]warmup run: 1185it [00:02, 925.65it/s]warmup run: 1410it [00:02, 954.86it/s]warmup run: 1307it [00:02, 915.87it/s]warmup run: 1420it [00:02, 970.70it/s]warmup run: 1368it [00:02, 939.87it/s]warmup run: 1365it [00:02, 942.83it/s]warmup run: 1411it [00:02, 979.50it/s]warmup run: 1397it [00:03, 912.90it/s]warmup run: 1286it [00:02, 949.04it/s]warmup run: 1509it [00:03, 953.24it/s]warmup run: 1404it [00:03, 929.54it/s]warmup run: 1522it [00:03, 982.53it/s]warmup run: 1465it [00:03, 948.54it/s]warmup run: 1464it [00:03, 955.10it/s]warmup run: 1513it [00:03, 988.87it/s]warmup run: 1491it [00:03, 919.78it/s]warmup run: 1390it [00:02, 973.49it/s]warmup run: 1607it [00:03, 954.29it/s]warmup run: 1500it [00:03, 938.20it/s]warmup run: 1624it [00:03, 991.21it/s]warmup run: 1563it [00:03, 955.53it/s]warmup run: 1562it [00:03, 962.12it/s]warmup run: 1614it [00:03, 994.18it/s]warmup run: 1585it [00:03, 923.52it/s]warmup run: 1493it [00:02, 989.06it/s]warmup run: 1704it [00:03, 953.45it/s]warmup run: 1597it [00:03, 946.32it/s]warmup run: 1726it [00:03, 999.48it/s]warmup run: 1661it [00:03, 962.38it/s]warmup run: 1660it [00:03, 966.23it/s]warmup run: 1716it [00:03, 999.73it/s]warmup run: 1679it [00:03, 927.01it/s]warmup run: 1598it [00:03, 1004.89it/s]warmup run: 1801it [00:03, 953.81it/s]warmup run: 1693it [00:03, 948.10it/s]warmup run: 1829it [00:03, 1005.48it/s]warmup run: 1760it [00:03, 969.09it/s]warmup run: 1758it [00:03, 968.58it/s]warmup run: 1817it [00:03, 1002.22it/s]warmup run: 1779it [00:03, 945.95it/s]warmup run: 1703it [00:03, 1015.72it/s]warmup run: 1898it [00:03, 957.53it/s]warmup run: 1789it [00:03, 948.87it/s]warmup run: 1931it [00:03, 1009.61it/s]warmup run: 1859it [00:03, 972.80it/s]warmup run: 1856it [00:03, 971.92it/s]warmup run: 1919it [00:03, 1006.21it/s]warmup run: 1878it [00:03, 957.66it/s]warmup run: 1807it [00:03, 1022.14it/s]warmup run: 1995it [00:03, 958.26it/s]warmup run: 1885it [00:03, 949.28it/s]warmup run: 2039it [00:03, 1028.49it/s]warmup run: 1957it [00:03, 973.43it/s]warmup run: 1955it [00:03, 974.83it/s]warmup run: 2023it [00:03, 1014.47it/s]warmup run: 1977it [00:03, 965.82it/s]warmup run: 1911it [00:03, 1026.06it/s]warmup run: 2114it [00:03, 1025.10it/s]warmup run: 1981it [00:03, 950.62it/s]warmup run: 2160it [00:03, 1080.45it/s]warmup run: 2066it [00:03, 1006.77it/s]warmup run: 2064it [00:03, 1007.34it/s]warmup run: 2141it [00:03, 1062.51it/s]warmup run: 2088it [00:03, 1006.35it/s]warmup run: 2017it [00:03, 1036.12it/s]warmup run: 2236it [00:03, 1080.66it/s]warmup run: 2095it [00:03, 1004.55it/s]warmup run: 2280it [00:03, 1116.02it/s]warmup run: 2184it [00:03, 1057.95it/s]warmup run: 2182it [00:03, 1058.40it/s]warmup run: 2258it [00:03, 1093.82it/s]warmup run: 2203it [00:03, 1048.94it/s]warmup run: 2139it [00:03, 1089.68it/s]warmup run: 2358it [00:03, 1120.10it/s]warmup run: 2214it [00:03, 1058.86it/s]warmup run: 2401it [00:03, 1141.87it/s]warmup run: 2303it [00:03, 1094.84it/s]warmup run: 2300it [00:03, 1094.40it/s]warmup run: 2376it [00:03, 1118.02it/s]warmup run: 2318it [00:03, 1077.32it/s]warmup run: 2261it [00:03, 1126.41it/s]warmup run: 2480it [00:03, 1147.25it/s]warmup run: 2333it [00:03, 1095.49it/s]warmup run: 2522it [00:03, 1160.49it/s]warmup run: 2422it [00:03, 1122.22it/s]warmup run: 2419it [00:03, 1120.50it/s]warmup run: 2495it [00:03, 1138.31it/s]warmup run: 2433it [00:04, 1098.23it/s]warmup run: 2383it [00:03, 1152.03it/s]warmup run: 2601it [00:04, 1164.59it/s]warmup run: 2452it [00:04, 1121.17it/s]warmup run: 2644it [00:04, 1175.60it/s]warmup run: 2541it [00:04, 1141.29it/s]warmup run: 2539it [00:04, 1141.55it/s]warmup run: 2617it [00:04, 1160.97it/s]warmup run: 2548it [00:04, 1113.64it/s]warmup run: 2505it [00:03, 1169.83it/s]warmup run: 2718it [00:04, 1163.03it/s]warmup run: 2571it [00:04, 1139.32it/s]warmup run: 2765it [00:04, 1183.62it/s]warmup run: 2660it [00:04, 1154.73it/s]warmup run: 2659it [00:04, 1157.27it/s]warmup run: 2739it [00:04, 1177.05it/s]warmup run: 2660it [00:04, 1042.32it/s]warmup run: 2627it [00:03, 1182.79it/s]warmup run: 2838it [00:04, 1173.25it/s]warmup run: 2690it [00:04, 1152.95it/s]warmup run: 2886it [00:04, 1191.07it/s]warmup run: 2778it [00:04, 1164.46it/s]warmup run: 2776it [00:04, 1136.48it/s]warmup run: 2859it [00:04, 1183.61it/s]warmup run: 2749it [00:04, 1192.99it/s]warmup run: 2766it [00:04, 1035.61it/s]warmup run: 2959it [00:04, 1181.38it/s]warmup run: 2808it [00:04, 1158.89it/s]warmup run: 3000it [00:04, 687.78it/s] warmup run: 2897it [00:04, 1169.96it/s]warmup run: 2890it [00:04, 1131.02it/s]warmup run: 2978it [00:04, 1183.91it/s]warmup run: 3000it [00:04, 684.65it/s] warmup run: 3000it [00:04, 687.64it/s] warmup run: 2869it [00:04, 1192.30it/s]warmup run: 2882it [00:04, 1070.43it/s]warmup run: 2926it [00:04, 1164.48it/s]warmup run: 3000it [00:04, 675.14it/s] warmup run: 3000it [00:04, 671.88it/s] warmup run: 3000it [00:04, 663.00it/s] warmup run: 2989it [00:04, 1192.71it/s]warmup run: 2999it [00:04, 1097.32it/s]warmup run: 3000it [00:04, 656.91it/s] warmup run: 3000it [00:04, 695.71it/s] 

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1625.68it/s]warmup should be done:   5%|         | 161/3000 [00:00<00:01, 1609.74it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1645.64it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1626.32it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1630.73it/s]warmup should be done:   4%|         | 112/3000 [00:00<00:02, 1113.50it/s]warmup should be done:   4%|         | 109/3000 [00:00<00:02, 1085.29it/s]warmup should be done:   4%|         | 112/3000 [00:00<00:02, 1116.74it/s]warmup should be done:  11%|         | 328/3000 [00:00<00:01, 1639.99it/s]warmup should be done:  11%|         | 325/3000 [00:00<00:01, 1625.48it/s]warmup should be done:  11%|         | 331/3000 [00:00<00:01, 1651.04it/s]warmup should be done:  11%|         | 327/3000 [00:00<00:01, 1629.50it/s]warmup should be done:  11%|         | 328/3000 [00:00<00:01, 1633.92it/s]warmup should be done:   9%|         | 272/3000 [00:00<00:01, 1396.92it/s]warmup should be done:   7%|         | 218/3000 [00:00<00:02, 1066.74it/s]warmup should be done:   7%|         | 224/3000 [00:00<00:02, 1077.77it/s]warmup should be done:  16%|        | 488/3000 [00:00<00:01, 1626.45it/s]warmup should be done:  16%|        | 493/3000 [00:00<00:01, 1640.57it/s]warmup should be done:  15%|        | 437/3000 [00:00<00:01, 1510.75it/s]warmup should be done:  16%|        | 490/3000 [00:00<00:01, 1624.57it/s]warmup should be done:  17%|        | 497/3000 [00:00<00:01, 1647.91it/s]warmup should be done:  16%|        | 492/3000 [00:00<00:01, 1629.32it/s]warmup should be done:  12%|        | 373/3000 [00:00<00:02, 1283.37it/s]warmup should be done:  13%|        | 381/3000 [00:00<00:02, 1296.95it/s]warmup should be done:  22%|       | 651/3000 [00:00<00:01, 1625.55it/s]warmup should be done:  20%|        | 601/3000 [00:00<00:01, 1559.69it/s]warmup should be done:  22%|       | 662/3000 [00:00<00:01, 1645.71it/s]warmup should be done:  22%|       | 656/3000 [00:00<00:01, 1630.55it/s]warmup should be done:  22%|       | 653/3000 [00:00<00:01, 1619.98it/s]warmup should be done:  18%|        | 535/3000 [00:00<00:01, 1414.58it/s]warmup should be done:  22%|       | 658/3000 [00:00<00:01, 1612.97it/s]warmup should be done:  18%|        | 544/3000 [00:00<00:01, 1426.07it/s]warmup should be done:  27%|       | 814/3000 [00:00<00:01, 1623.57it/s]warmup should be done:  26%|       | 765/3000 [00:00<00:01, 1587.46it/s]warmup should be done:  27%|       | 820/3000 [00:00<00:01, 1631.08it/s]warmup should be done:  28%|       | 827/3000 [00:00<00:01, 1642.86it/s]warmup should be done:  27%|       | 815/3000 [00:00<00:01, 1615.50it/s]warmup should be done:  23%|       | 698/3000 [00:00<00:01, 1491.32it/s]warmup should be done:  27%|       | 820/3000 [00:00<00:01, 1610.00it/s]warmup should be done:  24%|       | 708/3000 [00:00<00:01, 1502.25it/s]warmup should be done:  31%|       | 928/3000 [00:00<00:01, 1599.23it/s]warmup should be done:  33%|      | 977/3000 [00:00<00:01, 1620.20it/s]warmup should be done:  33%|      | 984/3000 [00:00<00:01, 1630.30it/s]warmup should be done:  33%|      | 992/3000 [00:00<00:01, 1639.29it/s]warmup should be done:  33%|      | 977/3000 [00:00<00:01, 1609.84it/s]warmup should be done:  29%|       | 858/3000 [00:00<00:01, 1527.47it/s]warmup should be done:  33%|      | 984/3000 [00:00<00:01, 1617.72it/s]warmup should be done:  29%|       | 872/3000 [00:00<00:01, 1545.91it/s]warmup should be done:  36%|      | 1091/3000 [00:00<00:01, 1606.76it/s]warmup should be done:  38%|      | 1140/3000 [00:00<00:01, 1615.16it/s]warmup should be done:  39%|      | 1156/3000 [00:00<00:01, 1634.82it/s]warmup should be done:  38%|      | 1148/3000 [00:00<00:01, 1625.49it/s]warmup should be done:  34%|      | 1018/3000 [00:00<00:01, 1548.08it/s]warmup should be done:  38%|      | 1138/3000 [00:00<00:01, 1604.59it/s]warmup should be done:  38%|      | 1147/3000 [00:00<00:01, 1619.68it/s]warmup should be done:  35%|      | 1036/3000 [00:00<00:01, 1574.88it/s]warmup should be done:  42%|     | 1253/3000 [00:00<00:01, 1608.71it/s]warmup should be done:  43%|     | 1302/3000 [00:00<00:01, 1615.62it/s]warmup should be done:  44%|     | 1320/3000 [00:00<00:01, 1635.86it/s]warmup should be done:  44%|     | 1311/3000 [00:00<00:01, 1625.32it/s]warmup should be done:  39%|      | 1177/3000 [00:00<00:01, 1560.49it/s]warmup should be done:  43%|     | 1299/3000 [00:00<00:01, 1604.07it/s]warmup should be done:  44%|     | 1311/3000 [00:00<00:01, 1624.64it/s]warmup should be done:  40%|      | 1199/3000 [00:00<00:01, 1591.76it/s]warmup should be done:  47%|     | 1414/3000 [00:00<00:00, 1604.44it/s]warmup should be done:  49%|     | 1464/3000 [00:00<00:00, 1616.94it/s]warmup should be done:  49%|     | 1484/3000 [00:00<00:00, 1635.47it/s]warmup should be done:  45%|     | 1337/3000 [00:00<00:01, 1572.28it/s]warmup should be done:  49%|     | 1475/3000 [00:00<00:00, 1627.06it/s]warmup should be done:  49%|     | 1460/3000 [00:00<00:00, 1603.76it/s]warmup should be done:  45%|     | 1363/3000 [00:00<00:01, 1606.08it/s]warmup should be done:  49%|     | 1475/3000 [00:00<00:00, 1626.83it/s]warmup should be done:  54%|    | 1626/3000 [00:01<00:00, 1616.49it/s]warmup should be done:  52%|    | 1575/3000 [00:01<00:00, 1602.63it/s]warmup should be done:  50%|     | 1496/3000 [00:01<00:00, 1577.51it/s]warmup should be done:  55%|    | 1648/3000 [00:01<00:00, 1634.94it/s]warmup should be done:  55%|    | 1638/3000 [00:01<00:00, 1627.55it/s]warmup should be done:  54%|    | 1621/3000 [00:01<00:00, 1603.37it/s]warmup should be done:  55%|    | 1639/3000 [00:01<00:00, 1629.66it/s]warmup should be done:  51%|     | 1527/3000 [00:01<00:00, 1613.85it/s]warmup should be done:  60%|    | 1788/3000 [00:01<00:00, 1615.82it/s]warmup should be done:  58%|    | 1736/3000 [00:01<00:00, 1599.45it/s]warmup should be done:  60%|    | 1801/3000 [00:01<00:00, 1627.88it/s]warmup should be done:  55%|    | 1656/3000 [00:01<00:00, 1581.39it/s]warmup should be done:  60%|    | 1812/3000 [00:01<00:00, 1632.49it/s]warmup should be done:  59%|    | 1782/3000 [00:01<00:00, 1602.97it/s]warmup should be done:  60%|    | 1803/3000 [00:01<00:00, 1632.42it/s]warmup should be done:  56%|    | 1690/3000 [00:01<00:00, 1618.32it/s]warmup should be done:  65%|   | 1950/3000 [00:01<00:00, 1614.60it/s]warmup should be done:  63%|   | 1896/3000 [00:01<00:00, 1599.37it/s]warmup should be done:  65%|   | 1964/3000 [00:01<00:00, 1627.41it/s]warmup should be done:  61%|    | 1816/3000 [00:01<00:00, 1585.17it/s]warmup should be done:  65%|   | 1943/3000 [00:01<00:00, 1600.26it/s]warmup should be done:  66%|   | 1967/3000 [00:01<00:00, 1634.27it/s]warmup should be done:  62%|   | 1854/3000 [00:01<00:00, 1623.03it/s]warmup should be done:  66%|   | 1976/3000 [00:01<00:00, 1616.91it/s]warmup should be done:  70%|   | 2112/3000 [00:01<00:00, 1614.11it/s]warmup should be done:  69%|   | 2056/3000 [00:01<00:00, 1597.91it/s]warmup should be done:  66%|   | 1976/3000 [00:01<00:00, 1588.04it/s]warmup should be done:  71%|   | 2127/3000 [00:01<00:00, 1622.26it/s]warmup should be done:  70%|   | 2104/3000 [00:01<00:00, 1601.84it/s]warmup should be done:  71%|   | 2131/3000 [00:01<00:00, 1634.31it/s]warmup should be done:  67%|   | 2017/3000 [00:01<00:00, 1623.36it/s]warmup should be done:  71%|  | 2138/3000 [00:01<00:00, 1608.34it/s]warmup should be done:  76%|  | 2274/3000 [00:01<00:00, 1614.18it/s]warmup should be done:  74%|  | 2216/3000 [00:01<00:00, 1597.39it/s]warmup should be done:  71%|   | 2136/3000 [00:01<00:00, 1589.26it/s]warmup should be done:  76%|  | 2290/3000 [00:01<00:00, 1621.75it/s]warmup should be done:  76%|  | 2266/3000 [00:01<00:00, 1606.23it/s]warmup should be done:  76%|  | 2295/3000 [00:01<00:00, 1635.27it/s]warmup should be done:  73%|  | 2180/3000 [00:01<00:00, 1619.77it/s]warmup should be done:  77%|  | 2299/3000 [00:01<00:00, 1599.79it/s]warmup should be done:  81%|  | 2436/3000 [00:01<00:00, 1611.08it/s]warmup should be done:  79%|  | 2376/3000 [00:01<00:00, 1594.04it/s]warmup should be done:  77%|  | 2296/3000 [00:01<00:00, 1590.78it/s]warmup should be done:  82%| | 2453/3000 [00:01<00:00, 1619.21it/s]warmup should be done:  81%|  | 2427/3000 [00:01<00:00, 1605.15it/s]warmup should be done:  82%| | 2459/3000 [00:01<00:00, 1632.21it/s]warmup should be done:  78%|  | 2342/3000 [00:01<00:00, 1614.48it/s]warmup should be done:  82%| | 2459/3000 [00:01<00:00, 1596.09it/s]warmup should be done:  87%| | 2598/3000 [00:01<00:00, 1612.30it/s]warmup should be done:  85%| | 2537/3000 [00:01<00:00, 1595.65it/s]warmup should be done:  82%| | 2456/3000 [00:01<00:00, 1589.38it/s]warmup should be done:  86%| | 2589/3000 [00:01<00:00, 1608.46it/s]warmup should be done:  87%| | 2615/3000 [00:01<00:00, 1617.07it/s]warmup should be done:  87%| | 2623/3000 [00:01<00:00, 1633.70it/s]warmup should be done:  83%| | 2504/3000 [00:01<00:00, 1611.43it/s]warmup should be done:  87%| | 2619/3000 [00:01<00:00, 1596.31it/s]warmup should be done:  92%|| 2760/3000 [00:01<00:00, 1612.99it/s]warmup should be done:  90%| | 2698/3000 [00:01<00:00, 1597.12it/s]warmup should be done:  87%| | 2616/3000 [00:01<00:00, 1590.81it/s]warmup should be done:  92%|| 2751/3000 [00:01<00:00, 1611.53it/s]warmup should be done:  93%|| 2777/3000 [00:01<00:00, 1614.25it/s]warmup should be done:  93%|| 2787/3000 [00:01<00:00, 1635.28it/s]warmup should be done:  89%| | 2666/3000 [00:01<00:00, 1610.74it/s]warmup should be done:  93%|| 2779/3000 [00:01<00:00, 1597.31it/s]warmup should be done:  97%|| 2923/3000 [00:01<00:00, 1618.06it/s]warmup should be done:  95%|| 2860/3000 [00:01<00:00, 1602.51it/s]warmup should be done:  93%|| 2776/3000 [00:01<00:00, 1591.77it/s]warmup should be done:  97%|| 2916/3000 [00:01<00:00, 1621.66it/s]warmup should be done:  98%|| 2940/3000 [00:01<00:00, 1616.70it/s]warmup should be done:  98%|| 2953/3000 [00:01<00:00, 1640.57it/s]warmup should be done:  94%|| 2828/3000 [00:01<00:00, 1611.71it/s]warmup should be done:  98%|| 2942/3000 [00:01<00:00, 1605.14it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1630.93it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1622.93it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1620.11it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1616.83it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1611.73it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1582.73it/s]warmup should be done:  98%|| 2939/3000 [00:01<00:00, 1600.51it/s]warmup should be done: 100%|| 2991/3000 [00:01<00:00, 1616.84it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1562.59it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1540.32it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]




warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1639.60it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1666.20it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1675.30it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1654.72it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1634.99it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1642.78it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1640.77it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1620.85it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1650.04it/s]warmup should be done:  11%|         | 336/3000 [00:00<00:01, 1677.91it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1656.05it/s]warmup should be done:  11%|         | 336/3000 [00:00<00:01, 1676.15it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1643.95it/s]warmup should be done:  11%|         | 327/3000 [00:00<00:01, 1630.52it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1643.56it/s]warmup should be done:  11%|         | 329/3000 [00:00<00:01, 1638.23it/s]warmup should be done:  17%|        | 505/3000 [00:00<00:01, 1681.27it/s]warmup should be done:  17%|        | 497/3000 [00:00<00:01, 1655.29it/s]warmup should be done:  17%|        | 505/3000 [00:00<00:01, 1681.77it/s]warmup should be done:  17%|        | 499/3000 [00:00<00:01, 1658.97it/s]warmup should be done:  17%|        | 496/3000 [00:00<00:01, 1646.73it/s]warmup should be done:  17%|        | 496/3000 [00:00<00:01, 1646.88it/s]warmup should be done:  16%|        | 491/3000 [00:00<00:01, 1614.89it/s]warmup should be done:  16%|        | 493/3000 [00:00<00:01, 1616.55it/s]warmup should be done:  22%|       | 674/3000 [00:00<00:01, 1684.94it/s]warmup should be done:  22%|       | 675/3000 [00:00<00:01, 1685.25it/s]warmup should be done:  22%|       | 664/3000 [00:00<00:01, 1657.36it/s]warmup should be done:  22%|       | 666/3000 [00:00<00:01, 1661.32it/s]warmup should be done:  22%|       | 662/3000 [00:00<00:01, 1651.56it/s]warmup should be done:  22%|       | 661/3000 [00:00<00:01, 1644.34it/s]warmup should be done:  22%|       | 657/3000 [00:00<00:01, 1630.09it/s]warmup should be done:  22%|       | 660/3000 [00:00<00:01, 1635.81it/s]warmup should be done:  28%|       | 844/3000 [00:00<00:01, 1686.90it/s]warmup should be done:  28%|       | 843/3000 [00:00<00:01, 1684.34it/s]warmup should be done:  28%|       | 833/3000 [00:00<00:01, 1662.81it/s]warmup should be done:  28%|       | 830/3000 [00:00<00:01, 1655.93it/s]warmup should be done:  28%|       | 828/3000 [00:00<00:01, 1652.60it/s]warmup should be done:  28%|       | 826/3000 [00:00<00:01, 1641.23it/s]warmup should be done:  27%|       | 824/3000 [00:00<00:01, 1642.64it/s]warmup should be done:  28%|       | 827/3000 [00:00<00:01, 1645.64it/s]warmup should be done:  34%|      | 1012/3000 [00:00<00:01, 1685.43it/s]warmup should be done:  33%|      | 996/3000 [00:00<00:01, 1656.86it/s]warmup should be done:  34%|      | 1013/3000 [00:00<00:01, 1684.39it/s]warmup should be done:  33%|      | 1000/3000 [00:00<00:01, 1661.53it/s]warmup should be done:  33%|      | 994/3000 [00:00<00:01, 1651.15it/s]warmup should be done:  33%|      | 991/3000 [00:00<00:01, 1639.00it/s]warmup should be done:  33%|      | 992/3000 [00:00<00:01, 1653.22it/s]warmup should be done:  33%|      | 993/3000 [00:00<00:01, 1649.63it/s]warmup should be done:  39%|      | 1181/3000 [00:00<00:01, 1684.15it/s]warmup should be done:  39%|      | 1163/3000 [00:00<00:01, 1659.58it/s]warmup should be done:  39%|      | 1182/3000 [00:00<00:01, 1682.59it/s]warmup should be done:  39%|      | 1160/3000 [00:00<00:01, 1652.05it/s]warmup should be done:  39%|      | 1167/3000 [00:00<00:01, 1660.16it/s]warmup should be done:  39%|      | 1157/3000 [00:00<00:01, 1642.95it/s]warmup should be done:  39%|      | 1160/3000 [00:00<00:01, 1661.56it/s]warmup should be done:  39%|      | 1160/3000 [00:00<00:01, 1654.33it/s]warmup should be done:  45%|     | 1351/3000 [00:00<00:00, 1686.49it/s]warmup should be done:  44%|     | 1329/3000 [00:00<00:01, 1657.24it/s]warmup should be done:  45%|     | 1352/3000 [00:00<00:00, 1685.14it/s]warmup should be done:  44%|     | 1334/3000 [00:00<00:01, 1661.22it/s]warmup should be done:  44%|     | 1326/3000 [00:00<00:01, 1649.60it/s]warmup should be done:  44%|     | 1322/3000 [00:00<00:01, 1642.28it/s]warmup should be done:  44%|     | 1328/3000 [00:00<00:01, 1665.78it/s]warmup should be done:  44%|     | 1326/3000 [00:00<00:01, 1653.98it/s]warmup should be done:  51%|     | 1520/3000 [00:00<00:00, 1685.88it/s]warmup should be done:  50%|     | 1498/3000 [00:00<00:00, 1664.83it/s]warmup should be done:  51%|     | 1521/3000 [00:00<00:00, 1685.25it/s]warmup should be done:  50%|     | 1501/3000 [00:00<00:00, 1661.29it/s]warmup should be done:  50%|     | 1491/3000 [00:00<00:00, 1649.45it/s]warmup should be done:  50%|     | 1496/3000 [00:00<00:00, 1669.65it/s]warmup should be done:  50%|     | 1488/3000 [00:00<00:00, 1645.79it/s]warmup should be done:  50%|     | 1492/3000 [00:00<00:00, 1651.57it/s]warmup should be done:  56%|    | 1690/3000 [00:01<00:00, 1687.48it/s]warmup should be done:  56%|    | 1667/3000 [00:01<00:00, 1671.23it/s]warmup should be done:  55%|    | 1657/3000 [00:01<00:00, 1652.27it/s]warmup should be done:  56%|    | 1668/3000 [00:01<00:00, 1663.19it/s]warmup should be done:  56%|    | 1690/3000 [00:01<00:00, 1681.54it/s]warmup should be done:  56%|    | 1665/3000 [00:01<00:00, 1674.27it/s]warmup should be done:  55%|    | 1654/3000 [00:01<00:00, 1647.89it/s]warmup should be done:  55%|    | 1658/3000 [00:01<00:00, 1652.36it/s]warmup should be done:  61%|    | 1836/3000 [00:01<00:00, 1675.21it/s]warmup should be done:  62%|   | 1860/3000 [00:01<00:00, 1689.21it/s]warmup should be done:  61%|    | 1823/3000 [00:01<00:00, 1653.66it/s]warmup should be done:  61%|    | 1835/3000 [00:01<00:00, 1662.78it/s]warmup should be done:  62%|   | 1859/3000 [00:01<00:00, 1677.64it/s]warmup should be done:  61%|    | 1834/3000 [00:01<00:00, 1677.50it/s]warmup should be done:  61%|    | 1819/3000 [00:01<00:00, 1648.11it/s]warmup should be done:  61%|    | 1824/3000 [00:01<00:00, 1652.55it/s]warmup should be done:  67%|   | 2004/3000 [00:01<00:00, 1675.84it/s]warmup should be done:  68%|   | 2029/3000 [00:01<00:00, 1688.57it/s]warmup should be done:  66%|   | 1989/3000 [00:01<00:00, 1650.96it/s]warmup should be done:  67%|   | 2002/3000 [00:01<00:00, 1661.68it/s]warmup should be done:  67%|   | 2002/3000 [00:01<00:00, 1677.31it/s]warmup should be done:  68%|   | 2027/3000 [00:01<00:00, 1674.53it/s]warmup should be done:  66%|   | 1984/3000 [00:01<00:00, 1644.15it/s]warmup should be done:  66%|   | 1990/3000 [00:01<00:00, 1652.78it/s]warmup should be done:  72%|  | 2172/3000 [00:01<00:00, 1676.27it/s]warmup should be done:  73%|  | 2198/3000 [00:01<00:00, 1687.21it/s]warmup should be done:  72%|  | 2155/3000 [00:01<00:00, 1650.62it/s]warmup should be done:  72%|  | 2169/3000 [00:01<00:00, 1661.07it/s]warmup should be done:  72%|  | 2170/3000 [00:01<00:00, 1676.93it/s]warmup should be done:  73%|  | 2195/3000 [00:01<00:00, 1670.60it/s]warmup should be done:  72%|  | 2149/3000 [00:01<00:00, 1641.80it/s]warmup should be done:  72%|  | 2156/3000 [00:01<00:00, 1650.93it/s]warmup should be done:  79%|  | 2367/3000 [00:01<00:00, 1687.76it/s]warmup should be done:  78%|  | 2336/3000 [00:01<00:00, 1662.88it/s]warmup should be done:  77%|  | 2321/3000 [00:01<00:00, 1651.34it/s]warmup should be done:  78%|  | 2339/3000 [00:01<00:00, 1679.50it/s]warmup should be done:  78%|  | 2340/3000 [00:01<00:00, 1660.14it/s]warmup should be done:  77%|  | 2314/3000 [00:01<00:00, 1642.70it/s]warmup should be done:  79%|  | 2363/3000 [00:01<00:00, 1670.40it/s]warmup should be done:  77%|  | 2322/3000 [00:01<00:00, 1650.88it/s]warmup should be done:  85%| | 2536/3000 [00:01<00:00, 1688.14it/s]warmup should be done:  83%| | 2503/3000 [00:01<00:00, 1664.61it/s]warmup should be done:  83%| | 2487/3000 [00:01<00:00, 1652.29it/s]warmup should be done:  84%| | 2508/3000 [00:01<00:00, 1680.08it/s]warmup should be done:  84%| | 2509/3000 [00:01<00:00, 1667.74it/s]warmup should be done:  83%| | 2479/3000 [00:01<00:00, 1642.95it/s]warmup should be done:  84%| | 2531/3000 [00:01<00:00, 1670.78it/s]warmup should be done:  83%| | 2488/3000 [00:01<00:00, 1650.34it/s]warmup should be done:  90%| | 2705/3000 [00:01<00:00, 1688.03it/s]warmup should be done:  89%| | 2670/3000 [00:01<00:00, 1664.64it/s]warmup should be done:  88%| | 2653/3000 [00:01<00:00, 1651.12it/s]warmup should be done:  89%| | 2677/3000 [00:01<00:00, 1680.65it/s]warmup should be done:  89%| | 2678/3000 [00:01<00:00, 1672.38it/s]warmup should be done:  88%| | 2644/3000 [00:01<00:00, 1641.56it/s]warmup should be done:  90%| | 2699/3000 [00:01<00:00, 1669.73it/s]warmup should be done:  88%| | 2654/3000 [00:01<00:00, 1651.61it/s]warmup should be done:  96%|| 2874/3000 [00:01<00:00, 1685.68it/s]warmup should be done:  95%|| 2837/3000 [00:01<00:00, 1663.98it/s]warmup should be done:  94%|| 2819/3000 [00:01<00:00, 1650.57it/s]warmup should be done:  95%|| 2846/3000 [00:01<00:00, 1679.65it/s]warmup should be done:  95%|| 2847/3000 [00:01<00:00, 1674.77it/s]warmup should be done:  94%|| 2809/3000 [00:01<00:00, 1643.33it/s]warmup should be done:  96%|| 2866/3000 [00:01<00:00, 1668.43it/s]warmup should be done:  94%|| 2821/3000 [00:01<00:00, 1654.58it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1683.49it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1676.12it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1667.22it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1667.05it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1662.56it/s]warmup should be done: 100%|| 2985/3000 [00:01<00:00, 1651.38it/s]warmup should be done:  99%|| 2975/3000 [00:01<00:00, 1645.41it/s]warmup should be done: 100%|| 2989/3000 [00:01<00:00, 1659.43it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1650.52it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1650.36it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1643.62it/s]
WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fc85a5fb1f0>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fc85a92de80>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fc85a5f91c0>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fc85a92e730>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fc85a5fb190>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fc85a6092b0>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fc85a930d30>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7fc85a5fc0d0>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2022-12-12 01:53:35.784858: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc38a82c670 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:53:35.784931: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:53:35.794559: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:53:35.870202: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc38282fea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:53:35.870268: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:53:35.878725: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:53:36.670254: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc38b02db50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:53:36.670322: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:53:36.680079: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:53:36.774403: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc396830170 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:53:36.774468: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:53:36.782578: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:53:36.790927: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc39682c6f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:53:36.790984: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:53:36.800207: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:53:36.863088: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc38a837300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:53:36.863159: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:53:36.871061: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:53:36.891719: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc38e798f10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:53:36.891767: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:53:36.900791: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:53:36.925818: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fc38e833b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:53:36.925883: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:53:36.935626: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:53:42.936184: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:53:43.032432: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:53:43.519121: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:53:43.569157: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:53:43.612607: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:53:43.620421: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:53:43.881331: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:53:43.891690: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][01:54:40.250][ERROR][RK0][main]: replica 7 reaches 1000, calling init pre replica
[HCTR][01:54:40.250][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:54:40.259][ERROR][RK0][main]: coll ps creation done
[HCTR][01:54:40.259][ERROR][RK0][main]: replica 7 waits for coll ps creation barrier
[HCTR][01:54:40.521][ERROR][RK0][tid #140478397781760]: replica 2 reaches 1000, calling init pre replica
[HCTR][01:54:40.521][ERROR][RK0][tid #140478397781760]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:54:40.526][ERROR][RK0][tid #140478397781760]: coll ps creation done
[HCTR][01:54:40.526][ERROR][RK0][tid #140478397781760]: replica 2 waits for coll ps creation barrier
[HCTR][01:54:40.556][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][01:54:40.556][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:54:40.561][ERROR][RK0][tid #140478540392192]: replica 4 reaches 1000, calling init pre replica
[HCTR][01:54:40.561][ERROR][RK0][tid #140478540392192]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:54:40.563][ERROR][RK0][main]: coll ps creation done
[HCTR][01:54:40.563][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][01:54:40.569][ERROR][RK0][tid #140478540392192]: coll ps creation done
[HCTR][01:54:40.569][ERROR][RK0][tid #140478540392192]: replica 4 waits for coll ps creation barrier
[HCTR][01:54:40.589][ERROR][RK0][main]: replica 5 reaches 1000, calling init pre replica
[HCTR][01:54:40.589][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:54:40.596][ERROR][RK0][main]: coll ps creation done
[HCTR][01:54:40.596][ERROR][RK0][main]: replica 5 waits for coll ps creation barrier
[HCTR][01:54:40.611][ERROR][RK0][tid #140478548784896]: replica 1 reaches 1000, calling init pre replica
[HCTR][01:54:40.611][ERROR][RK0][tid #140478548784896]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:54:40.616][ERROR][RK0][tid #140478548784896]: coll ps creation done
[HCTR][01:54:40.616][ERROR][RK0][tid #140478548784896]: replica 1 waits for coll ps creation barrier
[HCTR][01:54:40.621][ERROR][RK0][tid #140478397781760]: replica 6 reaches 1000, calling init pre replica
[HCTR][01:54:40.621][ERROR][RK0][tid #140478397781760]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:54:40.626][ERROR][RK0][tid #140478397781760]: coll ps creation done
[HCTR][01:54:40.626][ERROR][RK0][tid #140478397781760]: replica 6 waits for coll ps creation barrier
[HCTR][01:54:40.707][ERROR][RK0][main]: replica 0 reaches 1000, calling init pre replica
[HCTR][01:54:40.707][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:54:40.715][ERROR][RK0][main]: coll ps creation done
[HCTR][01:54:40.715][ERROR][RK0][main]: replica 0 waits for coll ps creation barrier
[HCTR][01:54:40.715][ERROR][RK0][main]: replica 0 preparing frequency
[HCTR][01:54:41.577][ERROR][RK0][main]: replica 0 preparing frequency done
[HCTR][01:54:41.619][ERROR][RK0][main]: replica 0 calling init per replica
[HCTR][01:54:41.619][ERROR][RK0][tid #140478548784896]: replica 1 calling init per replica
[HCTR][01:54:41.619][ERROR][RK0][tid #140478397781760]: replica 6 calling init per replica
[HCTR][01:54:41.619][ERROR][RK0][tid #140478540392192]: replica 4 calling init per replica
[HCTR][01:54:41.619][ERROR][RK0][main]: replica 5 calling init per replica
[HCTR][01:54:41.619][ERROR][RK0][tid #140478397781760]: replica 2 calling init per replica
[HCTR][01:54:41.619][ERROR][RK0][main]: replica 7 calling init per replica
[HCTR][01:54:41.619][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][01:54:41.619][ERROR][RK0][main]: Calling build_v2
[HCTR][01:54:41.619][ERROR][RK0][tid #140478548784896]: Calling build_v2
[HCTR][01:54:41.619][ERROR][RK0][tid #140478397781760]: Calling build_v2
[HCTR][01:54:41.619][ERROR][RK0][tid #140478540392192]: Calling build_v2
[HCTR][01:54:41.619][ERROR][RK0][main]: Calling build_v2
[HCTR][01:54:41.619][ERROR][RK0][tid #140478397781760]: Calling build_v2
[HCTR][01:54:41.619][ERROR][RK0][tid #140478397781760]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:54:41.619][ERROR][RK0][main]: Calling build_v2
[HCTR][01:54:41.619][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:54:41.619][ERROR][RK0][main]: Calling build_v2
[HCTR][01:54:41.619][ERROR][RK0][tid #140478548784896]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:54:41.619][ERROR][RK0][tid #140478540392192]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:54:41.619][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:54:41.619][ERROR][RK0][tid #140478397781760]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:54:41.619][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:54:41.619][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[[[[[[[[2022-12-12 01:54:412022-12-12 01:54:412022-12-12 01:54:412022-12-12 01:54:412022-12-12 01:54:41...2022-12-12 01:54:412022-12-12 01:54:41..2022-12-12 01:54:41619968619971619971..619965619975.: : : 619988619988: : 619965EEE: : EE:    EE  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc  /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc :::/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc::/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc136136136::136136:] ] ] 136136] ] 136using concurrent impl MPSusing concurrent impl MPSusing concurrent impl MPS] ] using concurrent impl MPSusing concurrent impl MPS] 


using concurrent impl MPSusing concurrent impl MPS

using concurrent impl MPS


[2022-12-12 01:54:41.624095: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[2022-12-12 01:54:41.624133: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[:2022-12-12 01:54:41196.] 624140assigning 8 to cpu: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[2022-12-12 01:54:41.624187[: 2022-12-12 01:54:41E[. 2022-12-12 01:54:41624188/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.: :624201E196:  ] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[assigning 8 to cpu :2022-12-12 01:54:41
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc178.:] 624235212v100x8, slow pcie: ] 
Ebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8[ 
[2022-12-12 01:54:41/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:54:41.:.624276[178624286: [2022-12-12 01:54:41] : E2022-12-12 01:54:41.v100x8, slow pcieE [.624303
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:54:41624309: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:.[: E:1786243212022-12-12 01:54:41E 196] : . /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] [v100x8, slow pcieE624349/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:assigning 8 to cpu2022-12-12 01:54:41
 : :212
./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE[[213] 624372: 2022-12-12 01:54:412022-12-12 01:54:41[] build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8: 178/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc..2022-12-12 01:54:41remote time is 8.68421
E] :624415624421.
 v100x8, slow pcie196[: : 624447/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
[] 2022-12-12 01:54:41[EE: :2022-12-12 01:54:41assigning 8 to cpu.2022-12-12 01:54:41  E178.
624515./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc ] 624532: 624562::/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccv100x8, slow pcie: E: 178196[:
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE] ] 2022-12-12 01:54:41212 [: v100x8, slow pcieassigning 8 to cpu.] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:54:41213/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc

624651build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8:.] :: [
214624686remote time is 8.68421196E[2022-12-12 01:54:41] : 
] [ 2022-12-12 01:54:41.cpu time is 97.0588Eassigning 8 to cpu2022-12-12 01:54:41/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[.624753
 
.:2022-12-12 01:54:41624789: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc624792212.: E:: ] 624817E[ 196Ebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8:  2022-12-12 01:54:41/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc]  
E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.:assigning 8 to cpu/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc :624888196[
:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc213: ] 2022-12-12 01:54:41212:] Eassigning 8 to cpu.] 214remote time is 8.68421 
624948build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8[] 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: 
2022-12-12 01:54:41cpu time is 97.0588:E[.
212 [[2022-12-12 01:54:41625007] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:54:412022-12-12 01:54:41.: build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8:..625040E
213625051625052:  ] : : [E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421EE2022-12-12 01:54:41 :
  ./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc212/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[625140:] ::2022-12-12 01:54:41: 214build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8212213.E] 
] ] 625198 cpu time is 97.0588build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8remote time is 8.68421: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
[

E:2022-12-12 01:54:41 213[.[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 2022-12-12 01:54:416252842022-12-12 01:54:41:remote time is 8.68421.: .214
625311E625315[] :  : 2022-12-12 01:54:41cpu time is 97.0588E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE.
 : 625368/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc213/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: :] :E214remote time is 8.68421213 ] 
] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cccpu time is 97.0588remote time is 8.68421:[

2142022-12-12 01:54:41] [.cpu time is 97.05882022-12-12 01:54:41625470
.: 625502E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc214:] 214cpu time is 97.0588] 
cpu time is 97.0588
[2022-12-12 01:55:58.961162: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-12 01:55:59.  1100: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-12 01:55:59.  1168: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 5000000
[2022-12-12 01:55:59.126176: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-12 01:55:59.126265: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-12 01:55:59.126299: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-12 01:55:59.126330: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-12 01:55:59.126781: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.134617: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.138503: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.141446: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 7 solved
[2022-12-12 01:55:59.141503: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 7 initing device 7
[[2022-12-12 01:55:592022-12-12 01:55:59..141758141756: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::202202] ] 5 solved1 solved

[[2022-12-12 01:55:592022-12-12 01:55:59..[1418482022-12-12 01:55:59141850: .: E141847E :  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc[E/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc[:2022-12-12 01:55:59 :2022-12-12 01:55:59205./hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc205.] 141888:] 141883worker 0 thread 5 initing device 5: 202worker 0 thread 1 initing device 1: 
E] 
E 4 solved /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::1980202[] ] 2022-12-12 01:55:59eager alloc mem 381.47 MB6 solved.

141986: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc2022-12-12 01:55:59:.205142016] : worker 0 thread 4 initing device 4E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 6 initing device 6
[2022-12-12 01:55:59.142110: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 2 solved
[2022-12-12 01:55:59.142170: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 2 initing device 2
[2022-12-12 01:55:59.142308: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 01:55:591980.] 142332eager alloc mem 381.47 MB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 01:55:591980.] 142338[eager alloc mem 381.47 MB: 2022-12-12 01:55:59
E[. 2022-12-12 01:55:59142390/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc.: :142408E202:  ] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu3 solved :
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980:] 1980[eager alloc mem 381.47 MB] 2022-12-12 01:55:59
eager alloc mem 381.47 MB.
142496: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 3 initing device 3
[2022-12-12 01:55:59.142545: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.142938: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.146092: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.146362: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.146520: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.146563: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.147068: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.147119: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.147628: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.150462: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.150626: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.150763: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.150812: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.150866: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.151360: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.151859: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:55:59.219922: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 01:55:59.220331: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 01:55:59.226081: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:55:59.226188: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:55:59.226235: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:55:59.227186: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:55:59.228405: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.229403: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.229490: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:55:59.230161: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:55:59.230221: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[[[[[2022-12-12 01:55:592022-12-12 01:55:59[2022-12-12 01:55:592022-12-12 01:55:592022-12-12 01:55:59..2022-12-12 01:55:59...238564238578.238566238579238566: : 238599: : : EE: EEE  E   /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:::19801980:198019801980] ] 1980] ] ] eager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes] eager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes

eager alloc mem 2.00 Bytes



[2022-12-12 01:55:59[.[[2022-12-12 01:55:59[2390362022-12-12 01:55:592022-12-12 01:55:59.2022-12-12 01:55:59: [..239040.E2022-12-12 01:55:59239042239042: 239045 .: : E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu239057EE E::   /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 1980E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu]  ::1980:eager alloc mem 1024.00 Bytes/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu19801980] 1980
:] ] eager alloc mem 1024.00 Bytes] 1980eager alloc mem 1024.00 Byteseager alloc mem 1024.00 Bytes
eager alloc mem 1024.00 Bytes] 


eager alloc mem 1024.00 Bytes
[2022-12-12 01:55:59.240734: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 01:55:59.241066: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 01:55:59.249856: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:55:59.249936: E[ 2022-12-12 01:55:59/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:249929638: ] Eeager release cuda mem 2 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:55:59.250003: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 01:55:59638.] 250016eager release cuda mem 400000000: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:55:59.250071: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:55:59.250173: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:55:59.250236: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[[2022-12-12 01:55:592022-12-12 01:55:59..250260250279: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 1024eager release cuda mem 400000000

[2022-12-12 01:55:59.250346: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:55:59[.2022-12-12 01:55:59250367.: 250391E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 1024] 
eager release cuda mem 400000000[
2022-12-12 01:55:59.250419: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 10242022-12-12 01:55:59
.250459: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:55:59.250491: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 01:55:59638.] 250510eager release cuda mem 2: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[[2022-12-12 01:55:592022-12-12 01:55:59..250558250547: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 400000000eager release cuda mem 1024

[2022-12-12 01:55:59.250674: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:55:59.250723: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:55:59.251003: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:55:59.251699: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:55:59.253092: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:55:59.253649: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:55:59.254229: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:55:59.254729: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:55:59.255250: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:55:59.255820: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.256776: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.256862: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:55:59.257528: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:55:59.257565: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:55:59.263214: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.264130: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.264210: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:55:59.264763: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:55:59.264803: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:55:59.267065: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.267991: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.268073: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:55:59.268624: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:55:59.268662: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:55:59.270165: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.270233: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB[
2022-12-12 01:55:59.270262: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.270293: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.271099: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.271162: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59[.2022-12-12 01:55:59271194.: 271201E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu6382022-12-12 01:55:59:] [.1980eager release cuda mem 6256632022-12-12 01:55:59271223] 
.: eager alloc mem 25.25 KB271244E
:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638:] 1980eager release cuda mem 625663] 
[eager alloc mem 25.25 KB2022-12-12 01:55:59
.271339: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:55:59.271405: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:55:59.271830: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:55:59.271872: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:[19802022-12-12 01:55:59] .eager alloc mem 2.38 GB271885
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855[
2022-12-12 01:55:59.271913: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 01:55:59eager release cuda mem 25855.
271936: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB[
[2022-12-12 01:55:592022-12-12 01:55:59..271962271965: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::6381980] ] eager release cuda mem 25855eager alloc mem 2.38 GB

[2022-12-12 01:55:59.272069: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[[[[[[[[2022-12-12 01:55:592022-12-12 01:55:592022-12-12 01:55:592022-12-12 01:55:592022-12-12 01:55:592022-12-12 01:55:592022-12-12 01:55:592022-12-12 01:55:59........744497744517744497744508744497744502744497744505: : : : : : : : EEEEEEEE        /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::::::19801980198019801980198019801980] ] ] ] ] ] ] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB







[2022-12-12 01:55:59.[[7456062022-12-12 01:55:59[[2022-12-12 01:55:59: .[[2022-12-12 01:55:59[2022-12-12 01:55:59.E7456112022-12-12 01:55:59.2022-12-12 01:55:59.2022-12-12 01:55:59.745613 : 745618.745615.745616: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 745618: 745626: E: E: E: E 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc E E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:eager release cuda mem 625663638:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638
] 638:638:638] eager release cuda mem 625663] 638] 638] eager release cuda mem 625663
eager release cuda mem 625663] eager release cuda mem 625663] [eager release cuda mem 625663

eager release cuda mem 625663
eager release cuda mem 6256632022-12-12 01:55:59


.[7458532022-12-12 01:55:59: .E745892 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[] :2022-12-12 01:55:59eager alloc mem 611.00 KB[1980[.
2022-12-12 01:55:59] [2022-12-12 01:55:59745924.[[eager alloc mem 611.00 KB2022-12-12 01:55:59.: 7459322022-12-12 01:55:592022-12-12 01:55:59
.745933E: ..745941:  E745947745948: E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu : : E :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuEE /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980:  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:] 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980eager alloc mem 611.00 KB] ::1980] 
eager alloc mem 611.00 KB19801980] eager alloc mem 611.00 KB
] ] eager alloc mem 611.00 KB
eager alloc mem 611.00 KBeager alloc mem 611.00 KB


[2022-12-12 01:55:59.746677: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.746717: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.746747: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.746786: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.746833: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 01:55:59] [.eager release cuda mem 6256632022-12-12 01:55:59746849
.[: 746857[2022-12-12 01:55:59E[: 2022-12-12 01:55:59. 2022-12-12 01:55:59E.746867/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc. 746872: :[746876/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: E6382022-12-12 01:55:59: :E ] .E638 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663746917 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:
: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663:638E:
638]  638] eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] eager release cuda mem 625663
:[eager release cuda mem 625663
19802022-12-12 01:55:59[
] .2022-12-12 01:55:59eager alloc mem 611.00 KB747040.
: 747062E: [ E2022-12-12 01:55:59/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu .:[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu74709019802022-12-12 01:55:59:: ] [.1980Eeager alloc mem 611.00 KB2022-12-12 01:55:59747102]  
.: eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu747116E
::  1980E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu]  :eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980
:] 1980eager alloc mem 611.00 KB] 
eager alloc mem 611.00 KB
[2022-12-12 01:55:59.747494: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.747534: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.747561: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.747601: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.747812: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.747879: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.747899: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 01:55:59638.] 747916eager release cuda mem 625663: 
E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:55:59:.638747964] : eager release cuda mem 625663E
[ 2022-12-12 01:55:59[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.2022-12-12 01:55:59:[747986.6382022-12-12 01:55:59: 747990[] .E: 2022-12-12 01:55:59eager release cuda mem 625663748009 E.
: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc 748031E:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:  638:E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] 638 :[eager release cuda mem 625663] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu19802022-12-12 01:55:59
eager release cuda mem 625663:] .
1980eager alloc mem 611.00 KB748116] 
: eager alloc mem 611.00 KBE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB[
2022-12-12 01:55:59.748187: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 01:55:591980.] 748204eager alloc mem 611.00 KB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.748309: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.748349: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.748375: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.748414: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.748626: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.748696: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[[2022-12-12 01:55:592022-12-12 01:55:59..748901748904: [: E2022-12-12 01:55:59E . /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc748919/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:: :638E638]  ] eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663
:[
6382022-12-12 01:55:59] .eager release cuda mem 625663[748963
2022-12-12 01:55:59: .E748977 [[: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:55:592022-12-12 01:55:59E:..[ 6387490147490112022-12-12 01:55:59/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] : : .:eager release cuda mem 625663EE749035638
  : ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuEeager release cuda mem 625663:: [
19801980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 01:55:59] [] :.eager alloc mem 611.00 KB2022-12-12 01:55:59eager alloc mem 611.00 KB1980749119
.
[] : 7491392022-12-12 01:55:59eager alloc mem 611.00 KBE: .
[ E7491592022-12-12 01:55:59/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc : .:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE749179638: : ] 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccEeager release cuda mem 625663] : 
eager alloc mem 611.00 KB638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
] :eager release cuda mem 6256631980
] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.749307: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.749336: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.749439: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.749502: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.749884: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:55:59:.638749896] : eager release cuda mem 625663[E
2022-12-12 01:55:59 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc749914:: 638E]  eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 625663
[2022-12-12 01:55:59.749964: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.749992[: 2022-12-12 01:55:59E[. 2022-12-12 01:55:59749999/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.: :750005E1980[:  ] 2022-12-12 01:55:59E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 611.00 KB[. :
2022-12-12 01:55:59750026/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc1980.[: :] 7500502022-12-12 01:55:59E638eager alloc mem 611.00 KB: . ] 
E750080/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663 : :
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE638: ] 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663] :
eager release cuda mem 625663638[
] 2022-12-12 01:55:59eager release cuda mem 625663.
750194: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.[7502352022-12-12 01:55:59: [.[E2022-12-12 01:55:597502412022-12-12 01:55:59 .: ./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu750252E750255::  : 1980E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE]  : eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:] :1980eager alloc mem 611.00 KB638] 
] eager alloc mem 611.00 KBeager release cuda mem 625663

[2022-12-12 01:55:59.750420: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.750708: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.750772: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.750800: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.750854: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 01:55:59638.] 750868eager release cuda mem 625663: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.750928: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.750953: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.751018: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.751091: [[E2022-12-12 01:55:592022-12-12 01:55:59 ../hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc751099751095:: : 638EE]  [ eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:55:59/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:.:638751166638[] : ] 2022-12-12 01:55:59eager release cuda mem 625663Eeager release cuda mem 625663.
 
751210/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :[E6382022-12-12 01:55:59 ] ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663751258:
: 638E]  eager release cuda mem 20400000/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[
:2022-12-12 01:55:59638.] 751296[eager release cuda mem 20400000: 2022-12-12 01:55:59
E. 751307/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 20400000:
1980] eager alloc mem 611.00 KB
[2022-12-12 01:55:59.751518: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.751556: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:55:59.751628: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.751670: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:55:59:.638751681] : eager release cuda mem 20400000E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.751730: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:55:59.751764: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:55:59.751801: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:55:59.752140: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 01:55:59638.] 752151eager release cuda mem 625663: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] [Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.609766 secs 2022-12-12 01:55:59
.752206: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:55:59.752355: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.610055 secs 
[2022-12-12 01:55:59.752648: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.610247 secs 
[2022-12-12 01:55:59.753143: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.610605 secs 
[2022-12-12 01:55:59.753266: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.610941 secs 
[2022-12-12 01:55:59.753465: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.611584 secs 
[2022-12-12 01:55:59.753905: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.627131 secs 
[2022-12-12 01:55:59.754050: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.611121 secs 
[2022-12-12 01:55:59.755454: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 10.70 GB
[2022-12-12 01:56:01.146308: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 10.97 GB
[2022-12-12 01:56:01.146637: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 10.97 GB
[2022-12-12 01:56:01.147642: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 10.97 GB
[2022-12-12 01:56:02.818149: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 11.23 GB
[2022-12-12 01:56:02.818422: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 11.23 GB
[2022-12-12 01:56:02.819296: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 11.23 GB
[2022-12-12 01:56:03.897992: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 11.45 GB
[2022-12-12 01:56:03.898145: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 11.45 GB
[2022-12-12 01:56:03.898494: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 11.45 GB
[2022-12-12 01:56:05.560420: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 11.66 GB
[2022-12-12 01:56:05.560934: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 11.66 GB
[2022-12-12 01:56:05.562204: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 11.66 GB
[2022-12-12 01:56:07.233923: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 12.12 GB
[2022-12-12 01:56:07.234314: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 12.12 GB
[2022-12-12 01:56:07.235170: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 12.12 GB
[2022-12-12 01:56:08.710173: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 12.32 GB
[2022-12-12 01:56:08.710383: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 12.32 GB
[HCTR][01:56:08.728][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier
[HCTR][01:56:08.728][ERROR][RK0][tid #140478540392192]: replica 4 calling init per replica done, doing barrier
[HCTR][01:56:08.728][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier
[HCTR][01:56:08.728][ERROR][RK0][tid #140478548784896]: replica 1 calling init per replica done, doing barrier
[HCTR][01:56:08.728][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][01:56:08.728][ERROR][RK0][tid #140478397781760]: replica 6 calling init per replica done, doing barrier
[HCTR][01:56:08.728][ERROR][RK0][tid #140478397781760]: replica 2 calling init per replica done, doing barrier
[HCTR][01:56:08.728][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier
[HCTR][01:56:08.729][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier done
[HCTR][01:56:08.729][ERROR][RK0][tid #140478540392192]: replica 4 calling init per replica done, doing barrier done
[HCTR][01:56:08.729][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier done
[HCTR][01:56:08.729][ERROR][RK0][tid #140478397781760]: replica 2 calling init per replica done, doing barrier done
[HCTR][01:56:08.729][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][01:56:08.729][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier done
[HCTR][01:56:08.729][ERROR][RK0][tid #140478397781760]: replica 6 calling init per replica done, doing barrier done
[HCTR][01:56:08.729][ERROR][RK0][tid #140478548784896]: replica 1 calling init per replica done, doing barrier done
[HCTR][01:56:08.729][ERROR][RK0][main]: init per replica done
[HCTR][01:56:08.729][ERROR][RK0][tid #140478540392192]: init per replica done
[HCTR][01:56:08.729][ERROR][RK0][main]: init per replica done
[HCTR][01:56:08.729][ERROR][RK0][tid #140478397781760]: init per replica done
[HCTR][01:56:08.729][ERROR][RK0][main]: init per replica done
[HCTR][01:56:08.729][ERROR][RK0][tid #140478397781760]: init per replica done
[HCTR][01:56:08.729][ERROR][RK0][tid #140478548784896]: init per replica done
[HCTR][01:56:08.732][ERROR][RK0][main]: init per replica done
[HCTR][01:56:08.767][ERROR][RK0][tid #140478540392192]: 4 allocated 3276800 at 0x7fa67c238400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478540392192]: 4 allocated 6553600 at 0x7fa67c558400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478540392192]: 4 allocated 3276800 at 0x7fa67cb98400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478540392192]: 4 allocated 6553600 at 0x7fa67ceb8400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478406174464]: 7 allocated 3276800 at 0x7fa690238400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478406174464]: 7 allocated 6553600 at 0x7fa690558400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478406174464]: 7 allocated 3276800 at 0x7fa690b98400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478397781760]: 6 allocated 3276800 at 0x7fa764238400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478406174464]: 7 allocated 6553600 at 0x7fa690eb8400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478397781760]: 6 allocated 6553600 at 0x7fa764558400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478397781760]: 6 allocated 3276800 at 0x7fa764b98400
[HCTR][01:56:08.767][ERROR][RK0][tid #140478397781760]: 6 allocated 6553600 at 0x7fa764eb8400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478397781760]: 2 allocated 3276800 at 0x7fa7bc238400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478397781760]: 2 allocated 6553600 at 0x7fa7bc558400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478397781760]: 2 allocated 3276800 at 0x7fa7bcb98400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478397781760]: 2 allocated 6553600 at 0x7fa7bceb8400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478548784896]: 1 allocated 3276800 at 0x7fa744238400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478548784896]: 1 allocated 6553600 at 0x7fa744558400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478548784896]: 1 allocated 3276800 at 0x7fa744b98400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478548784896]: 1 allocated 6553600 at 0x7fa744eb8400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478406174464]: 3 allocated 3276800 at 0x7fa7c8238400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478406174464]: 3 allocated 6553600 at 0x7fa7c8558400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478406174464]: 3 allocated 3276800 at 0x7fa7c8b98400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478406174464]: 3 allocated 6553600 at 0x7fa7c8eb8400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478934652672]: 5 allocated 3276800 at 0x7fa7c4238400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478934652672]: 5 allocated 6553600 at 0x7fa7c4558400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478934652672]: 5 allocated 3276800 at 0x7fa7c4b98400
[HCTR][01:56:08.768][ERROR][RK0][tid #140478934652672]: 5 allocated 6553600 at 0x7fa7c4eb8400
[HCTR][01:56:08.771][ERROR][RK0][tid #140478397781760]: 0 allocated 3276800 at 0x7fa764320000
[HCTR][01:56:08.771][ERROR][RK0][tid #140478397781760]: 0 allocated 6553600 at 0x7fa764640000
[HCTR][01:56:08.771][ERROR][RK0][tid #140478397781760]: 0 allocated 3276800 at 0x7fa764c80000
[HCTR][01:56:08.771][ERROR][RK0][tid #140478397781760]: 0 allocated 6553600 at 0x7fa764fa0000
