2022-12-12 01:15:39.358904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.366825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.372380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.377373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.389779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.397565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.401689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.413686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.463608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.466651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.469760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.470976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.472916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.473708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.474058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.475544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.475600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.477175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.477246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.478907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.479035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.486245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.486339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.488298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.488311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.490090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.490148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.491729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.491831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.493293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.494313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.495232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.496968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.498160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.499298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.500341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.501358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.502376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.503342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.504277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.509638: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:15:39.512980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.514652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.516555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.516697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.518844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.518889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.519054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.519621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.521701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.521770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.522273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.522717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.525117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.525169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.525622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.525713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.525871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.528338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.528588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.529182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.529460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.532283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.532513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.533171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.533485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.534893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.536483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.537309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.537551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.537587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.539259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.539793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.540535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.541267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.541424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.541760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.543418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.543996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.545126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.545343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.545721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.547344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.547871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.548479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.549292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.550465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.550834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.551046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.551951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.553188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.553513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.553562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.555723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.555763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.556049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.557543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.557691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.558045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.564907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.566479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.567388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.568305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.569450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.580413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.588071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.592798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.597921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.605279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.605302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.605338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.605393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.605442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.609054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.609092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.609136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.609198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.609284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.609400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.611146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.613669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.613719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.613841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.614868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.614939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.615151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.616620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.618922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.619306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.619386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.619489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.619637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.619771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.621304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.624619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.624738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.624852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.624946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.625072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.625279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.626483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.629544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.629662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.629945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.629941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.630028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.630240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.631708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.634181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.634443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.634603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.634803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.634936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.635021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.636254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.638502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.638576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.638778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.639017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.639369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.639566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.641367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.644296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.644366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.644491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.644833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.644910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.645074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.646679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.649432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.649509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.649738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.650419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.650467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.650672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.652883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.655105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.655154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.655364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.655813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.655855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.655961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.657887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.660707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.660750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.660917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.661255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.661357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.661580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.663350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.665406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.665545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.665641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.666041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.666410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.667663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.669551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.669585: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.669727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.670101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.670580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.671001: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:15:39.671603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.673501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.673645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.673678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.673984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.674536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.675699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.678826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.679037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.679474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.679600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.680381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.680953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.681127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.683370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.683799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.683997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.684121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.684529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.685101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.685679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.688299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.688626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.688701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.689119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.689235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.690232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.690539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.693217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.693390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.693422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.693546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.693816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.695075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.697782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.697861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.697916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.698008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.698135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.700319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.703530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.703628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.703739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.703792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.703845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.705251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.707936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.708020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.708112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.708270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.708320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.709443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.712651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.712840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.713034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.713098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.713201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.714475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.717648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.719037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.720771: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:15:39.720773: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:15:39.720933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.721458: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:15:39.721583: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:15:39.722142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.726580: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:15:39.727683: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:15:39.731112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.731124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.732013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.732018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.735207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.735419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.735450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.735619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.736650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.737259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.739204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.739264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.739449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.769139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.799332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.799900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.804850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:39.805265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:40.875272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:40.882121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:40.883285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:40.883777: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:15:40.883832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 01:15:40.902232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:40.902886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:40.903437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:40.904021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:40.904636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:40.905142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 01:15:40.952257: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:40.952457: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:40.983705: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-12 01:15:41.084160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.084777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.085312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.085865: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:15:41.085920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 01:15:41.104955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.105604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.106692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.107297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.107829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.108309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 01:15:41.176307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.177098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.178019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.178499: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:15:41.178552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 01:15:41.180323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.180924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.181392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.181498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.182517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.182641: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:15:41.182695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 01:15:41.188884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.189374: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:15:41.189425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 01:15:41.197542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.198175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.198684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.199287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.199809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.200537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 01:15:41.202639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.203082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.203723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.204082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.204532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.205024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.205384: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:15:41.205444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 01:15:41.205754: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:15:41.205805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 01:15:41.206358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.206941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.207078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.207489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.207976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.208611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.209079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.209355: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:15:41.209401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 01:15:41.210177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.210450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.211178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.211498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.212124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.212531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.213069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 01:15:41.213314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 01:15:41.213582: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.213734: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.215696: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-12 01:15:41.224032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.224707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.225227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.225237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.226358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.226367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.227386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.227445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.227549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.228706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 01:15:41.229038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.229122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.230104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.230184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.231186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 01:15:41.231479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.232027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:15:41.232508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 01:15:41.246991: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.247193: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.248122: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-12 01:15:41.259510: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.259702: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.261441: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-12 01:15:41.276198: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.276303: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.276410: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.276467: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.278383: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-12 01:15:41.278426: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-12 01:15:41.279243: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.279402: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.281179: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-12 01:15:41.300826: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.301017: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:15:41.302783: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
[HCTR][01:15:42.575][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:15:42.575][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:15:42.575][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:15:42.575][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:15:42.575][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:15:42.575][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:15:42.575][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:15:42.576][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:01,  1.60s/it]warmup run: 1it [00:01,  1.64s/it]warmup run: 1it [00:01,  1.52s/it]warmup run: 94it [00:01, 76.87it/s]warmup run: 100it [00:01, 79.84it/s]warmup run: 94it [00:01, 80.44it/s]warmup run: 189it [00:01, 168.33it/s]warmup run: 200it [00:01, 174.25it/s]warmup run: 1it [00:01,  1.53s/it]warmup run: 190it [00:01, 176.35it/s]warmup run: 284it [00:01, 270.07it/s]warmup run: 301it [00:01, 280.89it/s]warmup run: 1it [00:01,  1.51s/it]warmup run: 94it [00:01, 79.86it/s]warmup run: 286it [00:01, 281.91it/s]warmup run: 377it [00:01, 373.51it/s]warmup run: 399it [00:02, 388.32it/s]warmup run: 1it [00:01,  1.50s/it]warmup run: 1it [00:01,  1.48s/it]warmup run: 1it [00:01,  1.54s/it]warmup run: 96it [00:01, 82.49it/s]warmup run: 192it [00:01, 177.37it/s]warmup run: 381it [00:01, 389.56it/s]warmup run: 473it [00:02, 480.64it/s]warmup run: 494it [00:02, 488.94it/s]warmup run: 98it [00:01, 84.71it/s]warmup run: 95it [00:01, 83.02it/s]warmup run: 93it [00:01, 78.53it/s]warmup run: 197it [00:01, 184.03it/s]warmup run: 291it [00:01, 286.16it/s]warmup run: 476it [00:02, 493.85it/s]warmup run: 570it [00:02, 581.37it/s]warmup run: 590it [00:02, 585.26it/s]warmup run: 197it [00:01, 184.36it/s]warmup run: 188it [00:01, 177.12it/s]warmup run: 185it [00:01, 169.34it/s]warmup run: 296it [00:01, 293.00it/s]warmup run: 390it [00:01, 399.13it/s]warmup run: 572it [00:02, 591.26it/s]warmup run: 668it [00:02, 672.17it/s]warmup run: 687it [00:02, 671.14it/s]warmup run: 298it [00:01, 296.42it/s]warmup run: 280it [00:01, 278.90it/s]warmup run: 278it [00:01, 270.82it/s]warmup run: 395it [00:01, 405.71it/s]warmup run: 490it [00:02, 511.15it/s]warmup run: 669it [00:02, 677.78it/s]warmup run: 767it [00:02, 749.22it/s]warmup run: 784it [00:02, 742.68it/s]warmup run: 398it [00:01, 410.37it/s]warmup run: 373it [00:01, 385.22it/s]warmup run: 370it [00:01, 374.37it/s]warmup run: 495it [00:02, 517.08it/s]warmup run: 592it [00:02, 617.20it/s]warmup run: 767it [00:02, 752.62it/s]warmup run: 864it [00:02, 806.45it/s]warmup run: 882it [00:02, 801.87it/s]warmup run: 499it [00:02, 522.70it/s]warmup run: 466it [00:01, 487.58it/s]warmup run: 460it [00:02, 472.13it/s]warmup run: 597it [00:02, 623.04it/s]warmup run: 694it [00:02, 708.98it/s]warmup run: 865it [00:02, 810.35it/s]warmup run: 961it [00:02, 848.45it/s]warmup run: 981it [00:02, 852.19it/s]warmup run: 594it [00:02, 612.62it/s]warmup run: 561it [00:02, 584.89it/s]warmup run: 552it [00:02, 564.38it/s]warmup run: 697it [00:02, 709.83it/s]warmup run: 792it [00:02, 771.94it/s]warmup run: 963it [00:02, 854.09it/s]warmup run: 1057it [00:02, 878.86it/s]warmup run: 1081it [00:02, 892.21it/s]warmup run: 690it [00:02, 692.54it/s]warmup run: 653it [00:02, 662.66it/s]warmup run: 644it [00:02, 646.12it/s]warmup run: 797it [00:02, 781.72it/s]warmup run: 889it [00:02, 817.92it/s]warmup run: 1060it [00:02, 884.37it/s]warmup run: 1153it [00:02, 900.22it/s]warmup run: 1182it [00:02, 923.58it/s]warmup run: 788it [00:02, 762.72it/s]warmup run: 744it [00:02, 723.27it/s]warmup run: 738it [00:02, 718.04it/s]warmup run: 898it [00:02, 839.88it/s]warmup run: 1157it [00:02, 907.76it/s]warmup run: 986it [00:02, 851.40it/s]warmup run: 1251it [00:02, 920.67it/s]warmup run: 1284it [00:02, 948.72it/s]warmup run: 885it [00:02, 816.87it/s]warmup run: 835it [00:02, 770.62it/s]warmup run: 997it [00:02, 878.65it/s]warmup run: 829it [00:02, 762.42it/s]warmup run: 1254it [00:02, 923.83it/s]warmup run: 1082it [00:02, 868.23it/s]warmup run: 1348it [00:03, 934.74it/s]warmup run: 1386it [00:03, 966.96it/s]warmup run: 986it [00:02, 867.69it/s]warmup run: 926it [00:02, 805.89it/s]warmup run: 1097it [00:02, 912.05it/s]warmup run: 922it [00:02, 806.32it/s]warmup run: 1352it [00:02, 939.90it/s]warmup run: 1177it [00:02, 883.04it/s]warmup run: 1445it [00:03, 943.11it/s]warmup run: 1487it [00:03, 978.90it/s]warmup run: 1086it [00:02, 904.45it/s]warmup run: 1017it [00:02, 831.91it/s]warmup run: 1197it [00:02, 935.38it/s]warmup run: 1022it [00:02, 859.34it/s]warmup run: 1449it [00:03, 948.53it/s]warmup run: 1271it [00:02, 893.39it/s]warmup run: 1542it [00:03, 946.11it/s]warmup run: 1589it [00:03, 989.23it/s]warmup run: 1187it [00:02, 932.54it/s]warmup run: 1109it [00:02, 854.81it/s]warmup run: 1298it [00:02, 955.63it/s]warmup run: 1124it [00:02, 902.62it/s]warmup run: 1547it [00:03, 955.47it/s]warmup run: 1364it [00:02, 903.72it/s]warmup run: 1640it [00:03, 954.03it/s]warmup run: 1691it [00:03, 997.82it/s]warmup run: 1290it [00:02, 960.02it/s]warmup run: 1200it [00:02, 870.70it/s]warmup run: 1226it [00:02, 935.42it/s]warmup run: 1398it [00:02, 944.91it/s]warmup run: 1646it [00:03, 965.15it/s]warmup run: 1457it [00:03, 907.39it/s]warmup run: 1737it [00:03, 957.81it/s]warmup run: 1792it [00:03, 997.65it/s]warmup run: 1394it [00:02, 981.39it/s]warmup run: 1294it [00:02, 888.82it/s]warmup run: 1326it [00:02, 954.16it/s]warmup run: 1746it [00:03, 975.17it/s]warmup run: 1496it [00:03, 933.45it/s]warmup run: 1550it [00:03, 912.50it/s]warmup run: 1835it [00:03, 963.14it/s]warmup run: 1894it [00:03, 1001.82it/s]warmup run: 1497it [00:03, 993.22it/s]warmup run: 1388it [00:02, 903.46it/s]warmup run: 1428it [00:03, 971.56it/s]warmup run: 1846it [00:03, 981.73it/s]warmup run: 1592it [00:03, 928.15it/s]warmup run: 1643it [00:03, 914.78it/s]warmup run: 1933it [00:03, 966.21it/s]warmup run: 1996it [00:03, 1006.69it/s]warmup run: 1600it [00:03, 1003.21it/s]warmup run: 1481it [00:03, 909.07it/s]warmup run: 1528it [00:03, 979.82it/s]warmup run: 1946it [00:03, 985.85it/s]warmup run: 1687it [00:03, 926.99it/s]warmup run: 1737it [00:03, 919.64it/s]warmup run: 2037it [00:03, 986.27it/s]warmup run: 2116it [00:03, 1061.93it/s]warmup run: 1702it [00:03, 1003.74it/s]warmup run: 1578it [00:03, 924.75it/s]warmup run: 1630it [00:03, 988.95it/s]warmup run: 2054it [00:03, 1012.20it/s]warmup run: 1831it [00:03, 925.23it/s]warmup run: 1781it [00:03, 927.73it/s]warmup run: 2156it [00:03, 1046.78it/s]warmup run: 2237it [00:03, 1105.37it/s]warmup run: 1805it [00:03, 1009.87it/s]warmup run: 1673it [00:03, 931.98it/s]warmup run: 1731it [00:03, 994.13it/s]warmup run: 2172it [00:03, 1060.73it/s]warmup run: 1925it [00:03, 928.36it/s]warmup run: 1875it [00:03, 927.78it/s]warmup run: 2275it [00:03, 1088.41it/s]warmup run: 2358it [00:03, 1136.20it/s]warmup run: 1908it [00:03, 1014.79it/s]warmup run: 1768it [00:03, 936.33it/s]warmup run: 1832it [00:03, 997.48it/s]warmup run: 2290it [00:03, 1094.35it/s]warmup run: 2024it [00:03, 945.37it/s]warmup run: 1969it [00:03, 929.12it/s]warmup run: 2395it [00:04, 1119.05it/s]warmup run: 2479it [00:04, 1157.41it/s]warmup run: 2012it [00:03, 1020.90it/s]warmup run: 1863it [00:03, 937.66it/s]warmup run: 1933it [00:03, 996.04it/s]warmup run: 2408it [00:03, 1117.69it/s]warmup run: 2143it [00:03, 1016.29it/s]warmup run: 2078it [00:03, 974.80it/s]warmup run: 2514it [00:04, 1139.76it/s]warmup run: 2600it [00:04, 1171.98it/s]warmup run: 2133it [00:03, 1076.12it/s]warmup run: 1958it [00:03, 940.50it/s]warmup run: 2038it [00:03, 1011.69it/s]warmup run: 2526it [00:04, 1133.74it/s]warmup run: 2262it [00:03, 1065.59it/s]warmup run: 2195it [00:03, 1032.32it/s]warmup run: 2633it [00:04, 1153.14it/s]warmup run: 2720it [00:04, 1180.21it/s]warmup run: 2254it [00:03, 1113.89it/s]warmup run: 2064it [00:03, 974.00it/s]warmup run: 2157it [00:03, 1062.21it/s]warmup run: 2643it [00:04, 1142.06it/s]warmup run: 2381it [00:03, 1100.50it/s]warmup run: 2311it [00:03, 1070.17it/s]warmup run: 2753it [00:04, 1164.57it/s]warmup run: 2842it [00:04, 1189.85it/s]warmup run: 2375it [00:03, 1141.47it/s]warmup run: 2180it [00:03, 1027.93it/s]warmup run: 2276it [00:03, 1097.90it/s]warmup run: 2760it [00:04, 1150.17it/s]warmup run: 2500it [00:04, 1125.38it/s]warmup run: 2429it [00:03, 1100.46it/s]warmup run: 2872it [00:04, 1171.46it/s]warmup run: 2964it [00:04, 1196.25it/s]warmup run: 2496it [00:03, 1159.78it/s]warmup run: 2297it [00:03, 1067.68it/s]warmup run: 3000it [00:04, 667.80it/s] warmup run: 2395it [00:03, 1122.85it/s]warmup run: 2878it [00:04, 1156.27it/s]warmup run: 2619it [00:04, 1141.86it/s]warmup run: 2546it [00:04, 1120.65it/s]warmup run: 2992it [00:04, 1177.76it/s]warmup run: 3000it [00:04, 662.84it/s] warmup run: 2615it [00:04, 1167.90it/s]warmup run: 2413it [00:04, 1093.26it/s]warmup run: 2514it [00:04, 1140.00it/s]warmup run: 2998it [00:04, 1166.86it/s]warmup run: 3000it [00:04, 675.01it/s] warmup run: 2734it [00:04, 1143.85it/s]warmup run: 2660it [00:04, 1124.53it/s]warmup run: 2734it [00:04, 1171.61it/s]warmup run: 2529it [00:04, 1111.52it/s]warmup run: 2632it [00:04, 1149.86it/s]warmup run: 2851it [00:04, 1151.39it/s]warmup run: 2779it [00:04, 1142.22it/s]warmup run: 2855it [00:04, 1182.43it/s]warmup run: 2644it [00:04, 1122.12it/s]warmup run: 2750it [00:04, 1157.60it/s]warmup run: 2968it [00:04, 1156.53it/s]warmup run: 2897it [00:04, 1151.84it/s]warmup run: 3000it [00:04, 666.77it/s] warmup run: 2976it [00:04, 1189.13it/s]warmup run: 2760it [00:04, 1130.22it/s]warmup run: 3000it [00:04, 690.45it/s] warmup run: 2866it [00:04, 1156.76it/s]warmup run: 3000it [00:04, 675.07it/s] warmup run: 2876it [00:04, 1138.63it/s]warmup run: 2984it [00:04, 1161.66it/s]warmup run: 3000it [00:04, 669.26it/s] warmup run: 2992it [00:04, 1143.24it/s]warmup run: 3000it [00:04, 664.08it/s] 
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]






warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1638.32it/s]warmup should be done:   5%|         | 160/3000 [00:00<00:01, 1599.60it/s]warmup should be done:   5%|         | 158/3000 [00:00<00:01, 1573.41it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1623.36it/s]warmup should be done:   5%|         | 160/3000 [00:00<00:01, 1593.58it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1612.41it/s]warmup should be done:   5%|         | 160/3000 [00:00<00:01, 1592.99it/s]warmup should be done:   5%|         | 161/3000 [00:00<00:01, 1600.84it/s]warmup should be done:  11%|         | 322/3000 [00:00<00:01, 1609.96it/s]warmup should be done:  11%|         | 329/3000 [00:00<00:01, 1642.07it/s]warmup should be done:  11%|         | 327/3000 [00:00<00:01, 1630.11it/s]warmup should be done:  11%|         | 322/3000 [00:00<00:01, 1605.91it/s]warmup should be done:  11%|         | 325/3000 [00:00<00:01, 1621.92it/s]warmup should be done:  11%|         | 322/3000 [00:00<00:01, 1604.78it/s]warmup should be done:  11%|         | 325/3000 [00:00<00:01, 1617.37it/s]warmup should be done:  11%|         | 316/3000 [00:00<00:01, 1567.85it/s]warmup should be done:  16%|        | 483/3000 [00:00<00:01, 1607.29it/s]warmup should be done:  16%|        | 494/3000 [00:00<00:01, 1640.37it/s]warmup should be done:  16%|        | 483/3000 [00:00<00:01, 1603.14it/s]warmup should be done:  16%|        | 483/3000 [00:00<00:01, 1602.25it/s]warmup should be done:  16%|        | 487/3000 [00:00<00:01, 1612.54it/s]warmup should be done:  16%|        | 491/3000 [00:00<00:01, 1624.50it/s]warmup should be done:  16%|        | 488/3000 [00:00<00:01, 1612.15it/s]warmup should be done:  16%|        | 473/3000 [00:00<00:01, 1557.66it/s]warmup should be done:  21%|       | 644/3000 [00:00<00:01, 1603.91it/s]warmup should be done:  21%|       | 644/3000 [00:00<00:01, 1602.22it/s]warmup should be done:  21%|       | 644/3000 [00:00<00:01, 1601.34it/s]warmup should be done:  22%|       | 659/3000 [00:00<00:01, 1636.19it/s]warmup should be done:  22%|       | 649/3000 [00:00<00:01, 1608.99it/s]warmup should be done:  22%|       | 654/3000 [00:00<00:01, 1616.05it/s]warmup should be done:  22%|       | 650/3000 [00:00<00:01, 1607.26it/s]warmup should be done:  21%|        | 629/3000 [00:00<00:01, 1550.48it/s]warmup should be done:  27%|       | 805/3000 [00:00<00:01, 1603.58it/s]warmup should be done:  27%|       | 805/3000 [00:00<00:01, 1601.33it/s]warmup should be done:  27%|       | 823/3000 [00:00<00:01, 1634.25it/s]warmup should be done:  27%|       | 805/3000 [00:00<00:01, 1600.34it/s]warmup should be done:  27%|       | 810/3000 [00:00<00:01, 1606.82it/s]warmup should be done:  27%|       | 816/3000 [00:00<00:01, 1616.72it/s]warmup should be done:  27%|       | 811/3000 [00:00<00:01, 1601.77it/s]warmup should be done:  26%|       | 785/3000 [00:00<00:01, 1546.94it/s]warmup should be done:  32%|      | 966/3000 [00:00<00:01, 1600.76it/s]warmup should be done:  32%|      | 966/3000 [00:00<00:01, 1595.29it/s]warmup should be done:  33%|      | 987/3000 [00:00<00:01, 1626.66it/s]warmup should be done:  32%|      | 966/3000 [00:00<00:01, 1593.83it/s]warmup should be done:  33%|      | 978/3000 [00:00<00:01, 1611.60it/s]warmup should be done:  32%|      | 972/3000 [00:00<00:01, 1597.29it/s]warmup should be done:  31%|      | 940/3000 [00:00<00:01, 1541.58it/s]warmup should be done:  32%|      | 971/3000 [00:00<00:01, 1582.40it/s]warmup should be done:  38%|      | 1127/3000 [00:00<00:01, 1596.79it/s]warmup should be done:  38%|      | 1127/3000 [00:00<00:01, 1597.07it/s]warmup should be done:  38%|      | 1126/3000 [00:00<00:01, 1593.84it/s]warmup should be done:  38%|      | 1140/3000 [00:00<00:01, 1612.47it/s]warmup should be done:  38%|      | 1150/3000 [00:00<00:01, 1617.41it/s]warmup should be done:  38%|      | 1131/3000 [00:00<00:01, 1586.48it/s]warmup should be done:  36%|      | 1095/3000 [00:00<00:01, 1534.54it/s]warmup should be done:  38%|      | 1132/3000 [00:00<00:01, 1584.38it/s]warmup should be done:  43%|     | 1287/3000 [00:00<00:01, 1595.51it/s]warmup should be done:  43%|     | 1302/3000 [00:00<00:01, 1613.73it/s]warmup should be done:  43%|     | 1287/3000 [00:00<00:01, 1591.50it/s]warmup should be done:  43%|     | 1286/3000 [00:00<00:01, 1589.90it/s]warmup should be done:  44%|     | 1312/3000 [00:00<00:01, 1610.91it/s]warmup should be done:  43%|     | 1291/3000 [00:00<00:01, 1588.80it/s]warmup should be done:  42%|     | 1249/3000 [00:00<00:01, 1534.08it/s]warmup should be done:  43%|     | 1294/3000 [00:00<00:01, 1595.03it/s]warmup should be done:  48%|     | 1447/3000 [00:00<00:00, 1595.68it/s]warmup should be done:  49%|     | 1464/3000 [00:00<00:00, 1613.25it/s]warmup should be done:  48%|     | 1447/3000 [00:00<00:00, 1593.60it/s]warmup should be done:  48%|     | 1445/3000 [00:00<00:00, 1585.71it/s]warmup should be done:  48%|     | 1451/3000 [00:00<00:00, 1590.37it/s]warmup should be done:  49%|     | 1456/3000 [00:00<00:00, 1602.04it/s]warmup should be done:  49%|     | 1474/3000 [00:00<00:00, 1605.95it/s]warmup should be done:  47%|     | 1403/3000 [00:00<00:01, 1533.39it/s]warmup should be done:  54%|    | 1607/3000 [00:01<00:00, 1590.06it/s]warmup should be done:  54%|    | 1607/3000 [00:01<00:00, 1594.49it/s]warmup should be done:  54%|    | 1626/3000 [00:01<00:00, 1610.84it/s]warmup should be done:  53%|    | 1604/3000 [00:01<00:00, 1582.51it/s]warmup should be done:  54%|    | 1618/3000 [00:01<00:00, 1606.86it/s]warmup should be done:  54%|    | 1611/3000 [00:01<00:00, 1589.22it/s]warmup should be done:  52%|    | 1557/3000 [00:01<00:00, 1532.62it/s]warmup should be done:  55%|    | 1635/3000 [00:01<00:00, 1602.58it/s]warmup should be done:  59%|    | 1768/3000 [00:01<00:00, 1596.31it/s]warmup should be done:  60%|    | 1788/3000 [00:01<00:00, 1611.26it/s]warmup should be done:  59%|    | 1767/3000 [00:01<00:00, 1585.86it/s]warmup should be done:  59%|    | 1763/3000 [00:01<00:00, 1581.48it/s]warmup should be done:  59%|    | 1781/3000 [00:01<00:00, 1611.23it/s]warmup should be done:  59%|    | 1770/3000 [00:01<00:00, 1589.20it/s]warmup should be done:  57%|    | 1711/3000 [00:01<00:00, 1532.91it/s]warmup should be done:  60%|    | 1796/3000 [00:01<00:00, 1600.65it/s]warmup should be done:  64%|   | 1928/3000 [00:01<00:00, 1596.83it/s]warmup should be done:  65%|   | 1950/3000 [00:01<00:00, 1610.77it/s]warmup should be done:  64%|   | 1926/3000 [00:01<00:00, 1583.00it/s]warmup should be done:  64%|   | 1922/3000 [00:01<00:00, 1579.94it/s]warmup should be done:  65%|   | 1943/3000 [00:01<00:00, 1613.76it/s]warmup should be done:  64%|   | 1931/3000 [00:01<00:00, 1592.87it/s]warmup should be done:  62%|   | 1865/3000 [00:01<00:00, 1533.03it/s]warmup should be done:  65%|   | 1957/3000 [00:01<00:00, 1598.18it/s]warmup should be done:  70%|   | 2088/3000 [00:01<00:00, 1595.01it/s]warmup should be done:  70%|   | 2112/3000 [00:01<00:00, 1610.14it/s]warmup should be done:  70%|   | 2085/3000 [00:01<00:00, 1580.35it/s]warmup should be done:  69%|   | 2080/3000 [00:01<00:00, 1579.34it/s]warmup should be done:  70%|   | 2105/3000 [00:01<00:00, 1615.60it/s]warmup should be done:  70%|   | 2093/3000 [00:01<00:00, 1599.07it/s]warmup should be done:  67%|   | 2019/3000 [00:01<00:00, 1533.50it/s]warmup should be done:  71%|   | 2117/3000 [00:01<00:00, 1597.26it/s]warmup should be done:  76%|  | 2274/3000 [00:01<00:00, 1607.97it/s]warmup should be done:  75%|  | 2244/3000 [00:01<00:00, 1578.61it/s]warmup should be done:  75%|  | 2238/3000 [00:01<00:00, 1576.07it/s]warmup should be done:  76%|  | 2267/3000 [00:01<00:00, 1614.23it/s]warmup should be done:  75%|  | 2248/3000 [00:01<00:00, 1581.98it/s]warmup should be done:  75%|  | 2253/3000 [00:01<00:00, 1599.15it/s]warmup should be done:  76%|  | 2277/3000 [00:01<00:00, 1594.97it/s]warmup should be done:  72%|  | 2173/3000 [00:01<00:00, 1515.53it/s]warmup should be done:  81%|  | 2436/3000 [00:01<00:00, 1609.26it/s]warmup should be done:  80%|  | 2396/3000 [00:01<00:00, 1576.12it/s]warmup should be done:  81%|  | 2430/3000 [00:01<00:00, 1616.23it/s]warmup should be done:  80%|  | 2402/3000 [00:01<00:00, 1574.64it/s]warmup should be done:  80%|  | 2414/3000 [00:01<00:00, 1599.64it/s]warmup should be done:  80%|  | 2407/3000 [00:01<00:00, 1576.03it/s]warmup should be done:  81%| | 2438/3000 [00:01<00:00, 1596.79it/s]warmup should be done:  78%|  | 2326/3000 [00:01<00:00, 1518.24it/s]warmup should be done:  85%| | 2554/3000 [00:01<00:00, 1576.45it/s]warmup should be done:  87%| | 2598/3000 [00:01<00:00, 1609.82it/s]warmup should be done:  86%| | 2592/3000 [00:01<00:00, 1615.78it/s]warmup should be done:  85%| | 2560/3000 [00:01<00:00, 1575.25it/s]warmup should be done:  86%| | 2575/3000 [00:01<00:00, 1602.34it/s]warmup should be done:  86%| | 2565/3000 [00:01<00:00, 1571.28it/s]warmup should be done:  87%| | 2598/3000 [00:01<00:00, 1596.73it/s]warmup should be done:  83%| | 2480/3000 [00:01<00:00, 1521.80it/s]warmup should be done:  90%| | 2713/3000 [00:01<00:00, 1577.90it/s]warmup should be done:  92%|| 2760/3000 [00:01<00:00, 1609.62it/s]warmup should be done:  91%| | 2718/3000 [00:01<00:00, 1576.29it/s]warmup should be done:  92%|| 2755/3000 [00:01<00:00, 1617.90it/s]warmup should be done:  91%| | 2737/3000 [00:01<00:00, 1606.35it/s]warmup should be done:  92%|| 2758/3000 [00:01<00:00, 1596.49it/s]warmup should be done:  91%| | 2723/3000 [00:01<00:00, 1569.34it/s]warmup should be done:  88%| | 2634/3000 [00:01<00:00, 1525.76it/s]warmup should be done:  96%|| 2877/3000 [00:01<00:00, 1580.17it/s]warmup should be done:  96%|| 2873/3000 [00:01<00:00, 1582.94it/s]warmup should be done:  97%|| 2923/3000 [00:01<00:00, 1613.66it/s]warmup should be done:  97%|| 2901/3000 [00:01<00:00, 1614.01it/s]warmup should be done:  97%|| 2919/3000 [00:01<00:00, 1621.57it/s]warmup should be done:  97%|| 2919/3000 [00:01<00:00, 1599.18it/s]warmup should be done:  96%|| 2881/3000 [00:01<00:00, 1571.42it/s]warmup should be done:  93%|| 2789/3000 [00:01<00:00, 1531.79it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1613.22it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1610.32it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1608.14it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1601.23it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1588.10it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1586.83it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1586.59it/s]warmup should be done:  98%|| 2947/3000 [00:01<00:00, 1543.35it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1536.00it/s]




warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1639.18it/s]warmup should be done:   5%|         | 159/3000 [00:00<00:01, 1586.17it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1664.28it/s]warmup should be done:   5%|         | 161/3000 [00:00<00:01, 1604.79it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1634.53it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1652.69it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1620.21it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1651.46it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1648.40it/s]warmup should be done:  11%|         | 336/3000 [00:00<00:01, 1675.74it/s]warmup should be done:  11%|         | 333/3000 [00:00<00:01, 1660.77it/s]warmup should be done:  11%|         | 324/3000 [00:00<00:01, 1614.58it/s]warmup should be done:  11%|         | 318/3000 [00:00<00:01, 1582.14it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1645.32it/s]warmup should be done:  11%|         | 327/3000 [00:00<00:01, 1627.95it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1639.44it/s]warmup should be done:  17%|        | 496/3000 [00:00<00:01, 1650.83it/s]warmup should be done:  17%|        | 505/3000 [00:00<00:01, 1680.85it/s]warmup should be done:  17%|        | 501/3000 [00:00<00:01, 1666.94it/s]warmup should be done:  16%|        | 486/3000 [00:00<00:01, 1615.45it/s]warmup should be done:  17%|        | 496/3000 [00:00<00:01, 1648.20it/s]warmup should be done:  16%|        | 477/3000 [00:00<00:01, 1581.72it/s]warmup should be done:  16%|        | 491/3000 [00:00<00:01, 1629.80it/s]warmup should be done:  17%|        | 496/3000 [00:00<00:01, 1632.04it/s]warmup should be done:  22%|       | 675/3000 [00:00<00:01, 1686.53it/s]warmup should be done:  22%|       | 669/3000 [00:00<00:01, 1668.60it/s]warmup should be done:  22%|       | 648/3000 [00:00<00:01, 1614.02it/s]warmup should be done:  22%|       | 654/3000 [00:00<00:01, 1627.89it/s]warmup should be done:  21%|        | 637/3000 [00:00<00:01, 1586.39it/s]warmup should be done:  22%|       | 661/3000 [00:00<00:01, 1646.10it/s]warmup should be done:  22%|       | 662/3000 [00:00<00:01, 1644.50it/s]warmup should be done:  22%|       | 662/3000 [00:00<00:01, 1639.75it/s]warmup should be done:  28%|       | 845/3000 [00:00<00:01, 1690.36it/s]warmup should be done:  28%|       | 836/3000 [00:00<00:01, 1668.77it/s]warmup should be done:  27%|       | 796/3000 [00:00<00:01, 1587.20it/s]warmup should be done:  27%|       | 818/3000 [00:00<00:01, 1631.28it/s]warmup should be done:  27%|       | 811/3000 [00:00<00:01, 1616.19it/s]warmup should be done:  28%|       | 826/3000 [00:00<00:01, 1642.13it/s]warmup should be done:  28%|       | 827/3000 [00:00<00:01, 1641.23it/s]warmup should be done:  28%|       | 827/3000 [00:00<00:01, 1639.87it/s]warmup should be done:  33%|      | 1003/3000 [00:00<00:01, 1669.06it/s]warmup should be done:  33%|      | 982/3000 [00:00<00:01, 1633.49it/s]warmup should be done:  34%|      | 1015/3000 [00:00<00:01, 1689.15it/s]warmup should be done:  32%|      | 955/3000 [00:00<00:01, 1586.66it/s]warmup should be done:  33%|      | 976/3000 [00:00<00:01, 1627.00it/s]warmup should be done:  33%|      | 992/3000 [00:00<00:01, 1640.94it/s]warmup should be done:  33%|      | 991/3000 [00:00<00:01, 1637.57it/s]warmup should be done:  33%|      | 991/3000 [00:00<00:01, 1630.28it/s]warmup should be done:  39%|      | 1170/3000 [00:00<00:01, 1668.99it/s]warmup should be done:  39%|      | 1184/3000 [00:00<00:01, 1687.64it/s]warmup should be done:  38%|      | 1146/3000 [00:00<00:01, 1633.69it/s]warmup should be done:  37%|      | 1115/3000 [00:00<00:01, 1589.15it/s]warmup should be done:  38%|      | 1142/3000 [00:00<00:01, 1636.28it/s]warmup should be done:  39%|      | 1157/3000 [00:00<00:01, 1641.52it/s]warmup should be done:  39%|      | 1158/3000 [00:00<00:01, 1646.11it/s]warmup should be done:  39%|      | 1157/3000 [00:00<00:01, 1639.54it/s]warmup should be done:  45%|     | 1337/3000 [00:00<00:00, 1668.75it/s]warmup should be done:  45%|     | 1354/3000 [00:00<00:00, 1689.83it/s]warmup should be done:  44%|     | 1307/3000 [00:00<00:01, 1639.73it/s]warmup should be done:  44%|     | 1310/3000 [00:00<00:01, 1630.46it/s]warmup should be done:  42%|     | 1274/3000 [00:00<00:01, 1582.54it/s]warmup should be done:  44%|     | 1325/3000 [00:00<00:01, 1652.97it/s]warmup should be done:  44%|     | 1322/3000 [00:00<00:01, 1636.97it/s]warmup should be done:  44%|     | 1322/3000 [00:00<00:01, 1642.66it/s]warmup should be done:  50%|     | 1504/3000 [00:00<00:00, 1668.66it/s]warmup should be done:  49%|     | 1473/3000 [00:00<00:00, 1644.57it/s]warmup should be done:  51%|     | 1524/3000 [00:00<00:00, 1690.81it/s]warmup should be done:  49%|     | 1474/3000 [00:00<00:00, 1632.36it/s]warmup should be done:  48%|     | 1436/3000 [00:00<00:00, 1592.52it/s]warmup should be done:  50%|     | 1493/3000 [00:00<00:00, 1658.83it/s]warmup should be done:  50%|     | 1487/3000 [00:00<00:00, 1639.93it/s]warmup should be done:  50%|     | 1488/3000 [00:00<00:00, 1645.41it/s]warmup should be done:  56%|    | 1672/3000 [00:01<00:00, 1669.65it/s]warmup should be done:  56%|    | 1694/3000 [00:01<00:00, 1691.62it/s]warmup should be done:  55%|    | 1640/3000 [00:01<00:00, 1649.42it/s]warmup should be done:  55%|    | 1638/3000 [00:01<00:00, 1634.35it/s]warmup should be done:  53%|    | 1598/3000 [00:01<00:00, 1600.20it/s]warmup should be done:  55%|    | 1662/3000 [00:01<00:00, 1665.64it/s]warmup should be done:  55%|    | 1653/3000 [00:01<00:00, 1643.04it/s]warmup should be done:  55%|    | 1654/3000 [00:01<00:00, 1649.02it/s]warmup should be done:  61%|   | 1840/3000 [00:01<00:00, 1669.92it/s]warmup should be done:  62%|   | 1864/3000 [00:01<00:00, 1692.19it/s]warmup should be done:  60%|    | 1806/3000 [00:01<00:00, 1650.00it/s]warmup should be done:  60%|    | 1802/3000 [00:01<00:00, 1632.69it/s]warmup should be done:  59%|    | 1760/3000 [00:01<00:00, 1604.19it/s]warmup should be done:  61%|    | 1831/3000 [00:01<00:00, 1671.40it/s]warmup should be done:  61%|    | 1818/3000 [00:01<00:00, 1644.81it/s]warmup should be done:  61%|    | 1820/3000 [00:01<00:00, 1651.93it/s]warmup should be done:  67%|   | 2007/3000 [00:01<00:00, 1668.16it/s]warmup should be done:  68%|   | 2034/3000 [00:01<00:00, 1691.72it/s]warmup should be done:  66%|   | 1971/3000 [00:01<00:00, 1648.51it/s]warmup should be done:  66%|   | 1966/3000 [00:01<00:00, 1627.70it/s]warmup should be done:  67%|   | 1999/3000 [00:01<00:00, 1672.86it/s]warmup should be done:  64%|   | 1921/3000 [00:01<00:00, 1592.56it/s]warmup should be done:  66%|   | 1983/3000 [00:01<00:00, 1639.51it/s]warmup should be done:  66%|   | 1986/3000 [00:01<00:00, 1644.47it/s]warmup should be done:  72%|  | 2174/3000 [00:01<00:00, 1665.10it/s]warmup should be done:  71%|   | 2136/3000 [00:01<00:00, 1648.38it/s]warmup should be done:  73%|  | 2204/3000 [00:01<00:00, 1689.24it/s]warmup should be done:  71%|   | 2129/3000 [00:01<00:00, 1628.15it/s]warmup should be done:  72%|  | 2167/3000 [00:01<00:00, 1674.67it/s]warmup should be done:  69%|   | 2083/3000 [00:01<00:00, 1599.19it/s]warmup should be done:  72%|  | 2148/3000 [00:01<00:00, 1641.99it/s]warmup should be done:  72%|  | 2152/3000 [00:01<00:00, 1647.19it/s]warmup should be done:  78%|  | 2341/3000 [00:01<00:00, 1666.27it/s]warmup should be done:  77%|  | 2302/3000 [00:01<00:00, 1649.55it/s]warmup should be done:  79%|  | 2373/3000 [00:01<00:00, 1688.24it/s]warmup should be done:  76%|  | 2293/3000 [00:01<00:00, 1629.67it/s]warmup should be done:  75%|  | 2245/3000 [00:01<00:00, 1603.44it/s]warmup should be done:  77%|  | 2314/3000 [00:01<00:00, 1645.01it/s]warmup should be done:  78%|  | 2335/3000 [00:01<00:00, 1662.47it/s]warmup should be done:  77%|  | 2317/3000 [00:01<00:00, 1647.57it/s]warmup should be done:  84%| | 2509/3000 [00:01<00:00, 1667.37it/s]warmup should be done:  82%| | 2467/3000 [00:01<00:00, 1649.21it/s]warmup should be done:  85%| | 2543/3000 [00:01<00:00, 1688.94it/s]warmup should be done:  82%| | 2456/3000 [00:01<00:00, 1628.24it/s]warmup should be done:  80%|  | 2406/3000 [00:01<00:00, 1604.51it/s]warmup should be done:  83%| | 2480/3000 [00:01<00:00, 1646.67it/s]warmup should be done:  83%| | 2503/3000 [00:01<00:00, 1666.36it/s]warmup should be done:  83%| | 2483/3000 [00:01<00:00, 1650.15it/s]warmup should be done:  89%| | 2676/3000 [00:01<00:00, 1666.74it/s]warmup should be done:  88%| | 2632/3000 [00:01<00:00, 1648.26it/s]warmup should be done:  90%| | 2712/3000 [00:01<00:00, 1688.36it/s]warmup should be done:  87%| | 2619/3000 [00:01<00:00, 1627.43it/s]warmup should be done:  86%| | 2568/3000 [00:01<00:00, 1609.04it/s]warmup should be done:  88%| | 2645/3000 [00:01<00:00, 1645.76it/s]warmup should be done:  89%| | 2671/3000 [00:01<00:00, 1669.02it/s]warmup should be done:  88%| | 2649/3000 [00:01<00:00, 1645.02it/s]warmup should be done:  95%|| 2843/3000 [00:01<00:00, 1665.45it/s]warmup should be done:  93%|| 2798/3000 [00:01<00:00, 1649.87it/s]warmup should be done:  96%|| 2881/3000 [00:01<00:00, 1688.01it/s]warmup should be done:  93%|| 2782/3000 [00:01<00:00, 1627.75it/s]warmup should be done:  91%| | 2730/3000 [00:01<00:00, 1611.97it/s]warmup should be done:  95%|| 2839/3000 [00:01<00:00, 1669.37it/s]warmup should be done:  94%|| 2810/3000 [00:01<00:00, 1643.20it/s]warmup should be done:  94%|| 2814/3000 [00:01<00:00, 1636.95it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1687.96it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1666.90it/s]warmup should be done:  99%|| 2964/3000 [00:01<00:00, 1651.10it/s]warmup should be done:  98%|| 2946/3000 [00:01<00:00, 1630.30it/s]warmup should be done:  96%|| 2892/3000 [00:01<00:00, 1611.94it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1656.68it/s]warmup should be done:  99%|| 2975/3000 [00:01<00:00, 1640.20it/s]warmup should be done:  99%|| 2979/3000 [00:01<00:00, 1638.75it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1642.30it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1641.29it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1640.87it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1629.65it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1598.72it/s]2022-12-12 01:17:18.791406: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f8563832370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:17:18.791472: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:17:19.516027: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f856782ffb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:17:19.516086: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:17:19.854658: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f856782ba50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:17:19.854723: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:17:19.860161: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f855bf92020 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:17:19.860216: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:17:20.032462: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f855b82f420 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:17:20.032533: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:17:20.066451: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f690802c7f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:17:20.066519: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:17:20.067679: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f856382bd60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:17:20.067745: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:17:20.111889: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f855bfffe80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:17:20.111963: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:17:21.033679: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:17:21.792956: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:17:22.103339: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:17:22.172257: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:17:22.329625: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:17:22.335693: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:17:22.349463: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:17:22.416591: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:17:23.934299: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:17:24.776145: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:17:24.939414: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:17:25.060262: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:17:25.228978: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:17:25.272385: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:17:25.280340: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:17:25.315569: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][01:17:59.485][ERROR][RK0][main]: replica 6 reaches 1000, calling init pre replica
[HCTR][01:17:59.485][ERROR][RK0][main]: replica 7 reaches 1000, calling init pre replica
[HCTR][01:17:59.485][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:17:59.485][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:17:59.494][ERROR][RK0][main]: coll ps creation done
[HCTR][01:17:59.494][ERROR][RK0][main]: replica 7 waits for coll ps creation barrier
[HCTR][01:17:59.494][ERROR][RK0][main]: coll ps creation done
[HCTR][01:17:59.494][ERROR][RK0][main]: replica 6 waits for coll ps creation barrier
[HCTR][01:17:59.589][ERROR][RK0][main]: replica 5 reaches 1000, calling init pre replica
[HCTR][01:17:59.589][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:17:59.598][ERROR][RK0][main]: coll ps creation done
[HCTR][01:17:59.599][ERROR][RK0][main]: replica 5 waits for coll ps creation barrier
[HCTR][01:17:59.639][ERROR][RK0][main]: replica 4 reaches 1000, calling init pre replica
[HCTR][01:17:59.640][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:17:59.647][ERROR][RK0][main]: coll ps creation done
[HCTR][01:17:59.647][ERROR][RK0][main]: replica 4 waits for coll ps creation barrier
[HCTR][01:17:59.649][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][01:17:59.649][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:17:59.654][ERROR][RK0][main]: coll ps creation done
[HCTR][01:17:59.654][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][01:17:59.732][ERROR][RK0][main]: replica 2 reaches 1000, calling init pre replica
[HCTR][01:17:59.732][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:17:59.737][ERROR][RK0][main]: coll ps creation done
[HCTR][01:17:59.737][ERROR][RK0][main]: replica 2 waits for coll ps creation barrier
[HCTR][01:17:59.789][ERROR][RK0][tid #140211640047360]: replica 1 reaches 1000, calling init pre replica
[HCTR][01:17:59.789][ERROR][RK0][tid #140211640047360]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:17:59.793][ERROR][RK0][tid #140211640047360]: coll ps creation done
[HCTR][01:17:59.793][ERROR][RK0][tid #140211640047360]: replica 1 waits for coll ps creation barrier
[HCTR][01:17:59.848][ERROR][RK0][main]: replica 0 reaches 1000, calling init pre replica
[HCTR][01:17:59.848][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:17:59.853][ERROR][RK0][main]: coll ps creation done
[HCTR][01:17:59.853][ERROR][RK0][main]: replica 0 waits for coll ps creation barrier
[HCTR][01:17:59.853][ERROR][RK0][main]: replica 0 preparing frequency
[HCTR][01:18:00.670][ERROR][RK0][main]: replica 0 preparing frequency done
[HCTR][01:18:00.702][ERROR][RK0][main]: replica 0 calling init per replica
[HCTR][01:18:00.702][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][01:18:00.702][ERROR][RK0][main]: replica 7 calling init per replica
[HCTR][01:18:00.702][ERROR][RK0][main]: replica 2 calling init per replica
[HCTR][01:18:00.702][ERROR][RK0][main]: replica 6 calling init per replica
[HCTR][01:18:00.702][ERROR][RK0][main]: replica 4 calling init per replica
[HCTR][01:18:00.702][ERROR][RK0][main]: replica 5 calling init per replica
[HCTR][01:18:00.702][ERROR][RK0][tid #140211640047360]: replica 1 calling init per replica
[HCTR][01:18:00.702][ERROR][RK0][main]: Calling build_v2
[HCTR][01:18:00.702][ERROR][RK0][main]: Calling build_v2
[HCTR][01:18:00.702][ERROR][RK0][main]: Calling build_v2
[HCTR][01:18:00.702][ERROR][RK0][main]: Calling build_v2
[HCTR][01:18:00.702][ERROR][RK0][main]: Calling build_v2
[HCTR][01:18:00.703][ERROR][RK0][main]: Calling build_v2
[HCTR][01:18:00.703][ERROR][RK0][main]: Calling build_v2
[HCTR][01:18:00.703][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:18:00.703][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:18:00.703][ERROR][RK0][tid #140211640047360]: Calling build_v2
[HCTR][01:18:00.703][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:18:00.703][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:18:00.703][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:18:00.703][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:18:00.703][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:18:00.703][ERROR][RK0][tid #140211640047360]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[[[[2022-12-12 01:18:00.2022-12-12 01:18:00[[[2022-12-12 01:18:002022-12-12 01:18:007031192022-12-12 01:18:00.[.2022-12-12 01:18:00.: .7031152022-12-12 01:18:00703114.703144E2022-12-12 01:18:00703115: .: 703147:  .: E703145E: E/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc703166E :  E ::  /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.ccE/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc136E/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc: :/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc:]  :136/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc136:136using concurrent impl MPS/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc136] :] 136] 
:] using concurrent impl MPS136using concurrent impl MPS] using concurrent impl MPS136using concurrent impl MPS
] 
using concurrent impl MPS
] 
using concurrent impl MPS
using concurrent impl MPS

[2022-12-12 01:18:00.707433: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[2022-12-12 01:18:00.707472: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] assigning 8 to cpu
[2022-12-12 01:18:00.707528: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:212] build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8
[2022-12-12 01:18:00.707569: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:213] remote time is 8.68421
[2022-12-12 01:18:00[.2022-12-12 01:18:00707588.: 707599E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc178:] 214v100x8, slow pcie] 
[cpu time is 97.05882022-12-12 01:18:00
[.2022-12-12 01:18:00707635.: 707647E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc178:] 196[v100x8, slow pcie] 2022-12-12 01:18:00
assigning 8 to cpu.
707678[: 2022-12-12 01:18:00E. 707703/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: :E178 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccv100x8, slow pcie:
[1962022-12-12 01:18:00] [[.assigning 8 to cpu2022-12-12 01:18:002022-12-12 01:18:00707731
..: 707746707746[E: : 2022-12-12 01:18:00 EE.[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc  7077812022-12-12 01:18:00:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: .178::E707810] 212[196 [: v100x8, slow pcie] 2022-12-12 01:18:00] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:18:00E
build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8.assigning 8 to cpu:. 
[707848
178707884/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:18:00: [] : :.E2022-12-12 01:18:00 v100x8, slow pcieE212707941[./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
 ] [: 2022-12-12 01:18:00707974:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 82022-12-12 01:18:00E.: 178:
. 708013E] 178708058/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: [ v100x8, slow pcie] : :E2022-12-12 01:18:00/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
v100x8, slow pcieE196 .:
 ] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc708122213/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[assigning 8 to cpu2022-12-12 01:18:00:: ] :2022-12-12 01:18:00
.212Eremote time is 8.68421196.708189]  
] 708211: build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccassigning 8 to cpu[: [E
:
2022-12-12 01:18:00E2022-12-12 01:18:00 213.[ ./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 7082882022-12-12 01:18:00/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc708291:[remote time is 8.68421: .:: 1962022-12-12 01:18:00
E708344196E] . [: ]  assigning 8 to cpu708384/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:18:00Eassigning 8 to cpu/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
: :. 
:E212708451/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc214 ] : :] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E213cpu time is 97.0588[2022-12-12 01:18:00:
 ] 
2022-12-12 01:18:00.212/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421.[708575] :
7085722022-12-12 01:18:00: build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8214: .[E
] E7086272022-12-12 01:18:00 cpu time is 97.0588 [: ./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:18:00E708664::. : 212212708703/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE] ] : : build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E213/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc

 ] :/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421[214[:
2022-12-12 01:18:00] [2022-12-12 01:18:00213.cpu time is 97.05882022-12-12 01:18:00.] 708855
.708859remote time is 8.68421: 708890: 
E: E E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:18:00:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:.213:213708964] 214] : remote time is 8.68421] remote time is 8.68421E
cpu time is 97.0588
 
[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:18:00[:2022-12-12 01:18:00.214.709052] 709060: cpu time is 97.0588: E
E  /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc::214214] ] cpu time is 97.0588cpu time is 97.0588

[2022-12-12 01:19:20. 13448: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-12 01:19:20. 53565: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-12 01:19:20. 53624: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 5000000
[2022-12-12 01:19:20.166422: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-12 01:19:20.166513: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-12 01:19:20.166546: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-12 01:19:20.166577: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-12 01:19:20.167017: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.168065: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.168732: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.181759: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 6 solved
[2022-12-12 01:19:20.181820: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 6 initing device 6
[2022-12-12 01:19:20.181987: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 7 solved
[2022-12-12 01:19:20.182039: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 7 initing device 7
[2022-12-12 01:19:20.[1821032022-12-12 01:19:20: .E182119 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.ccE: 202/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc] :5 solved202[
] 2022-12-12 01:19:20.2 solved182159[
: 2022-12-12 01:19:20E. [182192/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc2022-12-12 01:19:20: :.E202182205 ] : /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc4 solvedE:[
 2052022-12-12 01:19:20/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc] .[:worker 0 thread 5 initing device 51822352022-12-12 01:19:20205
: .] E182254worker 0 thread 2 initing device 2 : 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc] :eager alloc mem 381.47 MB205
] worker 0 thread 4 initing device 4
[2022-12-12 01:19:20.182437: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.182639: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 01:19:20:.1980182653] : eager alloc mem 381.47 MBE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB[
2022-12-12 01:19:20.182689: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.185496: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.185552: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.185609: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.185659: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.185713: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.186196: [E2022-12-12 01:19:20 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc186198:: 202E]  1 solved/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc
:202] [3 solved2022-12-12 01:19:20
.186304: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc2022-12-12 01:19:20:.205186328] : worker 0 thread 1 initing device 1E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 3 initing device 3
[2022-12-12 01:19:20.186748: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.186796: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.189651: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.189699: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.189985: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.190038: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.190090: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.191081: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.191151: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.194462: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.194506: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:19:20.249685: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 01:19:20.250089: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 01:19:20.255888: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:19:20.255992: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:19:20.256042: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:19:20.257717: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:19:20.258712: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.259719: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.259814: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:19:20.260495: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:19:20.260538: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[[[[[[2022-12-12 01:19:202022-12-12 01:19:202022-12-12 01:19:202022-12-12 01:19:202022-12-12 01:19:202022-12-12 01:19:20......275434275427275434275435275434275469: : : : : : EEEEEE      /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::::198019801980198019801980] ] ] ] ] ] eager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes





[2022-12-12 01:19:20[.[[2022-12-12 01:19:20[2759112022-12-12 01:19:20[2022-12-12 01:19:20.2022-12-12 01:19:20: .2022-12-12 01:19:20.275914.E275914.275916: 275919 : 275924: E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: E E: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980:eager alloc mem 1024.00 Bytes1980:1980] 1980
] 1980] eager alloc mem 1024.00 Bytes] eager alloc mem 1024.00 Bytes] eager alloc mem 1024.00 Bytes
eager alloc mem 1024.00 Bytes
eager alloc mem 1024.00 Bytes


[2022-12-12 01:19:20.280952: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 01:19:20.281293: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 01:19:20.290356: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:19:20.290435: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:19:20.290479: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:19:20.290490: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:19:20.290572: E[ 2022-12-12 01:19:20/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:290569638: ] Eeager release cuda mem 2 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:19:20.290638: E[ 2022-12-12 01:19:20/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:290648[638: 2022-12-12 01:19:20] E.eager release cuda mem 400000000 290648
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 2:
638] eager release cuda mem 1024
[2022-12-12 01:19:20.290732: E[ 2022-12-12 01:19:20/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:290742638: ] Eeager release cuda mem 400000000 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:19:20.290802: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:19:20.290871: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[[2022-12-12 01:19:202022-12-12 01:19:20..290924290939: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 1024eager release cuda mem 2

[[2022-12-12 01:19:202022-12-12 01:19:20..291010291010: : EE  [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:19:20::.638638291024] ] : eager release cuda mem 2eager release cuda mem 400000000E

 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:19:20.291126: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:19:20.291160: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:19:20.291206: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:19:20.291400: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:19:20.292547: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:19:20.293413: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:19:20.293918: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:19:20.294564: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:19:20.295066: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:19:20.295588: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:19:20.296220: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.296853: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.297069: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.297105: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.297176: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.297258: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:19:20.297339: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.297817: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.297916: [E2022-12-12 01:19:20 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu297925:: 1980E]  eager alloc mem 25.25 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 25855
[2022-12-12 01:19:20.297982: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:19:20.298022: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.298062: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.298105: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:19:20.298142: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:19:20.298248: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.298332: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:19:20.298605: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:19:20.298644: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:19:20.298778: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:19:20.298807: [E2022-12-12 01:19:20 .298818/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 25855:
1980] eager alloc mem 2.38 GB
[2022-12-12 01:19:20.298871: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:19:20.299016: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:19:20.299057: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:19:20.301626: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.301830: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.302577: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.302660: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:19:20.302802: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.302893: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:19:20.303331: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:19:20.303375: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:19:20.303567: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:19:20.303610: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[[[[[[[2022-12-12 01:19:202022-12-12 01:19:202022-12-12 01:19:202022-12-12 01:19:202022-12-12 01:19:202022-12-12 01:19:202022-12-12 01:19:20.......778765778773778765778765[778765778765778777: : : : 2022-12-12 01:19:20: : : EEEE.EEE    778847   /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::E:::1980198019801980 198019801980] ] ] ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] ] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB:eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB



1980


] eager alloc mem 611.00 KB
[[2022-12-12 01:19:20[2022-12-12 01:19:20.[2022-12-12 01:19:20[.7799092022-12-12 01:19:20.2022-12-12 01:19:20779913[: .779917[.: 2022-12-12 01:19:20E779922: 2022-12-12 01:19:20779924E. : E.:  779936/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE 779944E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:  :E638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638 ] :638 :] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663638] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638eager release cuda mem 625663:
] eager release cuda mem 6256632022-12-12 01:19:20:] 
638eager release cuda mem 625663
.638eager release cuda mem 625663] 
780033] 
eager release cuda mem 625663: [eager release cuda mem 625663
E2022-12-12 01:19:20
[ .[2022-12-12 01:19:20/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc7801292022-12-12 01:19:20[.:[: .2022-12-12 01:19:20780150638[2022-12-12 01:19:20E780159.: [] 2022-12-12 01:19:20. : 780175E2022-12-12 01:19:20eager release cuda mem 625663.780186/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE:  .
780203: : E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu780219: E1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu :: E ] :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 611.00 KB1980:]  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:
] 1980eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980eager alloc mem 611.00 KB] 
:1980] 
eager alloc mem 611.00 KB1980] eager alloc mem 611.00 KB[
] eager alloc mem 611.00 KB
2022-12-12 01:19:20eager alloc mem 611.00 KB
.
780374: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.781080: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:19:20:[.6382022-12-12 01:19:20781094] .: [eager release cuda mem 625663781102E2022-12-12 01:19:20[
:  .2022-12-12 01:19:20E[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc781117. 2022-12-12 01:19:20:: [781126/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.638E2022-12-12 01:19:20: :781139]  .E638[: eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc781153 ] 2022-12-12 01:19:20E
:: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663. 638E:[
781182/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc]  6382022-12-12 01:19:20: :eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] [.E638
:eager release cuda mem 6256632022-12-12 01:19:20781213 ] [638
.: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 6256632022-12-12 01:19:20] 781259E:
.eager release cuda mem 625663: [ 1980781289
E2022-12-12 01:19:20[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :  .2022-12-12 01:19:20:eager alloc mem 611.00 KBE/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[781335.638
 :2022-12-12 01:19:20: 781359[] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980.E: 2022-12-12 01:19:20eager release cuda mem 625663:] 781390 E.
1980eager alloc mem 611.00 KB: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 781416] 
E:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: eager alloc mem 611.00 KB 1980:E
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] 1980 :eager alloc mem 611.00 KB] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980
eager alloc mem 611.00 KB:] 
1980eager alloc mem 611.00 KB] 
eager alloc mem 611.00 KB
[2022-12-12 01:19:20.781578: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.782151: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.782220: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.782243: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 6256632022-12-12 01:19:20
.782263: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:19:20:.[6387822802022-12-12 01:19:20[] : .2022-12-12 01:19:20[eager release cuda mem 625663E782289.2022-12-12 01:19:20
 [: 782296./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:19:20E: 782302:. E: 638782319/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc E] : :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc eager release cuda mem 625663E[638:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
 2022-12-12 01:19:20] 638:[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.eager release cuda mem 625663] 6382022-12-12 01:19:20:782371
eager release cuda mem 625663] .1980: [
eager release cuda mem 625663782383] E2022-12-12 01:19:20
: eager alloc mem 611.00 KB .[E
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[7824342022-12-12 01:19:20 :2022-12-12 01:19:20: ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc1980.E[782478:] 782500 2022-12-12 01:19:20: 638eager alloc mem 611.00 KB: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.E] 
E:782521 eager release cuda mem 625663 1980: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] E::eager alloc mem 611.00 KB 19801980
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] ] :eager alloc mem 611.00 KBeager alloc mem 611.00 KB1980

] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.782690: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.782966: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.783034: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.783227: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.783295: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 01:19:20eager alloc mem 611.00 KB.
783312: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.783360: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] [2022-12-12 01:19:20eager release cuda mem 6256632022-12-12 01:19:20[.[
.2022-12-12 01:19:207833792022-12-12 01:19:20783381.: .: 783389E783390E:  :  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc : :[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc6382022-12-12 01:19:20:] :] .1980eager release cuda mem 625663638eager release cuda mem 625663783445] 
] 
: eager alloc mem 611.00 KBeager release cuda mem 625663E

 [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 01:19:20:.[1980[7834972022-12-12 01:19:20] 2022-12-12 01:19:20[: .eager alloc mem 611.00 KB.2022-12-12 01:19:20E783531
783534. : : 783549/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccEE: :  E638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu ] ::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 62566319801980:
] ] 1980eager alloc mem 611.00 KBeager alloc mem 611.00 KB] 

eager alloc mem 611.00 KB
[2022-12-12 01:19:20.783758: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 01:19:201980.783782: ] Eeager alloc mem 611.00 KB 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.783890: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.784052: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.784118: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.784227: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.784295: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB[
2022-12-12 01:19:20.784314: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.784384: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[[2022-12-12 01:19:202022-12-12 01:19:20..[7844257844272022-12-12 01:19:20: : .EE784435  : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE:: 638638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] ] :eager release cuda mem 625663eager release cuda mem 625663638

] eager release cuda mem 625663
[[2022-12-12 01:19:202022-12-12 01:19:20.[.7845392022-12-12 01:19:20784540: .: E784547E :  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: :1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980] :] eager alloc mem 611.00 KB1980eager alloc mem 611.00 KB
[] 
2022-12-12 01:19:20eager alloc mem 611.00 KB.
784597[: 2022-12-12 01:19:20E. 784639/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663:
638] eager release cuda mem 625663
[2022-12-12 01:19:20.784760: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.784782: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.784866: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.784933: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.785046: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.785114: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 611.00 KB2022-12-12 01:19:20
.785133: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.785204: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.785336: E[ 2022-12-12 01:19:20/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:785346638: [] E2022-12-12 01:19:20eager release cuda mem 625663 .
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc785364:: 638E]  eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 625663
[2022-12-12 01:19:20.785425: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.785456: [E2022-12-12 01:19:20 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu785466:: 1980E]  eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
:1980] eager alloc mem 611.00 KB
[2022-12-12 01:19:20.785508: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.785545: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:19:20.785586: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.785677: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 6256632022-12-12 01:19:20
.785695: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 01:19:20:.1980785729] : eager alloc mem 611.00 KBE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:19:20.785869: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.785905: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:19:20.785952: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.785989: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:19:20.786175: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.786211: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 01:19:20638.[] 7862222022-12-12 01:19:20eager release cuda mem 20400000: .
E786231 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 625663638
] eager release cuda mem 625663
[2022-12-12 01:19:20.[7862922022-12-12 01:19:20: .E786297 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 20400000638
] eager release cuda mem 20400000
[2022-12-12 01:19:20.786551: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:19:20.786611: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:19:20.789621: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.607188 secs 
[2022-12-12 01:19:20.794053: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.611826 secs 
[2022-12-12 01:19:20.794154: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.607413 secs 
[2022-12-12 01:19:20.794577: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.627566 secs 
[2022-12-12 01:19:20.794678: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.612044 secs 
[2022-12-12 01:19:20.794780: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.612099 secs 
[2022-12-12 01:19:20.794886: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.61224 secs 
[2022-12-12 01:19:20.795056: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.608269 secs 
[2022-12-12 01:19:20.799141: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 9.02 GB
[2022-12-12 01:19:22.677780: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 9.28 GB
[2022-12-12 01:19:22.679544: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 9.28 GB
[2022-12-12 01:19:22.680723: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 9.28 GB
[2022-12-12 01:19:23.973162: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 9.55 GB
[2022-12-12 01:19:23.974398: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 9.55 GB
[2022-12-12 01:19:23.979168: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 9.55 GB
[2022-12-12 01:19:25.171296: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 9.76 GB
[2022-12-12 01:19:25.171431: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 9.76 GB
[2022-12-12 01:19:25.171696: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 9.76 GB
[2022-12-12 01:19:27.280331: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 9.98 GB
[2022-12-12 01:19:27.281197: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 9.98 GB
[2022-12-12 01:19:27.281892: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 9.98 GB
[2022-12-12 01:19:29.113051: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 10.44 GB
[2022-12-12 01:19:29.113364: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 10.44 GB
[2022-12-12 01:19:29.113809: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 10.44 GB
[2022-12-12 01:19:30.543417: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 10.63 GB
[2022-12-12 01:19:30.543571: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 10.63 GB
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier
[HCTR][01:19:30.544][ERROR][RK0][tid #140211640047360]: replica 1 calling init per replica done, doing barrier
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier done
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier done
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier done
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier done
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier done
[HCTR][01:19:30.544][ERROR][RK0][tid #140211640047360]: replica 1 calling init per replica done, doing barrier done
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][01:19:30.544][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier done
[HCTR][01:19:30.544][ERROR][RK0][main]: init per replica done
[HCTR][01:19:30.544][ERROR][RK0][main]: init per replica done
[HCTR][01:19:30.544][ERROR][RK0][main]: init per replica done
[HCTR][01:19:30.544][ERROR][RK0][main]: init per replica done
[HCTR][01:19:30.544][ERROR][RK0][main]: init per replica done
[HCTR][01:19:30.544][ERROR][RK0][tid #140211640047360]: init per replica done
[HCTR][01:19:30.544][ERROR][RK0][main]: init per replica done
[HCTR][01:19:30.547][ERROR][RK0][main]: init per replica done
[HCTR][01:19:30.550][ERROR][RK0][main]: 7 allocated 3276800 at 0x7f8751b20000
[HCTR][01:19:30.550][ERROR][RK0][main]: 7 allocated 6553600 at 0x7f8752000000
[HCTR][01:19:30.550][ERROR][RK0][main]: 7 allocated 3276800 at 0x7f8752640000
[HCTR][01:19:30.550][ERROR][RK0][main]: 7 allocated 6553600 at 0x7f8752960000
[HCTR][01:19:30.550][ERROR][RK0][tid #140211145139968]: 6 allocated 3276800 at 0x7f874bb20000
[HCTR][01:19:30.551][ERROR][RK0][tid #140211145139968]: 6 allocated 6553600 at 0x7f874c000000
[HCTR][01:19:30.551][ERROR][RK0][tid #140211145139968]: 6 allocated 3276800 at 0x7f874c640000
[HCTR][01:19:30.551][ERROR][RK0][tid #140211145139968]: 6 allocated 6553600 at 0x7f874c960000
[HCTR][01:19:30.551][ERROR][RK0][tid #140210943813376]: 4 allocated 3276800 at 0x7f8751b20000
[HCTR][01:19:30.551][ERROR][RK0][tid #140210943813376]: 4 allocated 6553600 at 0x7f8752000000
[HCTR][01:19:30.551][ERROR][RK0][tid #140210943813376]: 4 allocated 3276800 at 0x7f8752640000
[HCTR][01:19:30.551][ERROR][RK0][tid #140210943813376]: 4 allocated 6553600 at 0x7f8752960000
[HCTR][01:19:30.551][ERROR][RK0][main]: 3 allocated 3276800 at 0x7f8751b20000
[HCTR][01:19:30.551][ERROR][RK0][main]: 3 allocated 6553600 at 0x7f8752000000
[HCTR][01:19:30.551][ERROR][RK0][main]: 3 allocated 3276800 at 0x7f8752640000
[HCTR][01:19:30.551][ERROR][RK0][main]: 1 allocated 3276800 at 0x7f8751b20000
[HCTR][01:19:30.551][ERROR][RK0][main]: 3 allocated 6553600 at 0x7f8752960000
[HCTR][01:19:30.551][ERROR][RK0][main]: 1 allocated 6553600 at 0x7f8752000000
[HCTR][01:19:30.551][ERROR][RK0][main]: 1 allocated 3276800 at 0x7f8752640000
[HCTR][01:19:30.551][ERROR][RK0][main]: 1 allocated 6553600 at 0x7f8752960000
[HCTR][01:19:30.551][ERROR][RK0][main]: 2 allocated 3276800 at 0x7f8751b20000
[HCTR][01:19:30.551][ERROR][RK0][main]: 2 allocated 6553600 at 0x7f8752000000
[HCTR][01:19:30.551][ERROR][RK0][main]: 2 allocated 3276800 at 0x7f8752640000
[HCTR][01:19:30.551][ERROR][RK0][main]: 2 allocated 6553600 at 0x7f8752960000
[HCTR][01:19:30.551][ERROR][RK0][tid #140211078031104]: 5 allocated 3276800 at 0x7f8747b20000
[HCTR][01:19:30.551][ERROR][RK0][tid #140211078031104]: 5 allocated 6553600 at 0x7f8748000000
[HCTR][01:19:30.551][ERROR][RK0][tid #140211078031104]: 5 allocated 3276800 at 0x7f8748640000
[HCTR][01:19:30.551][ERROR][RK0][tid #140211078031104]: 5 allocated 6553600 at 0x7f8748960000
[HCTR][01:19:30.554][ERROR][RK0][tid #140211438720768]: 0 allocated 3276800 at 0x7f8756120000
[HCTR][01:19:30.554][ERROR][RK0][tid #140211438720768]: 0 allocated 6553600 at 0x7f8756600000
[HCTR][01:19:30.554][ERROR][RK0][tid #140211438720768]: 0 allocated 3276800 at 0x7f875730e800
[HCTR][01:19:30.554][ERROR][RK0][tid #140211438720768]: 0 allocated 6553600 at 0x7f875762e800








