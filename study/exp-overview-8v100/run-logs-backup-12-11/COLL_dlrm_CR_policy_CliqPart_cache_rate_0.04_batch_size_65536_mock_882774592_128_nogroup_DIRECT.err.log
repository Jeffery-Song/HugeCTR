2022-12-11 18:56:56.218379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.220102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.221112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.222176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.223723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.225379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.225689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.226970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.227532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.228557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.229027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.230370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.231367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.232486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.233504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.234499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.237736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.239222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.240952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.241552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.242746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.244019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.245170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.245797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.246126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.247286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.247980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.248596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.249546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.250493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.250684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.252316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.253750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.253863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.256869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.257008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.257732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.258899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.259034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.259994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.261311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.262509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.263528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.264787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.265541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.266714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.267395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.267785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.267860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.268780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.269641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.269640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.270361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.271498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.271607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.272181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.273345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.273662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.274463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.274776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.275594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.275904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.276699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.277436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.396211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.396223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.396229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.396243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.396245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.396246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.396248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.396243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.401130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.401161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.401202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.401249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.401287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.401334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.401382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.401421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.405812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.405901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.406032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.406064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.406113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.406154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.406199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.406302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.410499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.410644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.410755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.410797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.410841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.410884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.410928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.411030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.414985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.415173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.415273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.415320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.415365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.415414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.415514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.415568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.419477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.419623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.419735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.419782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.419832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.419874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.419977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.420024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.423968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.424120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.424223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.424270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.424314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.424358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.424461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.424507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.428512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.428655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.428762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.428808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.428851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.428897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.428998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.429042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.433065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.433211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.433312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.433360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.433402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.433448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.433550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.433595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.437569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.437710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.437838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.437867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.437908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.437954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.437998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.438103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.442389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.442531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.442637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.442680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.442726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.442773: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.442875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.442920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.447561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.447704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.447811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.447856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.447910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.447948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.448053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.448089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.451989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.452130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.452326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.452371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.452419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.452517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.452563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.452661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.456405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.456578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.456685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.456782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.456826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.456925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.456971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.457074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.461354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.461476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.461582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.461671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.461723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.461767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.461868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.461969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.465992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.466118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.466251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.466302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.466355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.466390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.466437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.466594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.471473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.471489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.471590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.471739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.471740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.471748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.471750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.471777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.475281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.475837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.476232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.476659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.476702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.476891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.476938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.476976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.480348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.480628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.480781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.481489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.481581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.481625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.481857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.481904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.485004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.485288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.485383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.485780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.485965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.486054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.486307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.486352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.489670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.489959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.490105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.490531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.490678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.490812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.491051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.491099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.494225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.494515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.494662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.495077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.495193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.495323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.495559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.495607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.498722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.499006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.499166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.499604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.499702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.499845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.500086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.500143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.503187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.503471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.503626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.504049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.504153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.504301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.504536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.504580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.514036: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 18:56:56.514036: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 18:56:56.514040: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 18:56:56.514048: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 18:56:56.514052: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 18:56:56.514081: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 18:56:56.514081: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 18:56:56.514083: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 18:56:56.526702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.526745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.526822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.526822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.526824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.526822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.526822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.526822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.530875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.530956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.531204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.531232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.531288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.531388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.531436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.531535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.535236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.535467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.535609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.535752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.535805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.535851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.535952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:56.535995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.850507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.850507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.850508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.850564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.850556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.850557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.850556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.850557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.854627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.854756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.854822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.854861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.854908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.854955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.855001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.855036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.858858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.858951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.859106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.859155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.859198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.859243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.859342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.859388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.863068: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 18:56:58.863143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-11 18:56:58.863204: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 18:56:58.863257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-11 18:56:58.863309: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 18:56:58.863362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-11 18:56:58.863400: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 18:56:58.863441: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 18:56:58.863460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-11 18:56:58.863479: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 18:56:58.863494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-11 18:56:58.863526: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 18:56:58.863528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-11 18:56:58.863566: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 18:56:58.863574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-11 18:56:58.863618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-11 18:56:58.887736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.887763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.887736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.887736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.887736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.887736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.887736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.887769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.892262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.892387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.892420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.892451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.892464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.892522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.892555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.892621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.896332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.896419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.896557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.896685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.896740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.896770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.896775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.896893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.900748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.900909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.900929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.900988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.901009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.901022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.901092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.901109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.904704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.904876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.904923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.905062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.905116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.905198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.905399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.905534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 18:56:58.908826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-11 18:56:58.909168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-11 18:56:58.909215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-11 18:56:58.909353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-11 18:56:58.909398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-11 18:56:58.909442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-11 18:56:58.909540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-11 18:56:58.909578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-11 18:56:58.966537: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.966536: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.966559: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.966559: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.966559: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.966634: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.967328: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.967329: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.967330: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.967448: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.967465: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.967473: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:58.968266: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-11 18:56:58.968549: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-11 18:56:58.969136: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-11 18:56:58.969230: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-11 18:56:58.969280: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-11 18:56:59.002164: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:59.002349: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:59.003192: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-11 18:56:59.004182: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:59.004358: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 18:56:59.005315: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
2022-12-11 18:56:59.032298: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
[HCTR][18:57:00.408][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][18:57:00.408][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][18:57:00.408][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][18:57:00.408][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][18:57:00.408][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][18:57:00.408][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][18:57:00.408][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][18:57:00.409][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:00,  2.47it/s]warmup run: 1it [00:00,  2.47it/s]warmup run: 1it [00:00,  2.14it/s]warmup run: 68it [00:00, 176.22it/s]warmup run: 64it [00:00, 165.55it/s]warmup run: 67it [00:00, 155.89it/s]warmup run: 124it [00:00, 280.06it/s]warmup run: 116it [00:00, 260.42it/s]warmup run: 124it [00:00, 258.70it/s]warmup run: 180it [00:00, 357.86it/s]warmup run: 168it [00:00, 331.56it/s]warmup run: 180it [00:00, 337.87it/s]warmup run: 237it [00:00, 416.45it/s]warmup run: 222it [00:00, 390.10it/s]warmup run: 236it [00:00, 398.42it/s]warmup run: 294it [00:00, 458.58it/s]warmup run: 276it [00:00, 431.87it/s]warmup run: 292it [00:00, 442.01it/s]warmup run: 351it [00:01, 488.76it/s]warmup run: 333it [00:01, 469.85it/s]warmup run: 347it [00:01, 472.46it/s]warmup run: 408it [00:01, 510.43it/s]warmup run: 389it [00:01, 495.01it/s]warmup run: 402it [00:01, 494.18it/s]warmup run: 465it [00:01, 526.55it/s]warmup run: 445it [00:01, 512.67it/s]warmup run: 457it [00:01, 510.35it/s]warmup run: 501it [00:01, 526.10it/s]warmup run: 521it [00:01, 526.45it/s]warmup run: 513it [00:01, 523.29it/s]warmup run: 1it [00:01,  1.40s/it]warmup run: 1it [00:01,  1.41s/it]warmup run: 1it [00:01,  1.41s/it]warmup run: 1it [00:01,  1.41s/it]warmup run: 1it [00:01,  1.41s/it]warmup run: 559it [00:01, 540.16it/s]warmup run: 576it [00:01, 526.22it/s]warmup run: 568it [00:01, 522.91it/s]warmup run: 95it [00:01, 87.81it/s]warmup run: 95it [00:01, 86.97it/s]warmup run: 95it [00:01, 87.14it/s]warmup run: 93it [00:01, 85.08it/s]warmup run: 100it [00:01, 91.69it/s]warmup run: 615it [00:01, 542.72it/s]warmup run: 630it [00:01, 518.29it/s]warmup run: 622it [00:01, 507.64it/s]warmup run: 194it [00:01, 193.14it/s]warmup run: 192it [00:01, 189.36it/s]warmup run: 195it [00:01, 192.96it/s]warmup run: 185it [00:01, 181.67it/s]warmup run: 200it [00:01, 196.99it/s]warmup run: 671it [00:01, 534.00it/s]warmup run: 683it [00:01, 508.46it/s]warmup run: 674it [00:01, 501.38it/s]warmup run: 293it [00:01, 306.79it/s]warmup run: 288it [00:01, 298.80it/s]warmup run: 287it [00:01, 296.26it/s]warmup run: 280it [00:01, 290.68it/s]warmup run: 296it [00:01, 305.39it/s]warmup run: 726it [00:01, 523.78it/s]warmup run: 735it [00:01, 504.91it/s]warmup run: 725it [00:01, 500.85it/s]warmup run: 387it [00:01, 413.82it/s]warmup run: 385it [00:01, 412.01it/s]warmup run: 379it [00:01, 401.43it/s]warmup run: 377it [00:01, 404.78it/s]warmup run: 391it [00:01, 413.21it/s]warmup run: 786it [00:01, 543.76it/s]warmup run: 786it [00:01, 505.60it/s]warmup run: 479it [00:01, 511.73it/s]warmup run: 776it [00:01, 497.88it/s]warmup run: 481it [00:01, 518.10it/s]warmup run: 474it [00:01, 507.80it/s]warmup run: 475it [00:01, 515.72it/s]warmup run: 484it [00:01, 513.28it/s]warmup run: 841it [00:01, 544.08it/s]warmup run: 837it [00:01, 506.37it/s]warmup run: 573it [00:02, 604.82it/s]warmup run: 829it [00:02, 505.96it/s]warmup run: 579it [00:02, 617.99it/s]warmup run: 572it [00:02, 610.28it/s]warmup run: 573it [00:02, 615.87it/s]warmup run: 579it [00:02, 606.94it/s]warmup run: 891it [00:02, 513.51it/s]warmup run: 896it [00:02, 527.56it/s]warmup run: 673it [00:02, 697.42it/s]warmup run: 884it [00:02, 518.18it/s]warmup run: 681it [00:02, 711.85it/s]warmup run: 668it [00:02, 692.86it/s]warmup run: 670it [00:02, 676.41it/s]warmup run: 666it [00:02, 639.15it/s]warmup run: 945it [00:02, 519.36it/s]warmup run: 950it [00:02, 516.48it/s]warmup run: 767it [00:02, 756.67it/s]warmup run: 939it [00:02, 526.72it/s]warmup run: 783it [00:02, 787.96it/s]warmup run: 763it [00:02, 756.72it/s]warmup run: 762it [00:02, 737.53it/s]warmup run: 758it [00:02, 705.07it/s]warmup run: 998it [00:02, 507.65it/s]warmup run: 1002it [00:02, 507.28it/s]warmup run: 995it [00:02, 536.42it/s]warmup run: 861it [00:02, 801.12it/s]warmup run: 886it [00:02, 851.39it/s]warmup run: 857it [00:02, 801.62it/s]warmup run: 855it [00:02, 787.33it/s]warmup run: 852it [00:02, 762.53it/s]warmup run: 1052it [00:02, 516.73it/s]warmup run: 1053it [00:02, 502.46it/s]warmup run: 954it [00:02, 836.20it/s]warmup run: 1051it [00:02, 540.45it/s]warmup run: 986it [00:02, 891.34it/s]warmup run: 953it [00:02, 842.41it/s]warmup run: 949it [00:02, 827.94it/s]warmup run: 941it [00:02, 795.64it/s]warmup run: 1107it [00:02, 524.98it/s]warmup run: 1106it [00:02, 508.71it/s]warmup run: 1049it [00:02, 865.99it/s]warmup run: 1108it [00:02, 546.99it/s]warmup run: 1088it [00:02, 925.94it/s]warmup run: 1047it [00:02, 869.28it/s]warmup run: 1046it [00:02, 866.51it/s]warmup run: 1036it [00:02, 836.95it/s]warmup run: 1162it [00:02, 531.32it/s]warmup run: 1158it [00:02, 510.07it/s]warmup run: 1144it [00:02, 887.91it/s]warmup run: 1164it [00:02, 548.75it/s]warmup run: 1188it [00:02, 946.64it/s]warmup run: 1142it [00:02, 890.46it/s]warmup run: 1140it [00:02, 886.92it/s]warmup run: 1127it [00:02, 840.58it/s]warmup run: 1216it [00:02, 531.25it/s]warmup run: 1210it [00:02, 499.33it/s]warmup run: 1219it [00:02, 544.13it/s]warmup run: 1288it [00:02, 958.68it/s]warmup run: 1236it [00:02, 899.50it/s]warmup run: 1238it [00:02, 911.66it/s]warmup run: 1216it [00:02, 854.11it/s]warmup run: 1272it [00:02, 537.82it/s]warmup run: 1238it [00:02, 775.65it/s]warmup run: 1263it [00:02, 506.21it/s]warmup run: 1274it [00:02, 542.94it/s]warmup run: 1334it [00:02, 924.68it/s]warmup run: 1388it [00:02, 891.60it/s]warmup run: 1330it [00:02, 844.77it/s]warmup run: 1327it [00:02, 540.07it/s]warmup run: 1314it [00:02, 497.29it/s]warmup run: 1322it [00:02, 707.93it/s]warmup run: 1329it [00:02, 542.23it/s]warmup run: 1305it [00:02, 731.53it/s]warmup run: 1382it [00:02, 538.62it/s]warmup run: 1429it [00:02, 782.23it/s]warmup run: 1364it [00:02, 492.36it/s]warmup run: 1481it [00:03, 767.33it/s]warmup run: 1418it [00:03, 714.74it/s]warmup run: 1384it [00:03, 538.06it/s]warmup run: 1398it [00:03, 663.14it/s]warmup run: 1437it [00:03, 539.23it/s]warmup run: 1384it [00:03, 642.97it/s]warmup run: 1414it [00:03, 489.15it/s]warmup run: 1438it [00:03, 538.36it/s]warmup run: 1513it [00:03, 680.20it/s]warmup run: 1495it [00:03, 669.02it/s]warmup run: 1563it [00:03, 695.78it/s]warmup run: 1468it [00:03, 639.24it/s]warmup run: 1494it [00:03, 547.90it/s]warmup run: 1465it [00:03, 494.07it/s]warmup run: 1492it [00:03, 536.89it/s]warmup run: 1454it [00:03, 591.78it/s]warmup run: 1549it [00:03, 539.07it/s]warmup run: 1566it [00:03, 637.16it/s]warmup run: 1535it [00:03, 617.39it/s]warmup run: 1637it [00:03, 659.46it/s]warmup run: 1587it [00:03, 630.90it/s]warmup run: 1516it [00:03, 496.58it/s]warmup run: 1546it [00:03, 536.43it/s]warmup run: 1518it [00:03, 557.97it/s]warmup run: 1603it [00:03, 522.88it/s]warmup run: 1633it [00:03, 618.39it/s]warmup run: 1566it [00:03, 492.28it/s]warmup run: 1599it [00:03, 595.33it/s]warmup run: 1706it [00:03, 632.88it/s]warmup run: 1655it [00:03, 605.86it/s]warmup run: 1600it [00:03, 524.02it/s]warmup run: 1577it [00:03, 538.54it/s]warmup run: 1656it [00:03, 520.22it/s]warmup run: 1617it [00:03, 495.04it/s]warmup run: 1697it [00:03, 606.74it/s]warmup run: 1660it [00:03, 575.36it/s]warmup run: 1772it [00:03, 616.10it/s]warmup run: 1719it [00:03, 593.44it/s]warmup run: 1653it [00:03, 513.86it/s]warmup run: 1712it [00:03, 530.27it/s]warmup run: 1633it [00:03, 523.62it/s]warmup run: 1668it [00:03, 497.18it/s]warmup run: 1759it [00:03, 590.02it/s]warmup run: 1719it [00:03, 562.53it/s]warmup run: 1835it [00:03, 603.94it/s]warmup run: 1706it [00:03, 515.25it/s]warmup run: 1781it [00:03, 584.55it/s]warmup run: 1770it [00:03, 542.18it/s]warmup run: 1687it [00:03, 519.79it/s]warmup run: 1718it [00:03, 494.64it/s]warmup run: 1819it [00:03, 577.60it/s]warmup run: 1776it [00:03, 555.63it/s]warmup run: 1897it [00:03, 594.31it/s]warmup run: 1758it [00:03, 510.61it/s]warmup run: 1841it [00:03, 580.57it/s]warmup run: 1826it [00:03, 544.62it/s]warmup run: 1740it [00:03, 517.61it/s]warmup run: 1773it [00:03, 509.05it/s]warmup run: 1832it [00:03, 553.13it/s]warmup run: 1878it [00:03, 564.15it/s]warmup run: 1817it [00:03, 533.05it/s]warmup run: 1957it [00:03, 585.14it/s]warmup run: 1900it [00:03, 575.72it/s]warmup run: 1881it [00:03, 542.89it/s]warmup run: 1830it [00:03, 526.95it/s]warmup run: 1796it [00:03, 526.95it/s]warmup run: 1871it [00:03, 531.92it/s]warmup run: 1935it [00:03, 556.15it/s]warmup run: 1888it [00:03, 535.51it/s]warmup run: 2016it [00:03, 576.95it/s]warmup run: 1959it [00:03, 572.18it/s]warmup run: 1936it [00:03, 543.84it/s]warmup run: 1887it [00:04, 538.25it/s]warmup run: 1853it [00:04, 536.80it/s]warmup run: 1991it [00:04, 554.63it/s]warmup run: 1925it [00:04, 528.19it/s]warmup run: 1942it [00:04, 531.86it/s]warmup run: 2074it [00:04, 576.04it/s]warmup run: 2017it [00:04, 571.81it/s]warmup run: 1991it [00:04, 519.60it/s]warmup run: 1945it [00:04, 547.93it/s]warmup run: 1908it [00:04, 530.02it/s]warmup run: 1979it [00:04, 531.27it/s]warmup run: 2047it [00:04, 551.12it/s]warmup run: 1996it [00:04, 529.38it/s]warmup run: 2132it [00:04, 573.37it/s]warmup run: 2075it [00:04, 562.46it/s]warmup run: 2003it [00:04, 555.82it/s]warmup run: 2044it [00:04, 510.43it/s]warmup run: 1962it [00:04, 517.29it/s]warmup run: 2033it [00:04, 528.37it/s]warmup run: 2103it [00:04, 549.05it/s]warmup run: 2190it [00:04, 570.12it/s]warmup run: 2049it [00:04, 516.41it/s]warmup run: 2132it [00:04, 549.84it/s]warmup run: 2059it [00:04, 554.17it/s]warmup run: 2101it [00:04, 525.85it/s]warmup run: 2014it [00:04, 517.17it/s]warmup run: 2159it [00:04, 551.55it/s]warmup run: 2088it [00:04, 533.27it/s]warmup run: 2248it [00:04, 567.66it/s]warmup run: 2101it [00:04, 516.39it/s]warmup run: 2188it [00:04, 543.48it/s]warmup run: 2117it [00:04, 560.86it/s]warmup run: 2156it [00:04, 532.82it/s]warmup run: 2068it [00:04, 522.37it/s]warmup run: 2144it [00:04, 540.75it/s]warmup run: 2215it [00:04, 543.67it/s]warmup run: 2305it [00:04, 566.35it/s]warmup run: 2159it [00:04, 531.88it/s]warmup run: 2243it [00:04, 543.74it/s]warmup run: 2174it [00:04, 559.43it/s]warmup run: 2210it [00:04, 525.93it/s]warmup run: 2125it [00:04, 533.75it/s]warmup run: 2199it [00:04, 539.52it/s]warmup run: 2362it [00:04, 566.45it/s]warmup run: 2216it [00:04, 541.51it/s]warmup run: 2270it [00:04, 529.82it/s]warmup run: 2298it [00:04, 532.70it/s]warmup run: 2231it [00:04, 562.05it/s]warmup run: 2265it [00:04, 532.64it/s]warmup run: 2180it [00:04, 537.66it/s]warmup run: 2253it [00:04, 539.18it/s]warmup run: 2419it [00:04, 566.11it/s]warmup run: 2273it [00:04, 548.31it/s]warmup run: 2324it [00:04, 521.37it/s]warmup run: 2352it [00:04, 525.72it/s]warmup run: 2288it [00:04, 555.99it/s]warmup run: 2319it [00:04, 529.14it/s]warmup run: 2236it [00:04, 542.49it/s]warmup run: 2307it [00:04, 537.52it/s]warmup run: 2476it [00:04, 565.97it/s]warmup run: 2329it [00:04, 551.73it/s]warmup run: 2379it [00:04, 526.68it/s]warmup run: 2408it [00:04, 534.27it/s]warmup run: 2372it [00:04, 522.97it/s]warmup run: 2291it [00:04, 535.29it/s]warmup run: 2344it [00:04, 527.47it/s]warmup run: 2361it [00:04, 534.28it/s]warmup run: 2386it [00:04, 555.50it/s]warmup run: 2533it [00:04, 560.04it/s]warmup run: 2434it [00:04, 531.79it/s]warmup run: 2465it [00:04, 543.04it/s]warmup run: 2425it [00:04, 523.05it/s]warmup run: 2345it [00:04, 527.91it/s]warmup run: 2398it [00:04, 520.97it/s]warmup run: 2415it [00:04, 527.85it/s]warmup run: 2443it [00:04, 558.65it/s]warmup run: 2590it [00:04, 562.95it/s]warmup run: 2488it [00:04, 533.31it/s]warmup run: 2521it [00:04, 546.26it/s]warmup run: 2482it [00:05, 535.44it/s]warmup run: 2398it [00:05, 525.34it/s]warmup run: 2451it [00:05, 520.84it/s]warmup run: 2499it [00:05, 557.03it/s]warmup run: 2468it [00:05, 516.98it/s]warmup run: 2647it [00:05, 560.69it/s]warmup run: 2542it [00:05, 534.11it/s]warmup run: 2578it [00:05, 552.73it/s]warmup run: 2538it [00:05, 542.20it/s]warmup run: 2506it [00:05, 529.01it/s]warmup run: 2451it [00:05, 518.81it/s]warmup run: 2556it [00:05, 559.29it/s]warmup run: 2598it [00:05, 539.84it/s]warmup run: 2520it [00:05, 499.93it/s]warmup run: 2634it [00:05, 550.37it/s]warmup run: 2595it [00:05, 548.84it/s]warmup run: 2564it [00:05, 542.21it/s]warmup run: 2505it [00:05, 522.35it/s]warmup run: 2614it [00:05, 564.52it/s]warmup run: 2654it [00:05, 544.75it/s]warmup run: 2576it [00:05, 516.41it/s]warmup run: 2621it [00:05, 550.13it/s]warmup run: 2558it [00:05, 522.54it/s]warmup run: 2704it [00:05, 364.01it/s]warmup run: 2671it [00:05, 562.65it/s]warmup run: 2628it [00:05, 517.11it/s]warmup run: 2761it [00:05, 407.34it/s]warmup run: 2611it [00:05, 499.08it/s]warmup run: 2690it [00:05, 353.30it/s]warmup run: 2650it [00:05, 345.66it/s]warmup run: 2818it [00:05, 445.12it/s]warmup run: 2709it [00:05, 348.49it/s]warmup run: 2662it [00:05, 477.69it/s]warmup run: 2747it [00:05, 398.15it/s]warmup run: 2677it [00:05, 359.37it/s]warmup run: 2707it [00:05, 392.15it/s]warmup run: 2875it [00:05, 474.81it/s]warmup run: 2728it [00:05, 359.01it/s]warmup run: 2765it [00:05, 393.49it/s]warmup run: 2800it [00:05, 427.57it/s]warmup run: 2735it [00:05, 405.67it/s]warmup run: 2764it [00:05, 432.22it/s]warmup run: 2680it [00:05, 292.06it/s]warmup run: 2928it [00:05, 488.64it/s]warmup run: 2780it [00:05, 392.31it/s]warmup run: 2820it [00:05, 429.32it/s]warmup run: 2852it [00:05, 449.93it/s]warmup run: 2793it [00:05, 444.64it/s]warmup run: 2821it [00:05, 465.83it/s]warmup run: 2731it [00:05, 332.56it/s]warmup run: 2986it [00:05, 511.82it/s]warmup run: 2833it [00:05, 422.89it/s]warmup run: 2873it [00:05, 453.75it/s]warmup run: 2711it [00:05, 312.65it/s]warmup run: 3000it [00:05, 508.36it/s]warmup run: 2906it [00:05, 471.87it/s]warmup run: 2850it [00:05, 475.74it/s]warmup run: 2874it [00:05, 480.54it/s]warmup run: 2782it [00:05, 369.99it/s]warmup run: 2889it [00:05, 456.01it/s]warmup run: 2929it [00:05, 481.33it/s]warmup run: 2756it [00:05, 340.09it/s]warmup run: 2963it [00:05, 497.96it/s]warmup run: 2908it [00:06, 501.58it/s]warmup run: 2927it [00:06, 481.72it/s]warmup run: 2836it [00:06, 408.81it/s]warmup run: 3000it [00:06, 494.23it/s]warmup run: 2946it [00:06, 484.24it/s]warmup run: 2987it [00:06, 506.41it/s]warmup run: 2802it [00:06, 366.73it/s]warmup run: 3000it [00:06, 491.04it/s]warmup run: 2963it [00:06, 514.30it/s]warmup run: 2982it [00:06, 498.43it/s]warmup run: 2889it [00:06, 437.15it/s]warmup run: 3000it [00:06, 485.81it/s]warmup run: 2857it [00:06, 411.13it/s]warmup run: 3000it [00:06, 484.28it/s]warmup run: 3000it [00:06, 482.12it/s]warmup run: 2945it [00:06, 468.12it/s]warmup run: 2910it [00:06, 440.65it/s]warmup run: 3000it [00:06, 471.35it/s]warmup run: 2962it [00:06, 460.44it/s]warmup run: 3000it [00:06, 463.73it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]




warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 172/3000 [00:00<00:01, 1719.80it/s]warmup should be done:   6%|         | 169/3000 [00:00<00:01, 1687.66it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1673.92it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1674.38it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1674.91it/s]warmup should be done:   6%|         | 169/3000 [00:00<00:01, 1686.46it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1622.20it/s]warmup should be done:   6%|         | 171/3000 [00:00<00:01, 1701.35it/s]warmup should be done:  11%|        | 341/3000 [00:00<00:01, 1705.07it/s]warmup should be done:  11%|        | 338/3000 [00:00<00:01, 1689.43it/s]warmup should be done:  12%|        | 345/3000 [00:00<00:01, 1722.80it/s]warmup should be done:  11%|        | 340/3000 [00:00<00:01, 1698.99it/s]warmup should be done:  11%|         | 336/3000 [00:00<00:01, 1674.33it/s]warmup should be done:  11%|        | 339/3000 [00:00<00:01, 1689.74it/s]warmup should be done:  12%|        | 345/3000 [00:00<00:01, 1720.03it/s]warmup should be done:  11%|         | 326/3000 [00:00<00:01, 1598.88it/s]warmup should be done:  17%|        | 510/3000 [00:00<00:01, 1697.00it/s]warmup should be done:  17%|        | 509/3000 [00:00<00:01, 1693.06it/s]warmup should be done:  17%|        | 507/3000 [00:00<00:01, 1684.17it/s]warmup should be done:  17%|        | 512/3000 [00:00<00:01, 1700.87it/s]warmup should be done:  17%|        | 504/3000 [00:00<00:01, 1665.14it/s]warmup should be done:  17%|        | 518/3000 [00:00<00:01, 1715.09it/s]warmup should be done:  17%|        | 518/3000 [00:00<00:01, 1704.47it/s]warmup should be done:  16%|        | 487/3000 [00:00<00:01, 1600.68it/s]warmup should be done:  23%|       | 680/3000 [00:00<00:01, 1697.45it/s]warmup should be done:  23%|       | 683/3000 [00:00<00:01, 1702.72it/s]warmup should be done:  23%|       | 677/3000 [00:00<00:01, 1687.72it/s]warmup should be done:  23%|       | 680/3000 [00:00<00:01, 1696.45it/s]warmup should be done:  22%|       | 671/3000 [00:00<00:01, 1666.33it/s]warmup should be done:  23%|       | 690/3000 [00:00<00:01, 1715.85it/s]warmup should be done:  23%|       | 689/3000 [00:00<00:01, 1697.35it/s]warmup should be done:  22%|       | 648/3000 [00:00<00:01, 1598.28it/s]warmup should be done:  28%|       | 850/3000 [00:00<00:01, 1696.88it/s]warmup should be done:  28%|       | 846/3000 [00:00<00:01, 1686.88it/s]warmup should be done:  28%|       | 854/3000 [00:00<00:01, 1702.51it/s]warmup should be done:  28%|       | 838/3000 [00:00<00:01, 1664.04it/s]warmup should be done:  28%|       | 850/3000 [00:00<00:01, 1684.44it/s]warmup should be done:  27%|       | 808/3000 [00:00<00:01, 1597.87it/s]warmup should be done:  29%|       | 862/3000 [00:00<00:01, 1698.02it/s]warmup should be done:  29%|       | 859/3000 [00:00<00:01, 1689.52it/s]warmup should be done:  34%|      | 1020/3000 [00:00<00:01, 1694.33it/s]warmup should be done:  34%|      | 1015/3000 [00:00<00:01, 1684.33it/s]warmup should be done:  34%|      | 1025/3000 [00:00<00:01, 1701.91it/s]warmup should be done:  34%|      | 1005/3000 [00:00<00:01, 1661.08it/s]warmup should be done:  34%|      | 1019/3000 [00:00<00:01, 1685.92it/s]warmup should be done:  32%|      | 968/3000 [00:00<00:01, 1596.71it/s]warmup should be done:  34%|      | 1033/3000 [00:00<00:01, 1701.96it/s]warmup should be done:  34%|      | 1028/3000 [00:00<00:01, 1684.73it/s]warmup should be done:  40%|      | 1190/3000 [00:00<00:01, 1691.43it/s]warmup should be done:  39%|      | 1184/3000 [00:00<00:01, 1683.32it/s]warmup should be done:  40%|      | 1196/3000 [00:00<00:01, 1697.08it/s]warmup should be done:  40%|      | 1188/3000 [00:00<00:01, 1687.17it/s]warmup should be done:  39%|      | 1172/3000 [00:00<00:01, 1659.12it/s]warmup should be done:  38%|      | 1128/3000 [00:00<00:01, 1596.21it/s]warmup should be done:  40%|      | 1204/3000 [00:00<00:01, 1700.31it/s]warmup should be done:  40%|      | 1197/3000 [00:00<00:01, 1680.79it/s]warmup should be done:  45%|     | 1361/3000 [00:00<00:00, 1695.82it/s]warmup should be done:  45%|     | 1353/3000 [00:00<00:00, 1679.35it/s]warmup should be done:  46%|     | 1367/3000 [00:00<00:00, 1698.77it/s]warmup should be done:  45%|     | 1358/3000 [00:00<00:00, 1688.95it/s]warmup should be done:  45%|     | 1338/3000 [00:00<00:01, 1653.32it/s]warmup should be done:  46%|     | 1376/3000 [00:00<00:00, 1705.47it/s]warmup should be done:  43%|     | 1288/3000 [00:00<00:01, 1592.57it/s]warmup should be done:  46%|     | 1366/3000 [00:00<00:00, 1678.11it/s]warmup should be done:  51%|     | 1533/3000 [00:00<00:00, 1702.89it/s]warmup should be done:  51%|     | 1521/3000 [00:00<00:00, 1679.27it/s]warmup should be done:  51%|     | 1528/3000 [00:00<00:00, 1690.61it/s]warmup should be done:  51%|     | 1537/3000 [00:00<00:00, 1693.97it/s]warmup should be done:  52%|    | 1548/3000 [00:00<00:00, 1707.03it/s]warmup should be done:  48%|     | 1448/3000 [00:00<00:00, 1592.84it/s]warmup should be done:  50%|     | 1504/3000 [00:00<00:00, 1647.71it/s]warmup should be done:  51%|     | 1536/3000 [00:00<00:00, 1682.09it/s]warmup should be done:  57%|    | 1705/3000 [00:01<00:00, 1706.18it/s]warmup should be done:  56%|    | 1689/3000 [00:01<00:00, 1678.12it/s]warmup should be done:  57%|    | 1698/3000 [00:01<00:00, 1689.70it/s]warmup should be done:  57%|    | 1707/3000 [00:01<00:00, 1689.87it/s]warmup should be done:  56%|    | 1669/3000 [00:01<00:00, 1647.29it/s]warmup should be done:  54%|    | 1608/3000 [00:01<00:00, 1591.19it/s]warmup should be done:  57%|    | 1705/3000 [00:01<00:00, 1683.86it/s]warmup should be done:  57%|    | 1719/3000 [00:01<00:00, 1688.87it/s]warmup should be done:  63%|   | 1876/3000 [00:01<00:00, 1705.53it/s]warmup should be done:  62%|   | 1858/3000 [00:01<00:00, 1678.70it/s]warmup should be done:  63%|   | 1876/3000 [00:01<00:00, 1687.84it/s]warmup should be done:  61%|    | 1835/3000 [00:01<00:00, 1649.30it/s]warmup should be done:  59%|    | 1768/3000 [00:01<00:00, 1589.15it/s]warmup should be done:  62%|   | 1867/3000 [00:01<00:00, 1670.30it/s]warmup should be done:  62%|   | 1875/3000 [00:01<00:00, 1685.80it/s]warmup should be done:  63%|   | 1888/3000 [00:01<00:00, 1680.47it/s]warmup should be done:  68%|   | 2047/3000 [00:01<00:00, 1703.73it/s]warmup should be done:  68%|   | 2026/3000 [00:01<00:00, 1678.42it/s]warmup should be done:  68%|   | 2045/3000 [00:01<00:00, 1680.96it/s]warmup should be done:  67%|   | 2000/3000 [00:01<00:00, 1642.05it/s]warmup should be done:  64%|   | 1928/3000 [00:01<00:00, 1590.40it/s]warmup should be done:  68%|   | 2036/3000 [00:01<00:00, 1675.01it/s]warmup should be done:  68%|   | 2046/3000 [00:01<00:00, 1691.28it/s]warmup should be done:  69%|   | 2060/3000 [00:01<00:00, 1690.19it/s]warmup should be done:  74%|  | 2218/3000 [00:01<00:00, 1703.14it/s]warmup should be done:  73%|  | 2194/3000 [00:01<00:00, 1677.51it/s]warmup should be done:  74%|  | 2214/3000 [00:01<00:00, 1682.55it/s]warmup should be done:  72%|  | 2166/3000 [00:01<00:00, 1645.53it/s]warmup should be done:  70%|   | 2088/3000 [00:01<00:00, 1591.51it/s]warmup should be done:  74%|  | 2206/3000 [00:01<00:00, 1679.86it/s]warmup should be done:  74%|  | 2218/3000 [00:01<00:00, 1697.45it/s]warmup should be done:  74%|  | 2231/3000 [00:01<00:00, 1694.73it/s]warmup should be done:  80%|  | 2389/3000 [00:01<00:00, 1704.10it/s]warmup should be done:  79%|  | 2362/3000 [00:01<00:00, 1675.43it/s]warmup should be done:  79%|  | 2375/3000 [00:01<00:00, 1682.56it/s]warmup should be done:  78%|  | 2332/3000 [00:01<00:00, 1648.39it/s]warmup should be done:  75%|  | 2248/3000 [00:01<00:00, 1590.61it/s]warmup should be done:  80%|  | 2388/3000 [00:01<00:00, 1698.10it/s]warmup should be done:  79%|  | 2383/3000 [00:01<00:00, 1668.18it/s]warmup should be done:  80%|  | 2401/3000 [00:01<00:00, 1692.22it/s]warmup should be done:  85%| | 2560/3000 [00:01<00:00, 1703.72it/s]warmup should be done:  84%| | 2530/3000 [00:01<00:00, 1676.59it/s]warmup should be done:  83%| | 2498/3000 [00:01<00:00, 1650.42it/s]warmup should be done:  85%| | 2544/3000 [00:01<00:00, 1682.32it/s]warmup should be done:  85%| | 2560/3000 [00:01<00:00, 1703.20it/s]warmup should be done:  80%|  | 2408/3000 [00:01<00:00, 1588.78it/s]warmup should be done:  85%| | 2550/3000 [00:01<00:00, 1660.27it/s]warmup should be done:  86%| | 2571/3000 [00:01<00:00, 1692.35it/s]warmup should be done:  91%| | 2731/3000 [00:01<00:00, 1704.65it/s]warmup should be done:  90%| | 2699/3000 [00:01<00:00, 1677.96it/s]warmup should be done:  89%| | 2664/3000 [00:01<00:00, 1652.77it/s]warmup should be done:  86%| | 2567/3000 [00:01<00:00, 1588.81it/s]warmup should be done:  90%| | 2713/3000 [00:01<00:00, 1678.31it/s]warmup should be done:  91%| | 2732/3000 [00:01<00:00, 1706.03it/s]warmup should be done:  91%| | 2717/3000 [00:01<00:00, 1656.98it/s]warmup should be done:  91%|| 2741/3000 [00:01<00:00, 1692.75it/s]warmup should be done:  97%|| 2902/3000 [00:01<00:00, 1701.01it/s]warmup should be done:  96%|| 2868/3000 [00:01<00:00, 1679.58it/s]warmup should be done:  94%|| 2830/3000 [00:01<00:00, 1650.17it/s]warmup should be done:  91%| | 2727/3000 [00:01<00:00, 1590.24it/s]warmup should be done:  96%|| 2883/3000 [00:01<00:00, 1683.21it/s]warmup should be done:  97%|| 2903/3000 [00:01<00:00, 1705.93it/s]warmup should be done:  96%|| 2887/3000 [00:01<00:00, 1668.29it/s]warmup should be done:  97%|| 2911/3000 [00:01<00:00, 1693.64it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1700.40it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1696.89it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1696.36it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1684.38it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1683.70it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1680.77it/s]warmup should be done: 100%|| 2997/3000 [00:01<00:00, 1654.12it/s]warmup should be done:  96%|| 2887/3000 [00:01<00:00, 1591.32it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1653.78it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1593.09it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]



warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 175/3000 [00:00<00:01, 1749.00it/s]warmup should be done:   6%|         | 174/3000 [00:00<00:01, 1737.06it/s]warmup should be done:   6%|         | 174/3000 [00:00<00:01, 1736.46it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1632.96it/s]warmup should be done:   6%|         | 175/3000 [00:00<00:01, 1744.60it/s]warmup should be done:   6%|         | 170/3000 [00:00<00:01, 1693.49it/s]warmup should be done:   6%|         | 171/3000 [00:00<00:01, 1700.26it/s]warmup should be done:   6%|         | 174/3000 [00:00<00:01, 1730.89it/s]warmup should be done:  12%|        | 351/3000 [00:00<00:01, 1754.28it/s]warmup should be done:  12%|        | 349/3000 [00:00<00:01, 1743.67it/s]warmup should be done:  11%|        | 342/3000 [00:00<00:01, 1708.18it/s]warmup should be done:  11%|         | 329/3000 [00:00<00:01, 1641.50it/s]warmup should be done:  12%|        | 350/3000 [00:00<00:01, 1746.10it/s]warmup should be done:  11%|        | 344/3000 [00:00<00:01, 1715.78it/s]warmup should be done:  12%|        | 352/3000 [00:00<00:01, 1753.94it/s]warmup should be done:  12%|        | 349/3000 [00:00<00:01, 1737.57it/s]warmup should be done:  18%|        | 527/3000 [00:00<00:01, 1756.80it/s]warmup should be done:  17%|        | 524/3000 [00:00<00:01, 1745.80it/s]warmup should be done:  17%|        | 498/3000 [00:00<00:01, 1661.96it/s]warmup should be done:  17%|        | 517/3000 [00:00<00:01, 1720.96it/s]warmup should be done:  17%|        | 515/3000 [00:00<00:01, 1713.91it/s]warmup should be done:  18%|        | 528/3000 [00:00<00:01, 1755.23it/s]warmup should be done:  18%|        | 527/3000 [00:00<00:01, 1752.42it/s]warmup should be done:  17%|        | 524/3000 [00:00<00:01, 1741.18it/s]warmup should be done:  23%|       | 704/3000 [00:00<00:01, 1758.65it/s]warmup should be done:  23%|       | 699/3000 [00:00<00:01, 1745.68it/s]warmup should be done:  22%|       | 666/3000 [00:00<00:01, 1667.28it/s]warmup should be done:  23%|       | 690/3000 [00:00<00:01, 1721.74it/s]warmup should be done:  23%|       | 703/3000 [00:00<00:01, 1753.99it/s]warmup should be done:  23%|       | 699/3000 [00:00<00:01, 1744.24it/s]warmup should be done:  24%|       | 705/3000 [00:00<00:01, 1758.73it/s]warmup should be done:  23%|       | 687/3000 [00:00<00:01, 1712.99it/s]warmup should be done:  29%|       | 880/3000 [00:00<00:01, 1757.89it/s]warmup should be done:  29%|       | 874/3000 [00:00<00:01, 1744.98it/s]warmup should be done:  28%|       | 834/3000 [00:00<00:01, 1671.51it/s]warmup should be done:  29%|       | 874/3000 [00:00<00:01, 1746.28it/s]warmup should be done:  29%|       | 883/3000 [00:00<00:01, 1765.22it/s]warmup should be done:  29%|       | 879/3000 [00:00<00:01, 1753.41it/s]warmup should be done:  29%|       | 863/3000 [00:00<00:01, 1719.85it/s]warmup should be done:  29%|       | 859/3000 [00:00<00:01, 1710.38it/s]warmup should be done:  33%|      | 1002/3000 [00:00<00:01, 1674.28it/s]warmup should be done:  35%|      | 1056/3000 [00:00<00:01, 1756.23it/s]warmup should be done:  35%|      | 1049/3000 [00:00<00:01, 1744.76it/s]warmup should be done:  35%|      | 1049/3000 [00:00<00:01, 1745.85it/s]warmup should be done:  35%|      | 1061/3000 [00:00<00:01, 1769.18it/s]warmup should be done:  35%|      | 1055/3000 [00:00<00:01, 1751.99it/s]warmup should be done:  35%|      | 1036/3000 [00:00<00:01, 1721.37it/s]warmup should be done:  34%|      | 1031/3000 [00:00<00:01, 1711.33it/s]warmup should be done:  39%|      | 1170/3000 [00:00<00:01, 1674.92it/s]warmup should be done:  41%|      | 1232/3000 [00:00<00:01, 1755.54it/s]warmup should be done:  41%|      | 1224/3000 [00:00<00:01, 1743.84it/s]warmup should be done:  41%|     | 1239/3000 [00:00<00:00, 1771.60it/s]warmup should be done:  41%|      | 1231/3000 [00:00<00:01, 1751.76it/s]warmup should be done:  40%|      | 1209/3000 [00:00<00:01, 1720.81it/s]warmup should be done:  40%|      | 1203/3000 [00:00<00:01, 1709.38it/s]warmup should be done:  41%|      | 1224/3000 [00:00<00:01, 1721.09it/s]warmup should be done:  47%|     | 1408/3000 [00:00<00:00, 1756.72it/s]warmup should be done:  45%|     | 1338/3000 [00:00<00:00, 1673.72it/s]warmup should be done:  47%|     | 1418/3000 [00:00<00:00, 1775.33it/s]warmup should be done:  47%|     | 1408/3000 [00:00<00:00, 1754.69it/s]warmup should be done:  46%|     | 1374/3000 [00:00<00:00, 1709.50it/s]warmup should be done:  47%|     | 1399/3000 [00:00<00:00, 1734.03it/s]warmup should be done:  46%|     | 1382/3000 [00:00<00:00, 1717.79it/s]warmup should be done:  47%|     | 1399/3000 [00:00<00:00, 1728.86it/s]warmup should be done:  53%|    | 1584/3000 [00:00<00:00, 1755.98it/s]warmup should be done:  50%|     | 1506/3000 [00:00<00:00, 1673.48it/s]warmup should be done:  53%|    | 1596/3000 [00:00<00:00, 1771.09it/s]warmup should be done:  53%|    | 1586/3000 [00:00<00:00, 1761.72it/s]warmup should be done:  52%|    | 1545/3000 [00:00<00:00, 1709.33it/s]warmup should be done:  52%|    | 1573/3000 [00:00<00:00, 1735.73it/s]warmup should be done:  52%|    | 1555/3000 [00:00<00:00, 1719.92it/s]warmup should be done:  53%|    | 1576/3000 [00:00<00:00, 1740.79it/s]warmup should be done:  59%|    | 1760/3000 [00:01<00:00, 1753.62it/s]warmup should be done:  56%|    | 1674/3000 [00:01<00:00, 1668.62it/s]warmup should be done:  59%|    | 1764/3000 [00:01<00:00, 1766.09it/s]warmup should be done:  57%|    | 1717/3000 [00:01<00:00, 1710.02it/s]warmup should be done:  58%|    | 1748/3000 [00:01<00:00, 1737.36it/s]warmup should be done:  58%|    | 1727/3000 [00:01<00:00, 1718.76it/s]warmup should be done:  59%|    | 1774/3000 [00:01<00:00, 1758.88it/s]warmup should be done:  58%|    | 1753/3000 [00:01<00:00, 1747.96it/s]warmup should be done:  61%|   | 1844/3000 [00:01<00:00, 1678.11it/s]warmup should be done:  65%|   | 1942/3000 [00:01<00:00, 1769.25it/s]warmup should be done:  63%|   | 1889/3000 [00:01<00:00, 1711.83it/s]warmup should be done:  65%|   | 1936/3000 [00:01<00:00, 1745.26it/s]warmup should be done:  64%|   | 1923/3000 [00:01<00:00, 1740.22it/s]warmup should be done:  63%|   | 1899/3000 [00:01<00:00, 1717.35it/s]warmup should be done:  65%|   | 1950/3000 [00:01<00:00, 1753.72it/s]warmup should be done:  64%|   | 1931/3000 [00:01<00:00, 1755.50it/s]warmup should be done:  67%|   | 2016/3000 [00:01<00:00, 1688.95it/s]warmup should be done:  71%|   | 2121/3000 [00:01<00:00, 1772.61it/s]warmup should be done:  69%|   | 2061/3000 [00:01<00:00, 1713.05it/s]warmup should be done:  70%|   | 2098/3000 [00:01<00:00, 1742.14it/s]warmup should be done:  69%|   | 2071/3000 [00:01<00:00, 1716.00it/s]warmup should be done:  70%|   | 2111/3000 [00:01<00:00, 1731.00it/s]warmup should be done:  70%|   | 2108/3000 [00:01<00:00, 1758.55it/s]warmup should be done:  71%|   | 2126/3000 [00:01<00:00, 1750.73it/s]warmup should be done:  73%|  | 2187/3000 [00:01<00:00, 1693.89it/s]warmup should be done:  77%|  | 2300/3000 [00:01<00:00, 1775.22it/s]warmup should be done:  74%|  | 2233/3000 [00:01<00:00, 1712.73it/s]warmup should be done:  76%|  | 2273/3000 [00:01<00:00, 1742.84it/s]warmup should be done:  75%|  | 2243/3000 [00:01<00:00, 1713.26it/s]warmup should be done:  76%|  | 2285/3000 [00:01<00:00, 1760.67it/s]warmup should be done:  76%|  | 2288/3000 [00:01<00:00, 1739.79it/s]warmup should be done:  77%|  | 2302/3000 [00:01<00:00, 1749.23it/s]warmup should be done:  79%|  | 2357/3000 [00:01<00:00, 1691.54it/s]warmup should be done:  83%| | 2479/3000 [00:01<00:00, 1776.86it/s]warmup should be done:  80%|  | 2405/3000 [00:01<00:00, 1711.77it/s]warmup should be done:  82%| | 2448/3000 [00:01<00:00, 1740.48it/s]warmup should be done:  80%|  | 2415/3000 [00:01<00:00, 1708.55it/s]warmup should be done:  82%| | 2464/3000 [00:01<00:00, 1745.11it/s]warmup should be done:  82%| | 2462/3000 [00:01<00:00, 1761.75it/s]warmup should be done:  83%| | 2477/3000 [00:01<00:00, 1744.96it/s]warmup should be done:  89%| | 2657/3000 [00:01<00:00, 1777.15it/s]warmup should be done:  86%| | 2577/3000 [00:01<00:00, 1712.43it/s]warmup should be done:  87%| | 2623/3000 [00:01<00:00, 1741.77it/s]warmup should be done:  84%| | 2527/3000 [00:01<00:00, 1687.37it/s]warmup should be done:  86%| | 2588/3000 [00:01<00:00, 1714.95it/s]warmup should be done:  88%| | 2640/3000 [00:01<00:00, 1747.38it/s]warmup should be done:  88%| | 2639/3000 [00:01<00:00, 1759.77it/s]warmup should be done:  88%| | 2652/3000 [00:01<00:00, 1739.43it/s]warmup should be done:  94%|| 2835/3000 [00:01<00:00, 1775.93it/s]warmup should be done:  92%|| 2749/3000 [00:01<00:00, 1713.69it/s]warmup should be done:  90%| | 2700/3000 [00:01<00:00, 1698.84it/s]warmup should be done:  93%|| 2798/3000 [00:01<00:00, 1742.54it/s]warmup should be done:  92%|| 2763/3000 [00:01<00:00, 1724.36it/s]warmup should be done:  94%|| 2816/3000 [00:01<00:00, 1750.62it/s]warmup should be done:  94%|| 2816/3000 [00:01<00:00, 1761.83it/s]warmup should be done:  94%|| 2829/3000 [00:01<00:00, 1746.21it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1766.29it/s]warmup should be done:  97%|| 2921/3000 [00:01<00:00, 1714.70it/s]warmup should be done:  99%|| 2973/3000 [00:01<00:00, 1744.31it/s]warmup should be done:  96%|| 2873/3000 [00:01<00:00, 1706.33it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1756.15it/s]warmup should be done: 100%|| 2992/3000 [00:01<00:00, 1751.12it/s]warmup should be done: 100%|| 2994/3000 [00:01<00:00, 1765.04it/s]warmup should be done:  98%|| 2936/3000 [00:01<00:00, 1713.03it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1751.02it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1750.28it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1741.63it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1715.26it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1711.74it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1685.16it/s]2022-12-11 19:00:09.207423: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f3c16ee5ee0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:00:09.207480: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:00:09.305456: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:00:09.373254: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f3c1ef9f860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:00:09.373312: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:00:09.373688: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f3c1ec27fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:00:09.373736: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:00:09.443429: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:00:09.452973: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:00:09.569590: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f3c16c27c20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:00:09.569649: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:00:09.612546: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f3c1ac27d90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:00:09.612604: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:00:09.640135: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:00:09.684135: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:00:09.691616: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f3c26f9f6a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:00:09.691687: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:00:09.693394: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f3c1ef83920 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:00:09.693438: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:00:09.694969: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f3c1ec49300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:00:09.695012: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:00:09.754863: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:00:09.772941: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:00:09.775488: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:00:11.427541: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:00:11.427579: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:00:11.427579: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:00:11.427597: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:00:11.427606: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:00:11.427604: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:00:11.427604: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:00:11.427681: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][19:00:50.854][ERROR][RK0][tid #139896647825152]: replica 0 reaches 1000, calling init pre replica
[HCTR][19:00:50.854][ERROR][RK0][tid #139896647825152]: coll ps creation, with 8 devices, using policy clique_part
[HCTR][19:00:50.856][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][19:00:50.857][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy clique_part
[HCTR][19:00:50.862][ERROR][RK0][tid #139896647825152]: replica 4 reaches 1000, calling init pre replica
[HCTR][19:00:50.863][ERROR][RK0][tid #139896647825152]: coll ps creation, with 8 devices, using policy clique_part
[HCTR][19:00:50.873][ERROR][RK0][main]: replica 2 reaches 1000, calling init pre replica
[HCTR][19:00:50.874][ERROR][RK0][main]: replica 1 reaches 1000, calling init pre replica
[HCTR][19:00:50.874][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy clique_part
[HCTR][19:00:50.874][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy clique_part
[HCTR][19:00:50.875][ERROR][RK0][tid #139896647825152]: coll ps creation done
[HCTR][19:00:50.875][ERROR][RK0][tid #139896647825152]: replica 4 waits for coll ps creation barrier
[HCTR][19:00:50.876][ERROR][RK0][main]: replica 5 reaches 1000, calling init pre replica
[HCTR][19:00:50.876][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy clique_part
[HCTR][19:00:50.880][ERROR][RK0][tid #139896647825152]: coll ps creation done
[HCTR][19:00:50.880][ERROR][RK0][tid #139896647825152]: replica 0 waits for coll ps creation barrier
[HCTR][19:00:50.881][ERROR][RK0][main]: coll ps creation done
[HCTR][19:00:50.881][ERROR][RK0][main]: replica 1 waits for coll ps creation barrier
[HCTR][19:00:50.881][ERROR][RK0][main]: coll ps creation done
[HCTR][19:00:50.881][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][19:00:50.882][ERROR][RK0][main]: coll ps creation done
[HCTR][19:00:50.882][ERROR][RK0][main]: replica 2 waits for coll ps creation barrier
[HCTR][19:00:50.882][ERROR][RK0][main]: replica 7 reaches 1000, calling init pre replica
[HCTR][19:00:50.882][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy clique_part
[HCTR][19:00:50.884][ERROR][RK0][main]: coll ps creation done
[HCTR][19:00:50.884][ERROR][RK0][main]: replica 5 waits for coll ps creation barrier
[HCTR][19:00:50.887][ERROR][RK0][main]: coll ps creation done
[HCTR][19:00:50.887][ERROR][RK0][main]: replica 7 waits for coll ps creation barrier
[HCTR][19:00:50.888][ERROR][RK0][main]: replica 6 reaches 1000, calling init pre replica
[HCTR][19:00:50.888][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy clique_part
[HCTR][19:00:50.892][ERROR][RK0][main]: coll ps creation done
[HCTR][19:00:50.892][ERROR][RK0][main]: replica 6 waits for coll ps creation barrier
[HCTR][19:00:50.892][ERROR][RK0][tid #139896647825152]: replica 0 preparing frequency
[HCTR][19:00:58.055][ERROR][RK0][tid #139896647825152]: replica 0 preparing frequency done
[HCTR][19:00:58.097][ERROR][RK0][main]: replica 2 calling init per replica
[HCTR][19:00:58.097][ERROR][RK0][tid #139896647825152]: replica 4 calling init per replica
[HCTR][19:00:58.097][ERROR][RK0][main]: replica 5 calling init per replica
[HCTR][19:00:58.097][ERROR][RK0][main]: replica 6 calling init per replica
[HCTR][19:00:58.097][ERROR][RK0][tid #139896647825152]: replica 0 calling init per replica
[HCTR][19:00:58.097][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][19:00:58.097][ERROR][RK0][main]: replica 1 calling init per replica
[HCTR][19:00:58.097][ERROR][RK0][main]: replica 7 calling init per replica
[HCTR][19:00:58.097][ERROR][RK0][main]: Calling build_v2
[HCTR][19:00:58.097][ERROR][RK0][tid #139896647825152]: Calling build_v2
[HCTR][19:00:58.097][ERROR][RK0][main]: Calling build_v2
[HCTR][19:00:58.097][ERROR][RK0][main]: Calling build_v2
[HCTR][19:00:58.097][ERROR][RK0][main]: Calling build_v2
[HCTR][19:00:58.097][ERROR][RK0][tid #139896647825152]: Calling build_v2
[HCTR][19:00:58.097][ERROR][RK0][main]: Calling build_v2
[HCTR][19:00:58.097][ERROR][RK0][main]: Calling build_v2
[HCTR][19:00:58.097][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:00:58.097][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:00:58.097][ERROR][RK0][tid #139896647825152]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:00:58.097][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:00:58.097][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:00:58.097][ERROR][RK0][tid #139896647825152]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:00:58.097][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:00:58.097][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[2022-12-11 19:00:58.101655: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[[2022-12-11 19:00:582022-12-11 19:00:58..101721101694: : EE [ /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:2022-12-11 19:00:58:196.178[] 101744] assigning 0 to cpu: 2022-12-11 19:00:58v100x8, slow pcie
E.
 101780/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[: :[E1782022-12-11 19:00:58 2022-12-11 19:00:58] ./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.v100x8, slow pcie101850:101833
: 178: [E] E[2022-12-11 19:00:58 [v100x8, slow pcie 2022-12-11 19:00:582022-12-11 19:00:58./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc..[101885::101895101879[: 1961782022-12-11 19:00:58: : [2022-12-11 19:00:58E] ] .EE. assigning 0 to cpuv100x8, slow pcie101922  2022-12-11 19:00:58101952/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc

: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.: :E:[:101964E212 1962022-12-11 19:00:58178[:  ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] .102083] 2022-12-11 19:00:58E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8:assigning 0 to cpu: v100x8, slow pcie. :
178
E
102109/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc196]  [: [:] v100x8, slow pcie/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-11 19:00:58E[2022-12-11 19:00:58178assigning 0 to cpu
:. 2022-12-11 19:00:58.] 
196102226[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.102230v100x8, slow pcie] : 2022-12-11 19:00:58:102255: 
assigning 0 to cpuE.212: E
 [102308[] E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-11 19:00:58: 2022-12-11 19:00:58build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:.E[.
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:213102375 2022-12-11 19:00:58102377:196] : [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.: 212] remote time is 8.68421E2022-12-11 19:00:58:102426E] assigning 0 to cpu
 .196:  build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc102477[] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
:: 2022-12-11 19:00:58assigning 0 to cpu :212E.
[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc196[]  1025602022-12-11 19:00:58:] 2022-12-11 19:00:58[build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: .212assigning 0 to cpu.2022-12-11 19:00:58
:E102616] 
102623.213 : [build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8: [102668] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE2022-12-11 19:00:58
E2022-12-11 19:00:58: remote time is 8.68421: . .E[
214/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc102712/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc102742 2022-12-11 19:00:58] [:: :: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.cpu time is 97.05882022-12-11 19:00:58213E212E:102775
.]  ]  212: 102806remote time is 8.68421/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] E: 
:
:[build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8 E2132122022-12-11 19:00:58
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[ ] ] .:2022-12-11 19:00:58[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8102938213.2022-12-11 19:00:58:

: ] 102949.214E[remote time is 8.68421: [102979]  2022-12-11 19:00:58
E2022-12-11 19:00:58: cpu time is 97.0588/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc. .[E
:103038/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc1030462022-12-11 19:00:58 214: :./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] : E213103083:cpu time is 97.0588213E ] : 
]  /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421Eremote time is 8.68421/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:
 
:214/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[213] :2022-12-11 19:00:58[] cpu time is 97.0588214.2022-12-11 19:00:58remote time is 8.68421
] 103278.
103289cpu time is 97.0588: : 
E[E 2022-12-11 19:00:58 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:103352:214: 214] E] cpu time is 97.0588 cpu time is 97.0588
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
:214] cpu time is 97.0588
[2022-12-11 19:02:57.510777: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-11 19:02:59.874259: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
block 0 storage is 00010001
	access is	0	0	0	0	4	4	4	4	
block 1 storage is 00100010
	access is	1	1	1	1	5	5	5	5	
block 2 storage is 01000100
	access is	2	2	2	2	6	6	6	6	
block 3 storage is 10001000
	access is	3	3	3	3	7	7	7	7	
block 4 storage is 00000000
	access is	8	8	8	8	8	8	8	8	
[2022-12-11 19:03:01.363916: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-11 19:03:01.363993: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-11 19:03:01.364037: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-11 19:03:01.364081: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-11 19:03:01.364626: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:03:01.364681: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.368993: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.372935: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.496765: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 6 solved
[2022-12-11 19:03:01.496849: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 6 initing device 6
[2022-12-11 19:03:01.497254: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:03:01.497304: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.498923: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 1 solved
[2022-12-11 19:03:01.498998: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 1 initing device 1
[2022-12-11 19:03:01.499332: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 5 solved
[2022-12-11 19:03:01.[[4993842022-12-11 19:03:012022-12-11 19:03:01: ..E499376499386 : : /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.ccEE:  205/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] ::worker 0 thread 5 initing device 52021815
] ] Building Coll Cache with ... num gpu device is 87 solved

[2022-12-11 19:03:01.499473[: 2022-12-11 19:03:01E. 499480/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc: :E205 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuworker 0 thread 7 initing device 7:
1980] eager alloc mem 3.29 GB
[[2022-12-11 19:03:012022-12-11 19:03:01..499625499631: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::202202] ] 2 solved
3 solved
[2022-12-11 19:03:01[.2022-12-11 19:03:01499705.: 499709E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc205:] 205[worker 0 thread 2 initing device 2] 2022-12-11 19:03:01
worker 0 thread 3 initing device 3.
499721: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 4 solved[
2022-12-11 19:03:01.499806: E[ 2022-12-11 19:03:01/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.:4998271815: ] EBuilding Coll Cache with ... num gpu device is 8 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc[:2022-12-11 19:03:01205.[] 4998732022-12-11 19:03:01worker 0 thread 4 initing device 4: .
E499893 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: 1815/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :Building Coll Cache with ... num gpu device is 81980
] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.499974: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.[5001262022-12-11 19:03:01: .E500132 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: 1815/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :Building Coll Cache with ... num gpu device is 81815
] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:03:01.[5001862022-12-11 19:03:01: .E500192 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :eager alloc mem 3.29 GB1980
] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.500297: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1815] Building Coll Cache with ... num gpu device is 8
[2022-12-11 19:03:01.500343: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.526975: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.527076: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.527168: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.527247: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.527333: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.527420: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.527524: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.553696: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.553784: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.553874: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.553958: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.554047: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.554120: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:01.554221: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:03:02. 38328: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.00 Bytes
[2022-12-11 19:03:02. 38518: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1855] using empty feat=27
[2022-12-11 19:03:02. 55707: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5
[2022-12-11 19:03:02. 55801: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:03:02. 60017: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:03:02. 60708: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:02. 67882: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:02. 68165: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 134.70 MB
[2022-12-11 19:03:02.161222: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:03:02.165797: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:03:02.165844: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.88 GB
[2022-12-11 19:03:02.261346: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.00 Bytes
[2022-12-11 19:03:02.261531: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1855] using empty feat=27
[2022-12-11 19:03:02.278697: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5
[2022-12-11 19:03:02.278781: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:03:02.283225: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:03:02.283878: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:02.291038: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:02.291307: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 134.70 MB
[2022-12-11 19:03:02.365334: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.00 Bytes
[[[[[2022-12-11 19:03:022022-12-11 19:03:022022-12-11 19:03:022022-12-11 19:03:022022-12-11 19:03:02.....365405365404365405365405365405: : : : : EEEE[E    2022-12-11 19:03:02 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::365506:1980198019801980: 1980] ] ] ] W] eager alloc mem 5.00 Byteseager alloc mem 5.00 Byteseager alloc mem 5.00 Byteseager alloc mem 5.00 Bytes eager alloc mem 5.00 Bytes



/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
:1855] using empty feat=27
[2022-12-11 19:03:02[[.[2022-12-11 19:03:022022-12-11 19:03:02[3656882022-12-11 19:03:02..2022-12-11 19:03:02: .365691365692.W365694: : 365698 : WW: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuW  W: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 1855/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :18551855:using empty feat=271855] ] 1855
] using empty feat=27using empty feat=27] using empty feat=27

using empty feat=27

[2022-12-11 19:03:02.376680: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:03:02.381176: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:03:02.381220: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.88 GB
[2022-12-11 19:03:02.384333: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5
[2022-12-11 19:03:02[.2022-12-11 19:03:02384431.: 384419E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 3531098340] 
eager release cuda mem 5
[[2022-12-11 19:03:022022-12-11 19:03:02..384510384525: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 5eager release cuda mem 3531098340

[2022-12-11 19:03:02.384569: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5[
2022-12-11 19:03:02.384608: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:03:02.384648: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340[
2022-12-11 19:03:02.384656: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5
[2022-12-11 19:03:02.384739: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-11 19:03:02:.638384737] : eager release cuda mem 3531098340E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5
[2022-12-11 19:03:02.384826: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:03:02.429252: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:03:02.433167: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:03:02.437296: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:03:02.441308: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:03:02.445210: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:03:02.449137: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:03:02.451790: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:02.451842: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:02.451888: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:02.451944: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:02.451985: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:02.452049: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:02.459898: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:02.460064: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:02.460166: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 134.70 MB
[2022-12-11 19:03:02.460189: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:02.460257: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-11 19:03:02eager release cuda mem 5518079.
460278: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:02.460322: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:02.460442: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 134.70 MB
[2022-12-11 19:03:02.460891: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 134.70 MB
[2022-12-11 19:03:02.461037: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 134.70 MB
[2022-12-11 19:03:02.461107: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 134.70 MB
[2022-12-11 19:03:02.461189: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cpu/cpu_device.cc:43] WORKER[0] alloc host memory 134.70 MB
[2022-12-11 19:03:02.549558: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:03:02.550634: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:03:02.551616: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[[2022-12-11 19:03:022022-12-11 19:03:02..553682553688: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 25.25 KBeager alloc mem 25.25 KB

[2022-12-11 19:03:02.554029: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:03:02.554096: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:03:02.554142: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.88 GB
[2022-12-11 19:03:02.555174: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:03:02.555218: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.88 GB
[2022-12-11 19:03:02.556122: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:03:02.556166: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.88 GB
[[2022-12-11 19:03:022022-12-11 19:03:02..558211558214: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 25855eager release cuda mem 25855

[[2022-12-11 19:03:022022-12-11 19:03:02..558279558281: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 16.88 GBeager alloc mem 16.88 GB

[2022-12-11 19:03:02.558528: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:03:02.558574: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.88 GB
[[[2022-12-11 19:03:05.[2022-12-11 19:03:05745968.[2022-12-11 19:03:05: 745975[.2022-12-11 19:03:05[E: [2022-12-11 19:03:057459732022-12-11 19:03:05. 2022-12-11 19:03:05E2022-12-11 19:03:05.: .745968/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu. .745975E745969: :745972/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu745969:  : E1926: :: E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE ] E1926E : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuDevice 2 init p2p of link 1 ]  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1926/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuDevice 5 init p2p of link 6/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:] :1926:
:1926Device 1 init p2p of link 71926] 19261926] 
] Device 7 init p2p of link 4] ] Device 0 init p2p of link 3Device 6 init p2p of link 0
Device 4 init p2p of link 5Device 3 init p2p of link 2



[2022-12-11 19:03:05.746515: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.746555: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-11 19:03:051980.] 746568eager alloc mem 5.26 MB: 
E[ 2022-12-11 19:03:05[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.[2022-12-11 19:03:05:7465902022-12-11 19:03:05.[1980[: .7465972022-12-11 19:03:05] 2022-12-11 19:03:05E746600: .eager alloc mem 5.26 MB. : E746614
746620/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE : : : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuEE1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:  ] :1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 5.26 MB1980] ::
] eager alloc mem 5.26 MB19801980eager alloc mem 5.26 MB
] ] 
eager alloc mem 5.26 MBeager alloc mem 5.26 MB

[2022-12-11 19:03:05.755509: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.755691: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.755809: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.755972: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.756042: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.756143: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.756195: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.756248: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.775152: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 1 init p2p of link 2
[2022-12-11 19:03:05.775305: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.776651: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 6 init p2p of link 5
[2022-12-11 19:03:05.776806: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.784777: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.785022: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.790275: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 2 init p2p of link 3
[2022-12-11 19:03:05.790450: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.793696: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 7 init p2p of link 1
[2022-12-11 19:03:05.793735: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 5 init p2p of link 4
[2022-12-11 19:03:05.793859: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.793910: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.793927: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 0 init p2p of link 6
[2022-12-11 19:03:05.794073: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.794230: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 4 init p2p of link 7
[2022-12-11 19:03:05.794373: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.794463: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 3 init p2p of link 0
[2022-12-11 19:03:05.794617: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.797997: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.801329: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.801665: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.802068: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-11 19:03:05:.638802082] : eager release cuda mem 5518079E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.802172: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.806607: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 1 init p2p of link 3
[2022-12-11 19:03:05.806730: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.809116: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 6 init p2p of link 4
[2022-12-11 19:03:05.809236: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.813069: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 7 init p2p of link 6
[2022-12-11 19:03:05.813188: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.814553: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 0 init p2p of link 1
[2022-12-11 19:03:05.814674: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.817422: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 2 init p2p of link 0
[2022-12-11 19:03:05.817545: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.817840: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.819619: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.822214: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.822394: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.824281: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.831264: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 4 init p2p of link 2
[2022-12-11 19:03:05.831385: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.831601: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 5 init p2p of link 7
[[2022-12-11 19:03:052022-12-11 19:03:05..831732831724: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801926] ] eager alloc mem 5.26 MBDevice 3 init p2p of link 5

[2022-12-11 19:03:05.831907: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.839728: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.839980: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.840169: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.847892: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 4 init p2p of link 6
[2022-12-11 19:03:05.848013: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.849893: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 3 init p2p of link 1
[2022-12-11 19:03:05.850010: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.854373: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 1 init p2p of link 0
[2022-12-11 19:03:05.854495: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.856279: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.856733: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.859177: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 6 init p2p of link 7
[2022-12-11 19:03:05.859298: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.861250: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.864185: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 7 init p2p of link 5
[2022-12-11 19:03:05.864305: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.864577: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 0 init p2p of link 2
[2022-12-11 19:03:05.864699: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.866499: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 2 init p2p of link 4
[2022-12-11 19:03:05.866623: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.867677: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.871876: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.872451: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.873010: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.881668: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:03:05.882110: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: clique_part) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 105932946 / 882774585 nodes ( 12.00 %) | cpu 741530657 / 882774585 nodes ( 84.00 %) | 16.88 GB | 4.38193 secs 
[2022-12-11 19:03:05.882174: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1926] Device 5 init p2p of link 3
[2022-12-11 19:03:05.882298: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:03:05.888823: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:03:05.892316: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:03:05.892759: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: clique_part) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 105932946 / 882774585 nodes ( 12.00 %) | cpu 741530657 / 882774585 nodes ( 84.00 %) | 16.88 GB | 4.39287 secs 
[2022-12-11 19:03:05.894241: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:03:05.894715: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: clique_part) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 105932946 / 882774585 nodes ( 12.00 %) | cpu 741530657 / 882774585 nodes ( 84.00 %) | 16.88 GB | 4.39438 secs 
[2022-12-11 19:03:05.895868: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:03:05.896318: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: clique_part) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 105932946 / 882774585 nodes ( 12.00 %) | cpu 741530657 / 882774585 nodes ( 84.00 %) | 16.88 GB | 4.39613 secs 
[2022-12-11 19:03:05.898985: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:03:05.899449: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: clique_part) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 105932946 / 882774585 nodes ( 12.00 %) | cpu 741530657 / 882774585 nodes ( 84.00 %) | 16.88 GB | 4.39998 secs 
[2022-12-11 19:03:05.903422: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:03:05.903879: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: clique_part) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 105932946 / 882774585 nodes ( 12.00 %) | cpu 741530657 / 882774585 nodes ( 84.00 %) | 16.88 GB | 4.40659 secs 
[2022-12-11 19:03:05.913593: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:03:05.913878: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:03:05.914055: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: clique_part) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 105932946 / 882774585 nodes ( 12.00 %) | cpu 741530657 / 882774585 nodes ( 84.00 %) | 16.88 GB | 4.54938 secs 
[2022-12-11 19:03:05.914425: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1955] Asymm Coll cache (policy: clique_part) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 105932946 / 882774585 nodes ( 12.00 %) | cpu 741530657 / 882774585 nodes ( 84.00 %) | 16.88 GB | 4.41446 secs 
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier
[HCTR][19:03:05.914][ERROR][RK0][tid #139896647825152]: replica 4 calling init per replica done, doing barrier
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][19:03:05.914][ERROR][RK0][tid #139896647825152]: replica 0 calling init per replica done, doing barrier
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier done
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier done
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier done
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier done
[HCTR][19:03:05.914][ERROR][RK0][tid #139896647825152]: replica 4 calling init per replica done, doing barrier done
[HCTR][19:03:05.914][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier done
[HCTR][19:03:05.914][ERROR][RK0][tid #139896647825152]: replica 0 calling init per replica done, doing barrier done
[HCTR][19:03:05.914][ERROR][RK0][main]: init per replica done
[HCTR][19:03:05.914][ERROR][RK0][main]: init per replica done
[HCTR][19:03:05.914][ERROR][RK0][main]: init per replica done
[HCTR][19:03:05.914][ERROR][RK0][main]: init per replica done
[HCTR][19:03:05.914][ERROR][RK0][main]: init per replica done
[HCTR][19:03:05.914][ERROR][RK0][tid #139896647825152]: init per replica done
[HCTR][19:03:05.914][ERROR][RK0][main]: init per replica done
[HCTR][19:03:05.934][ERROR][RK0][tid #139896647825152]: init per replica done








