2022-12-11 19:10:34.210140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.214694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.222280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.228513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.232355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.245566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.252139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.257268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.307198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.313578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.324023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.328100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.329241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.330352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.331328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.332627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.334311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.335095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.335578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.336897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.337026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.338333: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.338429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.339727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.339861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.341461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.341696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.342968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.343470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.344378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.345166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.346488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.346616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.348539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.349593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.350683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.351881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.352945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.353989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.355034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.359910: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:10:34.362499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.363161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.363978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.364907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.365703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.366496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.367547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.368507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.369766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.370337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.370354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.370550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.372132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.372923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.373009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.373112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.374729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.375656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.375768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.375820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.377365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.378372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.378638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.381114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.382745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.384432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.385991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.391947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.393722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.393740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.394126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.404132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.404203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.404281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.404315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.406873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.406899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.407004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.407081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.425500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.425500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.431714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.443565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.443767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.444098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.444133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.445933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.446065: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.446454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.448879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.449287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.449798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.449913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.451070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.451166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.451397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.454351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.455118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.456390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.456581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.457269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.457370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.457686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.459603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.460916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.461380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.461465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.461767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.461947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.462230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.464639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.466778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.466804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.466900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.467027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.467121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.469308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.471327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.471445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.471588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.471694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.473071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.475107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.475292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.475354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.476908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.478128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.478270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.478455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.479788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.480974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.481074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.481567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.482621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.485078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.485178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.485768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.486821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.488139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.488251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.488481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.489846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.491418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.491513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.491710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.493031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.494474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.494703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.494852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.497076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.497326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.497475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.497568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.499984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.500030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.500175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.500278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.504111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.505010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.505070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.505118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.506810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.508004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.508212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.508311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.509605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.510876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.510901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.511051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.511172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.512804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.514285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.514432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.514488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.514538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.515650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.516293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.518881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.519538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.519583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.519604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.519721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.521225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.521825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.523957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.524341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.524473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.524513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.524615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.525805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.528134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.528495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.528528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.528637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.529124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.529873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.530626: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:10:34.531988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.532637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.532763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.532785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.532972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.533595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.535934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.536651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.537661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.539886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.540473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.540800: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:10:34.540802: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:10:34.540855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.540963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.541055: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:10:34.542457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.543568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.544084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.544160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.545674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.546558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.547162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.547195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.548502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.549207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.550255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.551519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.551779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.551829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.552099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.554147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.556484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.557561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.557800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.557875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.557891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.559298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.561229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.562364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.562613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.562672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.562708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.564383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.566051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.567732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.569148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.609854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.611340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.612706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.614956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.617682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.617960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.621247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.625062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.625245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.627611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.630948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.631709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.633836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.637380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.638064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.639169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.641392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.643258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.645241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.647476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.648228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.649369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.651925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.652553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.653613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.682249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.683564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.685041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.704671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.705498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.708358: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:10:34.709107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.715679: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:10:34.718517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.725809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.744404: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-11 19:10:34.754523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.794625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.794674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.795296: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.800711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.800729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:34.801064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.698759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.699593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.700179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.700649: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:10:35.700711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-11 19:10:35.719911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.720555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.721061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.721644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.722403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.723035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-11 19:10:35.767437: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:35.767640: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:35.831811: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-11 19:10:35.979951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.980581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.981100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:35.981571: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:10:35.981630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-11 19:10:36.001258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.001901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.002423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.003223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.003765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.004320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-11 19:10:36.006317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.007191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.007730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.008212: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:10:36.008270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-11 19:10:36.008569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.009622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.010147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.010625: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:10:36.010677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-11 19:10:36.014071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.014656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.015195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.015796: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:10:36.015846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-11 19:10:36.027954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.028630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.029674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.030185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.030263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.031259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.031272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.032251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-11 19:10:36.032257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.032830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.033354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.033815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-11 19:10:36.034409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.035035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.035572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.036139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.036660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.037121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-11 19:10:36.068521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.068521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.069640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.069672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.070653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.070686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.071605: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:10:36.071640: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:10:36.071668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-11 19:10:36.071695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-11 19:10:36.076282: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.076459: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.078339: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-11 19:10:36.078975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.079603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.080128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.080599: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-11 19:10:36.080654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-11 19:10:36.081135: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.081305: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.082914: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-11 19:10:36.091251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.092045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.092237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.093181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.093220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.094350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.094397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.094633: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.094786: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.095430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.095474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.096343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-11 19:10:36.096484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.096961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-11 19:10:36.097780: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-11 19:10:36.099794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.100408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.100918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.101493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.102001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-11 19:10:36.102476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-11 19:10:36.125969: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.126171: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.127905: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
2022-12-11 19:10:36.140040: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.140233: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.141501: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.141674: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.143858: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-11 19:10:36.146924: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.147081: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-11 19:10:36.147603: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-11 19:10:36.148027: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
[HCTR][19:10:37.412][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:10:37.414][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:10:37.414][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:10:37.414][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:10:37.414][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:10:37.414][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:10:37.414][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
[HCTR][19:10:37.414][ERROR][RK0][main]: using mock embedding with 882774585 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:00,  2.51it/s]warmup run: 1it [00:00,  2.50it/s]warmup run: 1it [00:00,  2.49it/s]warmup run: 69it [00:00, 180.63it/s]warmup run: 59it [00:00, 153.97it/s]warmup run: 67it [00:00, 174.91it/s]warmup run: 125it [00:00, 284.19it/s]warmup run: 112it [00:00, 255.90it/s]warmup run: 123it [00:00, 278.69it/s]warmup run: 183it [00:00, 366.63it/s]warmup run: 166it [00:00, 333.67it/s]warmup run: 176it [00:00, 348.12it/s]warmup run: 242it [00:00, 428.69it/s]warmup run: 221it [00:00, 393.49it/s]warmup run: 225it [00:00, 382.12it/s]warmup run: 299it [00:00, 467.33it/s]warmup run: 277it [00:00, 439.45it/s]warmup run: 275it [00:00, 415.34it/s]warmup run: 355it [00:01, 494.32it/s]warmup run: 334it [00:01, 475.83it/s]warmup run: 331it [00:01, 456.41it/s]warmup run: 412it [00:01, 515.43it/s]warmup run: 391it [00:01, 502.75it/s]warmup run: 387it [00:01, 485.87it/s]warmup run: 470it [00:01, 532.26it/s]warmup run: 446it [00:01, 515.74it/s]warmup run: 443it [00:01, 507.49it/s]warmup run: 527it [00:01, 541.06it/s]warmup run: 499it [00:01, 522.99it/s]warmup run: 501it [00:01, 512.54it/s]warmup run: 1it [00:01,  1.39s/it]warmup run: 1it [00:01,  1.39s/it]warmup run: 1it [00:01,  1.39s/it]warmup run: 1it [00:01,  1.40s/it]warmup run: 1it [00:01,  1.40s/it]warmup run: 584it [00:01, 547.95it/s]warmup run: 556it [00:01, 535.32it/s]warmup run: 555it [00:01, 510.19it/s]warmup run: 94it [00:01, 87.50it/s]warmup run: 97it [00:01, 90.30it/s]warmup run: 89it [00:01, 82.36it/s]warmup run: 95it [00:01, 87.71it/s]warmup run: 92it [00:01, 84.85it/s]warmup run: 641it [00:01, 548.35it/s]warmup run: 611it [00:01, 539.43it/s]warmup run: 609it [00:01, 517.07it/s]warmup run: 184it [00:01, 183.11it/s]warmup run: 195it [00:01, 194.80it/s]warmup run: 178it [00:01, 176.77it/s]warmup run: 189it [00:01, 187.21it/s]warmup run: 185it [00:01, 183.50it/s]warmup run: 697it [00:01, 551.05it/s]warmup run: 666it [00:01, 537.02it/s]warmup run: 663it [00:01, 521.35it/s]warmup run: 279it [00:01, 293.42it/s]warmup run: 293it [00:01, 307.35it/s]warmup run: 268it [00:01, 280.16it/s]warmup run: 282it [00:01, 293.38it/s]warmup run: 274it [00:01, 284.17it/s]warmup run: 756it [00:01, 561.88it/s]warmup run: 721it [00:01, 536.29it/s]warmup run: 716it [00:01, 521.61it/s]warmup run: 375it [00:01, 406.84it/s]warmup run: 390it [00:01, 419.79it/s]warmup run: 359it [00:01, 386.51it/s]warmup run: 375it [00:01, 401.12it/s]warmup run: 361it [00:01, 382.74it/s]warmup run: 820it [00:01, 583.25it/s]warmup run: 776it [00:01, 531.65it/s]warmup run: 769it [00:01, 520.51it/s]warmup run: 472it [00:01, 516.77it/s]warmup run: 485it [00:01, 523.06it/s]warmup run: 453it [00:01, 493.48it/s]warmup run: 465it [00:01, 497.55it/s]warmup run: 452it [00:01, 485.33it/s]warmup run: 883it [00:01, 595.61it/s]warmup run: 830it [00:01, 530.95it/s]warmup run: 822it [00:01, 511.49it/s]warmup run: 567it [00:01, 610.56it/s]warmup run: 584it [00:01, 623.98it/s]warmup run: 549it [00:01, 594.23it/s]warmup run: 556it [00:02, 586.30it/s]warmup run: 540it [00:02, 570.68it/s]warmup run: 943it [00:02, 587.38it/s]warmup run: 884it [00:02, 533.03it/s]warmup run: 874it [00:02, 502.34it/s]warmup run: 661it [00:02, 687.57it/s]warmup run: 682it [00:02, 707.03it/s]warmup run: 645it [00:02, 680.25it/s]warmup run: 632it [00:02, 653.41it/s]warmup run: 647it [00:02, 662.62it/s]warmup run: 1002it [00:02, 583.49it/s]warmup run: 939it [00:02, 536.65it/s]warmup run: 925it [00:02, 499.26it/s]warmup run: 754it [00:02, 747.90it/s]warmup run: 779it [00:02, 771.79it/s]warmup run: 741it [00:02, 749.87it/s]warmup run: 737it [00:02, 722.52it/s]warmup run: 726it [00:02, 724.54it/s]warmup run: 1061it [00:02, 576.76it/s]warmup run: 996it [00:02, 544.78it/s]warmup run: 976it [00:02, 494.95it/s]warmup run: 849it [00:02, 801.13it/s]warmup run: 874it [00:02, 816.31it/s]warmup run: 838it [00:02, 806.69it/s]warmup run: 829it [00:02, 772.91it/s]warmup run: 821it [00:02, 783.03it/s]warmup run: 1053it [00:02, 549.54it/s]warmup run: 1119it [00:02, 570.80it/s]warmup run: 1027it [00:02, 497.00it/s]warmup run: 944it [00:02, 841.26it/s]warmup run: 970it [00:02, 853.44it/s]warmup run: 934it [00:02, 846.70it/s]warmup run: 922it [00:02, 815.37it/s]warmup run: 912it [00:02, 816.20it/s]warmup run: 1110it [00:02, 552.89it/s]warmup run: 1177it [00:02, 565.69it/s]warmup run: 1082it [00:02, 509.80it/s]warmup run: 1038it [00:02, 868.77it/s]warmup run: 1068it [00:02, 887.91it/s]warmup run: 1030it [00:02, 877.98it/s]warmup run: 1016it [00:02, 848.19it/s]warmup run: 1003it [00:02, 840.12it/s]warmup run: 1166it [00:02, 554.79it/s]warmup run: 1234it [00:02, 551.52it/s]warmup run: 1134it [00:02, 507.07it/s]warmup run: 1134it [00:02, 892.34it/s]warmup run: 1166it [00:02, 914.08it/s]warmup run: 1127it [00:02, 902.75it/s]warmup run: 1111it [00:02, 875.05it/s]warmup run: 1094it [00:02, 856.66it/s]warmup run: 1223it [00:02, 557.92it/s]warmup run: 1290it [00:02, 543.66it/s]warmup run: 1185it [00:02, 501.10it/s]warmup run: 1229it [00:02, 905.20it/s]warmup run: 1264it [00:02, 932.55it/s]warmup run: 1223it [00:02, 918.63it/s]warmup run: 1188it [00:02, 878.95it/s]warmup run: 1204it [00:02, 882.55it/s]warmup run: 1280it [00:02, 560.90it/s]warmup run: 1345it [00:02, 533.70it/s]warmup run: 1236it [00:02, 492.09it/s]warmup run: 1325it [00:02, 920.15it/s]warmup run: 1361it [00:02, 926.60it/s]warmup run: 1321it [00:02, 935.95it/s]warmup run: 1296it [00:02, 877.83it/s]warmup run: 1337it [00:02, 563.28it/s]warmup run: 1280it [00:02, 826.01it/s]warmup run: 1399it [00:02, 521.21it/s]warmup run: 1286it [00:02, 486.73it/s]warmup run: 1418it [00:02, 911.80it/s]warmup run: 1420it [00:02, 844.17it/s]warmup run: 1394it [00:02, 562.27it/s]warmup run: 1452it [00:02, 515.30it/s]warmup run: 1457it [00:02, 751.09it/s]warmup run: 1335it [00:02, 476.83it/s]warmup run: 1387it [00:02, 725.47it/s]warmup run: 1366it [00:03, 701.39it/s]warmup run: 1451it [00:03, 562.88it/s]warmup run: 1504it [00:03, 516.62it/s]warmup run: 1508it [00:03, 743.00it/s]warmup run: 1512it [00:03, 773.34it/s]warmup run: 1388it [00:03, 490.27it/s]warmup run: 1466it [00:03, 666.95it/s]warmup run: 1508it [00:03, 556.55it/s]warmup run: 1540it [00:03, 670.31it/s]warmup run: 1442it [00:03, 638.02it/s]warmup run: 1556it [00:03, 509.44it/s]warmup run: 1446it [00:03, 514.54it/s]warmup run: 1587it [00:03, 687.07it/s]warmup run: 1595it [00:03, 700.17it/s]warmup run: 1564it [00:03, 552.43it/s]warmup run: 1538it [00:03, 633.40it/s]warmup run: 1610it [00:03, 516.34it/s]warmup run: 1510it [00:03, 595.89it/s]warmup run: 1614it [00:03, 622.86it/s]warmup run: 1503it [00:03, 529.61it/s]warmup run: 1620it [00:03, 552.37it/s]warmup run: 1659it [00:03, 643.94it/s]warmup run: 1670it [00:03, 656.58it/s]warmup run: 1664it [00:03, 520.95it/s]warmup run: 1605it [00:03, 611.85it/s]warmup run: 1560it [00:03, 540.34it/s]warmup run: 1573it [00:03, 564.75it/s]warmup run: 1681it [00:03, 582.31it/s]warmup run: 1677it [00:03, 555.17it/s]warmup run: 1726it [00:03, 606.25it/s]warmup run: 1719it [00:03, 528.08it/s]warmup run: 1739it [00:03, 630.59it/s]warmup run: 1616it [00:03, 544.94it/s]warmup run: 1669it [00:03, 594.78it/s]warmup run: 1743it [00:03, 571.96it/s]warmup run: 1733it [00:03, 555.59it/s]warmup run: 1632it [00:03, 526.74it/s]warmup run: 1774it [00:03, 532.17it/s]warmup run: 1671it [00:03, 541.23it/s]warmup run: 1805it [00:03, 614.71it/s]warmup run: 1789it [00:03, 575.20it/s]warmup run: 1730it [00:03, 574.13it/s]warmup run: 1789it [00:03, 556.18it/s]warmup run: 1803it [00:03, 566.98it/s]warmup run: 1687it [00:03, 511.14it/s]warmup run: 1830it [00:03, 540.13it/s]warmup run: 1727it [00:03, 544.18it/s]warmup run: 1868it [00:03, 600.12it/s]warmup run: 1848it [00:03, 554.64it/s]warmup run: 1789it [00:03, 556.30it/s]warmup run: 1847it [00:03, 561.13it/s]warmup run: 1861it [00:03, 557.89it/s]warmup run: 1739it [00:03, 499.97it/s]warmup run: 1886it [00:03, 545.69it/s]warmup run: 1782it [00:03, 543.24it/s]warmup run: 1905it [00:03, 555.15it/s]warmup run: 1929it [00:03, 583.08it/s]warmup run: 1846it [00:03, 544.39it/s]warmup run: 1904it [00:03, 562.66it/s]warmup run: 1918it [00:03, 553.26it/s]warmup run: 1941it [00:03, 546.26it/s]warmup run: 1790it [00:03, 484.31it/s]warmup run: 1838it [00:03, 546.14it/s]warmup run: 1961it [00:03, 551.65it/s]warmup run: 1988it [00:03, 557.26it/s]warmup run: 1901it [00:03, 539.38it/s]warmup run: 1961it [00:03, 563.53it/s]warmup run: 1974it [00:03, 549.97it/s]warmup run: 1998it [00:03, 551.19it/s]warmup run: 1893it [00:04, 546.89it/s]warmup run: 1839it [00:04, 465.83it/s]warmup run: 2017it [00:04, 535.89it/s]warmup run: 2045it [00:04, 553.71it/s]warmup run: 2018it [00:04, 560.53it/s]warmup run: 1956it [00:04, 535.27it/s]warmup run: 2030it [00:04, 550.22it/s]warmup run: 2055it [00:04, 555.55it/s]warmup run: 1948it [00:04, 534.43it/s]warmup run: 1892it [00:04, 480.60it/s]warmup run: 2071it [00:04, 528.48it/s]warmup run: 2102it [00:04, 556.86it/s]warmup run: 2075it [00:04, 559.95it/s]warmup run: 2012it [00:04, 539.71it/s]warmup run: 2086it [00:04, 551.12it/s]warmup run: 2112it [00:04, 559.06it/s]warmup run: 2002it [00:04, 532.82it/s]warmup run: 1949it [00:04, 502.61it/s]warmup run: 2124it [00:04, 519.66it/s]warmup run: 2158it [00:04, 552.59it/s]warmup run: 2132it [00:04, 562.76it/s]warmup run: 2067it [00:04, 538.87it/s]warmup run: 2142it [00:04, 544.78it/s]warmup run: 2169it [00:04, 561.73it/s]warmup run: 2057it [00:04, 534.91it/s]warmup run: 2006it [00:04, 520.04it/s]warmup run: 2215it [00:04, 555.32it/s]warmup run: 2189it [00:04, 563.92it/s]warmup run: 2123it [00:04, 544.42it/s]warmup run: 2176it [00:04, 511.63it/s]warmup run: 2197it [00:04, 541.61it/s]warmup run: 2226it [00:04, 564.18it/s]warmup run: 2059it [00:04, 520.73it/s]warmup run: 2111it [00:04, 513.81it/s]warmup run: 2246it [00:04, 565.55it/s]warmup run: 2272it [00:04, 556.53it/s]warmup run: 2228it [00:04, 510.12it/s]warmup run: 2178it [00:04, 538.17it/s]warmup run: 2254it [00:04, 549.75it/s]warmup run: 2283it [00:04, 565.49it/s]warmup run: 2112it [00:04, 521.69it/s]warmup run: 2164it [00:04, 515.53it/s]warmup run: 2303it [00:04, 566.11it/s]warmup run: 2330it [00:04, 561.06it/s]warmup run: 2280it [00:04, 507.51it/s]warmup run: 2232it [00:04, 532.53it/s]warmup run: 2312it [00:04, 555.76it/s]warmup run: 2340it [00:04, 563.58it/s]warmup run: 2165it [00:04, 523.02it/s]warmup run: 2218it [00:04, 519.99it/s]warmup run: 2360it [00:04, 562.74it/s]warmup run: 2388it [00:04, 565.34it/s]warmup run: 2332it [00:04, 508.66it/s]warmup run: 2286it [00:04, 529.73it/s]warmup run: 2369it [00:04, 558.16it/s]warmup run: 2397it [00:04, 560.79it/s]warmup run: 2221it [00:04, 532.99it/s]warmup run: 2271it [00:04, 522.19it/s]warmup run: 2445it [00:04, 565.59it/s]warmup run: 2417it [00:04, 558.40it/s]warmup run: 2389it [00:04, 526.17it/s]warmup run: 2339it [00:04, 527.68it/s]warmup run: 2427it [00:04, 562.56it/s]warmup run: 2454it [00:04, 562.45it/s]warmup run: 2279it [00:04, 545.10it/s]warmup run: 2324it [00:04, 518.49it/s]warmup run: 2502it [00:04, 566.48it/s]warmup run: 2473it [00:04, 556.14it/s]warmup run: 2446it [00:04, 538.68it/s]warmup run: 2392it [00:04, 525.03it/s]warmup run: 2484it [00:04, 561.56it/s]warmup run: 2511it [00:04, 540.59it/s]warmup run: 2337it [00:04, 553.95it/s]warmup run: 2376it [00:04, 515.63it/s]warmup run: 2559it [00:04, 566.83it/s]warmup run: 2529it [00:04, 555.98it/s]warmup run: 2500it [00:04, 530.34it/s]warmup run: 2445it [00:04, 526.29it/s]warmup run: 2541it [00:04, 545.03it/s]warmup run: 2395it [00:05, 558.65it/s]warmup run: 2566it [00:05, 525.07it/s]warmup run: 2428it [00:05, 506.52it/s]warmup run: 2616it [00:05, 566.53it/s]warmup run: 2586it [00:05, 557.46it/s]warmup run: 2498it [00:05, 523.41it/s]warmup run: 2554it [00:05, 519.83it/s]warmup run: 2596it [00:05, 530.21it/s]warmup run: 2619it [00:05, 526.40it/s]warmup run: 2453it [00:05, 562.92it/s]warmup run: 2479it [00:05, 502.56it/s]warmup run: 2673it [00:05, 566.43it/s]warmup run: 2607it [00:05, 514.37it/s]warmup run: 2551it [00:05, 506.37it/s]warmup run: 2650it [00:05, 530.82it/s]warmup run: 2510it [00:05, 552.85it/s]warmup run: 2535it [00:05, 518.20it/s]warmup run: 2663it [00:05, 524.98it/s]warmup run: 2602it [00:05, 501.68it/s]warmup run: 2566it [00:05, 532.90it/s]warmup run: 2590it [00:05, 525.19it/s]warmup run: 2643it [00:05, 355.72it/s]warmup run: 2653it [00:05, 489.90it/s]warmup run: 2672it [00:05, 339.20it/s]warmup run: 2620it [00:05, 521.07it/s]warmup run: 2730it [00:05, 358.96it/s]warmup run: 2700it [00:05, 400.20it/s]warmup run: 2704it [00:05, 349.27it/s]warmup run: 2728it [00:05, 384.44it/s]warmup run: 2787it [00:05, 402.80it/s]warmup run: 2757it [00:05, 438.55it/s]warmup run: 2716it [00:05, 345.17it/s]warmup run: 2755it [00:05, 383.42it/s]warmup run: 2785it [00:05, 425.89it/s]warmup run: 2643it [00:05, 341.99it/s]warmup run: 2843it [00:05, 438.46it/s]warmup run: 2813it [00:05, 468.58it/s]warmup run: 2767it [00:05, 379.70it/s]warmup run: 2801it [00:05, 401.28it/s]warmup run: 2841it [00:05, 456.75it/s]warmup run: 2700it [00:05, 389.55it/s]warmup run: 2673it [00:05, 334.80it/s]warmup run: 2703it [00:05, 286.26it/s]warmup run: 2900it [00:05, 470.04it/s]warmup run: 2870it [00:05, 493.58it/s]warmup run: 2819it [00:05, 410.76it/s]warmup run: 2847it [00:05, 409.32it/s]warmup run: 2892it [00:05, 469.47it/s]warmup run: 2754it [00:05, 423.84it/s]warmup run: 2724it [00:05, 369.11it/s]warmup run: 2755it [00:05, 330.36it/s]warmup run: 2957it [00:05, 495.29it/s]warmup run: 2927it [00:05, 513.23it/s]warmup run: 2870it [00:05, 434.00it/s]warmup run: 2897it [00:05, 432.21it/s]warmup run: 2947it [00:05, 489.15it/s]warmup run: 2808it [00:05, 451.29it/s]warmup run: 3000it [00:05, 504.59it/s]warmup run: 2776it [00:05, 402.55it/s]warmup run: 2804it [00:05, 364.24it/s]warmup run: 2985it [00:05, 529.52it/s]warmup run: 2922it [00:05, 454.90it/s]warmup run: 2951it [00:05, 459.14it/s]warmup run: 3000it [00:06, 499.83it/s]warmup run: 3000it [00:06, 497.58it/s]warmup run: 2858it [00:06, 458.43it/s]warmup run: 2830it [00:06, 435.04it/s]warmup run: 2855it [00:06, 397.27it/s]warmup run: 2974it [00:06, 471.05it/s]warmup run: 3000it [00:06, 492.04it/s]warmup run: 3000it [00:06, 489.02it/s]warmup run: 2913it [00:06, 482.08it/s]warmup run: 2887it [00:06, 468.13it/s]warmup run: 2910it [00:06, 433.97it/s]warmup run: 2967it [00:06, 496.91it/s]warmup run: 2944it [00:06, 493.55it/s]warmup run: 2968it [00:06, 471.03it/s]warmup run: 3000it [00:06, 474.93it/s]warmup run: 3000it [00:06, 474.27it/s]warmup run: 3000it [00:06, 471.19it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]





warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1669.43it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1664.70it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1637.92it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1664.87it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1653.08it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1675.41it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1623.13it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1650.96it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1650.53it/s]warmup should be done:  11%|         | 335/3000 [00:00<00:01, 1672.31it/s]warmup should be done:  11%|         | 326/3000 [00:00<00:01, 1625.15it/s]warmup should be done:  11%|         | 335/3000 [00:00<00:01, 1671.23it/s]warmup should be done:  11%|         | 335/3000 [00:00<00:01, 1666.64it/s]warmup should be done:  11%|        | 339/3000 [00:00<00:01, 1690.51it/s]warmup should be done:  11%|         | 334/3000 [00:00<00:01, 1664.27it/s]warmup should be done:  11%|         | 334/3000 [00:00<00:01, 1656.13it/s]warmup should be done:  17%|        | 497/3000 [00:00<00:01, 1655.07it/s]warmup should be done:  17%|        | 503/3000 [00:00<00:01, 1674.54it/s]warmup should be done:  16%|        | 489/3000 [00:00<00:01, 1625.77it/s]warmup should be done:  17%|        | 503/3000 [00:00<00:01, 1671.63it/s]warmup should be done:  17%|        | 502/3000 [00:00<00:01, 1664.65it/s]warmup should be done:  17%|        | 502/3000 [00:00<00:01, 1663.96it/s]warmup should be done:  17%|        | 501/3000 [00:00<00:01, 1659.10it/s]warmup should be done:  17%|        | 509/3000 [00:00<00:01, 1686.29it/s]warmup should be done:  22%|       | 665/3000 [00:00<00:01, 1661.24it/s]warmup should be done:  22%|       | 652/3000 [00:00<00:01, 1623.73it/s]warmup should be done:  22%|       | 673/3000 [00:00<00:01, 1680.02it/s]warmup should be done:  22%|       | 671/3000 [00:00<00:01, 1669.46it/s]warmup should be done:  22%|       | 669/3000 [00:00<00:01, 1663.63it/s]warmup should be done:  22%|       | 672/3000 [00:00<00:01, 1677.26it/s]warmup should be done:  23%|       | 678/3000 [00:00<00:01, 1686.83it/s]warmup should be done:  22%|       | 667/3000 [00:00<00:01, 1657.39it/s]warmup should be done:  27%|       | 815/3000 [00:00<00:01, 1620.99it/s]warmup should be done:  28%|       | 840/3000 [00:00<00:01, 1676.21it/s]warmup should be done:  28%|       | 842/3000 [00:00<00:01, 1677.94it/s]warmup should be done:  28%|       | 835/3000 [00:00<00:01, 1663.88it/s]warmup should be done:  28%|       | 847/3000 [00:00<00:01, 1685.57it/s]warmup should be done:  28%|       | 838/3000 [00:00<00:01, 1661.60it/s]warmup should be done:  28%|       | 832/3000 [00:00<00:01, 1642.89it/s]warmup should be done:  28%|       | 836/3000 [00:00<00:01, 1643.65it/s]warmup should be done:  34%|      | 1011/3000 [00:00<00:01, 1681.46it/s]warmup should be done:  34%|      | 1009/3000 [00:00<00:01, 1679.63it/s]warmup should be done:  33%|      | 1003/3000 [00:00<00:01, 1668.27it/s]warmup should be done:  33%|      | 978/3000 [00:00<00:01, 1617.08it/s]warmup should be done:  34%|      | 1005/3000 [00:00<00:01, 1656.71it/s]warmup should be done:  34%|      | 1005/3000 [00:00<00:01, 1656.95it/s]warmup should be done:  34%|      | 1016/3000 [00:00<00:01, 1665.66it/s]warmup should be done:  33%|      | 997/3000 [00:00<00:01, 1616.57it/s]warmup should be done:  39%|      | 1180/3000 [00:00<00:01, 1684.17it/s]warmup should be done:  39%|      | 1177/3000 [00:00<00:01, 1678.72it/s]warmup should be done:  38%|      | 1140/3000 [00:00<00:01, 1614.57it/s]warmup should be done:  39%|      | 1171/3000 [00:00<00:01, 1656.77it/s]warmup should be done:  39%|      | 1174/3000 [00:00<00:01, 1666.58it/s]warmup should be done:  39%|      | 1184/3000 [00:00<00:01, 1667.95it/s]warmup should be done:  39%|      | 1170/3000 [00:00<00:01, 1638.24it/s]warmup should be done:  39%|      | 1160/3000 [00:00<00:01, 1620.17it/s]warmup should be done:  45%|     | 1345/3000 [00:00<00:00, 1678.49it/s]warmup should be done:  45%|     | 1349/3000 [00:00<00:00, 1676.72it/s]warmup should be done:  43%|     | 1302/3000 [00:00<00:01, 1614.44it/s]warmup should be done:  45%|     | 1338/3000 [00:00<00:01, 1660.03it/s]warmup should be done:  45%|     | 1342/3000 [00:00<00:00, 1670.23it/s]warmup should be done:  45%|     | 1353/3000 [00:00<00:00, 1671.79it/s]warmup should be done:  44%|     | 1324/3000 [00:00<00:01, 1623.41it/s]warmup should be done:  44%|     | 1334/3000 [00:00<00:01, 1611.19it/s]warmup should be done:  50%|     | 1514/3000 [00:00<00:00, 1681.92it/s]warmup should be done:  51%|     | 1519/3000 [00:00<00:00, 1681.32it/s]warmup should be done:  49%|     | 1464/3000 [00:00<00:00, 1613.94it/s]warmup should be done:  50%|     | 1505/3000 [00:00<00:00, 1661.12it/s]warmup should be done:  50%|     | 1511/3000 [00:00<00:00, 1675.11it/s]warmup should be done:  51%|     | 1522/3000 [00:00<00:00, 1675.54it/s]warmup should be done:  50%|     | 1488/3000 [00:00<00:00, 1626.37it/s]warmup should be done:  50%|     | 1496/3000 [00:00<00:00, 1599.81it/s]warmup should be done:  56%|    | 1683/3000 [00:01<00:00, 1682.34it/s]warmup should be done:  56%|    | 1688/3000 [00:01<00:00, 1681.93it/s]warmup should be done:  56%|    | 1672/3000 [00:01<00:00, 1659.41it/s]warmup should be done:  56%|    | 1680/3000 [00:01<00:00, 1676.81it/s]warmup should be done:  56%|    | 1690/3000 [00:01<00:00, 1674.92it/s]warmup should be done:  55%|    | 1651/3000 [00:01<00:00, 1625.60it/s]warmup should be done:  55%|    | 1657/3000 [00:01<00:00, 1597.44it/s]warmup should be done:  54%|    | 1626/3000 [00:01<00:00, 1468.24it/s]warmup should be done:  62%|   | 1852/3000 [00:01<00:00, 1680.22it/s]warmup should be done:  62%|   | 1858/3000 [00:01<00:00, 1684.83it/s]warmup should be done:  61%|   | 1838/3000 [00:01<00:00, 1656.79it/s]warmup should be done:  62%|   | 1848/3000 [00:01<00:00, 1676.98it/s]warmup should be done:  62%|   | 1858/3000 [00:01<00:00, 1675.01it/s]warmup should be done:  60%|    | 1814/3000 [00:01<00:00, 1625.46it/s]warmup should be done:  61%|    | 1817/3000 [00:01<00:00, 1597.51it/s]warmup should be done:  59%|    | 1783/3000 [00:01<00:00, 1494.93it/s]warmup should be done:  67%|   | 2021/3000 [00:01<00:00, 1681.85it/s]warmup should be done:  68%|   | 2028/3000 [00:01<00:00, 1686.82it/s]warmup should be done:  67%|   | 2005/3000 [00:01<00:00, 1660.62it/s]warmup should be done:  67%|   | 2017/3000 [00:01<00:00, 1680.28it/s]warmup should be done:  68%|   | 2027/3000 [00:01<00:00, 1676.63it/s]warmup should be done:  66%|   | 1977/3000 [00:01<00:00, 1625.72it/s]warmup should be done:  66%|   | 1981/3000 [00:01<00:00, 1607.91it/s]warmup should be done:  65%|   | 1952/3000 [00:01<00:00, 1549.18it/s]warmup should be done:  73%|  | 2190/3000 [00:01<00:00, 1683.90it/s]warmup should be done:  73%|  | 2198/3000 [00:01<00:00, 1688.17it/s]warmup should be done:  72%|  | 2174/3000 [00:01<00:00, 1668.31it/s]warmup should be done:  73%|  | 2186/3000 [00:01<00:00, 1681.80it/s]warmup should be done:  73%|  | 2196/3000 [00:01<00:00, 1677.83it/s]warmup should be done:  71%|  | 2140/3000 [00:01<00:00, 1626.87it/s]warmup should be done:  72%|  | 2146/3000 [00:01<00:00, 1619.94it/s]warmup should be done:  71%|   | 2121/3000 [00:01<00:00, 1589.84it/s]warmup should be done:  79%|  | 2359/3000 [00:01<00:00, 1682.44it/s]warmup should be done:  79%|  | 2367/3000 [00:01<00:00, 1687.60it/s]warmup should be done:  78%|  | 2341/3000 [00:01<00:00, 1666.92it/s]warmup should be done:  78%|  | 2355/3000 [00:01<00:00, 1679.29it/s]warmup should be done:  77%|  | 2303/3000 [00:01<00:00, 1626.66it/s]warmup should be done:  79%|  | 2364/3000 [00:01<00:00, 1655.18it/s]warmup should be done:  77%|  | 2311/3000 [00:01<00:00, 1627.54it/s]warmup should be done:  76%|  | 2290/3000 [00:01<00:00, 1618.95it/s]warmup should be done:  84%| | 2528/3000 [00:01<00:00, 1683.23it/s]warmup should be done:  85%| | 2536/3000 [00:01<00:00, 1687.32it/s]warmup should be done:  84%| | 2510/3000 [00:01<00:00, 1673.64it/s]warmup should be done:  84%| | 2524/3000 [00:01<00:00, 1679.98it/s]warmup should be done:  84%| | 2532/3000 [00:01<00:00, 1662.01it/s]warmup should be done:  82%| | 2466/3000 [00:01<00:00, 1618.28it/s]warmup should be done:  83%| | 2477/3000 [00:01<00:00, 1636.82it/s]warmup should be done:  82%| | 2459/3000 [00:01<00:00, 1639.27it/s]warmup should be done:  90%| | 2698/3000 [00:01<00:00, 1685.96it/s]warmup should be done:  89%| | 2679/3000 [00:01<00:00, 1677.80it/s]warmup should be done:  90%| | 2705/3000 [00:01<00:00, 1684.20it/s]warmup should be done:  90%| | 2693/3000 [00:01<00:00, 1679.18it/s]warmup should be done:  90%| | 2701/3000 [00:01<00:00, 1668.65it/s]warmup should be done:  88%| | 2629/3000 [00:01<00:00, 1619.88it/s]warmup should be done:  88%| | 2645/3000 [00:01<00:00, 1648.07it/s]warmup should be done:  88%| | 2628/3000 [00:01<00:00, 1652.90it/s]warmup should be done:  96%|| 2868/3000 [00:01<00:00, 1688.39it/s]warmup should be done:  95%|| 2847/3000 [00:01<00:00, 1677.12it/s]warmup should be done:  96%|| 2874/3000 [00:01<00:00, 1684.65it/s]warmup should be done:  95%|| 2862/3000 [00:01<00:00, 1681.56it/s]warmup should be done:  96%|| 2871/3000 [00:01<00:00, 1677.28it/s]warmup should be done:  93%|| 2792/3000 [00:01<00:00, 1621.24it/s]warmup should be done:  94%|| 2813/3000 [00:01<00:00, 1656.63it/s]warmup should be done:  93%|| 2796/3000 [00:01<00:00, 1660.47it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1682.12it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1681.50it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1674.59it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1673.64it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1668.28it/s]warmup should be done:  98%|| 2955/3000 [00:01<00:00, 1620.56it/s]warmup should be done:  99%|| 2981/3000 [00:01<00:00, 1663.47it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1638.15it/s]warmup should be done:  99%|| 2966/3000 [00:01<00:00, 1669.51it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1627.18it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1612.74it/s]



warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 173/3000 [00:00<00:01, 1729.44it/s]warmup should be done:   6%|         | 171/3000 [00:00<00:01, 1708.40it/s]warmup should be done:   6%|         | 172/3000 [00:00<00:01, 1717.97it/s]warmup should be done:   6%|         | 173/3000 [00:00<00:01, 1726.61it/s]warmup should be done:   6%|         | 173/3000 [00:00<00:01, 1726.21it/s]warmup should be done:   6%|         | 173/3000 [00:00<00:01, 1725.84it/s]warmup should be done:   6%|         | 168/3000 [00:00<00:01, 1674.82it/s]warmup should be done:   6%|         | 173/3000 [00:00<00:01, 1720.48it/s]warmup should be done:  11%|        | 344/3000 [00:00<00:01, 1718.91it/s]warmup should be done:  11%|        | 343/3000 [00:00<00:01, 1712.25it/s]warmup should be done:  12%|        | 347/3000 [00:00<00:01, 1730.64it/s]warmup should be done:  11%|        | 338/3000 [00:00<00:01, 1686.99it/s]warmup should be done:  12%|        | 347/3000 [00:00<00:01, 1731.07it/s]warmup should be done:  12%|        | 348/3000 [00:00<00:01, 1735.22it/s]warmup should be done:  12%|        | 346/3000 [00:00<00:01, 1722.95it/s]warmup should be done:  12%|        | 346/3000 [00:00<00:01, 1708.00it/s]warmup should be done:  17%|        | 517/3000 [00:00<00:01, 1721.25it/s]warmup should be done:  17%|        | 511/3000 [00:00<00:01, 1706.29it/s]warmup should be done:  17%|        | 523/3000 [00:00<00:01, 1739.97it/s]warmup should be done:  17%|        | 522/3000 [00:00<00:01, 1735.32it/s]warmup should be done:  17%|        | 521/3000 [00:00<00:01, 1729.71it/s]warmup should be done:  17%|        | 515/3000 [00:00<00:01, 1707.64it/s]warmup should be done:  17%|        | 519/3000 [00:00<00:01, 1719.78it/s]warmup should be done:  17%|        | 517/3000 [00:00<00:01, 1702.00it/s]warmup should be done:  23%|       | 683/3000 [00:00<00:01, 1710.21it/s]warmup should be done:  23%|       | 698/3000 [00:00<00:01, 1741.26it/s]warmup should be done:  23%|       | 696/3000 [00:00<00:01, 1735.22it/s]warmup should be done:  23%|       | 690/3000 [00:00<00:01, 1716.53it/s]warmup should be done:  23%|       | 686/3000 [00:00<00:01, 1705.94it/s]warmup should be done:  23%|       | 694/3000 [00:00<00:01, 1725.79it/s]warmup should be done:  23%|       | 691/3000 [00:00<00:01, 1710.75it/s]warmup should be done:  23%|       | 688/3000 [00:00<00:01, 1702.27it/s]warmup should be done:  28%|       | 855/3000 [00:00<00:01, 1711.82it/s]warmup should be done:  29%|       | 870/3000 [00:00<00:01, 1734.54it/s]warmup should be done:  29%|       | 862/3000 [00:00<00:01, 1716.29it/s]warmup should be done:  29%|       | 873/3000 [00:00<00:01, 1740.46it/s]warmup should be done:  29%|       | 858/3000 [00:00<00:01, 1708.19it/s]warmup should be done:  29%|       | 867/3000 [00:00<00:01, 1723.28it/s]warmup should be done:  29%|       | 859/3000 [00:00<00:01, 1702.90it/s]warmup should be done:  29%|       | 863/3000 [00:00<00:01, 1704.95it/s]warmup should be done:  34%|      | 1029/3000 [00:00<00:01, 1718.72it/s]warmup should be done:  35%|      | 1044/3000 [00:00<00:01, 1734.75it/s]warmup should be done:  35%|      | 1048/3000 [00:00<00:01, 1741.36it/s]warmup should be done:  34%|      | 1030/3000 [00:00<00:01, 1708.71it/s]warmup should be done:  35%|      | 1041/3000 [00:00<00:01, 1725.90it/s]warmup should be done:  34%|      | 1030/3000 [00:00<00:01, 1701.37it/s]warmup should be done:  34%|      | 1034/3000 [00:00<00:01, 1704.34it/s]warmup should be done:  34%|      | 1034/3000 [00:00<00:01, 1693.58it/s]warmup should be done:  40%|      | 1202/3000 [00:00<00:01, 1720.99it/s]warmup should be done:  41%|      | 1218/3000 [00:00<00:01, 1734.42it/s]warmup should be done:  41%|      | 1223/3000 [00:00<00:01, 1741.49it/s]warmup should be done:  40%|      | 1214/3000 [00:00<00:01, 1726.59it/s]warmup should be done:  40%|      | 1201/3000 [00:00<00:01, 1707.36it/s]warmup should be done:  40%|      | 1201/3000 [00:00<00:01, 1697.35it/s]warmup should be done:  40%|      | 1206/3000 [00:00<00:01, 1701.73it/s]warmup should be done:  40%|      | 1205/3000 [00:00<00:01, 1687.70it/s]warmup should be done:  46%|     | 1376/3000 [00:00<00:00, 1726.85it/s]warmup should be done:  47%|     | 1398/3000 [00:00<00:00, 1743.57it/s]warmup should be done:  46%|     | 1393/3000 [00:00<00:00, 1736.31it/s]warmup should be done:  46%|     | 1388/3000 [00:00<00:00, 1730.72it/s]warmup should be done:  46%|     | 1373/3000 [00:00<00:00, 1710.22it/s]warmup should be done:  46%|     | 1372/3000 [00:00<00:00, 1701.16it/s]warmup should be done:  46%|     | 1379/3000 [00:00<00:00, 1709.82it/s]warmup should be done:  46%|     | 1376/3000 [00:00<00:00, 1692.40it/s]warmup should be done:  52%|    | 1550/3000 [00:00<00:00, 1728.79it/s]warmup should be done:  52%|    | 1545/3000 [00:00<00:00, 1712.99it/s]warmup should be done:  52%|    | 1562/3000 [00:00<00:00, 1731.56it/s]warmup should be done:  52%|    | 1573/3000 [00:00<00:00, 1742.69it/s]warmup should be done:  52%|    | 1567/3000 [00:00<00:00, 1735.27it/s]warmup should be done:  51%|    | 1544/3000 [00:00<00:00, 1704.87it/s]warmup should be done:  52%|    | 1551/3000 [00:00<00:00, 1709.26it/s]warmup should be done:  52%|    | 1546/3000 [00:00<00:00, 1694.41it/s]warmup should be done:  57%|    | 1723/3000 [00:01<00:00, 1728.27it/s]warmup should be done:  57%|    | 1717/3000 [00:01<00:00, 1713.82it/s]warmup should be done:  58%|    | 1741/3000 [00:01<00:00, 1734.64it/s]warmup should be done:  58%|    | 1748/3000 [00:01<00:00, 1741.74it/s]warmup should be done:  58%|    | 1736/3000 [00:01<00:00, 1730.76it/s]warmup should be done:  57%|    | 1716/3000 [00:01<00:00, 1706.85it/s]warmup should be done:  57%|    | 1722/3000 [00:01<00:00, 1708.87it/s]warmup should be done:  57%|    | 1716/3000 [00:01<00:00, 1695.54it/s]warmup should be done:  63%|   | 1897/3000 [00:01<00:00, 1729.78it/s]warmup should be done:  64%|   | 1923/3000 [00:01<00:00, 1743.10it/s]warmup should be done:  64%|   | 1916/3000 [00:01<00:00, 1736.48it/s]warmup should be done:  64%|   | 1910/3000 [00:01<00:00, 1731.52it/s]warmup should be done:  63%|   | 1889/3000 [00:01<00:00, 1701.55it/s]warmup should be done:  63%|   | 1893/3000 [00:01<00:00, 1708.91it/s]warmup should be done:  63%|   | 1887/3000 [00:01<00:00, 1703.05it/s]warmup should be done:  63%|   | 1888/3000 [00:01<00:00, 1702.72it/s]warmup should be done:  69%|   | 2071/3000 [00:01<00:00, 1730.75it/s]warmup should be done:  70%|   | 2098/3000 [00:01<00:00, 1745.13it/s]warmup should be done:  70%|   | 2091/3000 [00:01<00:00, 1738.67it/s]warmup should be done:  69%|   | 2084/3000 [00:01<00:00, 1732.39it/s]warmup should be done:  69%|   | 2064/3000 [00:01<00:00, 1709.00it/s]warmup should be done:  69%|   | 2060/3000 [00:01<00:00, 1697.39it/s]warmup should be done:  69%|   | 2058/3000 [00:01<00:00, 1698.08it/s]warmup should be done:  69%|   | 2061/3000 [00:01<00:00, 1709.39it/s]warmup should be done:  75%|  | 2245/3000 [00:01<00:00, 1730.89it/s]warmup should be done:  76%|  | 2274/3000 [00:01<00:00, 1746.62it/s]warmup should be done:  75%|  | 2258/3000 [00:01<00:00, 1732.61it/s]warmup should be done:  76%|  | 2266/3000 [00:01<00:00, 1739.06it/s]warmup should be done:  74%|  | 2235/3000 [00:01<00:00, 1702.69it/s]warmup should be done:  74%|  | 2230/3000 [00:01<00:00, 1692.57it/s]warmup should be done:  74%|  | 2233/3000 [00:01<00:00, 1712.06it/s]warmup should be done:  74%|  | 2228/3000 [00:01<00:00, 1693.39it/s]warmup should be done:  81%|  | 2419/3000 [00:01<00:00, 1730.54it/s]warmup should be done:  82%| | 2449/3000 [00:01<00:00, 1746.02it/s]warmup should be done:  81%| | 2440/3000 [00:01<00:00, 1737.92it/s]warmup should be done:  81%|  | 2432/3000 [00:01<00:00, 1732.08it/s]warmup should be done:  80%|  | 2405/3000 [00:01<00:00, 1713.89it/s]warmup should be done:  80%|  | 2400/3000 [00:01<00:00, 1689.53it/s]warmup should be done:  80%|  | 2406/3000 [00:01<00:00, 1696.48it/s]warmup should be done:  80%|  | 2398/3000 [00:01<00:00, 1690.44it/s]warmup should be done:  86%| | 2593/3000 [00:01<00:00, 1731.72it/s]warmup should be done:  87%| | 2614/3000 [00:01<00:00, 1737.28it/s]warmup should be done:  87%| | 2606/3000 [00:01<00:00, 1732.29it/s]warmup should be done:  87%| | 2624/3000 [00:01<00:00, 1733.30it/s]warmup should be done:  86%| | 2578/3000 [00:01<00:00, 1716.21it/s]warmup should be done:  86%| | 2570/3000 [00:01<00:00, 1690.71it/s]warmup should be done:  86%| | 2576/3000 [00:01<00:00, 1693.79it/s]warmup should be done:  86%| | 2568/3000 [00:01<00:00, 1685.99it/s]warmup should be done:  92%|| 2767/3000 [00:01<00:00, 1733.13it/s]warmup should be done:  93%|| 2788/3000 [00:01<00:00, 1736.31it/s]warmup should be done:  93%|| 2780/3000 [00:01<00:00, 1733.88it/s]warmup should be done:  93%|| 2798/3000 [00:01<00:00, 1733.51it/s]warmup should be done:  92%|| 2750/3000 [00:01<00:00, 1716.97it/s]warmup should be done:  91%|| 2740/3000 [00:01<00:00, 1691.40it/s]warmup should be done:  92%|| 2746/3000 [00:01<00:00, 1690.93it/s]warmup should be done:  91%| | 2737/3000 [00:01<00:00, 1684.71it/s]warmup should be done:  98%|| 2942/3000 [00:01<00:00, 1735.15it/s]warmup should be done:  98%|| 2955/3000 [00:01<00:00, 1735.83it/s]warmup should be done:  99%|| 2962/3000 [00:01<00:00, 1728.75it/s]warmup should be done:  99%|| 2973/3000 [00:01<00:00, 1736.09it/s]warmup should be done:  97%|| 2922/3000 [00:01<00:00, 1716.97it/s]warmup should be done:  97%|| 2910/3000 [00:01<00:00, 1693.55it/s]warmup should be done:  97%|| 2906/3000 [00:01<00:00, 1683.90it/s]warmup should be done:  97%|| 2916/3000 [00:01<00:00, 1684.34it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1739.67it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1734.03it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1731.07it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1724.96it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1708.17it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1700.85it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1698.90it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1695.64it/s]2022-12-11 19:11:42.354999: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f607af05860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:11:42.355057: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:11:42.434790: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:11:42.458250: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f606afa31d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:11:42.458312: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:11:42.476967: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f6072c27180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:11:42.477020: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:11:42.477957: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f607ac271a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:11:42.478015: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:11:42.538789: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:11:42.557378: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:11:42.573491: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:11:42.938001: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f6076c275d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:11:42.938068: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:11:42.960741: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f6076c440d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:11:42.960813: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:11:42.973558: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f6076fa2fc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:11:42.973629: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:11:42.977397: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f6056f9f230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-11 19:11:42.977446: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-11 19:11:43.023654: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:11:43.029171: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:11:43.036641: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:11:43.039057: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-11 19:11:44.286499: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:11:44.289771: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:11:44.338937: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:11:44.351337: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:11:44.612363: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:11:44.655959: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:11:44.671184: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-11 19:11:44.677117: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][19:12:05.118][ERROR][RK0][tid #140053170874112]: replica 7 reaches 1000, calling init pre replica
[HCTR][19:12:05.121][ERROR][RK0][tid #140053170874112]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][19:12:05.139][ERROR][RK0][tid #140053170874112]: coll ps creation done
[HCTR][19:12:05.139][ERROR][RK0][tid #140053170874112]: replica 7 waits for coll ps creation barrier
[HCTR][19:12:05.288][ERROR][RK0][main]: replica 2 reaches 1000, calling init pre replica
[HCTR][19:12:05.288][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][19:12:05.305][ERROR][RK0][main]: coll ps creation done
[HCTR][19:12:05.305][ERROR][RK0][main]: replica 2 waits for coll ps creation barrier
[HCTR][19:12:05.331][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][19:12:05.331][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][19:12:05.332][ERROR][RK0][tid #140052826937088]: replica 5 reaches 1000, calling init pre replica
[HCTR][19:12:05.335][ERROR][RK0][tid #140052826937088]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][19:12:05.338][ERROR][RK0][main]: coll ps creation done
[HCTR][19:12:05.338][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][19:12:05.346][ERROR][RK0][tid #140052826937088]: coll ps creation done
[HCTR][19:12:05.346][ERROR][RK0][tid #140052826937088]: replica 5 waits for coll ps creation barrier
[HCTR][19:12:05.354][ERROR][RK0][main]: replica 6 reaches 1000, calling init pre replica
[HCTR][19:12:05.358][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][19:12:05.361][ERROR][RK0][main]: replica 4 reaches 1000, calling init pre replica
[HCTR][19:12:05.361][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][19:12:05.366][ERROR][RK0][main]: coll ps creation done
[HCTR][19:12:05.366][ERROR][RK0][main]: replica 6 waits for coll ps creation barrier
[HCTR][19:12:05.368][ERROR][RK0][main]: replica 1 reaches 1000, calling init pre replica
[HCTR][19:12:05.368][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][19:12:05.369][ERROR][RK0][main]: coll ps creation done
[HCTR][19:12:05.369][ERROR][RK0][main]: replica 4 waits for coll ps creation barrier
[HCTR][19:12:05.375][ERROR][RK0][main]: coll ps creation done
[HCTR][19:12:05.375][ERROR][RK0][main]: replica 1 waits for coll ps creation barrier
[HCTR][19:12:05.378][ERROR][RK0][tid #140053699352320]: replica 0 reaches 1000, calling init pre replica
[HCTR][19:12:05.379][ERROR][RK0][tid #140053699352320]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][19:12:05.386][ERROR][RK0][tid #140053699352320]: coll ps creation done
[HCTR][19:12:05.386][ERROR][RK0][tid #140053699352320]: replica 0 waits for coll ps creation barrier
[HCTR][19:12:05.386][ERROR][RK0][tid #140053699352320]: replica 0 preparing frequency
[HCTR][19:12:12.440][ERROR][RK0][tid #140053699352320]: replica 0 preparing frequency done
[HCTR][19:12:12.476][ERROR][RK0][tid #140053699352320]: replica 0 calling init per replica
[HCTR][19:12:12.476][ERROR][RK0][main]: replica 4 calling init per replica
[HCTR][19:12:12.476][ERROR][RK0][main]: replica 2 calling init per replica
[HCTR][19:12:12.476][ERROR][RK0][main]: replica 1 calling init per replica
[HCTR][19:12:12.476][ERROR][RK0][tid #140052826937088]: replica 5 calling init per replica
[HCTR][19:12:12.476][ERROR][RK0][tid #140053170874112]: replica 7 calling init per replica
[HCTR][19:12:12.476][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][19:12:12.476][ERROR][RK0][main]: replica 6 calling init per replica
[HCTR][19:12:12.476][ERROR][RK0][tid #140053699352320]: Calling build_v2
[HCTR][19:12:12.476][ERROR][RK0][main]: Calling build_v2
[HCTR][19:12:12.476][ERROR][RK0][main]: Calling build_v2
[HCTR][19:12:12.476][ERROR][RK0][main]: Calling build_v2
[HCTR][19:12:12.476][ERROR][RK0][tid #140052826937088]: Calling build_v2
[HCTR][19:12:12.476][ERROR][RK0][tid #140053170874112]: Calling build_v2
[HCTR][19:12:12.476][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:12:12.476][ERROR][RK0][main]: Calling build_v2
[HCTR][19:12:12.476][ERROR][RK0][tid #140053699352320]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:12:12.476][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:12:12.476][ERROR][RK0][main]: Calling build_v2
[HCTR][19:12:12.476][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:12:12.476][ERROR][RK0][tid #140052826937088]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:12:12.476][ERROR][RK0][tid #140053170874112]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:12:12.476][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][19:12:12.476][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[2022-12-11 19:12:12.480370: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie2022-12-11 19:12:12
.480412: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-11 19:12:12:.178480457[] : v100x8, slow pcieE
 2022-12-11 19:12:12/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.:[4804571962022-12-11 19:12:12: ] .Eassigning 0 to cpu480493 
[: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE: 178/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-11 19:12:12] :.v100x8, slow pcie196480502
] : assigning 0 to cpuE
 [[[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-11 19:12:122022-12-11 19:12:12:..2022-12-11 19:12:12178480559480561.] : : 480548v100x8, slow pcieEE: [
[  E2022-12-11 19:12:12/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc [.::/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-11 19:12:12480605196212:.: 2022-12-11 19:12:12] ] 178480622E.assigning 0 to cpubuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8] :  [480591

v100x8, slow pcieE/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: 
 2022-12-11 19:12:12:E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[.[[212[ :4806432022-12-11 19:12:122022-12-11 19:12:122022-12-11 19:12:12] 2022-12-11 19:12:12/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc196: ...build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8.:] E480705480705480688
480730178assigning 0 to cpu : : : : ] 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[EEEEv100x8, slow pcie:2022-12-11 19:12:12    
178[./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 2022-12-11 19:12:12[480817::::v100x8, slow pcie.2022-12-11 19:12:12: 196213178212
480858.E] ] ] ] : 480882 assigning 0 to cpu[remote time is 8.68421v100x8, slow pciebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
2022-12-11 19:12:12


 E:[.[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc 213[2022-12-11 19:12:12[4809552022-12-11 19:12:12:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 2022-12-11 19:12:12.2022-12-11 19:12:12: .212:remote time is 8.68421.481018.E481015] 196
481024: 481027 : build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8] : E[: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE
assigning 0 to cpuE  2022-12-11 19:12:12E: 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[. 196/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc::2022-12-11 19:12:12481116/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] :213[196.: :assigning 0 to cpu214] 2022-12-11 19:12:12] 481167E212
] remote time is 8.68421.assigning 0 to cpu:  ] cpu time is 97.0588
481208
E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8
[: [ :
2022-12-11 19:12:12E2022-12-11 19:12:12/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc214[. .:] 2022-12-11 19:12:12481311/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[481305213cpu time is 97.0588.: :2022-12-11 19:12:12: ] 
481341E212.Eremote time is 8.68421:  ] 481352 
E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc :[
E:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2122022-12-11 19:12:12 214:[] ./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 2132022-12-11 19:12:12build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8481451:cpu time is 97.0588] .
: 212
remote time is 8.68421481485E[] 
:  2022-12-11 19:12:12build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[.
 :2022-12-11 19:12:12481564/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc214.: [:] 481582E2022-12-11 19:12:12213cpu time is 97.0588:  .] 
E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc481614remote time is 8.68421 :: 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc213E:] [ 214remote time is 8.684212022-12-11 19:12:12/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 
.:cpu time is 97.0588481692[213
: 2022-12-11 19:12:12] E.remote time is 8.68421 481743
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: :E[214 2022-12-11 19:12:12] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.cpu time is 97.0588:481797
214: ] Ecpu time is 97.0588 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:214] cpu time is 97.0588
[2022-12-11 19:13:56.315980: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-11 19:13:56.668566: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-11 19:13:56.668651: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 35310982
[2022-12-11 19:13:58.116097: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-11 19:13:58.116202: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-11 19:13:58.116245: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-11 19:13:58.116289: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-11 19:13:58.116718: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.121223: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.125123: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.251093: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 2 solved
[2022-12-11 19:13:58.251182: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 2 initing device 2
[2022-12-11 19:13:58.251507: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 1 solved
[2022-12-11 19:13:58.[2515612022-12-11 19:13:58: .E251570 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc] :eager alloc mem 3.29 GB205
] worker 0 thread 1 initing device 1
[2022-12-11 19:13:58.251888: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 4 solved
[2022-12-11 19:13:58[.2022-12-11 19:13:58251946.: 251952E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu :/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc1980:] 205eager alloc mem 3.29 GB] 
worker 0 thread 4 initing device 4
[2022-12-11 19:13:58.252310: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.252749: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 6 solved
[2022-12-11 19:13:58.252803: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 6 initing device 6
[2022-12-11 19:13:58.252996: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 7 solved
[2022-12-11 19:13:58.253048: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 7 initing device 7
[2022-12-11 19:13:58.253138: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.253378: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.254459: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 3 solved
[2022-12-11 19:13:58.254530: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 3 initing device 3
[2022-12-11 19:13:58.254898: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.255492: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 5 solved
[2022-12-11 19:13:58.255552: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 5 initing device 5
[2022-12-11 19:13:58.255905: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.278341: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.278519: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.278654: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.278746: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.278826: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.278927: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.286181: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.309089: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.309290: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.309330: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.309425: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.309498: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.309601: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.309733: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 3.29 GB
[2022-12-11 19:13:58.796957: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-11 19:13:58.797360: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-11 19:13:58.797411: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1683] using empty feat=27
[2022-12-11 19:13:58.815155: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-11 19:13:58.815280: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-11 19:13:58.815326: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:13:58.819598: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:13:58.820366: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:13:58.827699: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:13:58.828308: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:13:58.834079: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:13:58.834136: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.84 GB
[[[[[2022-12-11 19:13:592022-12-11 19:13:592022-12-11 19:13:592022-12-11 19:13:592022-12-11 19:13:59..... 55947 55936 55948 55945 55936: : : : : EEEEE     /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:::::19801980198019801980] ] ] ] ] eager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes




[[2022-12-11 19:13:59[[2022-12-11 19:13:59.[2022-12-11 19:13:592022-12-11 19:13:59. 564062022-12-11 19:13:59.. 56408: . 56408 56409: E 56416: : E : EE /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::1980] :19801980] eager alloc mem 1024.00 Bytes1980] ] eager alloc mem 1024.00 Bytes
] eager alloc mem 1024.00 Byteseager alloc mem 1024.00 Bytes
eager alloc mem 1024.00 Bytes


[2022-12-11 19:13:59. 56538[: 2022-12-11 19:13:59W[.[ [2022-12-11 19:13:59 565452022-12-11 19:13:59/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-11 19:13:59.: .:. 56549W 565511683 56553:  : ] : W/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuWusing empty feat=27W : 
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1683/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:] ::1683using empty feat=2716831683] 
] ] using empty feat=27using empty feat=27using empty feat=27


[[2022-12-11 19:13:592022-12-11 19:13:59.. 69805 69797: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes

[2022-12-11 19:13:59[.2022-12-11 19:13:59 70167.:  70171E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980:] 1980eager alloc mem 1024.00 Bytes] 
eager alloc mem 1024.00 Bytes
[2022-12-11 19:13:59[.2022-12-11 19:13:59 70236.:  70240W:  W/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1683:] 1683using empty feat=27] 
using empty feat=27
[2022-12-11 19:13:59. 74940: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-11 19:13:59. 75024: E[ 2022-12-11 19:13:59/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.: 75019638: ] Eeager release cuda mem 2 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-11 19:13:59. 75084: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-11 19:13:59638[.] 2022-12-11 19:13:59 75098eager release cuda mem 3531098340.: 
 75093E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 2] 
eager release cuda mem 1024
[2022-12-11 19:13:59.[ 75183[2022-12-11 19:13:59: 2022-12-11 19:13:59.E. 75175  75190: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: E:E 638 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:eager release cuda mem 3531098340:638
638] ] eager release cuda mem 1024eager release cuda mem 2

[2022-12-11 19:13:59[[.2022-12-11 19:13:592022-12-11 19:13:59 75259..:  75278 75278E: :  EE/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc  :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638::] 638638eager release cuda mem 1024] ] 
eager release cuda mem 3531098340eager release cuda mem 2

[2022-12-11 19:13:59.[ 753632022-12-11 19:13:59: .E 75369 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 2638
] eager release cuda mem 3531098340
[2022-12-11 19:13:59. 75426: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:13:59. 79583: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:13:59. 84179: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:13:59. 87556: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[[2022-12-11 19:13:592022-12-11 19:13:59.. 87627 87615: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 2eager release cuda mem 1024

[2022-12-11 19:13:59.[ 877022022-12-11 19:13:59: .E 87706 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 3531098340638
] eager release cuda mem 2
[2022-12-11 19:13:59. 87767: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 3531098340
[2022-12-11 19:13:59. 88290: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:13:59. 92231: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:13:59. 96115: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:13:59. 97562: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:13:59.101516: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:13:59.105481: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 138.07 MB
[2022-12-11 19:13:59.105867: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:13:59.106243: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:13:59.106496: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:13:59.106535: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:13:59.107716: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:13:59.107772: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:13:59.114184: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:13:59.114518: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:13:59.114562: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:13:59.114747: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:13:59.114891: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 25.25 KB2022-12-11 19:13:59
.114909: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:13:59.115058: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:13:59.115090: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:13:59.115318: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:13:59.115350: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:13:59.115388: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:13:59.115485: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:13:59.115789: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:13:59.115851: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-11 19:13:59.120220: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:13:59.120265: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.84 GB
[2022-12-11 19:13:59.120585: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:13:59.120627: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.84 GB
[2022-12-11 19:13:59.120815: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:13:59.120858: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.84 GB
[2022-12-11 19:13:59.121069: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:13:59.121121: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.84 GB
[2022-12-11 19:13:59.121178: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:13:59.121221: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.84 GB
[2022-12-11 19:13:59.121492: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:13:59.121538: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.84 GB
[2022-12-11 19:13:59.121556: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-11 19:13:59.121601: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 16.84 GB
[[[[[2022-12-11 19:14:02[[[2022-12-11 19:14:022022-12-11 19:14:022022-12-11 19:14:022022-12-11 19:14:02.2022-12-11 19:14:022022-12-11 19:14:022022-12-11 19:14:02....417066...417079417079417079417080: 417083417081417097: : : : E: : : EEEE EEE    /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu   /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::1980:::1980198019801980] 198019801980] ] ] ] eager alloc mem 5.26 MB] ] ] eager alloc mem 5.26 MBeager alloc mem 5.26 MBeager alloc mem 5.26 MBeager alloc mem 5.26 MB
eager alloc mem 5.26 MBeager alloc mem 5.26 MBeager alloc mem 5.26 MB






[2022-12-11 19:14:02.426504: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.426550: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.426607: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.426644: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.426707: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.426831: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.426872: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.426931: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.427152: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.427376: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.427755: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.428407: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.428590: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.428937: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.429007: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.429156: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.436423: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.436482: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.436797: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.436838: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.436903: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.437039: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.437073: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.437150: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.437196: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.437253: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.437607: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.438604: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.438671: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.438744: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.438859: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.438920: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.444465: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.444773: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.444917: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.445324: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.446128: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.446421: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.446644: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.446693: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.446732: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.446784: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.446835: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.447347: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.447561: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.447691: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.447942: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.448007: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.451288: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.451594: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.451700: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.452152: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.453036: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.453332: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.455212: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.455380: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.455423: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.455482: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02[.2022-12-11 19:14:02455531.: 455534E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc1980:] 638eager alloc mem 5.26 MB] 
eager release cuda mem 5518079
[2022-12-11 19:14:02.456203: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.456268: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.456383: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.456961: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.458125: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.458422: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.458515: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.458979: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.459696: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.459986: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.463190: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.463486: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.463752: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.463806: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.463905: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.463962: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.464337: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.464464: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.464597: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.464851: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.464963: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.465347: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.466263: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.466334: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.466387: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.467160: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.469923: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.470230: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.471960: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.472135: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.[4722602022-12-11 19:14:02: .E472271 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :eager release cuda mem 55180791980
] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.472381: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.472471: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.473198[: 2022-12-11 19:14:02E. 473212/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E[638 2022-12-11 19:14:02] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.eager release cuda mem 5518079:473240
1980: ] Eeager alloc mem 5.26 MB 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.473392: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 5.26 MB
[2022-12-11 19:14:02.473574: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.474334: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:14:02.474530: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:14:02.474700: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:14:02.475248: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 0 / 882774585 nodes ( 0.00 %) | cpu 847463603 / 882774585 nodes ( 96.00 %) | 16.84 GB | 4.35854 secs 
[2022-12-11 19:14:02.475520: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 0 / 882774585 nodes ( 0.00 %) | cpu 847463603 / 882774585 nodes ( 96.00 %) | 16.84 GB | 4.22215 secs 
[2022-12-11 19:14:02.475749: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 0 / 882774585 nodes ( 0.00 %) | cpu 847463603 / 882774585 nodes ( 96.00 %) | 16.84 GB | 4.22381 secs 
[2022-12-11 19:14:02.476604: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.476849: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:14:02.477240: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 0 / 882774585 nodes ( 0.00 %) | cpu 847463603 / 882774585 nodes ( 96.00 %) | 16.84 GB | 4.22494 secs 
[2022-12-11 19:14:02.479445: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.479703: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:14:02.479787: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.480159: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 0 / 882774585 nodes ( 0.00 %) | cpu 847463603 / 882774585 nodes ( 96.00 %) | 16.84 GB | 4.22703 secs 
[2022-12-11 19:14:02.480271: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:14:02.480673: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 0 / 882774585 nodes ( 0.00 %) | cpu 847463603 / 882774585 nodes ( 96.00 %) | 16.84 GB | 4.22578 secs 
[2022-12-11 19:14:02.480744: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.480850: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 5518079
[2022-12-11 19:14:02.481033: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:14:02.481203: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 144775028
[2022-12-11 19:14:02.481541: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 0 / 882774585 nodes ( 0.00 %) | cpu 847463603 / 882774585 nodes ( 96.00 %) | 16.84 GB | 4.22999 secs 
[2022-12-11 19:14:02.481813: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 35310982 / 882774585 nodes ( 4.00 %~4.00 %) | remote 0 / 882774585 nodes ( 0.00 %) | cpu 847463603 / 882774585 nodes ( 96.00 %) | 16.84 GB | 4.22592 secs 
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier
[HCTR][19:14:02.481][ERROR][RK0][tid #140052826937088]: replica 5 calling init per replica done, doing barrier
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier
[HCTR][19:14:02.481][ERROR][RK0][tid #140053699352320]: replica 0 calling init per replica done, doing barrier
[HCTR][19:14:02.481][ERROR][RK0][tid #140053170874112]: replica 7 calling init per replica done, doing barrier
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier done
[HCTR][19:14:02.481][ERROR][RK0][tid #140053170874112]: replica 7 calling init per replica done, doing barrier done
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier done
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier done
[HCTR][19:14:02.481][ERROR][RK0][tid #140052826937088]: replica 5 calling init per replica done, doing barrier done
[HCTR][19:14:02.481][ERROR][RK0][main]: init per replica done
[HCTR][19:14:02.481][ERROR][RK0][main]: init per replica done
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][19:14:02.481][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier done
[HCTR][19:14:02.481][ERROR][RK0][tid #140053699352320]: replica 0 calling init per replica done, doing barrier done
[HCTR][19:14:02.481][ERROR][RK0][tid #140053170874112]: init per replica done
[HCTR][19:14:02.481][ERROR][RK0][main]: init per replica done
[HCTR][19:14:02.481][ERROR][RK0][tid #140052826937088]: init per replica done
[HCTR][19:14:02.482][ERROR][RK0][main]: init per replica done
[HCTR][19:14:02.482][ERROR][RK0][main]: init per replica done
[HCTR][19:14:02.501][ERROR][RK0][tid #140053699352320]: init per replica done








