2022-12-12 03:37:53.757109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.762869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.770459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.774493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.781386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.791508: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.800021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.811875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.862062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.867916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.869322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.871457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.872013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.872895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.873733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.874419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.875472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.875875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.877079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.877461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.878808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.879139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.880398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.880667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.882016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.882124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.883671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.884577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.885712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.886853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.887941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.889048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.890923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.892028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.893061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.894103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.895162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.896200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.897206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.898223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.903557: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:37:53.906630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.907643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.908046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.909220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.909639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.910803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.911357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.912549: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.912941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.913303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.914853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.915375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.915699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.917886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.918443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.918598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.919164: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.921076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.921945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.923152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.923306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.924974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.927190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.927397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.927750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.927763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.930472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.930673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.930851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.931181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.933861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.933943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.934025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.934523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.935686: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.936984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.937234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.937413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.937790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.939159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.940162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.940625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.940701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.941176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.942550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.943258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.943980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.944196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.944478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.945886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.946403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.948132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.948221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.949434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.949454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.950588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.958747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.959104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.961445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.961638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.962648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.963124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.970105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.971966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.992507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.994561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:53.999207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.001623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.001662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.001750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.001788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.002205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.004506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.005492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.005535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.005639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.005676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.006145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.009048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.009878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.009921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.010026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.010104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.011447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.013558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.014300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.014352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.014786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.014859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.015189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.017924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.018725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.018849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.018995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.019070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.020276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.021965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.022995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.023264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.023392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.023425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.025010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.025931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.026867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.027186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.027415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.027431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.029037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.030062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.030851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.031075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.031378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.031413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.033251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.033887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.034778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.034971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.035165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.035543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.037235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.037814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.038720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.039042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.039181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.039794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.041484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.041856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.042752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.043085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.043822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.044236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.044968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.046859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.047399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.048649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.048915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.048985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.049194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.049895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.051767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.052081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.052976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.053465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.053494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.053703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.054582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.056441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.057542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.057795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.057838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.057899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.058730: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.060414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.060703: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:37:54.061216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.061475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.061698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.061753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.062733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.064298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.065565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.065985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.066255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.066476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.067437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.067965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.069091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.070084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.070309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.070488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.070652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.071844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.073567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.073601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.074558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.074725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.075205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.075476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.076347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.078032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.078291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.079406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.079649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.080012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.080055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.081118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.082860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.083161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.084015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.084026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.084744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.085978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.087595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.088011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.088974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.089136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.089533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.090863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.092179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.092663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.094032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.094381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.094663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.095412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.097022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.097273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.098850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.099101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.099428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.100402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.101548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.101902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.105227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.105448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.107547: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:37:54.107594: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:37:54.107899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.107941: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:37:54.107958: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:37:54.111197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.111418: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:37:54.113073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.114859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.118059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.118320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.118384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.118727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.121622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.126576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.131753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.131812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.131948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.132045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.132081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.132570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.136445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.136702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.136801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.136836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.136990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.137220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.199696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.205437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.215883: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 03:37:54.225379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.232418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:54.237723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.228447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.229115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.229645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.230127: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:37:55.230182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 03:37:55.247661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.248311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.248810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.249610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.250142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.250833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 03:37:55.298339: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.298545: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.331785: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-12 03:37:55.416755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.417375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.417895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.418369: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:37:55.418423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 03:37:55.436371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.436991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.437683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.438642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.439208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.439678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 03:37:55.517638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.518262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.518782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.519423: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:37:55.519481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 03:37:55.521385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.521951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.522479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.522940: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:37:55.522984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 03:37:55.525679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.526302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.526822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.527344: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:37:55.527403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 03:37:55.534577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.535222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.535748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.536226: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:37:55.536278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 03:37:55.537200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.537807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.538341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.538465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.539334: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:37:55.539401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 03:37:55.539614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.540221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.540356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.541268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.541488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.542093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.542652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.543363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.543456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 03:37:55.543934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.544411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 03:37:55.546093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.546707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.547268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.547414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.548308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.548431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.549243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.549364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.550095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 03:37:55.550212: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 03:37:55.550257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 03:37:55.553457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.554057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.554567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.555158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.555703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.555798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.556666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 03:37:55.556937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.557485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.558064: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.558580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.559047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 03:37:55.567245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.567895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.568415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.569012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.569528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 03:37:55.570000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 03:37:55.577406: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.577568: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.579503: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-12 03:37:55.590967: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.591188: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.592978: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-12 03:37:55.596917: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.597074: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.598735: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-12 03:37:55.603431: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.603582: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.605312: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-12 03:37:55.605302: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.605426: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.607114: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-12 03:37:55.617278: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.617463: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.619370: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-12 03:37:55.640751: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.640939: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 03:37:55.642797: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
[HCTR][03:37:56.916][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:37:56.916][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:37:56.917][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:37:56.917][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:37:56.917][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:37:56.917][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:37:56.917][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][03:37:56.917][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:01,  1.55s/it]warmup run: 1it [00:01,  1.56s/it]warmup run: 1it [00:01,  1.51s/it]warmup run: 1it [00:01,  1.58s/it]warmup run: 100it [00:01, 84.06it/s]warmup run: 99it [00:01, 82.69it/s]warmup run: 94it [00:01, 80.76it/s]warmup run: 1it [00:01,  1.53s/it]warmup run: 1it [00:01,  1.50s/it]warmup run: 91it [00:01, 74.97it/s]warmup run: 198it [00:01, 180.15it/s]warmup run: 198it [00:01, 179.55it/s]warmup run: 192it [00:01, 179.15it/s]warmup run: 1it [00:01,  1.50s/it]warmup run: 100it [00:01, 85.31it/s]warmup run: 97it [00:01, 84.13it/s]warmup run: 1it [00:01,  1.49s/it]warmup run: 181it [00:01, 161.99it/s]warmup run: 294it [00:01, 283.45it/s]warmup run: 298it [00:01, 287.86it/s]warmup run: 289it [00:01, 286.14it/s]warmup run: 99it [00:01, 85.64it/s]warmup run: 199it [00:01, 183.66it/s]warmup run: 197it [00:01, 185.21it/s]warmup run: 94it [00:01, 82.18it/s]warmup run: 269it [00:01, 255.77it/s]warmup run: 390it [00:01, 390.77it/s]warmup run: 398it [00:01, 400.63it/s]warmup run: 386it [00:01, 396.77it/s]warmup run: 199it [00:01, 186.30it/s]warmup run: 298it [00:01, 291.89it/s]warmup run: 297it [00:01, 295.88it/s]warmup run: 187it [00:01, 176.51it/s]warmup run: 356it [00:01, 352.37it/s]warmup run: 485it [00:02, 493.62it/s]warmup run: 498it [00:02, 510.98it/s]warmup run: 484it [00:02, 505.85it/s]warmup run: 299it [00:01, 296.71it/s]warmup run: 397it [00:01, 403.68it/s]warmup run: 398it [00:01, 411.46it/s]warmup run: 281it [00:01, 281.01it/s]warmup run: 444it [00:02, 449.03it/s]warmup run: 581it [00:02, 590.67it/s]warmup run: 599it [00:02, 614.11it/s]warmup run: 582it [00:02, 605.92it/s]warmup run: 398it [00:01, 409.08it/s]warmup run: 495it [00:02, 511.33it/s]warmup run: 498it [00:02, 522.29it/s]warmup run: 378it [00:01, 393.82it/s]warmup run: 535it [00:02, 544.01it/s]warmup run: 677it [00:02, 674.62it/s]warmup run: 700it [00:02, 703.77it/s]warmup run: 681it [00:02, 693.84it/s]warmup run: 498it [00:02, 519.63it/s]warmup run: 594it [00:02, 611.54it/s]warmup run: 598it [00:02, 623.16it/s]warmup run: 477it [00:01, 506.77it/s]warmup run: 627it [00:02, 628.87it/s]warmup run: 774it [00:02, 745.78it/s]warmup run: 801it [00:02, 779.17it/s]warmup run: 779it [00:02, 764.05it/s]warmup run: 599it [00:02, 622.98it/s]warmup run: 693it [00:02, 698.55it/s]warmup run: 698it [00:02, 710.16it/s]warmup run: 578it [00:02, 613.32it/s]warmup run: 721it [00:02, 703.49it/s]warmup run: 870it [00:02, 801.28it/s]warmup run: 902it [00:02, 838.85it/s]warmup run: 880it [00:02, 826.60it/s]warmup run: 703it [00:02, 718.39it/s]warmup run: 794it [00:02, 774.96it/s]warmup run: 799it [00:02, 784.10it/s]warmup run: 679it [00:02, 705.33it/s]warmup run: 811it [00:02, 747.56it/s]warmup run: 966it [00:02, 843.14it/s]warmup run: 1003it [00:02, 883.13it/s]warmup run: 979it [00:02, 868.59it/s]warmup run: 807it [00:02, 796.42it/s]warmup run: 894it [00:02, 832.35it/s]warmup run: 899it [00:02, 840.66it/s]warmup run: 780it [00:02, 779.64it/s]warmup run: 900it [00:02, 784.80it/s]warmup run: 1065it [00:02, 883.53it/s]warmup run: 1104it [00:02, 917.24it/s]warmup run: 1077it [00:02, 898.28it/s]warmup run: 992it [00:02, 869.25it/s]warmup run: 907it [00:02, 845.43it/s]warmup run: 999it [00:02, 881.74it/s]warmup run: 880it [00:02, 837.35it/s]warmup run: 990it [00:02, 815.21it/s]warmup run: 1166it [00:02, 917.30it/s]warmup run: 1205it [00:02, 942.08it/s]warmup run: 1175it [00:02, 916.34it/s]warmup run: 1010it [00:02, 893.43it/s]warmup run: 1090it [00:02, 894.67it/s]warmup run: 1098it [00:02, 907.94it/s]warmup run: 980it [00:02, 880.60it/s]warmup run: 1081it [00:02, 839.56it/s]warmup run: 1267it [00:02, 942.64it/s]warmup run: 1307it [00:02, 963.86it/s]warmup run: 1273it [00:02, 928.71it/s]warmup run: 1188it [00:02, 913.88it/s]warmup run: 1111it [00:02, 900.66it/s]warmup run: 1197it [00:02, 916.76it/s]warmup run: 1171it [00:02, 852.86it/s]warmup run: 1079it [00:02, 871.53it/s]warmup run: 1368it [00:02, 961.46it/s]warmup run: 1409it [00:02, 977.77it/s]warmup run: 1370it [00:02, 939.69it/s]warmup run: 1285it [00:02, 926.74it/s]warmup run: 1294it [00:02, 926.30it/s]warmup run: 1262it [00:02, 866.92it/s]warmup run: 1209it [00:02, 843.52it/s]warmup run: 1469it [00:03, 974.43it/s]warmup run: 1174it [00:02, 826.62it/s]warmup run: 1512it [00:03, 990.45it/s]warmup run: 1469it [00:03, 951.69it/s]warmup run: 1382it [00:02, 939.23it/s]warmup run: 1394it [00:02, 947.34it/s]warmup run: 1355it [00:03, 883.11it/s]warmup run: 1300it [00:02, 856.59it/s]warmup run: 1569it [00:03, 981.23it/s]warmup run: 1270it [00:02, 860.74it/s]warmup run: 1614it [00:03, 997.83it/s]warmup run: 1567it [00:03, 955.47it/s]warmup run: 1479it [00:03, 947.74it/s]warmup run: 1494it [00:03, 960.12it/s]warmup run: 1452it [00:03, 906.65it/s]warmup run: 1397it [00:02, 885.40it/s]warmup run: 1669it [00:03, 977.15it/s]warmup run: 1368it [00:02, 892.20it/s]warmup run: 1717it [00:03, 1005.21it/s]warmup run: 1665it [00:03, 961.34it/s]warmup run: 1577it [00:03, 954.33it/s]warmup run: 1595it [00:03, 974.04it/s]warmup run: 1549it [00:03, 924.93it/s]warmup run: 1494it [00:03, 907.95it/s]warmup run: 1465it [00:03, 913.18it/s]warmup run: 1768it [00:03, 968.31it/s]warmup run: 1819it [00:03, 1008.62it/s]warmup run: 1763it [00:03, 960.50it/s]warmup run: 1675it [00:03, 959.45it/s]warmup run: 1695it [00:03, 981.20it/s]warmup run: 1643it [00:03, 927.34it/s]warmup run: 1590it [00:03, 920.86it/s]warmup run: 1563it [00:03, 932.03it/s]warmup run: 1866it [00:03, 968.40it/s]warmup run: 1922it [00:03, 1012.26it/s]warmup run: 1860it [00:03, 959.69it/s]warmup run: 1772it [00:03, 959.11it/s]warmup run: 1796it [00:03, 987.18it/s]warmup run: 1737it [00:03, 927.83it/s]warmup run: 1684it [00:03, 926.38it/s]warmup run: 1660it [00:03, 940.33it/s]warmup run: 1965it [00:03, 974.58it/s]warmup run: 2025it [00:03, 1016.78it/s]warmup run: 1958it [00:03, 963.62it/s]warmup run: 1869it [00:03, 961.52it/s]warmup run: 1897it [00:03, 991.02it/s]warmup run: 1831it [00:03, 928.54it/s]warmup run: 1780it [00:03, 934.85it/s]warmup run: 1758it [00:03, 949.42it/s]warmup run: 2069it [00:03, 992.49it/s]warmup run: 2146it [00:03, 1073.48it/s]warmup run: 2068it [00:03, 1001.62it/s]warmup run: 1966it [00:03, 963.68it/s]warmup run: 1998it [00:03, 994.18it/s]warmup run: 1925it [00:03, 921.54it/s]warmup run: 1878it [00:03, 947.22it/s]warmup run: 1856it [00:03, 956.46it/s]warmup run: 2178it [00:03, 1020.60it/s]warmup run: 2267it [00:03, 1114.03it/s]warmup run: 2187it [00:03, 1055.32it/s]warmup run: 2075it [00:03, 998.85it/s]warmup run: 2116it [00:03, 1049.19it/s]warmup run: 2023it [00:03, 937.33it/s]warmup run: 1976it [00:03, 956.30it/s]warmup run: 1954it [00:03, 962.20it/s]warmup run: 2288it [00:03, 1043.06it/s]warmup run: 2389it [00:03, 1143.47it/s]warmup run: 2306it [00:03, 1093.72it/s]warmup run: 2192it [00:03, 1048.82it/s]warmup run: 2236it [00:03, 1092.92it/s]warmup run: 2141it [00:03, 1007.89it/s]warmup run: 2086it [00:03, 996.61it/s]warmup run: 2060it [00:03, 989.84it/s]warmup run: 2399it [00:03, 1060.37it/s]warmup run: 2511it [00:03, 1164.67it/s]warmup run: 2425it [00:03, 1121.22it/s]warmup run: 2310it [00:03, 1085.49it/s]warmup run: 2355it [00:03, 1120.83it/s]warmup run: 2259it [00:04, 1057.90it/s]warmup run: 2200it [00:03, 1037.47it/s]warmup run: 2177it [00:03, 1042.91it/s]warmup run: 2509it [00:04, 1071.24it/s]warmup run: 2631it [00:04, 1175.11it/s]warmup run: 2544it [00:04, 1140.71it/s]warmup run: 2427it [00:03, 1109.72it/s]warmup run: 2474it [00:03, 1138.97it/s]warmup run: 2379it [00:04, 1097.47it/s]warmup run: 2314it [00:03, 1066.54it/s]warmup run: 2295it [00:03, 1083.46it/s]warmup run: 2620it [00:04, 1079.89it/s]warmup run: 2753it [00:04, 1185.78it/s]warmup run: 2662it [00:04, 1149.96it/s]warmup run: 2593it [00:04, 1151.34it/s]warmup run: 2539it [00:04, 1021.95it/s]warmup run: 2498it [00:04, 1124.34it/s]warmup run: 2429it [00:03, 1090.56it/s]warmup run: 2414it [00:03, 1113.11it/s]warmup run: 2729it [00:04, 1082.21it/s]warmup run: 2874it [00:04, 1192.52it/s]warmup run: 2781it [00:04, 1159.91it/s]warmup run: 2709it [00:04, 1153.68it/s]warmup run: 2643it [00:04, 1024.16it/s]warmup run: 2617it [00:04, 1143.17it/s]warmup run: 2545it [00:04, 1110.38it/s]warmup run: 2532it [00:04, 1131.81it/s]warmup run: 2839it [00:04, 1086.98it/s]warmup run: 2995it [00:04, 1197.67it/s]warmup run: 3000it [00:04, 683.86it/s] warmup run: 2900it [00:04, 1167.22it/s]warmup run: 2827it [00:04, 1159.43it/s]warmup run: 2763it [00:04, 1074.30it/s]warmup run: 2734it [00:04, 1150.62it/s]warmup run: 2660it [00:04, 1120.31it/s]warmup run: 2650it [00:04, 1144.35it/s]warmup run: 2949it [00:04, 1089.61it/s]warmup run: 3000it [00:04, 677.51it/s] warmup run: 3000it [00:04, 662.27it/s] warmup run: 2943it [00:04, 1158.30it/s]warmup run: 2880it [00:04, 1100.70it/s]warmup run: 2852it [00:04, 1157.55it/s]warmup run: 2776it [00:04, 1130.65it/s]warmup run: 2766it [00:04, 1148.76it/s]warmup run: 3000it [00:04, 685.27it/s] warmup run: 2999it [00:04, 1124.11it/s]warmup run: 2971it [00:04, 1165.32it/s]warmup run: 3000it [00:04, 669.15it/s] warmup run: 2893it [00:04, 1140.83it/s]warmup run: 2882it [00:04, 1151.34it/s]warmup run: 3000it [00:04, 646.15it/s] warmup run: 3000it [00:04, 672.49it/s] warmup run: 3000it [00:04, 674.49it/s] 

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1628.57it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1644.86it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1621.17it/s]warmup should be done:   5%|         | 159/3000 [00:00<00:01, 1581.88it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1609.69it/s]warmup should be done:   5%|         | 160/3000 [00:00<00:01, 1591.43it/s]warmup should be done:   5%|         | 151/3000 [00:00<00:01, 1500.05it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1610.95it/s]warmup should be done:  11%|         | 328/3000 [00:00<00:01, 1639.34it/s]warmup should be done:  11%|         | 326/3000 [00:00<00:01, 1624.22it/s]warmup should be done:  11%|         | 321/3000 [00:00<00:01, 1601.22it/s]warmup should be done:  11%|         | 323/3000 [00:00<00:01, 1607.86it/s]warmup should be done:  10%|         | 303/3000 [00:00<00:01, 1509.95it/s]warmup should be done:  11%|         | 326/3000 [00:00<00:01, 1626.17it/s]warmup should be done:  11%|         | 320/3000 [00:00<00:01, 1592.64it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1636.57it/s]warmup should be done:  16%|        | 492/3000 [00:00<00:01, 1637.97it/s]warmup should be done:  15%|        | 454/3000 [00:00<00:01, 1508.79it/s]warmup should be done:  16%|        | 491/3000 [00:00<00:01, 1634.23it/s]warmup should be done:  16%|        | 482/3000 [00:00<00:01, 1598.33it/s]warmup should be done:  16%|        | 489/3000 [00:00<00:01, 1618.15it/s]warmup should be done:  16%|        | 480/3000 [00:00<00:01, 1588.61it/s]warmup should be done:  16%|        | 494/3000 [00:00<00:01, 1628.26it/s]warmup should be done:  16%|        | 484/3000 [00:00<00:01, 1593.22it/s]warmup should be done:  22%|       | 656/3000 [00:00<00:01, 1633.44it/s]warmup should be done:  22%|       | 656/3000 [00:00<00:01, 1637.67it/s]warmup should be done:  20%|        | 605/3000 [00:00<00:01, 1501.90it/s]warmup should be done:  21%|       | 642/3000 [00:00<00:01, 1593.28it/s]warmup should be done:  21%|       | 639/3000 [00:00<00:01, 1585.26it/s]warmup should be done:  22%|       | 651/3000 [00:00<00:01, 1611.89it/s]warmup should be done:  21%|       | 644/3000 [00:00<00:01, 1592.80it/s]warmup should be done:  22%|       | 657/3000 [00:00<00:01, 1624.04it/s]warmup should be done:  27%|       | 821/3000 [00:00<00:01, 1641.23it/s]warmup should be done:  25%|       | 756/3000 [00:00<00:01, 1502.51it/s]warmup should be done:  27%|       | 798/3000 [00:00<00:01, 1583.10it/s]warmup should be done:  27%|       | 802/3000 [00:00<00:01, 1590.11it/s]warmup should be done:  27%|       | 813/3000 [00:00<00:01, 1609.88it/s]warmup should be done:  27%|       | 820/3000 [00:00<00:01, 1621.10it/s]warmup should be done:  27%|       | 804/3000 [00:00<00:01, 1590.94it/s]warmup should be done:  27%|       | 820/3000 [00:00<00:01, 1618.89it/s]warmup should be done:  33%|      | 986/3000 [00:00<00:01, 1638.74it/s]warmup should be done:  30%|       | 907/3000 [00:00<00:01, 1499.21it/s]warmup should be done:  32%|      | 974/3000 [00:00<00:01, 1605.24it/s]warmup should be done:  32%|      | 957/3000 [00:00<00:01, 1578.50it/s]warmup should be done:  32%|      | 962/3000 [00:00<00:01, 1583.53it/s]warmup should be done:  32%|      | 964/3000 [00:00<00:01, 1587.06it/s]warmup should be done:  33%|      | 982/3000 [00:00<00:01, 1611.28it/s]warmup should be done:  33%|      | 983/3000 [00:00<00:01, 1607.10it/s]warmup should be done:  38%|      | 1151/3000 [00:00<00:01, 1640.59it/s]warmup should be done:  35%|      | 1057/3000 [00:00<00:01, 1493.80it/s]warmup should be done:  38%|      | 1135/3000 [00:00<00:01, 1601.24it/s]warmup should be done:  37%|      | 1115/3000 [00:00<00:01, 1573.92it/s]warmup should be done:  37%|      | 1121/3000 [00:00<00:01, 1583.42it/s]warmup should be done:  37%|      | 1123/3000 [00:00<00:01, 1583.78it/s]warmup should be done:  38%|      | 1144/3000 [00:00<00:01, 1610.42it/s]warmup should be done:  38%|      | 1144/3000 [00:00<00:01, 1607.79it/s]warmup should be done:  44%|     | 1316/3000 [00:00<00:01, 1641.66it/s]warmup should be done:  40%|      | 1207/3000 [00:00<00:01, 1492.08it/s]warmup should be done:  42%|     | 1274/3000 [00:00<00:01, 1578.06it/s]warmup should be done:  43%|     | 1282/3000 [00:00<00:01, 1584.76it/s]warmup should be done:  43%|     | 1296/3000 [00:00<00:01, 1599.11it/s]warmup should be done:  44%|     | 1306/3000 [00:00<00:01, 1610.70it/s]warmup should be done:  44%|     | 1306/3000 [00:00<00:01, 1608.92it/s]warmup should be done:  43%|     | 1280/3000 [00:00<00:01, 1571.33it/s]warmup should be done:  49%|     | 1481/3000 [00:00<00:00, 1644.11it/s]warmup should be done:  48%|     | 1433/3000 [00:00<00:00, 1581.10it/s]warmup should be done:  45%|     | 1357/3000 [00:00<00:01, 1490.54it/s]warmup should be done:  49%|     | 1456/3000 [00:00<00:00, 1598.42it/s]warmup should be done:  48%|     | 1441/3000 [00:00<00:00, 1584.48it/s]warmup should be done:  49%|     | 1470/3000 [00:00<00:00, 1618.31it/s]warmup should be done:  49%|     | 1468/3000 [00:00<00:00, 1609.44it/s]warmup should be done:  48%|     | 1439/3000 [00:00<00:00, 1574.93it/s]warmup should be done:  55%|    | 1646/3000 [00:01<00:00, 1644.68it/s]warmup should be done:  53%|    | 1593/3000 [00:01<00:00, 1586.31it/s]warmup should be done:  53%|    | 1600/3000 [00:01<00:00, 1585.36it/s]warmup should be done:  54%|    | 1618/3000 [00:01<00:00, 1602.63it/s]warmup should be done:  54%|    | 1632/3000 [00:01<00:00, 1618.57it/s]warmup should be done:  50%|     | 1507/3000 [00:01<00:01, 1488.47it/s]warmup should be done:  54%|    | 1629/3000 [00:01<00:00, 1609.30it/s]warmup should be done:  53%|    | 1597/3000 [00:01<00:00, 1576.38it/s]warmup should be done:  60%|    | 1811/3000 [00:01<00:00, 1644.47it/s]warmup should be done:  58%|    | 1754/3000 [00:01<00:00, 1593.23it/s]warmup should be done:  59%|    | 1759/3000 [00:01<00:00, 1585.67it/s]warmup should be done:  59%|    | 1781/3000 [00:01<00:00, 1608.40it/s]warmup should be done:  55%|    | 1656/3000 [00:01<00:00, 1488.26it/s]warmup should be done:  60%|    | 1794/3000 [00:01<00:00, 1611.02it/s]warmup should be done:  59%|    | 1756/3000 [00:01<00:00, 1577.83it/s]warmup should be done:  60%|    | 1790/3000 [00:01<00:00, 1558.31it/s]warmup should be done:  66%|   | 1976/3000 [00:01<00:00, 1643.68it/s]warmup should be done:  64%|   | 1916/3000 [00:01<00:00, 1598.53it/s]warmup should be done:  64%|   | 1918/3000 [00:01<00:00, 1585.94it/s]warmup should be done:  65%|   | 1944/3000 [00:01<00:00, 1613.38it/s]warmup should be done:  60%|    | 1805/3000 [00:01<00:00, 1487.39it/s]warmup should be done:  65%|   | 1958/3000 [00:01<00:00, 1617.65it/s]warmup should be done:  64%|   | 1914/3000 [00:01<00:00, 1577.68it/s]warmup should be done:  65%|   | 1947/3000 [00:01<00:00, 1478.74it/s]warmup should be done:  71%|  | 2141/3000 [00:01<00:00, 1643.47it/s]warmup should be done:  69%|   | 2078/3000 [00:01<00:00, 1602.52it/s]warmup should be done:  69%|   | 2077/3000 [00:01<00:00, 1584.18it/s]warmup should be done:  65%|   | 1961/3000 [00:01<00:00, 1507.94it/s]warmup should be done:  69%|   | 2072/3000 [00:01<00:00, 1578.34it/s]warmup should be done:  71%|   | 2123/3000 [00:01<00:00, 1626.17it/s]warmup should be done:  70%|   | 2106/3000 [00:01<00:00, 1605.16it/s]warmup should be done:  70%|   | 2105/3000 [00:01<00:00, 1507.55it/s]warmup should be done:  77%|  | 2306/3000 [00:01<00:00, 1640.55it/s]warmup should be done:  75%|  | 2239/3000 [00:01<00:00, 1602.11it/s]warmup should be done:  71%|   | 2120/3000 [00:01<00:00, 1531.15it/s]warmup should be done:  75%|  | 2236/3000 [00:01<00:00, 1578.50it/s]warmup should be done:  74%|  | 2230/3000 [00:01<00:00, 1578.49it/s]warmup should be done:  76%|  | 2287/3000 [00:01<00:00, 1629.48it/s]warmup should be done:  76%|  | 2267/3000 [00:01<00:00, 1600.26it/s]warmup should be done:  75%|  | 2262/3000 [00:01<00:00, 1525.33it/s]warmup should be done:  82%| | 2471/3000 [00:01<00:00, 1640.89it/s]warmup should be done:  80%|  | 2401/3000 [00:01<00:00, 1605.27it/s]warmup should be done:  76%|  | 2278/3000 [00:01<00:00, 1545.13it/s]warmup should be done:  80%|  | 2389/3000 [00:01<00:00, 1579.12it/s]warmup should be done:  82%| | 2451/3000 [00:01<00:00, 1630.62it/s]warmup should be done:  80%|  | 2394/3000 [00:01<00:00, 1572.49it/s]warmup should be done:  81%|  | 2428/3000 [00:01<00:00, 1595.16it/s]warmup should be done:  81%|  | 2420/3000 [00:01<00:00, 1541.08it/s]warmup should be done:  88%| | 2636/3000 [00:01<00:00, 1642.94it/s]warmup should be done:  81%| | 2438/3000 [00:01<00:00, 1560.16it/s]warmup should be done:  85%| | 2562/3000 [00:01<00:00, 1601.71it/s]warmup should be done:  85%| | 2549/3000 [00:01<00:00, 1583.69it/s]warmup should be done:  87%| | 2615/3000 [00:01<00:00, 1621.33it/s]warmup should be done:  85%| | 2552/3000 [00:01<00:00, 1563.14it/s]warmup should be done:  86%| | 2592/3000 [00:01<00:00, 1605.90it/s]warmup should be done:  86%| | 2579/3000 [00:01<00:00, 1553.97it/s]warmup should be done:  93%|| 2801/3000 [00:01<00:00, 1644.47it/s]warmup should be done:  87%| | 2597/3000 [00:01<00:00, 1569.06it/s]warmup should be done:  91%| | 2726/3000 [00:01<00:00, 1610.59it/s]warmup should be done:  90%| | 2709/3000 [00:01<00:00, 1586.69it/s]warmup should be done:  92%|| 2756/3000 [00:01<00:00, 1615.10it/s]warmup should be done:  90%| | 2709/3000 [00:01<00:00, 1560.87it/s]warmup should be done:  93%|| 2778/3000 [00:01<00:00, 1611.33it/s]warmup should be done:  91%|| 2741/3000 [00:01<00:00, 1570.69it/s]warmup should be done:  99%|| 2968/3000 [00:01<00:00, 1649.24it/s]warmup should be done:  92%|| 2755/3000 [00:01<00:00, 1570.56it/s]warmup should be done:  96%|| 2889/3000 [00:01<00:00, 1616.03it/s]warmup should be done:  96%|| 2870/3000 [00:01<00:00, 1592.40it/s]warmup should be done:  97%|| 2922/3000 [00:01<00:00, 1626.76it/s]warmup should be done:  96%|| 2868/3000 [00:01<00:00, 1568.76it/s]warmup should be done:  98%|| 2942/3000 [00:01<00:00, 1616.89it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1641.93it/s]warmup should be done:  97%|| 2904/3000 [00:01<00:00, 1586.23it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1619.77it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1610.75it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1596.97it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1585.50it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1580.41it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1579.50it/s]warmup should be done:  97%|| 2915/3000 [00:01<00:00, 1576.76it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1527.36it/s]



warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]


warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1617.06it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1647.08it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1657.50it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1646.19it/s]warmup should be done:   6%|         | 169/3000 [00:00<00:01, 1684.07it/s]warmup should be done:   5%|         | 160/3000 [00:00<00:01, 1594.59it/s]warmup should be done:   6%|         | 169/3000 [00:00<00:01, 1680.30it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1630.25it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1658.52it/s]warmup should be done:  11%|         | 322/3000 [00:00<00:01, 1608.54it/s]warmup should be done:  11%|         | 331/3000 [00:00<00:01, 1651.54it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1655.98it/s]warmup should be done:  11%|         | 324/3000 [00:00<00:01, 1611.01it/s]warmup should be done:  11%|         | 329/3000 [00:00<00:01, 1638.25it/s]warmup should be done:  11%|        | 338/3000 [00:00<00:01, 1677.79it/s]warmup should be done:  11%|        | 338/3000 [00:00<00:01, 1671.60it/s]warmup should be done:  17%|        | 499/3000 [00:00<00:01, 1662.45it/s]warmup should be done:  16%|        | 484/3000 [00:00<00:01, 1613.35it/s]warmup should be done:  17%|        | 498/3000 [00:00<00:01, 1656.18it/s]warmup should be done:  17%|        | 499/3000 [00:00<00:01, 1658.51it/s]warmup should be done:  16%|        | 486/3000 [00:00<00:01, 1611.52it/s]warmup should be done:  16%|        | 495/3000 [00:00<00:01, 1644.12it/s]warmup should be done:  17%|        | 507/3000 [00:00<00:01, 1678.94it/s]warmup should be done:  17%|        | 506/3000 [00:00<00:01, 1666.54it/s]warmup should be done:  22%|       | 667/3000 [00:00<00:01, 1665.57it/s]warmup should be done:  22%|       | 646/3000 [00:00<00:01, 1612.38it/s]warmup should be done:  22%|       | 666/3000 [00:00<00:01, 1660.42it/s]warmup should be done:  22%|       | 664/3000 [00:00<00:01, 1653.24it/s]warmup should be done:  22%|       | 660/3000 [00:00<00:01, 1644.07it/s]warmup should be done:  23%|       | 676/3000 [00:00<00:01, 1683.25it/s]warmup should be done:  22%|       | 649/3000 [00:00<00:01, 1615.11it/s]warmup should be done:  22%|       | 673/3000 [00:00<00:01, 1667.37it/s]warmup should be done:  28%|       | 835/3000 [00:00<00:01, 1667.70it/s]warmup should be done:  27%|       | 808/3000 [00:00<00:01, 1612.18it/s]warmup should be done:  28%|       | 833/3000 [00:00<00:01, 1660.12it/s]warmup should be done:  27%|       | 811/3000 [00:00<00:01, 1614.88it/s]warmup should be done:  28%|       | 830/3000 [00:00<00:01, 1650.00it/s]warmup should be done:  28%|       | 825/3000 [00:00<00:01, 1640.95it/s]warmup should be done:  28%|       | 840/3000 [00:00<00:01, 1667.92it/s]warmup should be done:  28%|       | 845/3000 [00:00<00:01, 1670.57it/s]warmup should be done:  33%|      | 1002/3000 [00:00<00:01, 1668.31it/s]warmup should be done:  32%|      | 971/3000 [00:00<00:01, 1614.96it/s]warmup should be done:  32%|      | 973/3000 [00:00<00:01, 1614.54it/s]warmup should be done:  33%|      | 1000/3000 [00:00<00:01, 1660.58it/s]warmup should be done:  33%|      | 990/3000 [00:00<00:01, 1642.12it/s]warmup should be done:  33%|      | 996/3000 [00:00<00:01, 1650.36it/s]warmup should be done:  34%|      | 1007/3000 [00:00<00:01, 1665.92it/s]warmup should be done:  34%|      | 1014/3000 [00:00<00:01, 1674.45it/s]warmup should be done:  39%|      | 1170/3000 [00:00<00:01, 1669.08it/s]warmup should be done:  38%|      | 1133/3000 [00:00<00:01, 1614.72it/s]warmup should be done:  39%|      | 1167/3000 [00:00<00:01, 1661.54it/s]warmup should be done:  38%|      | 1135/3000 [00:00<00:01, 1613.75it/s]warmup should be done:  38%|      | 1155/3000 [00:00<00:01, 1644.01it/s]warmup should be done:  39%|      | 1162/3000 [00:00<00:01, 1652.62it/s]warmup should be done:  39%|      | 1174/3000 [00:00<00:01, 1663.39it/s]warmup should be done:  39%|      | 1182/3000 [00:00<00:01, 1673.02it/s]warmup should be done:  45%|     | 1340/3000 [00:00<00:00, 1676.67it/s]warmup should be done:  43%|     | 1295/3000 [00:00<00:01, 1614.79it/s]warmup should be done:  44%|     | 1334/3000 [00:00<00:01, 1662.69it/s]warmup should be done:  44%|     | 1328/3000 [00:00<00:01, 1651.65it/s]warmup should be done:  44%|     | 1320/3000 [00:00<00:01, 1639.74it/s]warmup should be done:  45%|     | 1341/3000 [00:00<00:00, 1663.56it/s]warmup should be done:  43%|     | 1297/3000 [00:00<00:01, 1604.87it/s]warmup should be done:  45%|     | 1350/3000 [00:00<00:00, 1671.86it/s]warmup should be done:  50%|     | 1510/3000 [00:00<00:00, 1682.08it/s]warmup should be done:  49%|     | 1459/3000 [00:00<00:00, 1622.14it/s]warmup should be done:  50%|     | 1501/3000 [00:00<00:00, 1663.88it/s]warmup should be done:  50%|     | 1494/3000 [00:00<00:00, 1652.46it/s]warmup should be done:  49%|     | 1484/3000 [00:00<00:00, 1639.75it/s]warmup should be done:  50%|     | 1508/3000 [00:00<00:00, 1662.45it/s]warmup should be done:  49%|     | 1459/3000 [00:00<00:00, 1606.66it/s]warmup should be done:  51%|     | 1518/3000 [00:00<00:00, 1666.76it/s]warmup should be done:  56%|    | 1680/3000 [00:01<00:00, 1686.92it/s]warmup should be done:  54%|    | 1623/3000 [00:01<00:00, 1627.59it/s]warmup should be done:  56%|    | 1668/3000 [00:01<00:00, 1664.49it/s]warmup should be done:  55%|    | 1660/3000 [00:01<00:00, 1653.69it/s]warmup should be done:  55%|    | 1649/3000 [00:01<00:00, 1641.27it/s]warmup should be done:  56%|    | 1675/3000 [00:01<00:00, 1662.28it/s]warmup should be done:  54%|    | 1621/3000 [00:01<00:00, 1608.95it/s]warmup should be done:  56%|    | 1685/3000 [00:01<00:00, 1664.86it/s]warmup should be done:  60%|    | 1786/3000 [00:01<00:00, 1627.95it/s]warmup should be done:  62%|   | 1849/3000 [00:01<00:00, 1684.42it/s]warmup should be done:  61%|    | 1835/3000 [00:01<00:00, 1665.87it/s]warmup should be done:  61%|    | 1826/3000 [00:01<00:00, 1655.23it/s]warmup should be done:  60%|    | 1814/3000 [00:01<00:00, 1641.39it/s]warmup should be done:  61%|   | 1842/3000 [00:01<00:00, 1663.29it/s]warmup should be done:  59%|    | 1783/3000 [00:01<00:00, 1611.16it/s]warmup should be done:  62%|   | 1852/3000 [00:01<00:00, 1665.46it/s]warmup should be done:  65%|   | 1949/3000 [00:01<00:00, 1626.12it/s]warmup should be done:  67%|   | 2004/3000 [00:01<00:00, 1673.09it/s]warmup should be done:  67%|   | 2018/3000 [00:01<00:00, 1679.56it/s]warmup should be done:  66%|   | 1992/3000 [00:01<00:00, 1654.26it/s]warmup should be done:  67%|   | 2009/3000 [00:01<00:00, 1663.46it/s]warmup should be done:  65%|   | 1945/3000 [00:01<00:00, 1612.47it/s]warmup should be done:  66%|   | 1979/3000 [00:01<00:00, 1631.74it/s]warmup should be done:  67%|   | 2019/3000 [00:01<00:00, 1664.15it/s]warmup should be done:  70%|   | 2112/3000 [00:01<00:00, 1618.75it/s]warmup should be done:  72%|  | 2158/3000 [00:01<00:00, 1653.66it/s]warmup should be done:  72%|  | 2172/3000 [00:01<00:00, 1666.56it/s]warmup should be done:  73%|  | 2176/3000 [00:01<00:00, 1662.76it/s]warmup should be done:  70%|   | 2108/3000 [00:01<00:00, 1614.93it/s]warmup should be done:  73%|  | 2186/3000 [00:01<00:00, 1655.53it/s]warmup should be done:  71%|  | 2143/3000 [00:01<00:00, 1621.77it/s]warmup should be done:  73%|  | 2186/3000 [00:01<00:00, 1642.90it/s]warmup should be done:  77%|  | 2324/3000 [00:01<00:00, 1654.90it/s]warmup should be done:  78%|  | 2339/3000 [00:01<00:00, 1662.70it/s]warmup should be done:  76%|  | 2274/3000 [00:01<00:00, 1612.11it/s]warmup should be done:  78%|  | 2343/3000 [00:01<00:00, 1663.42it/s]warmup should be done:  76%|  | 2274/3000 [00:01<00:00, 1625.58it/s]warmup should be done:  77%|  | 2309/3000 [00:01<00:00, 1632.61it/s]warmup should be done:  78%|  | 2352/3000 [00:01<00:00, 1629.85it/s]warmup should be done:  78%|  | 2351/3000 [00:01<00:00, 1620.75it/s]warmup should be done:  83%| | 2491/3000 [00:01<00:00, 1657.01it/s]warmup should be done:  84%| | 2506/3000 [00:01<00:00, 1663.12it/s]warmup should be done:  84%| | 2510/3000 [00:01<00:00, 1663.71it/s]warmup should be done:  81%| | 2438/3000 [00:01<00:00, 1628.72it/s]warmup should be done:  83%| | 2476/3000 [00:01<00:00, 1641.43it/s]warmup should be done:  84%| | 2516/3000 [00:01<00:00, 1613.33it/s]warmup should be done:  84%| | 2514/3000 [00:01<00:00, 1607.17it/s]warmup should be done:  81%|  | 2436/3000 [00:01<00:00, 1515.04it/s]warmup should be done:  89%| | 2657/3000 [00:01<00:00, 1655.65it/s]warmup should be done:  89%| | 2673/3000 [00:01<00:00, 1661.44it/s]warmup should be done:  89%| | 2677/3000 [00:01<00:00, 1663.79it/s]warmup should be done:  87%| | 2602/3000 [00:01<00:00, 1631.77it/s]warmup should be done:  88%| | 2642/3000 [00:01<00:00, 1644.20it/s]warmup should be done:  89%| | 2678/3000 [00:01<00:00, 1600.05it/s]warmup should be done:  89%| | 2675/3000 [00:01<00:00, 1596.07it/s]warmup should be done:  87%| | 2602/3000 [00:01<00:00, 1554.38it/s]warmup should be done:  94%|| 2823/3000 [00:01<00:00, 1656.29it/s]warmup should be done:  92%|| 2767/3000 [00:01<00:00, 1636.16it/s]warmup should be done:  95%|| 2840/3000 [00:01<00:00, 1660.02it/s]warmup should be done:  95%|| 2844/3000 [00:01<00:00, 1663.10it/s]warmup should be done:  94%|| 2808/3000 [00:01<00:00, 1646.44it/s]warmup should be done:  95%|| 2839/3000 [00:01<00:00, 1589.93it/s]warmup should be done:  94%|| 2835/3000 [00:01<00:00, 1586.95it/s]warmup should be done:  92%|| 2769/3000 [00:01<00:00, 1586.83it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1664.45it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1662.48it/s]warmup should be done:  98%|| 2932/3000 [00:01<00:00, 1639.26it/s]warmup should be done: 100%|| 2989/3000 [00:01<00:00, 1577.99it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1643.57it/s]warmup should be done: 100%|| 2996/3000 [00:01<00:00, 1592.77it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1639.52it/s]warmup should be done:  98%|| 2936/3000 [00:01<00:00, 1609.49it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1635.90it/s]warmup should be done:  99%|| 2973/3000 [00:01<00:00, 1538.16it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1620.88it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1619.26it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1605.40it/s]2022-12-12 03:39:33.030036: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4e4b28c310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:39:33.030099: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:39:33.035028: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4e4f8311b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:39:33.035070: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:39:33.051959: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4e4f8346e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:39:33.052026: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:39:33.382642: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f310802a490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:39:33.382703: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:39:33.392920: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4e4b795de0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:39:33.392989: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:39:33.587168: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4e4f15d220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:39:33.587245: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:39:33.595623: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4e4f82c510 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:39:33.595690: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:39:33.629701: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f3140030ec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 03:39:33.629780: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 03:39:35.298082: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:39:35.325906: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:39:35.389554: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:39:35.623368: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:39:35.666124: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:39:35.887080: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:39:35.920564: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:39:35.949331: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 03:39:38.191343: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:39:38.205153: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:39:38.289842: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:39:38.463477: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:39:38.576969: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:39:38.777246: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:39:38.893287: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 03:39:38.960846: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][03:40:04.767][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][03:40:04.767][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:40:04.776][ERROR][RK0][main]: coll ps creation done
[HCTR][03:40:04.776][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][03:40:04.851][ERROR][RK0][main]: replica 0 reaches 1000, calling init pre replica
[HCTR][03:40:04.851][ERROR][RK0][main]: replica 2 reaches 1000, calling init pre replica
[HCTR][03:40:04.851][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:40:04.851][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:40:04.856][ERROR][RK0][main]: coll ps creation done
[HCTR][03:40:04.856][ERROR][RK0][main]: replica 2 waits for coll ps creation barrier
[HCTR][03:40:04.860][ERROR][RK0][main]: coll ps creation done
[HCTR][03:40:04.860][ERROR][RK0][main]: replica 0 waits for coll ps creation barrier
[HCTR][03:40:04.867][ERROR][RK0][tid #139974821259008]: replica 5 reaches 1000, calling init pre replica
[HCTR][03:40:04.867][ERROR][RK0][tid #139974821259008]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:40:04.868][ERROR][RK0][main]: replica 1 reaches 1000, calling init pre replica
[HCTR][03:40:04.868][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:40:04.875][ERROR][RK0][tid #139974821259008]: coll ps creation done
[HCTR][03:40:04.875][ERROR][RK0][tid #139974821259008]: replica 5 waits for coll ps creation barrier
[HCTR][03:40:04.876][ERROR][RK0][main]: coll ps creation done
[HCTR][03:40:04.876][ERROR][RK0][main]: replica 1 waits for coll ps creation barrier
[HCTR][03:40:04.933][ERROR][RK0][main]: replica 4 reaches 1000, calling init pre replica
[HCTR][03:40:04.933][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:40:04.941][ERROR][RK0][main]: coll ps creation done
[HCTR][03:40:04.941][ERROR][RK0][main]: replica 4 waits for coll ps creation barrier
[HCTR][03:40:04.984][ERROR][RK0][tid #139975014192896]: replica 7 reaches 1000, calling init pre replica
[HCTR][03:40:04.984][ERROR][RK0][tid #139975014192896]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:40:04.989][ERROR][RK0][tid #139975089694464]: replica 6 reaches 1000, calling init pre replica
[HCTR][03:40:04.989][ERROR][RK0][tid #139975089694464]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][03:40:04.990][ERROR][RK0][tid #139975014192896]: coll ps creation done
[HCTR][03:40:04.990][ERROR][RK0][tid #139975014192896]: replica 7 waits for coll ps creation barrier
[HCTR][03:40:04.996][ERROR][RK0][tid #139975089694464]: coll ps creation done
[HCTR][03:40:04.996][ERROR][RK0][tid #139975089694464]: replica 6 waits for coll ps creation barrier
[HCTR][03:40:04.996][ERROR][RK0][main]: replica 0 preparing frequency
[HCTR][03:40:05.823][ERROR][RK0][main]: replica 0 preparing frequency done
[HCTR][03:40:05.863][ERROR][RK0][main]: replica 0 calling init per replica
[HCTR][03:40:05.863][ERROR][RK0][tid #139975014192896]: replica 7 calling init per replica
[HCTR][03:40:05.863][ERROR][RK0][main]: replica 1 calling init per replica
[HCTR][03:40:05.863][ERROR][RK0][tid #139974821259008]: replica 5 calling init per replica
[HCTR][03:40:05.863][ERROR][RK0][main]: replica 4 calling init per replica
[HCTR][03:40:05.863][ERROR][RK0][main]: replica 2 calling init per replica
[HCTR][03:40:05.863][ERROR][RK0][tid #139975089694464]: replica 6 calling init per replica
[HCTR][03:40:05.863][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][03:40:05.863][ERROR][RK0][main]: Calling build_v2
[HCTR][03:40:05.863][ERROR][RK0][tid #139975014192896]: Calling build_v2
[HCTR][03:40:05.863][ERROR][RK0][main]: Calling build_v2
[HCTR][03:40:05.863][ERROR][RK0][tid #139974821259008]: Calling build_v2
[HCTR][03:40:05.863][ERROR][RK0][main]: Calling build_v2
[HCTR][03:40:05.863][ERROR][RK0][main]: Calling build_v2
[HCTR][03:40:05.863][ERROR][RK0][tid #139975089694464]: Calling build_v2
[HCTR][03:40:05.863][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:40:05.863][ERROR][RK0][main]: Calling build_v2
[HCTR][03:40:05.863][ERROR][RK0][tid #139975014192896]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:40:05.863][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:40:05.863][ERROR][RK0][tid #139974821259008]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:40:05.863][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:40:05.863][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:40:05.863][ERROR][RK0][tid #139975089694464]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][03:40:05.863][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[2022-12-12 03:40:05.867729: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[[2022-12-12 03:40:052022-12-12 03:40:05..867808867778: : EE[  /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:2022-12-12 03:40:05:196.178[] 867822] assigning 0 to cpu: 2022-12-12 03:40:05v100x8, slow pcie
E.
[ 867866/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: [:E2022-12-12 03:40:052022-12-12 03:40:05178 ..] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc867911867936v100x8, slow pcie:: : [
178EE[2022-12-12 03:40:05]   [.v100x8, slow pcie/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 03:40:05867968
:[:2022-12-12 03:40:05.: 178196[.2022-12-12 03:40:05867991E] ] 2022-12-12 03:40:05[867962.:  v100x8, slow pcieassigning 0 to cpu.: 868010E2022-12-12 03:40:05/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc

868041E:  .:: [ E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc868054212E2022-12-12 03:40:05/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc :: ] [ .:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc196Ebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 82022-12-12 03:40:05/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc868141178:]  
.:: ] 178assigning 0 to cpu/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc868179196Ev100x8, slow pcie] 
[:: ]  
v100x8, slow pcie2022-12-12 03:40:05178Eassigning 0 to cpu/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[
.[]  
:2022-12-12 03:40:058682672022-12-12 03:40:05[v100x8, slow pcie/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc196.: .2022-12-12 03:40:05
:] 868311E868315[.212assigning 0 to cpu: [ : 2022-12-12 03:40:05868336] 
E2022-12-12 03:40:05/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE.: build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8 .: 868377E
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc868386213/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[: [ :: ] :2022-12-12 03:40:05E2022-12-12 03:40:05/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc212Eremote time is 8.68421196. .:]  
] 868456/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc868477196build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccassigning 0 to cpu: :[: ] 
:
E2122022-12-12 03:40:05Eassigning 0 to cpu196 ] [. 
] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 82022-12-12 03:40:05[868537/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccassigning 0 to cpu:
.2022-12-12 03:40:05: :
212868582[.[E213] : 2022-12-12 03:40:058686022022-12-12 03:40:05 ] build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E.: [./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421
 868639E2022-12-12 03:40:05868644:
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:  [.: 214:E[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 03:40:05868683E] 213 2022-12-12 03:40:05:.:  cpu time is 97.0588] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.212868731E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
remote time is 8.68421:868748] :  :
212: build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc213] E[
 :] build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8 2022-12-12 03:40:05/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc212remote time is 8.68421
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.[:] 
:8688752022-12-12 03:40:05[213build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8214[: .2022-12-12 03:40:05] 
] 2022-12-12 03:40:05E868911.remote time is 8.68421cpu time is 97.0588. [: 868929

868941/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 03:40:05E: : :[. EE2142022-12-12 03:40:05868982/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc  ] .: :/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cccpu time is 97.0588869012E213::
:  ] 213214E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421] ]  :
remote time is 8.68421cpu time is 97.0588/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc213

:[] 214[2022-12-12 03:40:05remote time is 8.68421] 2022-12-12 03:40:05.
cpu time is 97.0588.869139
869150[: : 2022-12-12 03:40:05EE.  869186/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: ::E214214 ] ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cccpu time is 97.0588cpu time is 97.0588:

214] cpu time is 97.0588
[2022-12-12 03:41:25. 50180: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-12 03:41:25. 90085: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-12 03:41:25. 90160: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 15000000
[2022-12-12 03:41:25.212760: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-12 03:41:25.212850: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-12 03:41:25.212883: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-12 03:41:25.212914: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-12 03:41:25.213355: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.214243: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.214901: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.228087: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 2 solved
[2022-12-12 03:41:25.228155: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 2 initing device 2
[2022-12-12 03:41:25.228517[: 2022-12-12 03:41:25E[.2022-12-12 03:41:25 228536.[[/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc: 2285492022-12-12 03:41:25:2022-12-12 03:41:25E: .202. E228577] 228566/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc : 5 solved: :/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.ccE
E202:  ] [202/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc4 solved2022-12-12 03:41:25] ::
.19807 solved202228657] [
] : 3 solvedeager alloc mem 381.47 MB2022-12-12 03:41:25E
[
. 2022-12-12 03:41:25228692[/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc.: 2022-12-12 03:41:25:228709E.205:  228724] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc: worker 0 thread 5 initing device 5 :E
/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc205 :] /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc205worker 0 thread 4 initing device 4:] 
205worker 0 thread 7 initing device 7] 
worker 0 thread 3 initing device 3
[2022-12-12 03:41:25.229160: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 381.47 MB[2022-12-12 03:41:25
2022-12-12 03:41:25..229181229183: [: E2022-12-12 03:41:25E . /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu229200/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:: :1980E1980]  ] eager alloc mem 381.47 MB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 381.47 MB
:
1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.231279: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202[] 2022-12-12 03:41:256 solved.
231300: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc2022-12-12 03:41:25:.202231360] : 1 solvedE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] [worker 0 thread 6 initing device 62022-12-12 03:41:25
.231414: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 1 initing device 1
[2022-12-12 03:41:25.231727: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.231795: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.231846: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.232096: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.232144: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.232635: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.233734: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.236383: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.236522: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.236593: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.236680: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.236730: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.236780: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.237702: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.240731: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.240845: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 03:41:25.294694: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 03:41:25.295090: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 03:41:25.300652: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 03:41:25.300757: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 03:41:25.300807: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:41:25.301746: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:41:25.303457: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:25.304526: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:25.304614: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:41:25.305290: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:41:25.305334: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[[[[[[2022-12-12 03:41:252022-12-12 03:41:252022-12-12 03:41:252022-12-12 03:41:252022-12-12 03:41:252022-12-12 03:41:25..322326....322326: 322326322326322326322326: E: : : : E EEEE /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu    /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980::::1980] 1980198019801980] eager alloc mem 2.00 Bytes] ] ] ] eager alloc mem 2.00 Bytes
eager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes




[[[2022-12-12 03:41:252022-12-12 03:41:252022-12-12 03:41:25.[.[.[3228102022-12-12 03:41:253228102022-12-12 03:41:253228122022-12-12 03:41:25: .: .: .E322821E322823E322825 :  :  : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: : : 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :] :] :eager alloc mem 1024.00 Bytes1980eager alloc mem 1024.00 Bytes1980eager alloc mem 1024.00 Bytes1980
] 
] 
] eager alloc mem 1024.00 Byteseager alloc mem 1024.00 Byteseager alloc mem 1024.00 Bytes


[2022-12-12 03:41:25.327824: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 03:41:25.328157: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 03:41:25.329490: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[[2022-12-12 03:41:252022-12-12 03:41:25..329552329571: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 1024eager release cuda mem 2

[[2022-12-12 03:41:252022-12-12 03:41:25..329642[329644: 2022-12-12 03:41:25: E.E 329640 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:E:638 638] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] eager release cuda mem 2:eager release cuda mem 400000000
638
] eager release cuda mem 1024
[2022-12-12 03:41:25.329733: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 03:41:25eager release cuda mem 400000000.
329749: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 03:41:25.329775[: 2022-12-12 03:41:25E. 329800/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 1024:
638] eager release cuda mem 400000000
[2022-12-12 03:41:25.329862: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 22022-12-12 03:41:25
.329868: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 03:41:25.329927: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:41:25.329956: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 03:41:25] .eager release cuda mem 2329958
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 03:41:25.330013: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:41:25.330037: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 03:41:25.330083: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:41:25.331017: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:41:25.331750: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:41:25.332254: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:41:25.333342: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:41:25.334053: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:41:25.334719: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 57.60 MB
[2022-12-12 03:41:25.335829: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:25.336074: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:25.336100: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:25.336345: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:25.336402: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:25.336429: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:25.336845: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:25.336928: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:41:25.336943: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 03:41:25.337013: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 03:41:25.337054: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 03:41:25.337086: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:25.337127: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:25.337171: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:41:25.337217: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:41:25.337358: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:25.337418: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 6256632022-12-12 03:41:25
.337439: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 03:41:25:.1980337455] : eager alloc mem 25.25 KBE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:25.337502: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:41:25.337558: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:41:25.337597: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:41:25.337639: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[2022-12-12 03:41:25.337845: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[[2022-12-12 03:41:252022-12-12 03:41:25..337885337886: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::1980638] ] eager alloc mem 7.15 GBeager release cuda mem 25855

[2022-12-12 03:41:25.337950: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[2022-12-12 03:41:25.338104: E[ 2022-12-12 03:41:25/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.:3381211980: ] Eeager alloc mem 57.60 MB 
[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 03:41:25:.638338168] : eager release cuda mem 25855E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:41:25.338220: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[2022-12-12 03:41:25:2022-12-12 03:41:25.1980.338231] 338233: eager alloc mem 7.15 GB: E
E  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::1980638] ] eager alloc mem 7.15 GBeager release cuda mem 25855

[2022-12-12 03:41:25.338311: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[2022-12-12 03:41:25.396325: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:25.397295: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:25.397378: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 03:41:25.397932: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 03:41:25.397970: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 7.15 GB
[[[[[[[[2022-12-12 03:41:262022-12-12 03:41:262022-12-12 03:41:262022-12-12 03:41:262022-12-12 03:41:262022-12-12 03:41:262022-12-12 03:41:262022-12-12 03:41:26........845824845824845824845824845824845824845824845824: : : : : : : : EEEEEEEE        /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::::::19801980198019801980198019801980] ] ] eager alloc mem 611.00 KB] ] ] ] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KB
eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB






[2022-12-12 03:41:26.[[8469512022-12-12 03:41:26[2022-12-12 03:41:26: [[.2022-12-12 03:41:26[.[E2022-12-12 03:41:262022-12-12 03:41:26846956.2022-12-12 03:41:268469572022-12-12 03:41:26 ..: 846961.: ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc846963846964E: 846964E846971:: :  E:  : 638EE/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE]   :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc : eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
::] 638:] :638638eager release cuda mem 625663] 638eager release cuda mem 625663638] ] 
eager release cuda mem 625663] 
] eager release cuda mem 625663eager release cuda mem 625663
eager release cuda mem 625663eager release cuda mem 625663[



2022-12-12 03:41:26.847224: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 03:41:26eager alloc mem 611.00 KB.
847264[: 2022-12-12 03:41:26E. [847277/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 03:41:26[: [:.2022-12-12 03:41:26E2022-12-12 03:41:26[1980847287[. .2022-12-12 03:41:26] : 2022-12-12 03:41:26847298/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu847295.eager alloc mem 611.00 KBE.: :: 847304
 847310E1980E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:  ]  E:E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 1980 :
:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu19801980:eager alloc mem 611.00 KB:] ] 1980
1980eager alloc mem 611.00 KBeager alloc mem 611.00 KB] ] 

eager alloc mem 611.00 KBeager alloc mem 611.00 KB

[2022-12-12 03:41:26.848008: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.848077: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.848104: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.848162: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 03:41:26] .eager release cuda mem 625663848178
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 03:41:261980.] 848199[eager alloc mem 611.00 KB: 2022-12-12 03:41:26[
E.2022-12-12 03:41:26 848210.[[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: 848216[2022-12-12 03:41:262022-12-12 03:41:26:E: 2022-12-12 03:41:26..638 E.848236848230] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc 848241: : eager release cuda mem 625663:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: EE
638:E  ] 638 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::
eager release cuda mem 625663:638638
[1980] ] 2022-12-12 03:41:26] eager release cuda mem 625663eager release cuda mem 625663.eager alloc mem 611.00 KB

848378
[: 2022-12-12 03:41:26E[. 2022-12-12 03:41:26848420/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.: :848435E1980:  ] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 611.00 KB :[[
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu19802022-12-12 03:41:262022-12-12 03:41:26:] ..1980eager alloc mem 611.00 KB848469848470] 
: : eager alloc mem 611.00 KBEE
  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KB

[2022-12-12 03:41:26.848825: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.848893: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.848951: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.849016: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.849156: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.849213: [E2022-12-12 03:41:26 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc849224:: 638E]  eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
:1980[] 2022-12-12 03:41:26eager alloc mem 611.00 KB.
849255: E[ 2022-12-12 03:41:26/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:849273638: ] Eeager release cuda mem 625663 [
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 03:41:26:.638849297] : eager release cuda mem 625663E
 [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 03:41:26[:.2022-12-12 03:41:261980849321[.] : 2022-12-12 03:41:26849326eager alloc mem 611.00 KBE[.: 
 2022-12-12 03:41:26849346E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:  :849366E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:  :] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638eager release cuda mem 625663 :] 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980eager release cuda mem 625663:] 
1980eager alloc mem 611.00 KB] 
eager alloc mem 611.00 KB
[2022-12-12 03:41:26.849506: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.849526: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.849653: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.849722: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.849764: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.849830: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.849992: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.850058: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.850115: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.850185: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[[2022-12-12 03:41:262022-12-12 03:41:26..850217850219: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] [] eager release cuda mem 6256632022-12-12 03:41:26eager release cuda mem 625663
.
850254: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 03:41:26] .eager release cuda mem 625663850280
: [[E2022-12-12 03:41:262022-12-12 03:41:26 ../hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc850311850315:: : [638EE2022-12-12 03:41:26]   .eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu850353
::: 19801980E] ]  eager alloc mem 611.00 KBeager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu

:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.850448: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 03:41:26eager alloc mem 611.00 KB.
850467: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.850550: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.850575: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.850641: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.850802: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.850868: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.850929: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.850993: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[[2022-12-12 03:41:262022-12-12 03:41:26.[.8511602022-12-12 03:41:26851161: .: E851169E :  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638] :] [eager release cuda mem 625663638eager release cuda mem 6256632022-12-12 03:41:26
] 
.eager release cuda mem 625663851216
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.[8512892022-12-12 03:41:26: [.E2022-12-12 03:41:26[851295 .2022-12-12 03:41:26: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu851301.E[:: 851309 2022-12-12 03:41:261980E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.]  E:851325eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc 1980[: 
:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] 2022-12-12 03:41:26E638:eager alloc mem 611.00 KB. ] 1980
851387/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 625663] : :
eager alloc mem 611.00 KBE1980
 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager alloc mem 611.00 KB:
638] eager release cuda mem 625663
[2022-12-12 03:41:26.851499: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.851538: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.851611: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.851678: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.851737: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.851804: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 03:41:26.852131: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.852161: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[[2022-12-12 03:41:262022-12-12 03:41:26..852194852197: : EE[  [2022-12-12 03:41:26/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 03:41:26.::.[85221463819808522292022-12-12 03:41:26: ] ] : .Eeager release cuda mem 625663eager alloc mem 611.00 KB[E852247 

2022-12-12 03:41:26 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE:852283: 638: 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] [E] :eager release cuda mem 6256632022-12-12 03:41:26 eager alloc mem 611.00 KB638
./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
] 852352:eager release cuda mem 625663: 638
E]  eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
[[:2022-12-12 03:41:26[2022-12-12 03:41:261980.[2022-12-12 03:41:26.] 8524232022-12-12 03:41:26.852424eager alloc mem 611.00 KB: .852432: 
E852442: E : E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] :[1980] eager release cuda mem 604000006382022-12-12 03:41:26] eager release cuda mem 625663
] .eager alloc mem 611.00 KB
eager release cuda mem 60400000852553

: [E2022-12-12 03:41:26 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc852612:: 638E]  eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 60400000
[2022-12-12 03:41:26.852656: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 60400000
[2022-12-12 03:41:26.853032: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.853067: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 60400000
[2022-12-12 03:41:26.853122: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.853163: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 60400000
[2022-12-12 03:41:26.853224: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.853260: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 60400000
[2022-12-12 03:41:26.853335: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 03:41:26.853373: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 60400000
[2022-12-12 03:41:26.853744: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.64039 secs 
[2022-12-12 03:41:26.853884: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62209 secs 
[2022-12-12 03:41:26.854079: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62551 secs 
[2022-12-12 03:41:26.854281: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62511 secs 
[2022-12-12 03:41:26.855279: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.6261 secs 
[2022-12-12 03:41:26.855420: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62623 secs 
[2022-12-12 03:41:26.855558: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.6264 secs 
[2022-12-12 03:41:26.855711: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 15000000 / 100000000 nodes ( 15.00 %~15.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 85000000 / 100000000 nodes ( 85.00 %) | 7.15 GB | 1.62387 secs 
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier
[HCTR][03:41:26.855][ERROR][RK0][tid #139975089694464]: replica 6 calling init per replica done, doing barrier
[HCTR][03:41:26.855][ERROR][RK0][tid #139975014192896]: replica 7 calling init per replica done, doing barrier
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][03:41:26.855][ERROR][RK0][tid #139974821259008]: replica 5 calling init per replica done, doing barrier
[HCTR][03:41:26.855][ERROR][RK0][tid #139974821259008]: replica 5 calling init per replica done, doing barrier done
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier done
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier done
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier done
[HCTR][03:41:26.855][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier done
[HCTR][03:41:26.855][ERROR][RK0][tid #139975014192896]: replica 7 calling init per replica done, doing barrier done
[HCTR][03:41:26.855][ERROR][RK0][tid #139975089694464]: replica 6 calling init per replica done, doing barrier done
[HCTR][03:41:26.855][ERROR][RK0][tid #139974821259008]: init per replica done
[HCTR][03:41:26.855][ERROR][RK0][main]: init per replica done
[HCTR][03:41:26.855][ERROR][RK0][main]: init per replica done
[HCTR][03:41:26.855][ERROR][RK0][main]: init per replica done
[HCTR][03:41:26.855][ERROR][RK0][main]: init per replica done
[HCTR][03:41:26.855][ERROR][RK0][tid #139975014192896]: init per replica done
[HCTR][03:41:26.855][ERROR][RK0][tid #139975089694464]: init per replica done
[HCTR][03:41:26.858][ERROR][RK0][main]: init per replica done








