2022-12-12 06:59:35.026947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.033986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.038320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.044058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.056176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.062918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.066836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.075256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.134542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.140230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.146111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.149184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.158179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.162785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.164997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.173474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.185125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.188260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.189935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.190892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.191099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.192590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.192607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.194058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.194220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.195564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.195953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.197259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.197583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.199119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.199692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.200525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.201221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.202271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.202862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.204350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.205377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.206424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.207395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.208316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.213696: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 06:59:35.219691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.220853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.222022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.223536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.223616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.225723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.225834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.225920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.229031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.229399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.229404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.229403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.233177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.233242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.233311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.233547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.237092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.237214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.237411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.237729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.238459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.241011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.241083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.241342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.242199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.244472: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.244570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.244847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.245809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.246889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.247652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.247746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.248018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.249060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.250188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.250577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.251410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.251557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.251985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.253275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.254168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.254843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.255653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.256180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.257141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.257580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.258488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.259494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.260363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.260418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.261277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.262814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.262889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.263259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.277519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.278027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.278926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.279323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.280641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.286635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.301316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.304197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.308339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.317853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.318334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.318377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.318475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.318522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.321119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.321946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.322218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.322282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.322411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.323122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.325447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.326281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.326524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.326622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.326786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.328536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.330069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.330764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.331034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.331494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.331565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.332533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.333832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.335214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.335483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.335589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.335756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.336570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.338146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.339544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.339783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.339873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.340068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.340754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.342393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.343510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.343602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.343784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.344061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.344839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.346340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.347505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.347539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.347774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.347862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.348668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.351100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.351196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.351211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.351408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.351510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.352114: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.355237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.355403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.355466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.355926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.356358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.357245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.360169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.360353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.360351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.360647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.360830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.360913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.361340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.365460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.365577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.365620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.365780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.365920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.366160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.366458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.369940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.369977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.370106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.370402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.370547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.370904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.371265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.374990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.375172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.375268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.375271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.375526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.375816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.376137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.379609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.379645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.379869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.379928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.380166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.380565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.380747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.385128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.385670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.385671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.385870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.386058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.386196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.387088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.390888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.391032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.391125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.391173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.391315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.391840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.394764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.394870: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 06:59:35.394921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.394964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.394966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.395737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.396451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.398458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.398794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.398841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.398897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.399660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.400486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.402433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.402742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.402920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.402941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.404104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.404579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.405083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.408496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.408805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.409101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.409193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.409904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.410522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.410867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.413419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.413624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.413870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.413953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.414573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.415022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.415351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.417958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.418174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.418556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.418701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.419063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.419807: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.422880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.424208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.426345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.426939: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 06:59:35.426940: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 06:59:35.427114: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 06:59:35.427116: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 06:59:35.428204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.429604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.432622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.434429: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 06:59:35.434610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.437014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.437295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.437347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.437406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.437778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.441719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.441791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.441837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.441920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.442131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.444054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.445825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.445873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.445980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.446144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.446385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.448402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.450833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.483973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.486428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.491557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.530080: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 06:59:35.539710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.545915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:35.551014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.589483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.590095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.591111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.591621: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 06:59:36.591678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 06:59:36.609936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.610579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.611082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.611872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.612403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.612879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 06:59:36.659900: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.660106: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.692468: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-12 06:59:36.839922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.840544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.841067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.842100: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 06:59:36.842156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 06:59:36.860406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.861030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.861547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.862109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.862857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.863673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 06:59:36.912438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.913080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.913255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.914233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.914363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.915439: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 06:59:36.915502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 06:59:36.915593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.916258: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 06:59:36.916316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 06:59:36.920781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.921409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.921907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.922189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.922886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.923082: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 06:59:36.923177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 06:59:36.923816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.924304: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 06:59:36.924350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 06:59:36.933213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.933854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.933941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.934897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.934983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.935970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.935976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.936637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.937152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.937512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.938567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.938672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 06:59:36.938952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.939679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.939868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 06:59:36.940249: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 06:59:36.940311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 06:59:36.940953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.941555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.941873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.942208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.942933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.943149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.943818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.944262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.944789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.944888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.945458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 06:59:36.946135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.946311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.946963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 06:59:36.947248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.947862: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 06:59:36.947939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 06:59:36.949147: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.949305: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.951198: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-12 06:59:36.957808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.958451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.959002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.959608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.960118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.960591: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 06:59:36.965993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.966640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.967157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.967770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.968346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 06:59:36.968822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 06:59:36.985382: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.985600: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.987730: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-12 06:59:36.991265: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.991463: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.992803: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.992943: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:36.993497: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-12 06:59:36.994668: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-12 06:59:37.006970: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:37.007160: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:37.009033: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-12 06:59:37.015477: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:37.015620: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:37.017468: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-12 06:59:37.070755: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:37.070964: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 06:59:37.072888: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
[HCTR][06:59:38.344][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][06:59:38.344][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][06:59:38.345][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][06:59:38.345][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][06:59:38.345][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][06:59:38.345][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][06:59:38.345][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][06:59:38.346][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:01,  1.56s/it]warmup run: 93it [00:01, 77.68it/s]warmup run: 1it [00:01,  1.52s/it]warmup run: 1it [00:01,  1.52s/it]warmup run: 1it [00:01,  1.51s/it]warmup run: 190it [00:01, 172.96it/s]warmup run: 1it [00:01,  1.54s/it]warmup run: 100it [00:01, 85.48it/s]warmup run: 93it [00:01, 79.61it/s]warmup run: 100it [00:01, 85.97it/s]warmup run: 290it [00:01, 282.16it/s]warmup run: 1it [00:01,  1.49s/it]warmup run: 98it [00:01, 82.70it/s]warmup run: 1it [00:01,  1.48s/it]warmup run: 1it [00:01,  1.47s/it]warmup run: 201it [00:01, 186.27it/s]warmup run: 187it [00:01, 173.53it/s]warmup run: 201it [00:01, 187.11it/s]warmup run: 391it [00:01, 397.42it/s]warmup run: 99it [00:01, 86.27it/s]warmup run: 197it [00:01, 180.51it/s]warmup run: 91it [00:01, 79.58it/s]warmup run: 101it [00:01, 89.07it/s]warmup run: 301it [00:01, 295.93it/s]warmup run: 280it [00:01, 275.31it/s]warmup run: 299it [00:01, 294.09it/s]warmup run: 489it [00:02, 504.19it/s]warmup run: 198it [00:01, 186.51it/s]warmup run: 297it [00:01, 289.75it/s]warmup run: 189it [00:01, 179.78it/s]warmup run: 200it [00:01, 189.94it/s]warmup run: 402it [00:01, 410.90it/s]warmup run: 373it [00:01, 380.64it/s]warmup run: 397it [00:01, 404.60it/s]warmup run: 587it [00:02, 603.28it/s]warmup run: 299it [00:01, 298.80it/s]warmup run: 397it [00:01, 402.98it/s]warmup run: 286it [00:01, 288.18it/s]warmup run: 295it [00:01, 294.77it/s]warmup run: 503it [00:02, 522.17it/s]warmup run: 467it [00:02, 484.98it/s]warmup run: 494it [00:02, 510.38it/s]warmup run: 686it [00:02, 690.69it/s]warmup run: 399it [00:01, 413.26it/s]warmup run: 497it [00:02, 513.04it/s]warmup run: 383it [00:01, 399.58it/s]warmup run: 390it [00:01, 402.47it/s]warmup run: 604it [00:02, 624.93it/s]warmup run: 562it [00:02, 582.58it/s]warmup run: 590it [00:02, 605.16it/s]warmup run: 788it [00:02, 771.49it/s]warmup run: 499it [00:01, 524.12it/s]warmup run: 599it [00:02, 619.17it/s]warmup run: 480it [00:01, 507.30it/s]warmup run: 485it [00:01, 506.59it/s]warmup run: 704it [00:02, 711.50it/s]warmup run: 658it [00:02, 669.10it/s]warmup run: 687it [00:02, 689.42it/s]warmup run: 890it [00:02, 835.42it/s]warmup run: 602it [00:02, 630.62it/s]warmup run: 701it [00:02, 710.65it/s]warmup run: 578it [00:02, 607.70it/s]warmup run: 582it [00:02, 605.45it/s]warmup run: 804it [00:02, 782.47it/s]warmup run: 754it [00:02, 739.58it/s]warmup run: 783it [00:02, 754.18it/s]warmup run: 991it [00:02, 881.70it/s]warmup run: 699it [00:02, 707.84it/s]warmup run: 802it [00:02, 784.32it/s]warmup run: 677it [00:02, 695.67it/s]warmup run: 683it [00:02, 699.40it/s]warmup run: 904it [00:02, 839.14it/s]warmup run: 850it [00:02, 794.92it/s]warmup run: 878it [00:02, 776.44it/s]warmup run: 1092it [00:02, 915.71it/s]warmup run: 776it [00:02, 768.59it/s]warmup run: 903it [00:02, 841.14it/s]warmup run: 796it [00:02, 769.62it/s]warmup run: 785it [00:02, 778.14it/s]warmup run: 1005it [00:02, 884.19it/s]warmup run: 946it [00:02, 837.17it/s]warmup run: 977it [00:02, 832.16it/s]warmup run: 1194it [00:02, 945.35it/s]warmup run: 875it [00:02, 825.30it/s]warmup run: 1005it [00:02, 887.55it/s]warmup run: 893it [00:02, 816.37it/s]warmup run: 887it [00:02, 840.20it/s]warmup run: 1108it [00:02, 922.34it/s]warmup run: 1042it [00:02, 869.99it/s]warmup run: 1075it [00:02, 872.66it/s]warmup run: 1295it [00:02, 963.22it/s]warmup run: 973it [00:02, 867.27it/s]warmup run: 1106it [00:02, 920.99it/s]warmup run: 989it [00:02, 887.99it/s]warmup run: 990it [00:02, 855.53it/s]warmup run: 1210it [00:02, 948.98it/s]warmup run: 1139it [00:02, 896.80it/s]warmup run: 1174it [00:02, 904.26it/s]warmup run: 1397it [00:02, 977.74it/s]warmup run: 1074it [00:02, 906.30it/s]warmup run: 1207it [00:02, 944.14it/s]warmup run: 1087it [00:02, 886.16it/s]warmup run: 1091it [00:02, 922.80it/s]warmup run: 1311it [00:02, 952.36it/s]warmup run: 1235it [00:02, 913.48it/s]warmup run: 1272it [00:02, 925.76it/s]warmup run: 1498it [00:03, 985.85it/s]warmup run: 1175it [00:02, 934.41it/s]warmup run: 1308it [00:02, 961.43it/s]warmup run: 1193it [00:02, 949.69it/s]warmup run: 1189it [00:02, 921.81it/s]warmup run: 1411it [00:02, 962.01it/s]warmup run: 1331it [00:02, 922.41it/s]warmup run: 1370it [00:02, 941.43it/s]warmup run: 1600it [00:03, 994.81it/s]warmup run: 1275it [00:02, 952.34it/s]warmup run: 1410it [00:02, 976.57it/s]warmup run: 1287it [00:02, 938.10it/s]warmup run: 1294it [00:02, 965.18it/s]warmup run: 1513it [00:03, 976.50it/s]warmup run: 1427it [00:03, 932.27it/s]warmup run: 1470it [00:03, 956.21it/s]warmup run: 1701it [00:03, 996.31it/s]warmup run: 1377it [00:02, 971.73it/s]warmup run: 1512it [00:03, 988.32it/s]warmup run: 1385it [00:02, 949.77it/s]warmup run: 1397it [00:02, 982.62it/s]warmup run: 1615it [00:03, 989.24it/s]warmup run: 1523it [00:03, 936.20it/s]warmup run: 1570it [00:03, 966.69it/s]warmup run: 1802it [00:03, 995.37it/s]warmup run: 1480it [00:02, 987.05it/s]warmup run: 1613it [00:03, 992.79it/s]warmup run: 1484it [00:03, 960.58it/s]warmup run: 1498it [00:02, 989.68it/s]warmup run: 1717it [00:03, 996.98it/s]warmup run: 1618it [00:03, 939.47it/s]warmup run: 1672it [00:03, 979.92it/s]warmup run: 1903it [00:03, 998.17it/s]warmup run: 1714it [00:03, 997.47it/s]warmup run: 1581it [00:03, 988.61it/s]warmup run: 1586it [00:03, 976.49it/s]warmup run: 1599it [00:03, 987.49it/s]warmup run: 1819it [00:03, 1001.80it/s]warmup run: 1721it [00:03, 965.32it/s]warmup run: 1773it [00:03, 987.95it/s]warmup run: 1816it [00:03, 1003.16it/s]warmup run: 1683it [00:03, 995.80it/s]warmup run: 2004it [00:03, 979.98it/s]warmup run: 1690it [00:03, 992.81it/s]warmup run: 1700it [00:03, 984.48it/s]warmup run: 1921it [00:03, 1005.84it/s]warmup run: 1825it [00:03, 985.36it/s]warmup run: 1874it [00:03, 993.41it/s]warmup run: 1918it [00:03, 1004.42it/s]warmup run: 1786it [00:03, 1003.08it/s]warmup run: 2126it [00:03, 1047.95it/s]warmup run: 1791it [00:03, 991.41it/s]warmup run: 1800it [00:03, 981.22it/s]warmup run: 2026it [00:03, 1017.93it/s]warmup run: 1927it [00:03, 994.70it/s]warmup run: 1974it [00:03, 994.83it/s]warmup run: 2022it [00:03, 1013.66it/s]warmup run: 1889it [00:03, 1009.97it/s]warmup run: 2248it [00:03, 1097.43it/s]warmup run: 1891it [00:03, 981.77it/s]warmup run: 2144it [00:03, 1064.37it/s]warmup run: 2036it [00:03, 1021.95it/s]warmup run: 1899it [00:03, 969.64it/s]warmup run: 2090it [00:03, 1041.71it/s]warmup run: 2138it [00:03, 1055.32it/s]warmup run: 1992it [00:03, 1013.74it/s]warmup run: 2370it [00:03, 1133.00it/s]warmup run: 1990it [00:03, 982.39it/s]warmup run: 2261it [00:03, 1093.82it/s]warmup run: 2158it [00:03, 1079.21it/s]warmup run: 1997it [00:03, 963.34it/s]warmup run: 2211it [00:03, 1090.56it/s]warmup run: 2252it [00:03, 1079.92it/s]warmup run: 2109it [00:03, 1058.80it/s]warmup run: 2493it [00:03, 1159.19it/s]warmup run: 2108it [00:03, 1038.33it/s]warmup run: 2382it [00:03, 1127.47it/s]warmup run: 2279it [00:03, 1116.93it/s]warmup run: 2116it [00:03, 1027.89it/s]warmup run: 2325it [00:03, 1102.91it/s]warmup run: 2366it [00:03, 1095.59it/s]warmup run: 2228it [00:03, 1096.47it/s]warmup run: 2615it [00:04, 1176.83it/s]warmup run: 2232it [00:03, 1095.93it/s]warmup run: 2503it [00:03, 1151.68it/s]warmup run: 2398it [00:03, 1136.67it/s]warmup run: 2236it [00:03, 1078.34it/s]warmup run: 2445it [00:03, 1131.30it/s]warmup run: 2480it [00:03, 1108.66it/s]warmup run: 2347it [00:03, 1123.36it/s]warmup run: 2737it [00:04, 1188.85it/s]warmup run: 2356it [00:03, 1136.34it/s]warmup run: 2625it [00:04, 1169.69it/s]warmup run: 2519it [00:04, 1157.94it/s]warmup run: 2356it [00:03, 1113.84it/s]warmup run: 2565it [00:04, 1150.11it/s]warmup run: 2593it [00:04, 1113.26it/s]warmup run: 2465it [00:03, 1139.49it/s]warmup run: 2858it [00:04, 1192.63it/s]warmup run: 2480it [00:03, 1165.52it/s]warmup run: 2747it [00:04, 1183.26it/s]warmup run: 2639it [00:04, 1167.98it/s]warmup run: 2477it [00:03, 1139.79it/s]warmup run: 2684it [00:04, 1159.35it/s]warmup run: 2708it [00:04, 1121.62it/s]warmup run: 2584it [00:03, 1152.09it/s]warmup run: 2981it [00:04, 1200.92it/s]warmup run: 2604it [00:04, 1185.27it/s]warmup run: 2867it [00:04, 1187.39it/s]warmup run: 2759it [00:04, 1175.03it/s]warmup run: 2597it [00:03, 1156.94it/s]warmup run: 3000it [00:04, 680.85it/s] warmup run: 2803it [00:04, 1165.74it/s]warmup run: 2822it [00:04, 1125.74it/s]warmup run: 2704it [00:04, 1164.38it/s]warmup run: 2728it [00:04, 1199.96it/s]warmup run: 2988it [00:04, 1193.58it/s]warmup run: 2877it [00:04, 1174.19it/s]warmup run: 2717it [00:04, 1169.07it/s]warmup run: 3000it [00:04, 688.41it/s] warmup run: 2923it [00:04, 1173.17it/s]warmup run: 2823it [00:04, 1170.64it/s]warmup run: 2850it [00:04, 1203.78it/s]warmup run: 3000it [00:04, 680.08it/s] warmup run: 2997it [00:04, 1180.61it/s]warmup run: 2835it [00:04, 1171.99it/s]warmup run: 2935it [00:04, 1060.56it/s]warmup run: 3000it [00:04, 674.29it/s] warmup run: 3000it [00:04, 674.51it/s] warmup run: 2942it [00:04, 1175.18it/s]warmup run: 2974it [00:04, 1212.63it/s]warmup run: 2955it [00:04, 1180.28it/s]warmup run: 3000it [00:04, 690.67it/s] warmup run: 3000it [00:04, 689.05it/s] warmup run: 3000it [00:04, 690.69it/s] 
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]





warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|▌         | 157/3000 [00:00<00:01, 1569.10it/s]warmup should be done:   6%|▌         | 168/3000 [00:00<00:01, 1678.39it/s]warmup should be done:   5%|▌         | 162/3000 [00:00<00:01, 1615.59it/s]warmup should be done:   5%|▌         | 160/3000 [00:00<00:01, 1593.70it/s]warmup should be done:   6%|▌         | 167/3000 [00:00<00:01, 1664.77it/s]warmup should be done:   6%|▌         | 168/3000 [00:00<00:01, 1672.15it/s]warmup should be done:   6%|▌         | 165/3000 [00:00<00:01, 1643.16it/s]warmup should be done:   5%|▌         | 162/3000 [00:00<00:01, 1610.49it/s]warmup should be done:  11%|█         | 317/3000 [00:00<00:01, 1585.87it/s]warmup should be done:  11%|█         | 334/3000 [00:00<00:01, 1667.68it/s]warmup should be done:  11%|█         | 324/3000 [00:00<00:01, 1615.46it/s]warmup should be done:  11%|█         | 324/3000 [00:00<00:01, 1620.05it/s]warmup should be done:  11%|█         | 336/3000 [00:00<00:01, 1673.97it/s]warmup should be done:  11%|█         | 332/3000 [00:00<00:01, 1655.82it/s]warmup should be done:  11%|█         | 336/3000 [00:00<00:01, 1671.52it/s]warmup should be done:  11%|█         | 326/3000 [00:00<00:01, 1624.04it/s]warmup should be done:  16%|█▌        | 487/3000 [00:00<00:01, 1623.98it/s]warmup should be done:  16%|█▌        | 477/3000 [00:00<00:01, 1588.51it/s]warmup should be done:  17%|█▋        | 498/3000 [00:00<00:01, 1655.37it/s]warmup should be done:  16%|█▋        | 489/3000 [00:00<00:01, 1623.78it/s]warmup should be done:  17%|█▋        | 504/3000 [00:00<00:01, 1671.09it/s]warmup should be done:  16%|█▌        | 486/3000 [00:00<00:01, 1608.78it/s]warmup should be done:  17%|█▋        | 501/3000 [00:00<00:01, 1655.36it/s]warmup should be done:  17%|█▋        | 504/3000 [00:00<00:01, 1662.31it/s]warmup should be done:  22%|██▏       | 650/3000 [00:00<00:01, 1623.54it/s]warmup should be done:  21%|██        | 636/3000 [00:00<00:01, 1586.23it/s]warmup should be done:  22%|██▏       | 652/3000 [00:00<00:01, 1625.98it/s]warmup should be done:  22%|██▏       | 664/3000 [00:00<00:01, 1652.74it/s]warmup should be done:  22%|██▏       | 672/3000 [00:00<00:01, 1667.95it/s]warmup should be done:  22%|██▏       | 647/3000 [00:00<00:01, 1603.03it/s]warmup should be done:  22%|██▏       | 667/3000 [00:00<00:01, 1653.30it/s]warmup should be done:  22%|██▏       | 671/3000 [00:00<00:01, 1659.09it/s]warmup should be done:  27%|██▋       | 813/3000 [00:00<00:01, 1625.26it/s]warmup should be done:  26%|██▋       | 795/3000 [00:00<00:01, 1586.37it/s]warmup should be done:  27%|██▋       | 815/3000 [00:00<00:01, 1626.39it/s]warmup should be done:  28%|██▊       | 839/3000 [00:00<00:01, 1665.86it/s]warmup should be done:  28%|██▊       | 830/3000 [00:00<00:01, 1647.24it/s]warmup should be done:  28%|██▊       | 833/3000 [00:00<00:01, 1652.81it/s]warmup should be done:  27%|██▋       | 808/3000 [00:00<00:01, 1600.95it/s]warmup should be done:  28%|██▊       | 837/3000 [00:00<00:01, 1655.80it/s]warmup should be done:  33%|███▎      | 976/3000 [00:00<00:01, 1625.09it/s]warmup should be done:  33%|███▎      | 978/3000 [00:00<00:01, 1626.57it/s]warmup should be done:  32%|███▏      | 954/3000 [00:00<00:01, 1582.69it/s]warmup should be done:  34%|███▎      | 1006/3000 [00:00<00:01, 1663.94it/s]warmup should be done:  33%|███▎      | 995/3000 [00:00<00:01, 1644.68it/s]warmup should be done:  32%|███▏      | 969/3000 [00:00<00:01, 1598.03it/s]warmup should be done:  33%|███▎      | 999/3000 [00:00<00:01, 1647.36it/s]warmup should be done:  33%|███▎      | 1003/3000 [00:00<00:01, 1652.16it/s]warmup should be done:  38%|███▊      | 1141/3000 [00:00<00:01, 1623.67it/s]warmup should be done:  38%|███▊      | 1139/3000 [00:00<00:01, 1620.43it/s]warmup should be done:  37%|███▋      | 1113/3000 [00:00<00:01, 1577.02it/s]warmup should be done:  39%|███▊      | 1160/3000 [00:00<00:01, 1643.63it/s]warmup should be done:  39%|███▉      | 1173/3000 [00:00<00:01, 1659.59it/s]warmup should be done:  38%|███▊      | 1129/3000 [00:00<00:01, 1592.69it/s]warmup should be done:  39%|███▉      | 1164/3000 [00:00<00:01, 1639.10it/s]warmup should be done:  39%|███▉      | 1169/3000 [00:00<00:01, 1645.83it/s]warmup should be done:  43%|████▎     | 1304/3000 [00:00<00:01, 1624.54it/s]warmup should be done:  43%|████▎     | 1302/3000 [00:00<00:01, 1619.07it/s]warmup should be done:  42%|████▏     | 1271/3000 [00:00<00:01, 1577.28it/s]warmup should be done:  44%|████▍     | 1326/3000 [00:00<00:01, 1645.72it/s]warmup should be done:  45%|████▍     | 1340/3000 [00:00<00:00, 1660.21it/s]warmup should be done:  43%|████▎     | 1289/3000 [00:00<00:01, 1592.23it/s]warmup should be done:  44%|████▍     | 1328/3000 [00:00<00:01, 1635.93it/s]warmup should be done:  44%|████▍     | 1334/3000 [00:00<00:01, 1644.25it/s]warmup should be done:  49%|████▉     | 1467/3000 [00:00<00:00, 1625.16it/s]warmup should be done:  49%|████▉     | 1464/3000 [00:00<00:00, 1618.35it/s]warmup should be done:  48%|████▊     | 1429/3000 [00:00<00:00, 1574.61it/s]warmup should be done:  50%|████▉     | 1491/3000 [00:00<00:00, 1645.19it/s]warmup should be done:  50%|█████     | 1507/3000 [00:00<00:00, 1660.21it/s]warmup should be done:  48%|████▊     | 1449/3000 [00:00<00:00, 1591.57it/s]warmup should be done:  50%|████▉     | 1492/3000 [00:00<00:00, 1633.44it/s]warmup should be done:  50%|████▉     | 1499/3000 [00:00<00:00, 1641.63it/s]warmup should be done:  54%|█████▍    | 1631/3000 [00:01<00:00, 1627.06it/s]warmup should be done:  54%|█████▍    | 1627/3000 [00:01<00:00, 1621.31it/s]warmup should be done:  53%|█████▎    | 1587/3000 [00:01<00:00, 1574.12it/s]warmup should be done:  55%|█████▌    | 1657/3000 [00:01<00:00, 1647.11it/s]warmup should be done:  56%|█████▌    | 1674/3000 [00:01<00:00, 1660.67it/s]warmup should be done:  54%|█████▎    | 1609/3000 [00:01<00:00, 1592.07it/s]warmup should be done:  55%|█████▌    | 1656/3000 [00:01<00:00, 1633.42it/s]warmup should be done:  55%|█████▌    | 1664/3000 [00:01<00:00, 1638.12it/s]warmup should be done:  60%|█████▉    | 1794/3000 [00:01<00:00, 1626.87it/s]warmup should be done:  60%|█████▉    | 1790/3000 [00:01<00:00, 1621.86it/s]warmup should be done:  58%|█████▊    | 1745/3000 [00:01<00:00, 1575.68it/s]warmup should be done:  61%|██████▏   | 1841/3000 [00:01<00:00, 1661.30it/s]warmup should be done:  61%|██████    | 1822/3000 [00:01<00:00, 1643.06it/s]warmup should be done:  59%|█████▉    | 1769/3000 [00:01<00:00, 1592.05it/s]warmup should be done:  61%|██████    | 1821/3000 [00:01<00:00, 1638.30it/s]warmup should be done:  61%|██████    | 1828/3000 [00:01<00:00, 1635.22it/s]warmup should be done:  65%|██████▌   | 1957/3000 [00:01<00:00, 1624.39it/s]warmup should be done:  65%|██████▌   | 1953/3000 [00:01<00:00, 1620.46it/s]warmup should be done:  63%|██████▎   | 1904/3000 [00:01<00:00, 1579.03it/s]warmup should be done:  67%|██████▋   | 2008/3000 [00:01<00:00, 1661.48it/s]warmup should be done:  66%|██████▌   | 1987/3000 [00:01<00:00, 1640.78it/s]warmup should be done:  66%|██████▌   | 1986/3000 [00:01<00:00, 1641.01it/s]warmup should be done:  64%|██████▍   | 1929/3000 [00:01<00:00, 1591.01it/s]warmup should be done:  66%|██████▋   | 1992/3000 [00:01<00:00, 1632.84it/s]warmup should be done:  71%|███████   | 2120/3000 [00:01<00:00, 1622.83it/s]warmup should be done:  71%|███████   | 2116/3000 [00:01<00:00, 1621.05it/s]warmup should be done:  69%|██████▉   | 2063/3000 [00:01<00:00, 1581.66it/s]warmup should be done:  72%|███████▎  | 2175/3000 [00:01<00:00, 1660.39it/s]warmup should be done:  72%|███████▏  | 2151/3000 [00:01<00:00, 1643.47it/s]warmup should be done:  72%|███████▏  | 2152/3000 [00:01<00:00, 1638.94it/s]warmup should be done:  70%|██████▉   | 2089/3000 [00:01<00:00, 1590.16it/s]warmup should be done:  72%|███████▏  | 2156/3000 [00:01<00:00, 1629.84it/s]warmup should be done:  74%|███████▍  | 2222/3000 [00:01<00:00, 1583.03it/s]warmup should be done:  76%|███████▌  | 2279/3000 [00:01<00:00, 1621.18it/s]warmup should be done:  76%|███████▌  | 2283/3000 [00:01<00:00, 1620.59it/s]warmup should be done:  77%|███████▋  | 2316/3000 [00:01<00:00, 1645.15it/s]warmup should be done:  77%|███████▋  | 2316/3000 [00:01<00:00, 1638.35it/s]warmup should be done:  78%|███████▊  | 2342/3000 [00:01<00:00, 1658.20it/s]warmup should be done:  75%|███████▍  | 2249/3000 [00:01<00:00, 1589.84it/s]warmup should be done:  77%|███████▋  | 2319/3000 [00:01<00:00, 1629.49it/s]warmup should be done:  79%|███████▉  | 2381/3000 [00:01<00:00, 1582.00it/s]warmup should be done:  81%|████████▏ | 2442/3000 [00:01<00:00, 1620.76it/s]warmup should be done:  83%|████████▎ | 2481/3000 [00:01<00:00, 1643.20it/s]warmup should be done:  84%|████████▎ | 2508/3000 [00:01<00:00, 1657.45it/s]warmup should be done:  83%|████████▎ | 2480/3000 [00:01<00:00, 1634.83it/s]warmup should be done:  80%|████████  | 2408/3000 [00:01<00:00, 1587.53it/s]warmup should be done:  83%|████████▎ | 2482/3000 [00:01<00:00, 1624.60it/s]warmup should be done:  82%|████████▏ | 2446/3000 [00:01<00:00, 1535.70it/s]warmup should be done:  87%|████████▋ | 2605/3000 [00:01<00:00, 1622.69it/s]warmup should be done:  85%|████████▍ | 2541/3000 [00:01<00:00, 1584.77it/s]warmup should be done:  88%|████████▊ | 2646/3000 [00:01<00:00, 1645.04it/s]warmup should be done:  89%|████████▉ | 2674/3000 [00:01<00:00, 1656.72it/s]warmup should be done:  88%|████████▊ | 2644/3000 [00:01<00:00, 1635.00it/s]warmup should be done:  86%|████████▌ | 2568/3000 [00:01<00:00, 1588.40it/s]warmup should be done:  88%|████████▊ | 2645/3000 [00:01<00:00, 1625.45it/s]warmup should be done:  87%|████████▋ | 2602/3000 [00:01<00:00, 1541.08it/s]warmup should be done:  92%|█████████▏| 2768/3000 [00:01<00:00, 1623.01it/s]warmup should be done:  90%|█████████ | 2700/3000 [00:01<00:00, 1585.58it/s]warmup should be done:  94%|█████████▎| 2811/3000 [00:01<00:00, 1644.30it/s]warmup should be done:  95%|█████████▍| 2840/3000 [00:01<00:00, 1656.20it/s]warmup should be done:  94%|█████████▎| 2809/3000 [00:01<00:00, 1636.80it/s]warmup should be done:  91%|█████████ | 2729/3000 [00:01<00:00, 1594.22it/s]warmup should be done:  94%|█████████▎| 2808/3000 [00:01<00:00, 1626.50it/s]warmup should be done:  92%|█████████▏| 2757/3000 [00:01<00:00, 1472.62it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1660.51it/s]warmup should be done:  98%|█████████▊| 2932/3000 [00:01<00:00, 1627.01it/s]warmup should be done:  95%|█████████▌| 2861/3000 [00:01<00:00, 1591.02it/s]warmup should be done:  99%|█████████▉| 2976/3000 [00:01<00:00, 1643.54it/s]warmup should be done:  99%|█████████▉| 2975/3000 [00:01<00:00, 1642.64it/s]warmup should be done:  96%|█████████▋| 2892/3000 [00:01<00:00, 1603.68it/s]warmup should be done:  99%|█████████▉| 2974/3000 [00:01<00:00, 1636.12it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1643.70it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1642.85it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1639.85it/s]warmup should be done:  97%|█████████▋| 2920/3000 [00:01<00:00, 1516.17it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1621.78it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1597.67it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1585.89it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1583.74it/s]






warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|▌         | 169/3000 [00:00<00:01, 1686.45it/s]warmup should be done:   6%|▌         | 166/3000 [00:00<00:01, 1656.42it/s]warmup should be done:   6%|▌         | 169/3000 [00:00<00:01, 1682.91it/s]warmup should be done:   6%|▌         | 169/3000 [00:00<00:01, 1682.63it/s]warmup should be done:   6%|▌         | 169/3000 [00:00<00:01, 1681.81it/s]warmup should be done:   6%|▌         | 165/3000 [00:00<00:01, 1639.89it/s]warmup should be done:   6%|▌         | 167/3000 [00:00<00:01, 1660.04it/s]warmup should be done:   5%|▌         | 164/3000 [00:00<00:01, 1630.12it/s]warmup should be done:  11%|█▏        | 338/3000 [00:00<00:01, 1684.16it/s]warmup should be done:  11%|█         | 332/3000 [00:00<00:01, 1653.91it/s]warmup should be done:  11%|█         | 330/3000 [00:00<00:01, 1647.11it/s]warmup should be done:  11%|█         | 329/3000 [00:00<00:01, 1637.19it/s]warmup should be done:  11%|█▏        | 338/3000 [00:00<00:01, 1681.29it/s]warmup should be done:  11%|█▏        | 338/3000 [00:00<00:01, 1680.61it/s]warmup should be done:  11%|█▏        | 338/3000 [00:00<00:01, 1679.15it/s]warmup should be done:  11%|█         | 334/3000 [00:00<00:01, 1480.52it/s]warmup should be done:  17%|█▋        | 496/3000 [00:00<00:01, 1652.80it/s]warmup should be done:  17%|█▋        | 507/3000 [00:00<00:01, 1684.34it/s]warmup should be done:  16%|█▋        | 494/3000 [00:00<00:01, 1641.33it/s]warmup should be done:  17%|█▋        | 506/3000 [00:00<00:01, 1679.25it/s]warmup should be done:  17%|█▋        | 498/3000 [00:00<00:01, 1650.24it/s]warmup should be done:  17%|█▋        | 507/3000 [00:00<00:01, 1677.59it/s]warmup should be done:  17%|█▋        | 507/3000 [00:00<00:01, 1661.40it/s]warmup should be done:  17%|█▋        | 497/3000 [00:00<00:01, 1541.67it/s]warmup should be done:  22%|██▏       | 665/3000 [00:00<00:01, 1663.83it/s]warmup should be done:  22%|██▏       | 660/3000 [00:00<00:01, 1647.39it/s]warmup should be done:  23%|██▎       | 677/3000 [00:00<00:01, 1686.80it/s]warmup should be done:  22%|██▎       | 675/3000 [00:00<00:01, 1681.17it/s]warmup should be done:  22%|██▏       | 664/3000 [00:00<00:01, 1652.17it/s]warmup should be done:  22%|██▎       | 675/3000 [00:00<00:01, 1677.91it/s]warmup should be done:  23%|██▎       | 676/3000 [00:00<00:01, 1670.22it/s]warmup should be done:  22%|██▏       | 653/3000 [00:00<00:01, 1478.62it/s]warmup should be done:  28%|██▊       | 826/3000 [00:00<00:01, 1651.89it/s]warmup should be done:  28%|██▊       | 846/3000 [00:00<00:01, 1687.57it/s]warmup should be done:  28%|██▊       | 844/3000 [00:00<00:01, 1682.90it/s]warmup should be done:  28%|██▊       | 843/3000 [00:00<00:01, 1676.88it/s]warmup should be done:  28%|██▊       | 831/3000 [00:00<00:01, 1655.17it/s]warmup should be done:  28%|██▊       | 832/3000 [00:00<00:01, 1652.63it/s]warmup should be done:  28%|██▊       | 846/3000 [00:00<00:01, 1680.83it/s]warmup should be done:  27%|██▋       | 802/3000 [00:00<00:01, 1473.55it/s]warmup should be done:  34%|███▍      | 1015/3000 [00:00<00:01, 1685.39it/s]warmup should be done:  34%|███▍      | 1013/3000 [00:00<00:01, 1680.43it/s]warmup should be done:  34%|███▎      | 1011/3000 [00:00<00:01, 1673.77it/s]warmup should be done:  33%|███▎      | 992/3000 [00:00<00:01, 1643.76it/s]warmup should be done:  33%|███▎      | 1000/3000 [00:00<00:01, 1659.16it/s]warmup should be done:  33%|███▎      | 997/3000 [00:00<00:01, 1645.61it/s]warmup should be done:  34%|███▍      | 1015/3000 [00:00<00:01, 1681.50it/s]warmup should be done:  32%|███▏      | 953/3000 [00:00<00:01, 1484.15it/s]warmup should be done:  39%|███▉      | 1184/3000 [00:00<00:01, 1683.15it/s]warmup should be done:  39%|███▉      | 1182/3000 [00:00<00:01, 1678.56it/s]warmup should be done:  39%|███▉      | 1179/3000 [00:00<00:01, 1671.91it/s]warmup should be done:  39%|███▊      | 1157/3000 [00:00<00:01, 1639.75it/s]warmup should be done:  39%|███▉      | 1168/3000 [00:00<00:01, 1662.75it/s]warmup should be done:  39%|███▉      | 1163/3000 [00:00<00:01, 1647.15it/s]warmup should be done:  39%|███▉      | 1184/3000 [00:00<00:01, 1679.05it/s]warmup should be done:  37%|███▋      | 1121/3000 [00:00<00:01, 1545.58it/s]warmup should be done:  45%|████▌     | 1354/3000 [00:00<00:00, 1685.61it/s]warmup should be done:  45%|████▌     | 1351/3000 [00:00<00:00, 1680.29it/s]warmup should be done:  45%|████▍     | 1347/3000 [00:00<00:00, 1672.49it/s]warmup should be done:  44%|████▍     | 1328/3000 [00:00<00:01, 1647.59it/s]warmup should be done:  45%|████▍     | 1337/3000 [00:00<00:00, 1668.46it/s]warmup should be done:  44%|████▍     | 1321/3000 [00:00<00:01, 1635.55it/s]warmup should be done:  45%|████▌     | 1354/3000 [00:00<00:00, 1685.18it/s]warmup should be done:  43%|████▎     | 1288/3000 [00:00<00:01, 1581.59it/s]warmup should be done:  51%|█████     | 1523/3000 [00:00<00:00, 1685.18it/s]warmup should be done:  51%|█████     | 1520/3000 [00:00<00:00, 1680.22it/s]warmup should be done:  50%|█████     | 1515/3000 [00:00<00:00, 1672.06it/s]warmup should be done:  50%|████▉     | 1496/3000 [00:00<00:00, 1657.04it/s]warmup should be done:  50%|█████     | 1505/3000 [00:00<00:00, 1670.74it/s]warmup should be done:  50%|████▉     | 1485/3000 [00:00<00:00, 1635.78it/s]warmup should be done:  51%|█████     | 1524/3000 [00:00<00:00, 1689.20it/s]warmup should be done:  49%|████▊     | 1456/3000 [00:00<00:00, 1610.99it/s]warmup should be done:  56%|█████▋    | 1692/3000 [00:01<00:00, 1684.69it/s]warmup should be done:  56%|█████▋    | 1689/3000 [00:01<00:00, 1680.38it/s]warmup should be done:  56%|█████▌    | 1665/3000 [00:01<00:00, 1665.34it/s]warmup should be done:  56%|█████▌    | 1674/3000 [00:01<00:00, 1674.39it/s]warmup should be done:  56%|█████▌    | 1683/3000 [00:01<00:00, 1668.93it/s]warmup should be done:  55%|█████▌    | 1650/3000 [00:01<00:00, 1637.62it/s]warmup should be done:  56%|█████▋    | 1694/3000 [00:01<00:00, 1691.02it/s]warmup should be done:  54%|█████▍    | 1624/3000 [00:01<00:00, 1630.95it/s]warmup should be done:  62%|██████▏   | 1862/3000 [00:01<00:00, 1686.72it/s]warmup should be done:  62%|██████▏   | 1858/3000 [00:01<00:00, 1681.53it/s]warmup should be done:  61%|██████    | 1833/3000 [00:01<00:00, 1669.46it/s]warmup should be done:  62%|██████▏   | 1851/3000 [00:01<00:00, 1671.09it/s]warmup should be done:  60%|██████    | 1814/3000 [00:01<00:00, 1637.76it/s]warmup should be done:  61%|██████▏   | 1843/3000 [00:01<00:00, 1676.69it/s]warmup should be done:  62%|██████▏   | 1865/3000 [00:01<00:00, 1694.91it/s]warmup should be done:  60%|█████▉    | 1791/3000 [00:01<00:00, 1642.44it/s]warmup should be done:  68%|██████▊   | 2031/3000 [00:01<00:00, 1686.34it/s]warmup should be done:  67%|██████▋   | 2001/3000 [00:01<00:00, 1670.00it/s]warmup should be done:  68%|██████▊   | 2027/3000 [00:01<00:00, 1680.68it/s]warmup should be done:  67%|██████▋   | 2019/3000 [00:01<00:00, 1671.73it/s]warmup should be done:  67%|██████▋   | 2011/3000 [00:01<00:00, 1676.55it/s]warmup should be done:  66%|██████▌   | 1978/3000 [00:01<00:00, 1634.27it/s]warmup should be done:  68%|██████▊   | 2035/3000 [00:01<00:00, 1694.25it/s]warmup should be done:  65%|██████▌   | 1958/3000 [00:01<00:00, 1649.78it/s]warmup should be done:  73%|███████▎  | 2200/3000 [00:01<00:00, 1684.76it/s]warmup should be done:  73%|███████▎  | 2179/3000 [00:01<00:00, 1676.49it/s]warmup should be done:  73%|███████▎  | 2196/3000 [00:01<00:00, 1678.75it/s]warmup should be done:  73%|███████▎  | 2187/3000 [00:01<00:00, 1669.80it/s]warmup should be done:  71%|███████▏  | 2142/3000 [00:01<00:00, 1633.37it/s]warmup should be done:  72%|███████▏  | 2169/3000 [00:01<00:00, 1664.86it/s]warmup should be done:  74%|███████▎  | 2205/3000 [00:01<00:00, 1691.84it/s]warmup should be done:  71%|███████   | 2130/3000 [00:01<00:00, 1668.59it/s]warmup should be done:  79%|███████▉  | 2369/3000 [00:01<00:00, 1685.87it/s]warmup should be done:  78%|███████▊  | 2348/3000 [00:01<00:00, 1679.13it/s]warmup should be done:  78%|███████▊  | 2355/3000 [00:01<00:00, 1672.50it/s]warmup should be done:  79%|███████▉  | 2365/3000 [00:01<00:00, 1679.43it/s]warmup should be done:  77%|███████▋  | 2307/3000 [00:01<00:00, 1635.96it/s]warmup should be done:  79%|███████▉  | 2376/3000 [00:01<00:00, 1696.87it/s]warmup should be done:  78%|███████▊  | 2336/3000 [00:01<00:00, 1659.07it/s]warmup should be done:  77%|███████▋  | 2301/3000 [00:01<00:00, 1680.86it/s]warmup should be done:  85%|████████▍ | 2538/3000 [00:01<00:00, 1686.01it/s]warmup should be done:  84%|████████▍ | 2517/3000 [00:01<00:00, 1681.34it/s]warmup should be done:  84%|████████▍ | 2524/3000 [00:01<00:00, 1675.73it/s]warmup should be done:  84%|████████▍ | 2534/3000 [00:01<00:00, 1680.15it/s]warmup should be done:  85%|████████▍ | 2546/3000 [00:01<00:00, 1696.71it/s]warmup should be done:  82%|████████▏ | 2471/3000 [00:01<00:00, 1635.42it/s]warmup should be done:  83%|████████▎ | 2502/3000 [00:01<00:00, 1656.41it/s]warmup should be done:  82%|████████▏ | 2472/3000 [00:01<00:00, 1689.40it/s]warmup should be done:  90%|█████████ | 2707/3000 [00:01<00:00, 1685.61it/s]warmup should be done:  90%|████████▉ | 2686/3000 [00:01<00:00, 1680.45it/s]warmup should be done:  90%|████████▉ | 2692/3000 [00:01<00:00, 1675.81it/s]warmup should be done:  91%|█████████ | 2718/3000 [00:01<00:00, 1703.59it/s]warmup should be done:  90%|█████████ | 2703/3000 [00:01<00:00, 1680.25it/s]warmup should be done:  88%|████████▊ | 2635/3000 [00:01<00:00, 1633.42it/s]warmup should be done:  89%|████████▉ | 2668/3000 [00:01<00:00, 1650.68it/s]warmup should be done:  88%|████████▊ | 2643/3000 [00:01<00:00, 1694.69it/s]warmup should be done:  96%|█████████▌| 2876/3000 [00:01<00:00, 1684.65it/s]warmup should be done:  95%|█████████▌| 2860/3000 [00:01<00:00, 1674.77it/s]warmup should be done:  96%|█████████▋| 2890/3000 [00:01<00:00, 1706.79it/s]warmup should be done:  95%|█████████▌| 2855/3000 [00:01<00:00, 1679.51it/s]warmup should be done:  93%|█████████▎| 2799/3000 [00:01<00:00, 1634.46it/s]warmup should be done:  96%|█████████▌| 2872/3000 [00:01<00:00, 1679.61it/s]warmup should be done:  94%|█████████▍| 2834/3000 [00:01<00:00, 1646.61it/s]warmup should be done:  94%|█████████▍| 2815/3000 [00:01<00:00, 1699.46it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1692.08it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1685.38it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1680.14it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1674.18it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1671.46it/s]warmup should be done:  99%|█████████▉| 2965/3000 [00:01<00:00, 1640.30it/s]warmup should be done: 100%|█████████▉| 2999/3000 [00:01<00:00, 1647.37it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1654.20it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1638.20it/s]warmup should be done: 100%|█████████▉| 2987/3000 [00:01<00:00, 1702.97it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1623.37it/s]
WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f311c079e80>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f311bd76190>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f311c07cd30>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f311bd76100>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f311c07a730>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f311c081e80>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f311bd752b0>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert

WARNING:tensorflow:AutoGraph could not transform <bound method DCNHPS.call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f311bd860a0>> and will run it as-is.
Cause: mangled names are not yet supported
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2022-12-12 07:01:05.183763: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2c530317b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:01:05.183825: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:01:05.192727: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:01:09.318117: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2c5702d790 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:01:09.318178: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:01:09.327511: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:01:09.674195: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2c5682cef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:01:09.674262: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:01:09.684047: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:01:09.788375: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2c4f02e200 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:01:09.788434: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:01:09.798472: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:01:09.881432: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2c4ef929b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:01:09.881501: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:01:09.890510: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:01:10.074236: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2c4f02f600 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:01:10.074306: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:01:10.080930: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2c5682d1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:01:10.080993: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:01:10.084055: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:01:10.090487: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:01:10.099472: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2c56838530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:01:10.099533: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:01:10.107543: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:01:12.833841: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:01:16.380157: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:01:16.634015: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:01:16.680352: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:01:16.773517: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:01:16.883270: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:01:16.974520: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:01:16.975059: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][07:02:06.458][ERROR][RK0][tid #139828968552192]: replica 5 reaches 1000, calling init pre replica
[HCTR][07:02:06.458][ERROR][RK0][tid #139828968552192]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:02:06.468][ERROR][RK0][tid #139828968552192]: coll ps creation done
[HCTR][07:02:06.468][ERROR][RK0][tid #139828968552192]: replica 5 waits for coll ps creation barrier
[HCTR][07:02:06.535][ERROR][RK0][tid #139828565899008]: replica 7 reaches 1000, calling init pre replica
[HCTR][07:02:06.536][ERROR][RK0][tid #139828565899008]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:02:06.540][ERROR][RK0][tid #139828565899008]: coll ps creation done
[HCTR][07:02:06.540][ERROR][RK0][tid #139828565899008]: replica 7 waits for coll ps creation barrier
[HCTR][07:02:06.759][ERROR][RK0][tid #139828565899008]: replica 6 reaches 1000, calling init pre replica
[HCTR][07:02:06.760][ERROR][RK0][tid #139828565899008]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:02:06.765][ERROR][RK0][tid #139828565899008]: coll ps creation done
[HCTR][07:02:06.765][ERROR][RK0][tid #139828565899008]: replica 6 waits for coll ps creation barrier
[HCTR][07:02:06.811][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][07:02:06.811][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:02:06.816][ERROR][RK0][main]: coll ps creation done
[HCTR][07:02:06.816][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][07:02:06.824][ERROR][RK0][tid #139828565899008]: replica 4 reaches 1000, calling init pre replica
[HCTR][07:02:06.824][ERROR][RK0][tid #139828565899008]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:02:06.831][ERROR][RK0][tid #139828565899008]: coll ps creation done
[HCTR][07:02:06.831][ERROR][RK0][tid #139828565899008]: replica 4 waits for coll ps creation barrier
[HCTR][07:02:06.860][ERROR][RK0][tid #139828691724032]: replica 1 reaches 1000, calling init pre replica
[HCTR][07:02:06.860][ERROR][RK0][tid #139828691724032]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:02:06.869][ERROR][RK0][tid #139828691724032]: coll ps creation done
[HCTR][07:02:06.869][ERROR][RK0][tid #139828691724032]: replica 1 waits for coll ps creation barrier
[HCTR][07:02:06.913][ERROR][RK0][tid #139828565899008]: replica 0 reaches 1000, calling init pre replica
[HCTR][07:02:06.913][ERROR][RK0][tid #139828565899008]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:02:06.920][ERROR][RK0][tid #139828565899008]: coll ps creation done
[HCTR][07:02:06.920][ERROR][RK0][tid #139828565899008]: replica 0 waits for coll ps creation barrier
[HCTR][07:02:07.051][ERROR][RK0][tid #139828498790144]: replica 2 reaches 1000, calling init pre replica
[HCTR][07:02:07.052][ERROR][RK0][tid #139828498790144]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:02:07.056][ERROR][RK0][tid #139828498790144]: coll ps creation done
[HCTR][07:02:07.056][ERROR][RK0][tid #139828498790144]: replica 2 waits for coll ps creation barrier
[HCTR][07:02:07.056][ERROR][RK0][tid #139828565899008]: replica 0 preparing frequency
[HCTR][07:02:07.922][ERROR][RK0][tid #139828565899008]: replica 0 preparing frequency done
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: replica 0 calling init per replica
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: replica 7 calling init per replica
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: replica 6 calling init per replica
[HCTR][07:02:07.969][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][07:02:07.969][ERROR][RK0][tid #139828968552192]: replica 5 calling init per replica
[HCTR][07:02:07.969][ERROR][RK0][main]: Calling build_v2
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: replica 4 calling init per replica
[HCTR][07:02:07.969][ERROR][RK0][tid #139828498790144]: replica 2 calling init per replica
[HCTR][07:02:07.969][ERROR][RK0][tid #139828691724032]: replica 1 calling init per replica
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: Calling build_v2
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: Calling build_v2
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: Calling build_v2
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:02:07.969][ERROR][RK0][tid #139828968552192]: Calling build_v2
[HCTR][07:02:07.969][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: Calling build_v2
[HCTR][07:02:07.969][ERROR][RK0][tid #139828498790144]: Calling build_v2
[HCTR][07:02:07.969][ERROR][RK0][tid #139828691724032]: Calling build_v2
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:02:07.969][ERROR][RK0][tid #139828498790144]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:02:07.969][ERROR][RK0][tid #139828968552192]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:02:07.969][ERROR][RK0][tid #139828565899008]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:02:07.969][ERROR][RK0][tid #139828691724032]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[[[[[[2022-12-12 07:02:07[[2022-12-12 07:02:072022-12-12 07:02:07.2022-12-12 07:02:072022-12-12 07:02:07..2022-12-12 07:02:079694682022-12-12 07:02:072022-12-12 07:02:07..969483969484.: ..969484969487: : 969488E969492969493: : EE:  : : EE  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.ccEE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc :  /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc::/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc136/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc::136136:] ::136136] ] 136using concurrent impl MPS136136] ] using concurrent impl MPSusing concurrent impl MPS] 
] ] using concurrent impl MPSusing concurrent impl MPS

using concurrent impl MPSusing concurrent impl MPSusing concurrent impl MPS




[2022-12-12 07:02:07.973713: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[2022-12-12 07:02:07.973753: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[:2022-12-12 07:02:07196.] 973759assigning 8 to cpu: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[[2022-12-12 07:02:072022-12-12 07:02:07..973804973809: : EE [ /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:02:07/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:.:[1789738321962022-12-12 07:02:07] : ] .v100x8, slow pcieEassigning 8 to cpu[973853
 
2022-12-12 07:02:07: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[.E:2022-12-12 07:02:07973897 212.: [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 973921[E2022-12-12 07:02:07:build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8: 2022-12-12 07:02:07 .178
[E./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc973947] 2022-12-12 07:02:07 973961:: [v100x8, slow pcie./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: [178E2022-12-12 07:02:07
973986:E2022-12-12 07:02:07]  .: 196[ .v100x8, slow pcie/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc974024E] 2022-12-12 07:02:07/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc974028
::  assigning 8 to cpu.:: 178[E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
974081212E] 2022-12-12 07:02:07 :: ]  v100x8, slow pcie.[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc178Ebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
9741552022-12-12 07:02:07:]  
:: .[213v100x8, slow pcie/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc178E974234[2022-12-12 07:02:07] 
:]  : 2022-12-12 07:02:07.remote time is 8.68421196v100x8, slow pcie[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE.974265
] 
2022-12-12 07:02:07: 974291: assigning 8 to cpu[.196[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: E
2022-12-12 07:02:07974332] 2022-12-12 07:02:07:E .: assigning 8 to cpu.212 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc974379: E
974382] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[:E : build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8:2022-12-12 07:02:07196 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE
[213.] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: 2022-12-12 07:02:07] 974464[assigning 8 to cpu:196/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.remote time is 8.68421: 2022-12-12 07:02:07
214] :974506
E.] assigning 8 to cpu196:  [974543[cpu time is 97.0588
] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:02:07: 2022-12-12 07:02:07
assigning 8 to cpu :.E.
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc212974623 [974625:] : /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:02:07: 212build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E[:.E] 
 2022-12-12 07:02:07213974682 build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.] : [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
:974717remote time is 8.68421E2022-12-12 07:02:07:212: 
 [.[214] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:02:079747702022-12-12 07:02:07] build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8 :.: .cpu time is 97.0588
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc212974810E974836
:] :  [: 212build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:02:07E] 
 :. build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc213974895[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
:] : 2022-12-12 07:02:07:213remote time is 8.68421E.[214] 
 9749482022-12-12 07:02:07[] remote time is 8.68421/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: .2022-12-12 07:02:07cpu time is 97.0588
:E974988.
213 : [975020] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE2022-12-12 07:02:07: remote time is 8.68421: .E
213/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc975054 ] :: [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421213E2022-12-12 07:02:07:
]  .214remote time is 8.68421/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc975099[] 
:: 2022-12-12 07:02:07cpu time is 97.0588214E.[
]  9751402022-12-12 07:02:07cpu time is 97.0588/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: .
:E975160214 : ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccEcpu time is 97.0588: 
214/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] :cpu time is 97.0588214
] cpu time is 97.0588
[2022-12-12 07:03:25.235561: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-12 07:03:25.275618: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-12 07:03:25.275696: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 25000000
[2022-12-12 07:03:25.394539: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-12 07:03:25.394635: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-12 07:03:25.418798: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-12 07:03:25.418832: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-12 07:03:25.419339: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.420267: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.421073: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.434076: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 3 solved
[2022-12-12 07:03:25.434137: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 3 initing device 3
[2022-12-12 07:03:25.434224: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 6 solved
[2022-12-12 07:03:25.434305: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 6 initing device 6
[2022-12-12 07:03:25.434420: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 1 solved
[2022-12-12 07:03:25.434491: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 1 initing device 1
[2022-12-12 07:03:25.434544: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.434722: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.434857: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[[2022-12-12 07:03:252022-12-12 07:03:25..435120435124: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::202202] ] 4 solved5 solved

[[2022-12-12 07:03:252022-12-12 07:03:25..435215435216: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::205205] ] worker 0 thread 4 initing device 4worker 0 thread 5 initing device 5

[[2022-12-12 07:03:252022-12-12 07:03:25..435633435634: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 381.47 MBeager alloc mem 381.47 MB

[2022-12-12 07:03:25.437862: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.437911: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.438119: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.438663: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.439151: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.441089: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.441203: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.441369: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.441410: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.442380: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[[2022-12-12 07:03:252022-12-12 07:03:25..444033444033: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::202202] ] 2 solved7 solved

[[2022-12-12 07:03:252022-12-12 07:03:25..444113444113: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::205205] ] worker 0 thread 2 initing device 2worker 0 thread 7 initing device 7

[[2022-12-12 07:03:252022-12-12 07:03:25..444619444619: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 381.47 MBeager alloc mem 381.47 MB

[2022-12-12 07:03:25.446217: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.446275: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.447707: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.447815: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:03:25.503802: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 07:03:25.504172: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 07:03:25.509219: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:03:25.509286: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 07:03:25.509328: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:03:25.510119: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 95.75 MB
[2022-12-12 07:03:25.510818: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:25.511903: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:25.511996: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:03:25.512681: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:03:25.512724: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 11.92 GB
[2022-12-12 07:03:25.522761: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 07:03:25.523082: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[[2022-12-12 07:03:25[[2022-12-12 07:03:25.[2022-12-12 07:03:252022-12-12 07:03:25.5307822022-12-12 07:03:25..530782: .530817530837: E530835: : E : EE /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::1980] :19801980] eager alloc mem 2.00 Bytes1980] ] eager alloc mem 2.00 Bytes
] eager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes
eager alloc mem 2.00 Bytes


[2022-12-12 07:03:25.531224[[[: 2022-12-12 07:03:252022-12-12 07:03:252022-12-12 07:03:25[E...2022-12-12 07:03:25 531231531231531231./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: : : 531241:EEE: 1980   E] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu eager alloc mem 1024.00 Bytes:::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
198019801980:] ] ] 1980eager alloc mem 1024.00 Byteseager alloc mem 1024.00 Byteseager alloc mem 1024.00 Bytes] 


eager alloc mem 1024.00 Bytes
[2022-12-12 07:03:25.537907: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 07:03:25.538204: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 07:03:25.554097: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:03:25.554176: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 07:03:25.554220: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:03:25.554241: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[[2022-12-12 07:03:252022-12-12 07:03:25..554300554316: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 1024eager release cuda mem 2

[[2022-12-12 07:03:252022-12-12 07:03:25[..2022-12-12 07:03:25554386554388.: : 554378EE:   E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc ::/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638638:] ] 638eager release cuda mem 2eager release cuda mem 400000000] 

eager release cuda mem 1024
[2022-12-12 07:03:25[[.2022-12-12 07:03:252022-12-12 07:03:25554483..: 554473554487E: :  EE/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc  :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638::] 638638eager release cuda mem 400000000] ] eager release cuda mem 1024
eager release cuda mem 2

[2022-12-12 07:03:25.554550: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[[:2022-12-12 07:03:252022-12-12 07:03:25638..] 554582554581eager release cuda mem 1024: : 
EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] [eager release cuda mem 400000000eager release cuda mem 22022-12-12 07:03:25

.554631: E[ 2022-12-12 07:03:25/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[.:2022-12-12 07:03:25554648638.: ] 554678Eeager release cuda mem 2:  
E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] [638eager release cuda mem 10242022-12-12 07:03:25] 
.eager release cuda mem 400000000554752
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 4000000002022-12-12 07:03:25
.554799: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 07:03:25.554853: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:03:25.555143: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 95.75 MB
[2022-12-12 07:03:25.556581: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 95.75 MB
[2022-12-12 07:03:25.557737: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 95.75 MB
[2022-12-12 07:03:25.558408: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 95.75 MB
[2022-12-12 07:03:25.558940: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 95.75 MB
[2022-12-12 07:03:25.559455: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 95.75 MB
[2022-12-12 07:03:25.559977: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 95.75 MB
[2022-12-12 07:03:25.561296: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:25.561754: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:25.562082: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:25.562154: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:25.562184: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:25.562242: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:25.562287: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:25.562361: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:25.562450: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:03:25.562816: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:25.562902: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:03:25.563123: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 07:03:25eager release cuda mem 25855.
563154: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663[
2022-12-12 07:03:25.563198: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 11.92 GB
[2022-12-12 07:03:25.563224: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:25[.2022-12-12 07:03:25563256.: 563263E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638:] 1980eager release cuda mem 625663] 
eager alloc mem 25.25 KB[
2022-12-12 07:03:25.[5633052022-12-12 07:03:25: .E563315 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[] :2022-12-12 07:03:25eager release cuda mem 625663[1980.
2022-12-12 07:03:25] 563348.eager alloc mem 25.25 KB: 563362
E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638:] [1980eager release cuda mem 6256632022-12-12 07:03:25] eager alloc mem 25.25 KB
.
563442: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:03:25.563538: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:03:25.563571: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:03:25.563615: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 11.92 GB
[2022-12-12 07:03:25.563957: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:03:25.563999: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 11.92 GB
[2022-12-12 07:03:25.564057: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:03:25.564098: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 11.92 GB
[2022-12-12 07:03:25.564130: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 07:03:25638.] 564146eager release cuda mem 25855: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:03:25.564182: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 07:03:251980.] 564196eager alloc mem 11.92 GB: 
E[ 2022-12-12 07:03:25/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.:5642151980: ] Eeager alloc mem 11.92 GB 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:03:25.564287: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 11.92 GB
[[[[[[[[2022-12-12 07:03:282022-12-12 07:03:282022-12-12 07:03:282022-12-12 07:03:282022-12-12 07:03:282022-12-12 07:03:282022-12-12 07:03:282022-12-12 07:03:28........145259145259145259145259145258145266145266145276: : : : : : : : EEEEEEEE        /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::::::19801980198019801980198019801980] ] ] eager alloc mem 611.00 KB] ] ] ] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KB
eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB






[2022-12-12 07:03:28.146383: [[E2022-12-12 07:03:28[2022-12-12 07:03:28 .[[2022-12-12 07:03:28.[[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc1463932022-12-12 07:03:282022-12-12 07:03:28.1463932022-12-12 07:03:282022-12-12 07:03:28:: ..146398: ..638E146402146405: E146426146409]  : : E : : eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccEE /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccEE
:  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:  638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] ::638] ::eager release cuda mem 625663638[638] eager release cuda mem 625663638638
] 2022-12-12 07:03:28] eager release cuda mem 625663
] ] eager release cuda mem 625663.eager release cuda mem 625663
eager release cuda mem 625663eager release cuda mem 625663
146615


: [E2022-12-12 07:03:28 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu146723:: 1980[E] 2022-12-12 07:03:28 eager alloc mem 611.00 KB.[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
1467392022-12-12 07:03:28:: [.1980[E[2022-12-12 07:03:28[146752] 2022-12-12 07:03:28 2022-12-12 07:03:28.2022-12-12 07:03:28: eager alloc mem 611.00 KB./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.146764.E
146769:146772: 146776 : 1980: E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE] E E: eager alloc mem 611.00 KB /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] ::1980:eager alloc mem 611.00 KB19801980] 1980
] ] eager alloc mem 611.00 KB] eager alloc mem 611.00 KBeager alloc mem 611.00 KB
eager alloc mem 611.00 KB


[2022-12-12 07:03:28.147502: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.147567: E[ 2022-12-12 07:03:28/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:147580638: ] Eeager release cuda mem 625663 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.147631: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663[
2022-12-12 07:03:28.147656: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB[
2022-12-12 07:03:28.147677: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 07:03:28638[[.[[] 2022-12-12 07:03:282022-12-12 07:03:281476962022-12-12 07:03:282022-12-12 07:03:28eager release cuda mem 625663..: ..
147703147706E147707147706: :  : : EE/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccEE  : [ /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 07:03:28/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::] :.:638638eager release cuda mem 6256631980147822638] ] 
] : ] eager release cuda mem 625663eager release cuda mem 625663eager alloc mem 611.00 KBEeager release cuda mem 625663


 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.147964: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[[2022-12-12 07:03:282022-12-12 07:03:28.[.1479892022-12-12 07:03:28147991: .: E148000E :  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: :1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980] :] eager alloc mem 611.00 KB1980eager alloc mem 611.00 KB
] 
eager alloc mem 611.00 KB
[2022-12-12 07:03:28.148351: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.[1484162022-12-12 07:03:28: .E148424 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :eager release cuda mem 6256631980
] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.148507: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.148673: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.148696: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 07:03:28eager release cuda mem 625663.
[1487182022-12-12 07:03:28: .E148743 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :[eager release cuda mem 62566319802022-12-12 07:03:28
] .eager alloc mem 611.00 KB148794
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB[
2022-12-12 07:03:28.148834: E[[ 2022-12-12 07:03:28[2022-12-12 07:03:28/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.2022-12-12 07:03:28.:148847.148847638: 148858: ] E: Eeager release cuda mem 625663 E 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:638:638] 1980] eager release cuda mem 625663] eager release cuda mem 625663[
eager alloc mem 611.00 KB
2022-12-12 07:03:28
.148982: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.149043[: 2022-12-12 07:03:28E. 149049/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: :E1980 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 611.00 KB:
1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.149194: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.[1492582022-12-12 07:03:28: .E149263 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] :eager release cuda mem 6256631980
] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.149351: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.149547: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663[
2022-12-12 07:03:28.149569: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.149620: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB[
2022-12-12 07:03:28.149641: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.149736: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663[
2022-12-12 07:03:28.149759: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.149813: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB[
[2022-12-12 07:03:282022-12-12 07:03:28..149834[149838: 2022-12-12 07:03:28: E.E 149853 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:E:1980 638] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] eager alloc mem 611.00 KB:eager release cuda mem 625663
638
] eager release cuda mem 625663
[2022-12-12 07:03:28.[1500082022-12-12 07:03:28: .E150014 [: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 07:03:28E:. 1980150036/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] : :eager alloc mem 611.00 KBE1980
 ] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager alloc mem 611.00 KB2022-12-12 07:03:28:
.638150102] : eager release cuda mem 625663E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.150192: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 07:03:28:.1980150204] : eager alloc mem 611.00 KBE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.150369: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.150393: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.150443: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.150468: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.150572: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.150645: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.150681: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.150751: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.150830: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.150858: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.150900: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.150928: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.150953: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 07:03:28:.638150967] : eager release cuda mem 625663E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.151035: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 07:03:28:.1980151047] : eager alloc mem 611.00 KBE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.151191: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.151220: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.151260: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.151289: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.151394: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.151466: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.151502: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.151573: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.151649: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.151681: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.151719: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.151751: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:03:28.[1518022022-12-12 07:03:28: .E151810 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 625663638
] eager release cuda mem 625663
[2022-12-12 07:03:28.[1518622022-12-12 07:03:28: .E151866 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 100400000638
] eager release cuda mem 100400000
[2022-12-12 07:03:28.152008: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.152042[: 2022-12-12 07:03:28E. 152051/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663:
638] eager release cuda mem 100400000
[2022-12-12 07:03:28.152097: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 100400000
[2022-12-12 07:03:28.152215: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.152255: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 100400000
[2022-12-12 07:03:28.152322: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28.152368: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 100400000
[2022-12-12 07:03:28.152474: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:03:28[.2022-12-12 07:03:28152507.: 152513E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 625663] 
eager release cuda mem 100400000
[2022-12-12 07:03:28.152601: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 100400000
[2022-12-12 07:03:28.152732: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 25000000 / 100000000 nodes ( 25.00 %~25.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 75000000 / 100000000 nodes ( 75.00 %) | 11.92 GB | 2.7171 secs 
[2022-12-12 07:03:28.153132: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 25000000 / 100000000 nodes ( 25.00 %~25.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 75000000 / 100000000 nodes ( 75.00 %) | 11.92 GB | 2.71842 secs 
[2022-12-12 07:03:28.153691: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 25000000 / 100000000 nodes ( 25.00 %~25.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 75000000 / 100000000 nodes ( 75.00 %) | 11.92 GB | 2.70908 secs 
[2022-12-12 07:03:28.154039: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 25000000 / 100000000 nodes ( 25.00 %~25.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 75000000 / 100000000 nodes ( 75.00 %) | 11.92 GB | 2.71841 secs 
[2022-12-12 07:03:28.154460: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 25000000 / 100000000 nodes ( 25.00 %~25.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 75000000 / 100000000 nodes ( 75.00 %) | 11.92 GB | 2.70985 secs 
[2022-12-12 07:03:28.154648: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 25000000 / 100000000 nodes ( 25.00 %~25.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 75000000 / 100000000 nodes ( 75.00 %) | 11.92 GB | 2.7198 secs 
[2022-12-12 07:03:28.154917: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 25000000 / 100000000 nodes ( 25.00 %~25.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 75000000 / 100000000 nodes ( 75.00 %) | 11.92 GB | 2.73558 secs 
[2022-12-12 07:03:28.155439: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 25000000 / 100000000 nodes ( 25.00 %~25.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 75000000 / 100000000 nodes ( 75.00 %) | 11.92 GB | 2.7209 secs 
[2022-12-12 07:03:28.157184: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 20.24 GB
[2022-12-12 07:03:29.874708: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 20.50 GB
[2022-12-12 07:03:29.875751: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 20.50 GB
[2022-12-12 07:03:29.877192: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 20.50 GB
[2022-12-12 07:03:31.456565: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 20.77 GB
[2022-12-12 07:03:31.457141: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 20.77 GB
[2022-12-12 07:03:31.458580: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 20.77 GB
[2022-12-12 07:03:32.805646: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 20.98 GB
[2022-12-12 07:03:32.806433: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 20.98 GB
[2022-12-12 07:03:32.807806: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 20.98 GB
[2022-12-12 07:03:34.666819: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 21.20 GB
[2022-12-12 07:03:34.667587: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 21.20 GB
[2022-12-12 07:03:34.668439: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 21.20 GB
[2022-12-12 07:03:36.242661: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 21.65 GB
[2022-12-12 07:03:36.243105: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 21.65 GB
[2022-12-12 07:03:36.243824: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 21.65 GB
[2022-12-12 07:03:37.343553: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 21.85 GB
[2022-12-12 07:03:37.343703: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 21.85 GB
[HCTR][07:03:37.343][ERROR][RK0][tid #139828498790144]: replica 2 calling init per replica done, doing barrier
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: replica 6 calling init per replica done, doing barrier
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: replica 0 calling init per replica done, doing barrier
[HCTR][07:03:37.343][ERROR][RK0][tid #139828691724032]: replica 1 calling init per replica done, doing barrier
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: replica 4 calling init per replica done, doing barrier
[HCTR][07:03:37.343][ERROR][RK0][tid #139828968552192]: replica 5 calling init per replica done, doing barrier
[HCTR][07:03:37.343][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: replica 7 calling init per replica done, doing barrier
[HCTR][07:03:37.343][ERROR][RK0][tid #139828691724032]: replica 1 calling init per replica done, doing barrier done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: replica 7 calling init per replica done, doing barrier done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: replica 4 calling init per replica done, doing barrier done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: replica 0 calling init per replica done, doing barrier done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: replica 6 calling init per replica done, doing barrier done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828968552192]: replica 5 calling init per replica done, doing barrier done
[HCTR][07:03:37.343][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828498790144]: replica 2 calling init per replica done, doing barrier done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828691724032]: init per replica done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: init per replica done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: init per replica done
[HCTR][07:03:37.343][ERROR][RK0][main]: init per replica done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828565899008]: init per replica done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828968552192]: init per replica done
[HCTR][07:03:37.343][ERROR][RK0][tid #139828498790144]: init per replica done
[HCTR][07:03:37.346][ERROR][RK0][tid #139828565899008]: init per replica done
[HCTR][07:03:37.382][ERROR][RK0][main]: 7 allocated 3276800 at 0x7f0d64238400
[HCTR][07:03:37.382][ERROR][RK0][main]: 7 allocated 6553600 at 0x7f0d64558400
[HCTR][07:03:37.382][ERROR][RK0][main]: 7 allocated 3276800 at 0x7f0d64b98400
[HCTR][07:03:37.382][ERROR][RK0][main]: 7 allocated 6553600 at 0x7f0d64eb8400
[HCTR][07:03:37.382][ERROR][RK0][main]: 2 allocated 3276800 at 0x7f0e20238400
[HCTR][07:03:37.382][ERROR][RK0][main]: 2 allocated 6553600 at 0x7f0e20558400
[HCTR][07:03:37.382][ERROR][RK0][main]: 2 allocated 3276800 at 0x7f0e20b98400
[HCTR][07:03:37.382][ERROR][RK0][main]: 2 allocated 6553600 at 0x7f0e20eb8400
[HCTR][07:03:37.382][ERROR][RK0][tid #139828968552192]: 5 allocated 3276800 at 0x7f0de0238400
[HCTR][07:03:37.382][ERROR][RK0][tid #139828565899008]: 6 allocated 3276800 at 0x7f0de4238400
[HCTR][07:03:37.382][ERROR][RK0][tid #139828968552192]: 5 allocated 6553600 at 0x7f0de0558400
[HCTR][07:03:37.382][ERROR][RK0][tid #139828565899008]: 6 allocated 6553600 at 0x7f0de4558400
[HCTR][07:03:37.382][ERROR][RK0][tid #139828968552192]: 5 allocated 3276800 at 0x7f0de0b98400
[HCTR][07:03:37.382][ERROR][RK0][tid #139828565899008]: 6 allocated 3276800 at 0x7f0de4b98400
[HCTR][07:03:37.382][ERROR][RK0][tid #139828968552192]: 5 allocated 6553600 at 0x7f0de0eb8400
[HCTR][07:03:37.382][ERROR][RK0][tid #139828565899008]: 6 allocated 6553600 at 0x7f0de4eb8400
[HCTR][07:03:37.382][ERROR][RK0][main]: 1 allocated 3276800 at 0x7f0e20238400
[HCTR][07:03:37.382][ERROR][RK0][main]: 1 allocated 6553600 at 0x7f0e20558400
[HCTR][07:03:37.382][ERROR][RK0][main]: 1 allocated 3276800 at 0x7f0e20b98400
[HCTR][07:03:37.382][ERROR][RK0][main]: 1 allocated 6553600 at 0x7f0e20eb8400
[HCTR][07:03:37.383][ERROR][RK0][tid #139828565899008]: 4 allocated 3276800 at 0x7f0d24238400
[HCTR][07:03:37.383][ERROR][RK0][tid #139828565899008]: 4 allocated 6553600 at 0x7f0d24558400
[HCTR][07:03:37.383][ERROR][RK0][tid #139828565899008]: 4 allocated 3276800 at 0x7f0d24b98400
[HCTR][07:03:37.383][ERROR][RK0][tid #139828565899008]: 4 allocated 6553600 at 0x7f0d24eb8400
[HCTR][07:03:37.383][ERROR][RK0][tid #139828633007872]: 3 allocated 3276800 at 0x7f0dbc238400
[HCTR][07:03:37.383][ERROR][RK0][tid #139828633007872]: 3 allocated 6553600 at 0x7f0dbc558400
[HCTR][07:03:37.383][ERROR][RK0][tid #139828633007872]: 3 allocated 3276800 at 0x7f0dbcb98400
[HCTR][07:03:37.383][ERROR][RK0][tid #139828633007872]: 3 allocated 6553600 at 0x7f0dbceb8400
[HCTR][07:03:37.385][ERROR][RK0][main]: 0 allocated 3276800 at 0x7f0db4320000
[HCTR][07:03:37.385][ERROR][RK0][main]: 0 allocated 6553600 at 0x7f0db4640000
[HCTR][07:03:37.385][ERROR][RK0][main]: 0 allocated 3276800 at 0x7f0db4c80000
[HCTR][07:03:37.385][ERROR][RK0][main]: 0 allocated 6553600 at 0x7f0db4fa0000
