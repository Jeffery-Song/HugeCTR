2022-12-12 07:31:35.330044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.338231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.344719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.351897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.356128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.367159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.374791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.379621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.436174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.439998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.440005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.441962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.448805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.451211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.452390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.454606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.455179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.456267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.457227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.457741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.459161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.459294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.461044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.461173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.462678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.462781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.464406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.465318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.466238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.467159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.468255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.469214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.470906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.471952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.473035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.474025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.474965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.475928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.476871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.477811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.483114: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:31:35.487486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.489112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.491043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.491102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.492866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.493034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.493326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.493653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.495905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.496145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.496373: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.496439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.496590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.498594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.499110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.499554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.499654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.499748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.502125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.502544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.502718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.502835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.505217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.505656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.505797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.505927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.508260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.508937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.508978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.509147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.511889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.512799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.512891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.512911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.516003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.516650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.516687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.516885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.520228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.520424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.520477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.521302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.522688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.523143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.524222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.525220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.525670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.526812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.527460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.527869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.529109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.540722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.542381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.543784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.543907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.544692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.546274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.546429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.547194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.556971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.560837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.563396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.566438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.584924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.585846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.587521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.587551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.587694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.587748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.589539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.591094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.592369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.592495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.592538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.592580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.594600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.597819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.597865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.597911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.597952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.599055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.601444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.601600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.601644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.601695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.602724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.605516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.605727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.605828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.605857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.607243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.609617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.609711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.609910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.610023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.611892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.613345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.613384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.613488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.613776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.615596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.616923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.617046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.617090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.617491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.619264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.620459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.620607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.620743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.621318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.623447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.625316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.625531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.625562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.626535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.628176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.629387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.629552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.629590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.629951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.630812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.631928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.633599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.633839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.633877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.634304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.635220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.636476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.637810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.637999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.638040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.638672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.639314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.640818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.641827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.641870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.641910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.642874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.643401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.644066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.645908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.645951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.646082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.647188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.647470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.648122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.649422: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:31:35.651363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.651365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.651863: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.652637: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.653161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.653700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.655366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.655660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.655774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.656548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.657248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.657975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.659485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.659680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.659772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.659881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.660520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.661477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.662169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.664252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.664490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.664629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.664874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.665159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.666189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.667163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.668857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.669470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.669564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.669888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.670527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.672226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.673316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.675167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.675976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.676093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.676505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.677538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.678183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.680477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.680733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.680820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.680924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.682061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.682759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.689250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.689415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.689597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.689646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.690860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.691663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.694272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.694912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.697617: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:31:35.698133: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:31:35.698250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.698363: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:31:35.698636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.699261: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:31:35.700801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.701221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.703590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.704558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.705592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.706984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.707643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.707901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.708331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.709239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.709971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.712722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.712949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.713222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.713411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.714323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.715232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.729590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.729797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.730111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.730178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.730803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.732154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.734131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.736672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.768756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.800831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.802943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.806260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.810283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.813510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.819909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.821927: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:31:35.825848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.831393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.834672: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:31:35.835341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.839354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.843961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.889924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:35.893950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:36.894892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:36.895552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:36.896993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:36.897462: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:31:36.897515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 07:31:36.915656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:36.916265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:36.916782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:36.917371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:36.918388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:36.918854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 07:31:36.965185: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:36.965383: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.000304: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-12 07:31:37.098479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.099097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.100033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.100511: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:31:37.100564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 07:31:37.118334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.119165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.120023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.120616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.121552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.122023: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 07:31:37.183861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.183861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.184982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.184997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.185997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.186029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.186929: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:31:37.186963: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:31:37.186987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 07:31:37.187011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 07:31:37.200775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.201275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.201485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.202766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.202779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.203936: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:31:37.203970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.204016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 07:31:37.204856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.204901: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:31:37.204961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 07:31:37.205641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.205711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.207051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.207106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.208034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.208225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.208935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.209080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.209831: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.209979: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.210041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.210218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 07:31:37.210611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 07:31:37.212026: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-12 07:31:37.216996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.217597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.218116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.218578: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:31:37.218624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 07:31:37.221880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.222546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.223049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.223120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.224058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.224151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.224961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.225076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.225827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 07:31:37.226050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.226407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.226759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.227594: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.227671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 07:31:37.228160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.228628: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:31:37.228670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 07:31:37.235886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.236503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.237010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.237584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.238095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.238567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 07:31:37.246659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.247314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.247832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.248813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.249332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:31:37.249808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 07:31:37.257938: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.258135: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.260047: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-12 07:31:37.272922: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.273105: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.274716: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.274839: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.274979: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-12 07:31:37.276590: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-12 07:31:37.288922: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.289091: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.291058: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
2022-12-12 07:31:37.294757: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.294921: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.295466: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.295622: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:31:37.297028: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-12 07:31:37.297468: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
[HCTR][07:31:38.552][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:31:38.552][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:31:38.557][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:31:38.561][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:31:38.561][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:31:38.562][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:31:38.562][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:31:38.562][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:01,  1.55s/it]warmup run: 1it [00:01,  1.57s/it]warmup run: 1it [00:01,  1.52s/it]warmup run: 1it [00:01,  1.51s/it]warmup run: 1it [00:01,  1.50s/it]warmup run: 100it [00:01, 84.19it/s]warmup run: 98it [00:01, 81.58it/s]warmup run: 99it [00:01, 84.59it/s]warmup run: 96it [00:01, 82.85it/s]warmup run: 100it [00:01, 86.83it/s]warmup run: 197it [00:01, 179.49it/s]warmup run: 1it [00:01,  1.51s/it]warmup run: 199it [00:01, 180.42it/s]warmup run: 199it [00:01, 184.32it/s]warmup run: 1it [00:01,  1.49s/it]warmup run: 1it [00:01,  1.55s/it]warmup run: 194it [00:01, 181.53it/s]warmup run: 199it [00:01, 186.67it/s]warmup run: 289it [00:01, 277.96it/s]warmup run: 96it [00:01, 82.65it/s]warmup run: 300it [00:01, 289.96it/s]warmup run: 298it [00:01, 292.83it/s]warmup run: 102it [00:01, 88.86it/s]warmup run: 75it [00:01, 63.15it/s]warmup run: 291it [00:01, 288.54it/s]warmup run: 297it [00:01, 294.52it/s]warmup run: 383it [00:01, 383.56it/s]warmup run: 195it [00:01, 182.26it/s]warmup run: 402it [00:01, 405.56it/s]warmup run: 398it [00:01, 406.86it/s]warmup run: 204it [00:01, 192.11it/s]warmup run: 167it [00:01, 155.32it/s]warmup run: 391it [00:01, 404.12it/s]warmup run: 394it [00:01, 404.32it/s]warmup run: 477it [00:02, 486.43it/s]warmup run: 299it [00:01, 298.17it/s]warmup run: 504it [00:02, 518.13it/s]warmup run: 498it [00:02, 517.83it/s]warmup run: 306it [00:01, 305.22it/s]warmup run: 266it [00:01, 266.57it/s]warmup run: 493it [00:02, 519.72it/s]warmup run: 491it [00:01, 510.90it/s]warmup run: 570it [00:02, 579.01it/s]warmup run: 402it [00:01, 416.49it/s]warmup run: 608it [00:02, 626.10it/s]warmup run: 599it [00:02, 620.74it/s]warmup run: 409it [00:01, 423.10it/s]warmup run: 366it [00:01, 383.85it/s]warmup run: 598it [00:02, 631.95it/s]warmup run: 593it [00:02, 617.88it/s]warmup run: 665it [00:02, 663.99it/s]warmup run: 503it [00:02, 527.10it/s]warmup run: 712it [00:02, 720.54it/s]warmup run: 700it [00:02, 709.16it/s]warmup run: 510it [00:01, 533.68it/s]warmup run: 703it [00:02, 728.83it/s]warmup run: 467it [00:02, 499.50it/s]warmup run: 693it [00:02, 705.44it/s]warmup run: 760it [00:02, 734.73it/s]warmup run: 604it [00:02, 628.97it/s]warmup run: 815it [00:02, 795.06it/s]warmup run: 801it [00:02, 782.37it/s]warmup run: 612it [00:02, 636.58it/s]warmup run: 568it [00:02, 606.14it/s]warmup run: 808it [00:02, 806.84it/s]warmup run: 792it [00:02, 775.95it/s]warmup run: 857it [00:02, 794.46it/s]warmup run: 705it [00:02, 716.08it/s]warmup run: 918it [00:02, 854.67it/s]warmup run: 903it [00:02, 844.17it/s]warmup run: 714it [00:02, 725.44it/s]warmup run: 669it [00:02, 697.95it/s]warmup run: 910it [00:02, 858.02it/s]warmup run: 890it [00:02, 826.42it/s]warmup run: 960it [00:02, 856.91it/s]warmup run: 807it [00:02, 791.36it/s]warmup run: 1007it [00:02, 897.07it/s]warmup run: 1021it [00:02, 899.96it/s]warmup run: 816it [00:02, 797.33it/s]warmup run: 766it [00:02, 763.58it/s]warmup run: 1011it [00:02, 895.82it/s]warmup run: 989it [00:02, 869.36it/s]warmup run: 1061it [00:02, 898.69it/s]warmup run: 909it [00:02, 850.47it/s]warmup run: 1112it [00:02, 939.18it/s]warmup run: 1123it [00:02, 927.85it/s]warmup run: 919it [00:02, 856.05it/s]warmup run: 867it [00:02, 827.44it/s]warmup run: 1112it [00:02, 923.22it/s]warmup run: 1088it [00:02, 901.00it/s]warmup run: 1162it [00:02, 928.22it/s]warmup run: 1011it [00:02, 894.92it/s]warmup run: 1214it [00:02, 960.05it/s]warmup run: 1224it [00:02, 947.85it/s]warmup run: 1020it [00:02, 892.19it/s]warmup run: 968it [00:02, 876.91it/s]warmup run: 1213it [00:02, 943.44it/s]warmup run: 1187it [00:02, 924.56it/s]warmup run: 1262it [00:02, 947.36it/s]warmup run: 1113it [00:02, 928.99it/s]warmup run: 1318it [00:02, 980.88it/s]warmup run: 1325it [00:02, 964.08it/s]warmup run: 1120it [00:02, 916.15it/s]warmup run: 1071it [00:02, 917.89it/s]warmup run: 1313it [00:02, 958.17it/s]warmup run: 1285it [00:02, 935.61it/s]warmup run: 1366it [00:02, 972.30it/s]warmup run: 1216it [00:02, 956.34it/s]warmup run: 1421it [00:02, 989.05it/s]warmup run: 1426it [00:02, 973.43it/s]warmup run: 1220it [00:02, 935.95it/s]warmup run: 1173it [00:02, 944.50it/s]warmup run: 1413it [00:02, 967.90it/s]warmup run: 1385it [00:02, 952.04it/s]warmup run: 1470it [00:03, 990.78it/s]warmup run: 1318it [00:02, 974.60it/s]warmup run: 1523it [00:03, 994.65it/s]warmup run: 1527it [00:03, 969.69it/s]warmup run: 1319it [00:02, 950.56it/s]warmup run: 1275it [00:02, 964.31it/s]warmup run: 1514it [00:03, 977.87it/s]warmup run: 1484it [00:03, 962.44it/s]warmup run: 1574it [00:03, 1004.91it/s]warmup run: 1420it [00:02, 983.81it/s]warmup run: 1625it [00:03, 1001.10it/s]warmup run: 1626it [00:03, 969.12it/s]warmup run: 1419it [00:02, 962.46it/s]warmup run: 1376it [00:02, 977.43it/s]warmup run: 1614it [00:03, 983.91it/s]warmup run: 1583it [00:03, 965.95it/s]warmup run: 1676it [00:03, 993.53it/s] warmup run: 1727it [00:03, 1005.52it/s]warmup run: 1522it [00:03, 977.57it/s]warmup run: 1725it [00:03, 958.12it/s]warmup run: 1518it [00:03, 970.07it/s]warmup run: 1477it [00:03, 984.51it/s]warmup run: 1714it [00:03, 986.14it/s]warmup run: 1681it [00:03, 967.73it/s]warmup run: 1777it [00:03, 994.03it/s]warmup run: 1829it [00:03, 1005.62it/s]warmup run: 1622it [00:03, 978.46it/s]warmup run: 1822it [00:03, 954.36it/s]warmup run: 1618it [00:03, 977.21it/s]warmup run: 1579it [00:03, 992.80it/s]warmup run: 1814it [00:03, 987.31it/s]warmup run: 1779it [00:03, 970.41it/s]warmup run: 1878it [00:03, 996.34it/s]warmup run: 1931it [00:03, 1004.52it/s]warmup run: 1722it [00:03, 979.14it/s]warmup run: 1920it [00:03, 960.30it/s]warmup run: 1718it [00:03, 980.28it/s]warmup run: 1681it [00:03, 998.35it/s]warmup run: 1914it [00:03, 988.37it/s]warmup run: 1877it [00:03, 970.93it/s]warmup run: 1979it [00:03, 993.28it/s]warmup run: 2037it [00:03, 1020.40it/s]warmup run: 1824it [00:03, 989.67it/s]warmup run: 2021it [00:03, 974.10it/s]warmup run: 1818it [00:03, 983.54it/s]warmup run: 1784it [00:03, 1006.25it/s]warmup run: 2014it [00:03, 986.40it/s]warmup run: 1975it [00:03, 972.26it/s]warmup run: 2094it [00:03, 1038.08it/s]warmup run: 2158it [00:03, 1075.48it/s]warmup run: 1925it [00:03, 994.41it/s]warmup run: 2139it [00:03, 1033.29it/s]warmup run: 1919it [00:03, 989.13it/s]warmup run: 1887it [00:03, 1010.96it/s]warmup run: 2131it [00:03, 1040.71it/s]warmup run: 2087it [00:03, 1014.32it/s]warmup run: 2214it [00:03, 1085.77it/s]warmup run: 2279it [00:03, 1114.22it/s]warmup run: 2030it [00:03, 1009.85it/s]warmup run: 2257it [00:03, 1075.55it/s]warmup run: 2024it [00:03, 1005.32it/s]warmup run: 1990it [00:03, 1016.41it/s]warmup run: 2251it [00:03, 1087.05it/s]warmup run: 2205it [00:03, 1063.03it/s]warmup run: 2334it [00:03, 1119.34it/s]warmup run: 2401it [00:03, 1143.37it/s]warmup run: 2151it [00:03, 1068.53it/s]warmup run: 2376it [00:03, 1106.75it/s]warmup run: 2147it [00:03, 1071.42it/s]warmup run: 2110it [00:03, 1068.69it/s]warmup run: 2372it [00:03, 1121.86it/s]warmup run: 2325it [00:03, 1102.58it/s]warmup run: 2448it [00:03, 1123.49it/s]warmup run: 2523it [00:03, 1163.38it/s]warmup run: 2272it [00:03, 1109.63it/s]warmup run: 2494it [00:03, 1127.43it/s]warmup run: 2270it [00:03, 1117.82it/s]warmup run: 2232it [00:03, 1111.13it/s]warmup run: 2493it [00:03, 1145.68it/s]warmup run: 2445it [00:03, 1131.27it/s]warmup run: 2567it [00:04, 1140.97it/s]warmup run: 2644it [00:04, 1174.50it/s]warmup run: 2393it [00:03, 1139.31it/s]warmup run: 2610it [00:04, 1136.51it/s]warmup run: 2393it [00:03, 1150.88it/s]warmup run: 2354it [00:03, 1140.85it/s]warmup run: 2608it [00:04, 1139.78it/s]warmup run: 2565it [00:04, 1150.94it/s]warmup run: 2686it [00:04, 1152.98it/s]warmup run: 2514it [00:03, 1159.47it/s]warmup run: 2765it [00:04, 1182.16it/s]warmup run: 2727it [00:04, 1143.87it/s]warmup run: 2514it [00:03, 1167.56it/s]warmup run: 2475it [00:03, 1160.26it/s]warmup run: 2727it [00:04, 1152.12it/s]warmup run: 2684it [00:04, 1160.69it/s]warmup run: 2802it [00:04, 1153.68it/s]warmup run: 2634it [00:04, 1170.88it/s]warmup run: 2885it [00:04, 1186.97it/s]warmup run: 2845it [00:04, 1153.54it/s]warmup run: 2634it [00:04, 1176.05it/s]warmup run: 2596it [00:04, 1174.80it/s]warmup run: 2848it [00:04, 1166.89it/s]warmup run: 2805it [00:04, 1172.48it/s]warmup run: 2920it [00:04, 1160.70it/s]warmup run: 2755it [00:04, 1181.81it/s]warmup run: 3000it [00:04, 690.79it/s] warmup run: 2962it [00:04, 1157.81it/s]warmup run: 2755it [00:04, 1185.45it/s]warmup run: 2717it [00:04, 1182.79it/s]warmup run: 2968it [00:04, 1176.64it/s]warmup run: 3000it [00:04, 676.05it/s] warmup run: 3000it [00:04, 674.95it/s] warmup run: 2925it [00:04, 1180.61it/s]warmup run: 3000it [00:04, 687.68it/s] warmup run: 2876it [00:04, 1190.04it/s]warmup run: 2877it [00:04, 1193.22it/s]warmup run: 2837it [00:04, 1184.86it/s]warmup run: 3000it [00:04, 684.33it/s] warmup run: 2997it [00:04, 1195.95it/s]warmup run: 3000it [00:04, 691.26it/s] warmup run: 2998it [00:04, 1196.00it/s]warmup run: 2956it [00:04, 1184.83it/s]warmup run: 3000it [00:04, 694.61it/s] warmup run: 3000it [00:04, 680.93it/s] 



warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   5%|▌         | 163/3000 [00:00<00:01, 1629.02it/s]warmup should be done:   5%|▌         | 160/3000 [00:00<00:01, 1597.49it/s]warmup should be done:   5%|▌         | 164/3000 [00:00<00:01, 1635.79it/s]warmup should be done:   5%|▌         | 164/3000 [00:00<00:01, 1636.17it/s]warmup should be done:   5%|▌         | 164/3000 [00:00<00:01, 1635.58it/s]warmup should be done:   5%|▌         | 164/3000 [00:00<00:01, 1634.01it/s]warmup should be done:   5%|▌         | 160/3000 [00:00<00:01, 1591.66it/s]warmup should be done:   5%|▌         | 160/3000 [00:00<00:01, 1590.77it/s]warmup should be done:  11%|█         | 329/3000 [00:00<00:01, 1643.87it/s]warmup should be done:  11%|█         | 321/3000 [00:00<00:01, 1601.59it/s]warmup should be done:  11%|█         | 328/3000 [00:00<00:01, 1634.26it/s]warmup should be done:  11%|█         | 322/3000 [00:00<00:01, 1605.13it/s]warmup should be done:  11%|█         | 331/3000 [00:00<00:01, 1649.34it/s]warmup should be done:  11%|█         | 323/3000 [00:00<00:01, 1608.56it/s]warmup should be done:  11%|█         | 328/3000 [00:00<00:01, 1355.43it/s]warmup should be done:  11%|█         | 326/3000 [00:00<00:02, 1332.06it/s]warmup should be done:  16%|█▋        | 492/3000 [00:00<00:01, 1633.70it/s]warmup should be done:  17%|█▋        | 496/3000 [00:00<00:01, 1648.86it/s]warmup should be done:  16%|█▋        | 494/3000 [00:00<00:01, 1639.94it/s]warmup should be done:  16%|█▌        | 482/3000 [00:00<00:01, 1596.73it/s]warmup should be done:  16%|█▌        | 483/3000 [00:00<00:01, 1600.04it/s]warmup should be done:  16%|█▌        | 484/3000 [00:00<00:01, 1584.57it/s]warmup should be done:  16%|█▋        | 492/3000 [00:00<00:01, 1470.11it/s]warmup should be done:  16%|█▋        | 488/3000 [00:00<00:01, 1448.86it/s]warmup should be done:  22%|██▏       | 658/3000 [00:00<00:01, 1637.75it/s]warmup should be done:  21%|██▏       | 642/3000 [00:00<00:01, 1597.81it/s]warmup should be done:  22%|██▏       | 656/3000 [00:00<00:01, 1631.68it/s]warmup should be done:  22%|██▏       | 661/3000 [00:00<00:01, 1643.70it/s]warmup should be done:  22%|██▏       | 648/3000 [00:00<00:01, 1618.32it/s]warmup should be done:  21%|██▏       | 643/3000 [00:00<00:01, 1580.64it/s]warmup should be done:  22%|██▏       | 656/3000 [00:00<00:01, 1531.57it/s]warmup should be done:  22%|██▏       | 653/3000 [00:00<00:01, 1521.95it/s]warmup should be done:  27%|██▋       | 820/3000 [00:00<00:01, 1634.30it/s]warmup should be done:  27%|██▋       | 822/3000 [00:00<00:01, 1636.26it/s]warmup should be done:  27%|██▋       | 813/3000 [00:00<00:01, 1628.04it/s]warmup should be done:  27%|██▋       | 802/3000 [00:00<00:01, 1593.17it/s]warmup should be done:  28%|██▊       | 826/3000 [00:00<00:01, 1641.97it/s]warmup should be done:  27%|██▋       | 804/3000 [00:00<00:01, 1589.57it/s]warmup should be done:  27%|██▋       | 820/3000 [00:00<00:01, 1567.12it/s]warmup should be done:  27%|██▋       | 818/3000 [00:00<00:01, 1563.22it/s]warmup should be done:  33%|███▎      | 984/3000 [00:00<00:01, 1631.78it/s]warmup should be done:  33%|███▎      | 978/3000 [00:00<00:01, 1634.38it/s]warmup should be done:  33%|███▎      | 986/3000 [00:00<00:01, 1632.29it/s]warmup should be done:  33%|███▎      | 991/3000 [00:00<00:01, 1638.30it/s]warmup should be done:  32%|███▏      | 962/3000 [00:00<00:01, 1585.89it/s]warmup should be done:  32%|███▏      | 963/3000 [00:00<00:01, 1583.48it/s]warmup should be done:  33%|███▎      | 982/3000 [00:00<00:01, 1582.25it/s]warmup should be done:  33%|███▎      | 981/3000 [00:00<00:01, 1583.83it/s]warmup should be done:  38%|███▊      | 1142/3000 [00:00<00:01, 1635.14it/s]warmup should be done:  38%|███▊      | 1151/3000 [00:00<00:01, 1635.98it/s]warmup should be done:  38%|███▊      | 1148/3000 [00:00<00:01, 1630.39it/s]warmup should be done:  38%|███▊      | 1155/3000 [00:00<00:01, 1638.69it/s]warmup should be done:  37%|███▋      | 1121/3000 [00:00<00:01, 1584.14it/s]warmup should be done:  37%|███▋      | 1122/3000 [00:00<00:01, 1583.38it/s]warmup should be done:  38%|███▊      | 1145/3000 [00:00<00:01, 1595.48it/s]warmup should be done:  38%|███▊      | 1146/3000 [00:00<00:01, 1602.16it/s]warmup should be done:  44%|████▍     | 1317/3000 [00:00<00:01, 1641.00it/s]warmup should be done:  44%|████▎     | 1306/3000 [00:00<00:01, 1630.53it/s]warmup should be done:  44%|████▎     | 1312/3000 [00:00<00:01, 1629.68it/s]warmup should be done:  43%|████▎     | 1280/3000 [00:00<00:01, 1582.06it/s]warmup should be done:  44%|████▍     | 1319/3000 [00:00<00:01, 1627.24it/s]warmup should be done:  43%|████▎     | 1282/3000 [00:00<00:01, 1588.17it/s]warmup should be done:  44%|████▎     | 1307/3000 [00:00<00:01, 1602.32it/s]warmup should be done:  44%|████▎     | 1310/3000 [00:00<00:01, 1611.48it/s]warmup should be done:  49%|████▉     | 1471/3000 [00:00<00:00, 1635.78it/s]warmup should be done:  49%|████▉     | 1475/3000 [00:00<00:00, 1627.45it/s]warmup should be done:  48%|████▊     | 1439/3000 [00:00<00:00, 1581.14it/s]warmup should be done:  48%|████▊     | 1443/3000 [00:00<00:00, 1591.95it/s]warmup should be done:  49%|████▉     | 1482/3000 [00:00<00:00, 1613.85it/s]warmup should be done:  49%|████▉     | 1482/3000 [00:00<00:00, 1608.84it/s]warmup should be done:  49%|████▉     | 1470/3000 [00:00<00:00, 1609.43it/s]warmup should be done:  49%|████▉     | 1472/3000 [00:00<00:00, 1603.81it/s]warmup should be done:  55%|█████▍    | 1636/3000 [00:01<00:00, 1639.64it/s]warmup should be done:  55%|█████▍    | 1639/3000 [00:01<00:00, 1629.10it/s]warmup should be done:  53%|█████▎    | 1598/3000 [00:01<00:00, 1574.59it/s]warmup should be done:  53%|█████▎    | 1603/3000 [00:01<00:00, 1592.47it/s]warmup should be done:  55%|█████▍    | 1645/3000 [00:01<00:00, 1618.04it/s]warmup should be done:  55%|█████▍    | 1643/3000 [00:01<00:00, 1596.41it/s]warmup should be done:  54%|█████▍    | 1634/3000 [00:01<00:00, 1618.09it/s]warmup should be done:  54%|█████▍    | 1633/3000 [00:01<00:00, 1599.97it/s]warmup should be done:  60%|██████    | 1802/3000 [00:01<00:00, 1643.31it/s]warmup should be done:  60%|██████    | 1802/3000 [00:01<00:00, 1626.07it/s]warmup should be done:  59%|█████▊    | 1756/3000 [00:01<00:00, 1571.42it/s]warmup should be done:  60%|██████    | 1810/3000 [00:01<00:00, 1626.41it/s]warmup should be done:  59%|█████▉    | 1763/3000 [00:01<00:00, 1585.00it/s]warmup should be done:  60%|██████    | 1803/3000 [00:01<00:00, 1587.84it/s]warmup should be done:  60%|██████    | 1800/3000 [00:01<00:00, 1627.93it/s]warmup should be done:  60%|█████▉    | 1796/3000 [00:01<00:00, 1607.64it/s]warmup should be done:  66%|██████▌   | 1967/3000 [00:01<00:00, 1643.98it/s]warmup should be done:  66%|██████▌   | 1965/3000 [00:01<00:00, 1625.17it/s]warmup should be done:  64%|██████▍   | 1914/3000 [00:01<00:00, 1568.66it/s]warmup should be done:  66%|██████▌   | 1976/3000 [00:01<00:00, 1634.28it/s]warmup should be done:  64%|██████▍   | 1923/3000 [00:01<00:00, 1588.12it/s]warmup should be done:  65%|██████▌   | 1962/3000 [00:01<00:00, 1583.25it/s]warmup should be done:  65%|██████▌   | 1963/3000 [00:01<00:00, 1621.05it/s]warmup should be done:  65%|██████▌   | 1959/3000 [00:01<00:00, 1612.63it/s]warmup should be done:  71%|███████   | 2133/3000 [00:01<00:00, 1646.23it/s]warmup should be done:  71%|███████   | 2129/3000 [00:01<00:00, 1628.81it/s]warmup should be done:  71%|███████▏  | 2142/3000 [00:01<00:00, 1640.98it/s]warmup should be done:  69%|██████▉   | 2073/3000 [00:01<00:00, 1572.46it/s]warmup should be done:  69%|██████▉   | 2083/3000 [00:01<00:00, 1591.24it/s]warmup should be done:  71%|███████   | 2121/3000 [00:01<00:00, 1585.05it/s]warmup should be done:  71%|███████   | 2126/3000 [00:01<00:00, 1606.27it/s]warmup should be done:  71%|███████   | 2123/3000 [00:01<00:00, 1619.88it/s]warmup should be done:  77%|███████▋  | 2299/3000 [00:01<00:00, 1648.28it/s]warmup should be done:  76%|███████▋  | 2292/3000 [00:01<00:00, 1628.70it/s]warmup should be done:  74%|███████▍  | 2232/3000 [00:01<00:00, 1575.00it/s]warmup should be done:  75%|███████▍  | 2243/3000 [00:01<00:00, 1590.98it/s]warmup should be done:  77%|███████▋  | 2307/3000 [00:01<00:00, 1627.61it/s]warmup should be done:  76%|███████▌  | 2280/3000 [00:01<00:00, 1579.44it/s]warmup should be done:  76%|███████▋  | 2291/3000 [00:01<00:00, 1618.83it/s]warmup should be done:  76%|███████▋  | 2289/3000 [00:01<00:00, 1630.56it/s]warmup should be done:  82%|████████▏ | 2464/3000 [00:01<00:00, 1645.82it/s]warmup should be done:  82%|████████▏ | 2456/3000 [00:01<00:00, 1629.76it/s]warmup should be done:  80%|████████  | 2403/3000 [00:01<00:00, 1590.26it/s]warmup should be done:  81%|████████▏ | 2438/3000 [00:01<00:00, 1575.42it/s]warmup should be done:  82%|████████▏ | 2470/3000 [00:01<00:00, 1600.50it/s]warmup should be done:  80%|███████▉  | 2390/3000 [00:01<00:00, 1523.99it/s]warmup should be done:  82%|████████▏ | 2458/3000 [00:01<00:00, 1631.23it/s]warmup should be done:  82%|████████▏ | 2453/3000 [00:01<00:00, 1626.97it/s]warmup should be done:  88%|████████▊ | 2629/3000 [00:01<00:00, 1646.72it/s]warmup should be done:  87%|████████▋ | 2620/3000 [00:01<00:00, 1631.82it/s]warmup should be done:  85%|████████▌ | 2563/3000 [00:01<00:00, 1592.42it/s]warmup should be done:  87%|████████▋ | 2596/3000 [00:01<00:00, 1573.06it/s]warmup should be done:  88%|████████▊ | 2635/3000 [00:01<00:00, 1613.45it/s]warmup should be done:  85%|████████▍ | 2547/3000 [00:01<00:00, 1534.81it/s]warmup should be done:  88%|████████▊ | 2626/3000 [00:01<00:00, 1643.05it/s]warmup should be done:  87%|████████▋ | 2617/3000 [00:01<00:00, 1628.42it/s]warmup should be done:  93%|█████████▎| 2794/3000 [00:01<00:00, 1647.58it/s]warmup should be done:  93%|█████████▎| 2785/3000 [00:01<00:00, 1635.05it/s]warmup should be done:  91%|█████████ | 2723/3000 [00:01<00:00, 1594.65it/s]warmup should be done:  92%|█████████▏| 2754/3000 [00:01<00:00, 1570.80it/s]warmup should be done:  93%|█████████▎| 2801/3000 [00:01<00:00, 1626.71it/s]warmup should be done:  90%|█████████ | 2706/3000 [00:01<00:00, 1549.36it/s]warmup should be done:  93%|█████████▎| 2793/3000 [00:01<00:00, 1650.75it/s]warmup should be done:  93%|█████████▎| 2781/3000 [00:01<00:00, 1630.36it/s]warmup should be done:  99%|█████████▊| 2961/3000 [00:01<00:00, 1651.88it/s]warmup should be done:  98%|█████████▊| 2951/3000 [00:01<00:00, 1640.08it/s]warmup should be done:  96%|█████████▌| 2885/3000 [00:01<00:00, 1600.06it/s]warmup should be done:  97%|█████████▋| 2913/3000 [00:01<00:00, 1575.60it/s]warmup should be done:  99%|█████████▉| 2969/3000 [00:01<00:00, 1640.62it/s]warmup should be done:  96%|█████████▌| 2866/3000 [00:01<00:00, 1563.36it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1638.32it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1632.42it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1630.84it/s]warmup should be done:  99%|█████████▊| 2960/3000 [00:01<00:00, 1655.49it/s]warmup should be done:  98%|█████████▊| 2946/3000 [00:01<00:00, 1635.20it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1604.82it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1600.04it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1595.91it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1592.93it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1572.27it/s]






warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|▌         | 171/3000 [00:00<00:01, 1709.71it/s]warmup should be done:   6%|▌         | 168/3000 [00:00<00:01, 1677.68it/s]warmup should be done:   6%|▌         | 167/3000 [00:00<00:01, 1667.69it/s]warmup should be done:   5%|▌         | 164/3000 [00:00<00:01, 1635.58it/s]warmup should be done:   5%|▌         | 161/3000 [00:00<00:01, 1606.88it/s]warmup should be done:   6%|▌         | 168/3000 [00:00<00:01, 1673.96it/s]warmup should be done:   6%|▌         | 170/3000 [00:00<00:01, 1691.81it/s]warmup should be done:   6%|▌         | 170/3000 [00:00<00:01, 1691.04it/s]warmup should be done:  11%|█▏        | 343/3000 [00:00<00:01, 1713.78it/s]warmup should be done:  11%|█▏        | 338/3000 [00:00<00:01, 1686.48it/s]warmup should be done:  11%|█         | 328/3000 [00:00<00:01, 1634.28it/s]warmup should be done:  11%|█         | 324/3000 [00:00<00:01, 1616.45it/s]warmup should be done:  11%|█         | 336/3000 [00:00<00:01, 1675.05it/s]warmup should be done:  11%|█▏        | 340/3000 [00:00<00:01, 1693.74it/s]warmup should be done:  11%|█         | 337/3000 [00:00<00:01, 1678.52it/s]warmup should be done:  11%|█▏        | 341/3000 [00:00<00:01, 1696.89it/s]warmup should be done:  17%|█▋        | 515/3000 [00:00<00:01, 1715.74it/s]warmup should be done:  17%|█▋        | 508/3000 [00:00<00:01, 1690.84it/s]warmup should be done:  17%|█▋        | 510/3000 [00:00<00:01, 1695.71it/s]warmup should be done:  17%|█▋        | 505/3000 [00:00<00:01, 1680.42it/s]warmup should be done:  16%|█▋        | 492/3000 [00:00<00:01, 1634.05it/s]warmup should be done:  17%|█▋        | 511/3000 [00:00<00:01, 1697.05it/s]warmup should be done:  17%|█▋        | 506/3000 [00:00<00:01, 1681.15it/s]warmup should be done:  16%|█▋        | 488/3000 [00:00<00:01, 1622.49it/s]warmup should be done:  23%|██▎       | 687/3000 [00:00<00:01, 1714.22it/s]warmup should be done:  23%|██▎       | 678/3000 [00:00<00:01, 1690.04it/s]warmup should be done:  22%|██▎       | 675/3000 [00:00<00:01, 1684.69it/s]warmup should be done:  23%|██▎       | 681/3000 [00:00<00:01, 1697.73it/s]warmup should be done:  23%|██▎       | 682/3000 [00:00<00:01, 1699.95it/s]warmup should be done:  22%|██▏       | 651/3000 [00:00<00:01, 1623.17it/s]warmup should be done:  22%|██▎       | 675/3000 [00:00<00:01, 1680.97it/s]warmup should be done:  22%|██▏       | 656/3000 [00:00<00:01, 1630.57it/s]warmup should be done:  29%|██▊       | 859/3000 [00:00<00:01, 1712.35it/s]warmup should be done:  28%|██▊       | 852/3000 [00:00<00:01, 1699.67it/s]warmup should be done:  28%|██▊       | 848/3000 [00:00<00:01, 1692.77it/s]warmup should be done:  28%|██▊       | 852/3000 [00:00<00:01, 1700.80it/s]warmup should be done:  28%|██▊       | 846/3000 [00:00<00:01, 1690.82it/s]warmup should be done:  28%|██▊       | 844/3000 [00:00<00:01, 1683.23it/s]warmup should be done:  27%|██▋       | 814/3000 [00:00<00:01, 1620.43it/s]warmup should be done:  27%|██▋       | 820/3000 [00:00<00:01, 1629.38it/s]warmup should be done:  34%|███▍      | 1023/3000 [00:00<00:01, 1703.32it/s]warmup should be done:  34%|███▍      | 1017/3000 [00:00<00:01, 1696.70it/s]warmup should be done:  34%|███▍      | 1019/3000 [00:00<00:01, 1695.48it/s]warmup should be done:  33%|███▎      | 977/3000 [00:00<00:01, 1623.37it/s]warmup should be done:  34%|███▍      | 1031/3000 [00:00<00:01, 1706.33it/s]warmup should be done:  34%|███▍      | 1013/3000 [00:00<00:01, 1680.06it/s]warmup should be done:  33%|███▎      | 984/3000 [00:00<00:01, 1631.17it/s]warmup should be done:  34%|███▍      | 1022/3000 [00:00<00:01, 1685.75it/s]warmup should be done:  40%|███▉      | 1188/3000 [00:00<00:01, 1700.50it/s]warmup should be done:  40%|███▉      | 1194/3000 [00:00<00:01, 1702.04it/s]warmup should be done:  38%|███▊      | 1141/3000 [00:00<00:01, 1627.69it/s]warmup should be done:  40%|███▉      | 1189/3000 [00:00<00:01, 1691.83it/s]warmup should be done:  38%|███▊      | 1148/3000 [00:00<00:01, 1631.70it/s]warmup should be done:  39%|███▉      | 1182/3000 [00:00<00:01, 1678.14it/s]warmup should be done:  40%|████      | 1202/3000 [00:00<00:01, 1699.49it/s]warmup should be done:  40%|███▉      | 1193/3000 [00:00<00:01, 1691.00it/s]warmup should be done:  45%|████▌     | 1360/3000 [00:00<00:00, 1705.57it/s]warmup should be done:  46%|████▌     | 1365/3000 [00:00<00:00, 1704.32it/s]warmup should be done:  45%|████▌     | 1359/3000 [00:00<00:00, 1691.53it/s]warmup should be done:  43%|████▎     | 1304/3000 [00:00<00:01, 1621.50it/s]warmup should be done:  45%|████▌     | 1350/3000 [00:00<00:00, 1676.19it/s]warmup should be done:  46%|████▌     | 1372/3000 [00:00<00:00, 1699.38it/s]warmup should be done:  44%|████▎     | 1312/3000 [00:00<00:01, 1628.28it/s]warmup should be done:  46%|████▌     | 1365/3000 [00:00<00:00, 1697.12it/s]warmup should be done:  51%|█████     | 1531/3000 [00:00<00:00, 1705.62it/s]warmup should be done:  51%|█████     | 1536/3000 [00:00<00:00, 1701.37it/s]warmup should be done:  49%|████▉     | 1467/3000 [00:00<00:00, 1622.55it/s]warmup should be done:  51%|█████▏    | 1542/3000 [00:00<00:00, 1697.64it/s]warmup should be done:  49%|████▉     | 1476/3000 [00:00<00:00, 1629.66it/s]warmup should be done:  51%|█████     | 1535/3000 [00:00<00:00, 1697.51it/s]warmup should be done:  51%|█████     | 1529/3000 [00:00<00:00, 1685.28it/s]warmup should be done:  51%|█████     | 1518/3000 [00:00<00:00, 1669.37it/s]warmup should be done:  57%|█████▋    | 1702/3000 [00:01<00:00, 1706.76it/s]warmup should be done:  57%|█████▋    | 1707/3000 [00:01<00:00, 1700.76it/s]warmup should be done:  54%|█████▍    | 1630/3000 [00:01<00:00, 1624.79it/s]warmup should be done:  57%|█████▋    | 1712/3000 [00:01<00:00, 1697.04it/s]warmup should be done:  55%|█████▍    | 1640/3000 [00:01<00:00, 1632.43it/s]warmup should be done:  57%|█████▋    | 1698/3000 [00:01<00:00, 1686.38it/s]warmup should be done:  57%|█████▋    | 1706/3000 [00:01<00:00, 1699.28it/s]warmup should be done:  56%|█████▌    | 1687/3000 [00:01<00:00, 1674.55it/s]warmup should be done:  62%|██████▎   | 1875/3000 [00:01<00:00, 1710.79it/s]warmup should be done:  63%|██████▎   | 1878/3000 [00:01<00:00, 1701.70it/s]warmup should be done:  60%|█████▉    | 1793/3000 [00:01<00:00, 1623.11it/s]warmup should be done:  63%|██████▎   | 1882/3000 [00:01<00:00, 1696.68it/s]warmup should be done:  60%|██████    | 1804/3000 [00:01<00:00, 1632.23it/s]warmup should be done:  62%|██████▏   | 1868/3000 [00:01<00:00, 1688.60it/s]warmup should be done:  63%|██████▎   | 1878/3000 [00:01<00:00, 1702.70it/s]warmup should be done:  62%|██████▏   | 1857/3000 [00:01<00:00, 1680.18it/s]warmup should be done:  68%|██████▊   | 2047/3000 [00:01<00:00, 1712.12it/s]warmup should be done:  68%|██████▊   | 2050/3000 [00:01<00:00, 1704.23it/s]warmup should be done:  65%|██████▌   | 1956/3000 [00:01<00:00, 1622.27it/s]warmup should be done:  68%|██████▊   | 2052/3000 [00:01<00:00, 1693.21it/s]warmup should be done:  68%|██████▊   | 2049/3000 [00:01<00:00, 1704.12it/s]warmup should be done:  68%|██████▊   | 2038/3000 [00:01<00:00, 1689.14it/s]warmup should be done:  66%|██████▌   | 1968/3000 [00:01<00:00, 1630.29it/s]warmup should be done:  68%|██████▊   | 2026/3000 [00:01<00:00, 1683.13it/s]warmup should be done:  74%|███████▍  | 2219/3000 [00:01<00:00, 1709.79it/s]warmup should be done:  74%|███████▍  | 2221/3000 [00:01<00:00, 1703.88it/s]warmup should be done:  71%|███████   | 2119/3000 [00:01<00:00, 1623.89it/s]warmup should be done:  73%|███████▎  | 2195/3000 [00:01<00:00, 1684.08it/s]warmup should be done:  74%|███████▎  | 2207/3000 [00:01<00:00, 1686.86it/s]warmup should be done:  74%|███████▍  | 2220/3000 [00:01<00:00, 1702.36it/s]warmup should be done:  71%|███████   | 2132/3000 [00:01<00:00, 1630.61it/s]warmup should be done:  74%|███████▍  | 2222/3000 [00:01<00:00, 1687.01it/s]warmup should be done:  80%|███████▉  | 2390/3000 [00:01<00:00, 1709.31it/s]warmup should be done:  80%|███████▉  | 2392/3000 [00:01<00:00, 1703.54it/s]warmup should be done:  76%|███████▌  | 2283/3000 [00:01<00:00, 1626.00it/s]warmup should be done:  79%|███████▉  | 2376/3000 [00:01<00:00, 1686.89it/s]warmup should be done:  77%|███████▋  | 2296/3000 [00:01<00:00, 1631.99it/s]warmup should be done:  79%|███████▉  | 2364/3000 [00:01<00:00, 1682.11it/s]warmup should be done:  80%|███████▉  | 2391/3000 [00:01<00:00, 1685.10it/s]warmup should be done:  80%|███████▉  | 2391/3000 [00:01<00:00, 1683.03it/s]warmup should be done:  85%|████████▌ | 2562/3000 [00:01<00:00, 1711.01it/s]warmup should be done:  85%|████████▌ | 2563/3000 [00:01<00:00, 1704.61it/s]warmup should be done:  82%|████████▏ | 2449/3000 [00:01<00:00, 1635.75it/s]warmup should be done:  85%|████████▍ | 2545/3000 [00:01<00:00, 1687.23it/s]warmup should be done:  82%|████████▏ | 2460/3000 [00:01<00:00, 1630.94it/s]warmup should be done:  85%|████████▌ | 2560/3000 [00:01<00:00, 1685.59it/s]warmup should be done:  84%|████████▍ | 2533/3000 [00:01<00:00, 1671.28it/s]warmup should be done:  85%|████████▌ | 2562/3000 [00:01<00:00, 1688.68it/s]warmup should be done:  91%|█████████ | 2735/3000 [00:01<00:00, 1713.71it/s]warmup should be done:  91%|█████████ | 2734/3000 [00:01<00:00, 1704.51it/s]warmup should be done:  87%|████████▋ | 2619/3000 [00:01<00:00, 1654.61it/s]warmup should be done:  90%|█████████ | 2715/3000 [00:01<00:00, 1688.75it/s]warmup should be done:  87%|████████▋ | 2624/3000 [00:01<00:00, 1629.02it/s]warmup should be done:  91%|█████████ | 2729/3000 [00:01<00:00, 1672.62it/s]warmup should be done:  90%|█████████ | 2701/3000 [00:01<00:00, 1653.41it/s]warmup should be done:  91%|█████████ | 2731/3000 [00:01<00:00, 1673.61it/s]warmup should be done:  97%|█████████▋| 2907/3000 [00:01<00:00, 1714.98it/s]warmup should be done:  97%|█████████▋| 2905/3000 [00:01<00:00, 1704.08it/s]warmup should be done:  93%|█████████▎| 2791/3000 [00:01<00:00, 1673.53it/s]warmup should be done:  96%|█████████▌| 2885/3000 [00:01<00:00, 1689.18it/s]warmup should be done:  93%|█████████▎| 2788/3000 [00:01<00:00, 1630.77it/s]warmup should be done:  97%|█████████▋| 2898/3000 [00:01<00:00, 1676.09it/s]warmup should be done:  97%|█████████▋| 2900/3000 [00:01<00:00, 1677.91it/s]warmup should be done:  96%|█████████▌| 2867/3000 [00:01<00:00, 1640.90it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1704.76it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1701.94it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1692.58it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1691.42it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1689.00it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1668.29it/s]warmup should be done:  99%|█████████▉| 2963/3000 [00:01<00:00, 1687.10it/s]warmup should be done:  98%|█████████▊| 2953/3000 [00:01<00:00, 1633.59it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1640.48it/s]warmup should be done: 100%|██████████| 3000/3000 [00:01<00:00, 1631.13it/s]2022-12-12 07:33:13.813304: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f075f82fb10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:33:13.813373: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:33:14.280425: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7ee76c02a490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:33:14.280488: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:33:14.281153: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f0767833f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:33:14.281207: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:33:14.295491: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x1c349bd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:33:14.295550: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:33:14.300946: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f0767830030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:33:14.300996: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:33:14.496216: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7ee7b802e830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:33:14.496281: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:33:14.543851: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7ee84802fec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:33:14.543922: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:33:14.581772: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7ee76402a490 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:33:14.581852: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:33:16.047326: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:33:16.504954: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:33:16.571490: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:33:16.578828: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:33:16.586886: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:33:16.811985: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:33:16.872169: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:33:16.879926: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:33:18.916673: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:33:19.345375: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:33:19.525502: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:33:19.529605: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:33:19.550268: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:33:19.726158: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:33:19.746930: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:33:19.909099: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][07:33:42.846][ERROR][RK0][main]: replica 4 reaches 1000, calling init pre replica
[HCTR][07:33:42.846][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:33:42.857][ERROR][RK0][main]: coll ps creation done
[HCTR][07:33:42.857][ERROR][RK0][main]: replica 4 waits for coll ps creation barrier
[HCTR][07:33:42.868][ERROR][RK0][main]: replica 2 reaches 1000, calling init pre replica
[HCTR][07:33:42.868][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:33:42.871][ERROR][RK0][tid #139670407059200]: replica 3 reaches 1000, calling init pre replica
[HCTR][07:33:42.871][ERROR][RK0][tid #139670407059200]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:33:42.876][ERROR][RK0][main]: coll ps creation done
[HCTR][07:33:42.876][ERROR][RK0][main]: replica 2 waits for coll ps creation barrier
[HCTR][07:33:42.879][ERROR][RK0][tid #139670407059200]: coll ps creation done
[HCTR][07:33:42.879][ERROR][RK0][tid #139670407059200]: replica 3 waits for coll ps creation barrier
[HCTR][07:33:42.903][ERROR][RK0][tid #139670876821248]: replica 1 reaches 1000, calling init pre replica
[HCTR][07:33:42.903][ERROR][RK0][tid #139670876821248]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:33:42.912][ERROR][RK0][tid #139670876821248]: coll ps creation done
[HCTR][07:33:42.912][ERROR][RK0][tid #139670876821248]: replica 1 waits for coll ps creation barrier
[HCTR][07:33:42.917][ERROR][RK0][tid #139670339950336]: replica 5 reaches 1000, calling init pre replica
[HCTR][07:33:42.917][ERROR][RK0][tid #139670339950336]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:33:42.923][ERROR][RK0][tid #139670339950336]: coll ps creation done
[HCTR][07:33:42.923][ERROR][RK0][tid #139670339950336]: replica 5 waits for coll ps creation barrier
[HCTR][07:33:42.930][ERROR][RK0][tid #139669920544512]: replica 7 reaches 1000, calling init pre replica
[HCTR][07:33:42.930][ERROR][RK0][tid #139669920544512]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:33:42.939][ERROR][RK0][tid #139669920544512]: coll ps creation done
[HCTR][07:33:42.939][ERROR][RK0][tid #139669920544512]: replica 7 waits for coll ps creation barrier
[HCTR][07:33:42.945][ERROR][RK0][main]: replica 6 reaches 1000, calling init pre replica
[HCTR][07:33:42.945][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:33:42.950][ERROR][RK0][main]: coll ps creation done
[HCTR][07:33:42.950][ERROR][RK0][main]: replica 6 waits for coll ps creation barrier
[HCTR][07:33:42.963][ERROR][RK0][main]: replica 0 reaches 1000, calling init pre replica
[HCTR][07:33:42.963][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:33:42.970][ERROR][RK0][main]: coll ps creation done
[HCTR][07:33:42.970][ERROR][RK0][main]: replica 0 waits for coll ps creation barrier
[HCTR][07:33:42.970][ERROR][RK0][main]: replica 0 preparing frequency
[HCTR][07:33:43.874][ERROR][RK0][main]: replica 0 preparing frequency done
[HCTR][07:33:43.925][ERROR][RK0][main]: replica 0 calling init per replica
[HCTR][07:33:43.925][ERROR][RK0][main]: replica 2 calling init per replica
[HCTR][07:33:43.925][ERROR][RK0][tid #139669920544512]: replica 7 calling init per replica
[HCTR][07:33:43.925][ERROR][RK0][tid #139670407059200]: replica 3 calling init per replica
[HCTR][07:33:43.925][ERROR][RK0][main]: replica 6 calling init per replica
[HCTR][07:33:43.925][ERROR][RK0][main]: replica 4 calling init per replica
[HCTR][07:33:43.925][ERROR][RK0][tid #139670876821248]: replica 1 calling init per replica
[HCTR][07:33:43.925][ERROR][RK0][tid #139670339950336]: replica 5 calling init per replica
[HCTR][07:33:43.925][ERROR][RK0][main]: Calling build_v2
[HCTR][07:33:43.925][ERROR][RK0][main]: Calling build_v2
[HCTR][07:33:43.925][ERROR][RK0][tid #139669920544512]: Calling build_v2
[HCTR][07:33:43.925][ERROR][RK0][tid #139670407059200]: Calling build_v2
[HCTR][07:33:43.925][ERROR][RK0][main]: Calling build_v2
[HCTR][07:33:43.925][ERROR][RK0][main]: Calling build_v2
[HCTR][07:33:43.925][ERROR][RK0][tid #139670876821248]: Calling build_v2
[HCTR][07:33:43.925][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:33:43.925][ERROR][RK0][tid #139670339950336]: Calling build_v2
[HCTR][07:33:43.925][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:33:43.925][ERROR][RK0][tid #139669920544512]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:33:43.925][ERROR][RK0][tid #139670407059200]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:33:43.925][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:33:43.925][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:33:43.925][ERROR][RK0][tid #139670876821248]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:33:43.925][ERROR][RK0][tid #139670339950336]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[2022-12-12 07:33:43.929831: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie[
[2022-12-12 07:33:432022-12-12 07:33:43..929881929913: : E[E  /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc::178196] ] v100x8, slow pcieassigning 0 to cpu
2022-12-12 07:33:43
.929919: [E2022-12-12 07:33:43 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[929983:: 178E]  [2022-12-12 07:33:43v100x8, slow pcie/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:33:43.
[:.929973196[930017: 2022-12-12 07:33:43] 2022-12-12 07:33:43: E.assigning 0 to cpu.E 930016
930054 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: : /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:EE:[178 [ 2022-12-12 07:33:43212] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:33:43/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.] [v100x8, slow pcie:.:2022-12-12 07:33:43930117build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8
178930138196.: [
] : [] 930158Ev100x8, slow pcieE2022-12-12 07:33:432022-12-12 07:33:43assigning 0 to cpu[:  
 ..
2022-12-12 07:33:43E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc930206[930228. ::: 2022-12-12 07:33:43: [930264/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc178212E.E2022-12-12 07:33:43: :] ]  930304 .E178v100x8, slow pciebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc930337 ] 

:E:: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccv100x8, slow pcie178 [196E[:
] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:33:43]  2022-12-12 07:33:43213v100x8, slow pcie:.[assigning 0 to cpu/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.] 
1969304552022-12-12 07:33:43
:930466remote time is 8.68421] : .[212: 
assigning 0 to cpuE9304972022-12-12 07:33:43] E
 : [.build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8[ /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE2022-12-12 07:33:43930538
2022-12-12 07:33:43/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[: .: .:2022-12-12 07:33:43[196/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc930573E930580213.2022-12-12 07:33:43] ::  : ] 930614.assigning 0 to cpu196E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccEremote time is 8.68421: 930643
]  : 
E: [assigning 0 to cpu/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc196/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc E2022-12-12 07:33:43[
:] :/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc .2022-12-12 07:33:43214assigning 0 to cpu212:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc930790.] 
] 212[:: 930792cpu time is 97.0588build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8] 2022-12-12 07:33:43213E: 

build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8.]  E
[930862remote time is 8.68421/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc [[2022-12-12 07:33:43: 
:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:33:432022-12-12 07:33:43.E214:[..930928 ] 2122022-12-12 07:33:43930956930941: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cccpu time is 97.0588] .: : E:
build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8930976EE 212
:   /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8[ ::212
2022-12-12 07:33:43/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc213213] .:] ] [build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8931091214remote time is 8.68421remote time is 8.684212022-12-12 07:33:43
: ] 

.Ecpu time is 97.0588[931160 [[
2022-12-12 07:33:43: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:33:432022-12-12 07:33:43.E:..931206 213931211931213: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] : : E:remote time is 8.68421EE 213
  /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:remote time is 8.68421[::213
2022-12-12 07:33:43214214] .] ] [remote time is 8.68421931293cpu time is 97.0588cpu time is 97.05882022-12-12 07:33:43
: 

.E[931316 2022-12-12 07:33:43: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.E:931343 214: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] E:cpu time is 97.0588 214
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] :cpu time is 97.0588214
] cpu time is 97.0588
[2022-12-12 07:35:03.303656: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-12 07:35:03.343652: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-12 07:35:03.343725: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 30000001
[2022-12-12 07:35:03.449980: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-12 07:35:03.450075: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-12 07:35:03.486707: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-12 07:35:03.486744: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-12 07:35:03.487232: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.488215: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.489028: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.501885: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 5 solved
[2022-12-12 07:35:03.501944: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 5 initing device 5
[[[2022-12-12 07:35:032022-12-12 07:35:03[2022-12-12 07:35:03..2022-12-12 07:35:03.502194502205.502203: : 502212: EE: [E  E2022-12-12 07:35:03 /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc ./hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc502265:202202:: 202[] [] 202E] 2022-12-12 07:35:031 solved2022-12-12 07:35:037 solved]  4 solved.
.
6 solved/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc
502308502329[
:[: : [2022-12-12 07:35:032022022-12-12 07:35:03[EE2022-12-12 07:35:03.] .2022-12-12 07:35:03  .5024093 solved502414./hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu502422: 
: 502434::: EE: [2021980E  E2022-12-12 07:35:03] ]  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc .2 solvedeager alloc mem 381.47 MB/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc502515

:205205:: 205] [] 205E] worker 0 thread 1 initing device 12022-12-12 07:35:03worker 0 thread 7 initing device 7]  worker 0 thread 4 initing device 4
.
worker 0 thread 6 initing device 6/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc
502607
:: 205E]  worker 0 thread 3 initing device 3/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc
:205] worker 0 thread 2 initing device 2
[2022-12-12 07:35:03.503013: E[ 2022-12-12 07:35:03/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.:5030261980: ] [Eeager alloc mem 381.47 MB2022-12-12 07:35:03 [
./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 07:35:03503045:.: 1980503053[E] : 2022-12-12 07:35:03 eager alloc mem 381.47 MBE./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
 503076:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: 1980:E] 1980 eager alloc mem 381.47 MB] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
eager alloc mem 381.47 MB[:
2022-12-12 07:35:031980.] 503140eager alloc mem 381.47 MB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.506911: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.507348: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.507396: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.507453: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.507943: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.508050: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.508115: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.511492: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.511791: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.511854: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.511899: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.512432: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.512485: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.512549: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:35:03.570592: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 07:35:03.570987: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 07:35:03.576574: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:35:03.576675: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 07:35:03.576720: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:35:03.577562: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:35:03.578208: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:03.579334: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:03.579446: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:35:03.580129: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:35:03.580172: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:35:03.598775: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[[2022-12-12 07:35:03[2022-12-12 07:35:03.2022-12-12 07:35:03.598835.[[598845: 5988472022-12-12 07:35:032022-12-12 07:35:03: E: ..E E598867598867 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu : : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuEE:1980:  1980] 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] eager alloc mem 2.00 Bytes] ::eager alloc mem 2.00 Bytes
eager alloc mem 2.00 Bytes19801980

] ] eager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes

[2022-12-12 07:35:03.599092: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 07:35:03[.2022-12-12 07:35:03599237.[: [599241[2022-12-12 07:35:03E2022-12-12 07:35:03: 2022-12-12 07:35:03. .E.599248/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu599252 599254: :: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: E1980E:E ]  1980 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 1024.00 Bytes/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:
:eager alloc mem 1024.00 Bytes:19801980
1980] ] ] eager alloc mem 1024.00 Byteseager alloc mem 1024.00 Byteseager alloc mem 1024.00 Bytes


[2022-12-12 07:35:03.603746: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 07:35:03.604062: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 07:35:03.631868: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:35:03.631956: [E2022-12-12 07:35:03 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc631943:: 638E]  eager release cuda mem 2/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 1024
[[2022-12-12 07:35:032022-12-12 07:35:03..[6320056320232022-12-12 07:35:03: : .EE632034  : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE:: 638638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] ] :eager release cuda mem 1024eager release cuda mem 400000000638

] [eager release cuda mem 22022-12-12 07:35:03
.632083: [E2022-12-12 07:35:03 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc632114:: [638E2022-12-12 07:35:03]  .eager release cuda mem 1024/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc632130
:: 638E]  eager release cuda mem 2/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:[6382022-12-12 07:35:03] .eager release cuda mem 400000000632173
[: [2022-12-12 07:35:03E2022-12-12 07:35:03. .632171/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc632191: :: E638E ]  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 2/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:
:638638] ] eager release cuda mem 1024eager release cuda mem 400000000

[2022-12-12 07:35:03.632263: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] [2022-12-12 07:35:03eager release cuda mem 4000000002022-12-12 07:35:03.
.632265632281: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638[638] 2022-12-12 07:35:03] eager release cuda mem 1024.eager release cuda mem 2
632326
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 10242022-12-12 07:35:03[
.2022-12-12 07:35:03632399.: 632409E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[ :2022-12-12 07:35:03/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638.:] 632438638eager release cuda mem 2: ] 
Eeager release cuda mem 400000000 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 07:35:03eager release cuda mem 2.
632520: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:35:03.632561: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:35:03.632974: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:35:03.634165: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:35:03.634669: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:35:03.635538: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:35:03.645282: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:35:03.645920: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:35:03.646437: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:35:03.647649: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:03.648288: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:03.648323: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:03.648567: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:03.648612: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:03.648656: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 07:35:03eager alloc mem 611.00 KB.
648683: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:03.648711: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:03.648782: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:35:03.649308: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:03.649345: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:35:03.649384: [E[2022-12-12 07:35:03 2022-12-12 07:35:03./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.649391:649391: 1980: E] E eager alloc mem 14.31 GB /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::1980638] ] eager alloc mem 25.25 KBeager release cuda mem 625663

[2022-12-12 07:35:03.649517: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:35:03.649567: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:03.649650: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 25.25 KB2022-12-12 07:35:03
.649666: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:03.649742: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:03.649774: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:35:03.649812: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 6256632022-12-12 07:35:03
.649834: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:35:03.649910: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:35:03.649988: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:35:03.650030: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:35:03.650073: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:35:03.650114: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:35:03.650210: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:35:03.650251: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:35:03.650451: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:35:03.650492: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:35:03.650520: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:35:03.650560: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:35:03.650585: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:35:03.650626: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[[[[[[[[2022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:06........919967919967919966919967919970919978919980919983: : : : : : : : EEEEEEEE        /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::::::19801980198019801980198019801980] ] ] ] ] ] ] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB







[[[[2022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:06.[[...[9211172022-12-12 07:35:06[2022-12-12 07:35:069211189211209211202022-12-12 07:35:06: .2022-12-12 07:35:06.: : : .E921133.921136EEE921143 : 921151:    : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: E ::: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638638638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:] ] ] :eager release cuda mem 625663638:638eager release cuda mem 625663eager release cuda mem 625663eager release cuda mem 625663638
] 638] 


] eager release cuda mem 625663] eager release cuda mem 625663eager release cuda mem 625663
eager release cuda mem 625663


[2022-12-12 07:35:06.921471: [E[2022-12-12 07:35:06 2022-12-12 07:35:06[./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.2022-12-12 07:35:06921481[[:[921485.: [2022-12-12 07:35:062022-12-12 07:35:0619802022-12-12 07:35:06: 921490E2022-12-12 07:35:06..] .E:  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.921508921501eager alloc mem 611.00 KB921504 E:921512: : 
: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 1980: EEE:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] E   1980:eager alloc mem 611.00 KB /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] 1980
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:::eager alloc mem 611.00 KB] :198019801980
eager alloc mem 611.00 KB1980] ] ] 
] eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB



[2022-12-12 07:35:06.922356: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06[.2022-12-12 07:35:06922424.: 922429E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[638:2022-12-12 07:35:06] 1980.eager release cuda mem 625663] 922455
eager alloc mem 611.00 KB[: 
2022-12-12 07:35:06E[[[.[ 2022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:069224772022-12-12 07:35:06/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc...[: .:9224879224869224902022-12-12 07:35:06E922493: 638: : : . E] EEE922528/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc eager release cuda mem 625663   : :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE638:::: ] 638638638638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 625663] ] ] ] :
[eager release cuda mem 625663eager release cuda mem 625663eager release cuda mem 625663eager release cuda mem 62566319802022-12-12 07:35:06



] .eager alloc mem 611.00 KB922710
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 07:35:06eager alloc mem 611.00 KB.
922774: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:[[[1980[2022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:06] 2022-12-12 07:35:06...eager alloc mem 611.00 KB.922795922798922799
922804: : : : EEEE    /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::1980198019801980] ] ] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB



[2022-12-12 07:35:06.923218: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.923293: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:06.923498: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663[
2022-12-12 07:35:06.923520: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.923572: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 07:35:06[eager alloc mem 611.00 KB.2022-12-12 07:35:06
923592.: 923599E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638:] 1980[eager release cuda mem 625663] [[[2022-12-12 07:35:06
eager alloc mem 611.00 KB2022-12-12 07:35:062022-12-12 07:35:062022-12-12 07:35:06.
...923650923657923658923659: : : : EEEE    /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::2022-12-12 07:35:06::638638.638638] ] 923733] ] eager release cuda mem 625663eager release cuda mem 625663: eager release cuda mem 625663eager release cuda mem 625663

E

 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[[2022-12-12 07:35:062022-12-12 07:35:06[..2022-12-12 07:35:06[923862923865.2022-12-12 07:35:06: : 923872.EE: 923876  E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu E::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 19801980:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] ] 1980:eager alloc mem 611.00 KBeager alloc mem 611.00 KB] 1980

eager alloc mem 611.00 KB] 
eager alloc mem 611.00 KB
[2022-12-12 07:35:06.924049: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.924119: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:06.924353: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.924422: E[ 2022-12-12 07:35:06/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.:9244311980: ] Eeager alloc mem 611.00 KB 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.924515: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:06.924575: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.924654: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[[2022-12-12 07:35:06[2022-12-12 07:35:06.2022-12-12 07:35:06[.924682.2022-12-12 07:35:06924685: 924690.: E: 924695E E:  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :638:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638] 638:] eager release cuda mem 625663] 638eager release cuda mem 625663
eager release cuda mem 625663] 

eager release cuda mem 625663
[2022-12-12 07:35:06.[[9248212022-12-12 07:35:062022-12-12 07:35:06[: ..2022-12-12 07:35:06E924827924830. : : 924834/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuEE: :  E[1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 2022-12-12 07:35:06] ::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.eager alloc mem 611.00 KB19801980:924869
] ] 1980: eager alloc mem 611.00 KBeager alloc mem 611.00 KB] E

eager alloc mem 611.00 KB 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.925023: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:06.925182: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.925251: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 07:35:061980.] 925263eager alloc mem 611.00 KB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.925349: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:06.925408: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.925477: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:06.925656: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[[2022-12-12 07:35:062022-12-12 07:35:06..[9256829256852022-12-12 07:35:06: : .EE925694  : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE::[ 6386382022-12-12 07:35:06/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] ] .:eager release cuda mem 625663eager release cuda mem 625663925728638

: ] Eeager release cuda mem 625663 [
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 07:35:06:.1980925770] : eager alloc mem 611.00 KBE[[
 2022-12-12 07:35:062022-12-12 07:35:06/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[..:2022-12-12 07:35:06925807925807638.: : ] 925827EEeager release cuda mem 625663:   
E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu ::/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu19801980:] ] 1980eager alloc mem 611.00 KBeager alloc mem 611.00 KB] 

eager alloc mem 611.00 KB
[2022-12-12 07:35:06.925941: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:06.926018: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.926087: E[ 2022-12-12 07:35:06/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.:9260961980: ] Eeager alloc mem 611.00 KB 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.926179: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:06.926231: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.926301: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:35:06.926548: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.926622: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[[2022-12-12 07:35:062022-12-12 07:35:06.[.9266572022-12-12 07:35:06926658: .: E926665E :  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:2022-12-12 07:35:06 :638./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638] 926693:] eager release cuda mem 625663: 638eager release cuda mem 625663
E] 
 eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 625663
[2022-12-12 07:35:06[.[2022-12-12 07:35:069268072022-12-12 07:35:06.[: .9268082022-12-12 07:35:06E926815: [. : E2022-12-12 07:35:06926829/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE .: : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu926847E638[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::  ] 2022-12-12 07:35:06:1980E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 120400004.1980]  :
926927] eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc1980: eager alloc mem 611.00 KB
:] E
638eager alloc mem 611.00 KB ] 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[eager release cuda mem 625663:2022-12-12 07:35:06
638.] 927053eager release cuda mem 625663: 
E[ 2022-12-12 07:35:06/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:927097[638: 2022-12-12 07:35:06] E. eager release cuda mem 625663927110/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 120400004:[
6382022-12-12 07:35:06] .eager release cuda mem 120400004927158
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 120400004
[2022-12-12 07:35:06.927376: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:35:06.927416: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 120400004
[2022-12-12 07:35:06.927671: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.42465 secs 
[2022-12-12 07:35:06.927751: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 07:35:06eager release cuda mem 625663.
927770: [E2022-12-12 07:35:06 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[927787:2022-12-12 07:35:06: 638.E] 927798 eager release cuda mem 625663: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
E: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :[eager release cuda mem 6256636382022-12-12 07:35:06
] .eager release cuda mem 120400004927844
: E[ 2022-12-12 07:35:06/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:927867638: ] E eager release cuda mem 120400004/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 120400004
[2022-12-12 07:35:06.928263: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.42519 secs 
[2022-12-12 07:35:06.928469: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.42542 secs 
[2022-12-12 07:35:06.928876: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.42584 secs 
[2022-12-12 07:35:06.929505: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.44228 secs 
[2022-12-12 07:35:06.929720: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.42671 secs 
[2022-12-12 07:35:06.929932: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.42761 secs 
[2022-12-12 07:35:06.930137: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.42702 secs 
[HCTR][07:35:06.930][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier
[HCTR][07:35:06.930][ERROR][RK0][tid #139670876821248]: replica 1 calling init per replica done, doing barrier
[HCTR][07:35:06.930][ERROR][RK0][tid #139669920544512]: replica 7 calling init per replica done, doing barrier
[HCTR][07:35:06.930][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier
[HCTR][07:35:06.930][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier
[HCTR][07:35:06.930][ERROR][RK0][tid #139670339950336]: replica 5 calling init per replica done, doing barrier
[HCTR][07:35:06.930][ERROR][RK0][tid #139670407059200]: replica 3 calling init per replica done, doing barrier
[HCTR][07:35:06.930][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier
[HCTR][07:35:06.930][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier done
[HCTR][07:35:06.930][ERROR][RK0][tid #139669920544512]: replica 7 calling init per replica done, doing barrier done
[HCTR][07:35:06.930][ERROR][RK0][tid #139670407059200]: replica 3 calling init per replica done, doing barrier done
[HCTR][07:35:06.930][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier done
[HCTR][07:35:06.930][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier done
[HCTR][07:35:06.930][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier done
[HCTR][07:35:06.930][ERROR][RK0][main]: init per replica done
[HCTR][07:35:06.930][ERROR][RK0][tid #139670339950336]: replica 5 calling init per replica done, doing barrier done
[HCTR][07:35:06.930][ERROR][RK0][main]: init per replica done
[HCTR][07:35:06.930][ERROR][RK0][tid #139670876821248]: replica 1 calling init per replica done, doing barrier done
[HCTR][07:35:06.930][ERROR][RK0][tid #139669920544512]: init per replica done
[HCTR][07:35:06.930][ERROR][RK0][tid #139670407059200]: init per replica done
[HCTR][07:35:06.930][ERROR][RK0][main]: init per replica done
[HCTR][07:35:06.930][ERROR][RK0][tid #139670339950336]: init per replica done
[HCTR][07:35:06.930][ERROR][RK0][tid #139670876821248]: init per replica done
[HCTR][07:35:06.933][ERROR][RK0][main]: init per replica done








