2022-12-12 07:36:18.285779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.294074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.301002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.305930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.310305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.323562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.338113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.351587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.398820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.399977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.400940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.401888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.402856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.403518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.404179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.405284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.405788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.407010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.407476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.408433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.409745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.410688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.411659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.412688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.413721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.414709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.415729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.416665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.417592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.418609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.419656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.420697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.422514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.423595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.425041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.426369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.426624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.428620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.429328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.430846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.431372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.431530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.432639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.433513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.433889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.434650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.435786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.436197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.437633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.438018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.439205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.439716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.440717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.441016: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:36:18.441369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.442743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.443935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.446780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.447988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.449478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.450120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.451561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.451992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.452079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.453308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.453750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.454108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.454559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.455816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.456624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.457311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.458301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.459536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.460532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.461179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.462766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.463931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.464336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.465075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.467116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.467212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.468194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.468787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.469609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.469754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.470905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.471659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.472232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.472618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.473755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.474466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.474867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.476365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.477060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.477107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.478669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.479152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.479247: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.480470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.480850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.481092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.486029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.489278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.493645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.494128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.494884: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.495541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.495745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.497160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.497810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.498388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.498555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.499713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.509571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.519344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.535316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.535436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.536588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.536824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.536986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.538505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.538553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.540754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.540954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.541021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.541760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.541812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.543780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.544875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.546270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.546385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.547034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.547178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.548728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.549500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.550347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.550423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.551012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.551212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.553499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.554185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.554747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.554862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.555408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.555507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.557817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.558533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.559107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.559231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.559764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.559912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.561909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.562789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.563471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.563602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.564184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.564391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.566208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.566870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.567479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.567607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.568210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.568446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.570215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.570862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.571416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.571564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.572113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.572597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.574155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.575376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.576379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.577487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.578213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.578709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.579557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.580230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.580895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.581569: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:36:18.581601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.582214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.583029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.583924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.584961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.585662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.586194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.586583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.587408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.588068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.588736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.589968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.590798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.591407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.591627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.591650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.591729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.592840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.593990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.594800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.596108: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.596449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.596547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.596641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.597438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.598577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.599493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.600874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.601168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.601199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.601289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.603138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.605149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.606494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.606795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.606810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.606893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.607896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.615412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.616905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.617213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.617331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.617495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.618497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.620394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.621581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.622135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.622224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.622601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.622881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.624887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.626122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.626829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.627351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.627501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.627684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.629281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.631287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.632473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.633225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.633268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.633740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.635232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.636297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.637989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.638242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.639531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.640010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.640955: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:36:18.641537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.641758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.641792: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:36:18.642843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.643090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.645142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.646546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.648329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.649625: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:36:18.649876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.649974: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:36:18.650160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.651040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.651645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.653541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.654075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.656175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.657684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.658121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.658886: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.659054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.659156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.660110: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:36:18.661673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.668952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.698664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.698751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.702271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.705122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.705160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.705318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.708486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.710473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.714876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.719872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.753569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.763006: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 07:36:18.771892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.778249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:18.786199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:19.831117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:19.831793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:19.832512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:19.832994: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:36:19.833050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 07:36:19.850747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:19.851464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:19.852172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:19.852749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:19.853271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:19.853926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 07:36:19.899034: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:19.899244: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:19.932439: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-12 07:36:20.042688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.043337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.044076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.044552: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:36:20.044606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 07:36:20.062452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.063226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.064212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.065014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.065732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.066215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 07:36:20.145123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.145736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.146268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.146881: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:36:20.146938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 07:36:20.147452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.148300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.148851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.149315: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:36:20.149365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 07:36:20.155250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.155872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.156407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.156879: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:36:20.156931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 07:36:20.161246: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.161442: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.163339: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-12 07:36:20.164167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.164789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.165229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.165353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.166260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.166302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.166516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.167265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.168057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.168181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.168363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.169351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.170199: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:36:20.170216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.170256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 07:36:20.170342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 07:36:20.171157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.171411: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:36:20.171458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 07:36:20.172087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.172602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.173072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 07:36:20.174606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.175233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.175749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.176320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.176836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.177304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 07:36:20.179110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.179775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.180323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.180784: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 07:36:20.180824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 07:36:20.187603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.188274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.188321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.189252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.189374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.190208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.190267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.191158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.191332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.191933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 07:36:20.192177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.192652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 07:36:20.197713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.198352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.198862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.199445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.199966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 07:36:20.200429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 07:36:20.216610: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.216851: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.218747: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-12 07:36:20.224918: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.225103: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.227169: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-12 07:36:20.238193: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.238193: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.238366: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.238370: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.240352: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
2022-12-12 07:36:20.240760: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-12 07:36:20.246465: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.246631: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.248633: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-12 07:36:20.253589: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.253754: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 07:36:20.255516: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
[HCTR][07:36:21.502][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:36:21.503][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:36:21.509][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:36:21.514][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:36:21.514][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:36:21.516][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:36:21.516][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][07:36:21.516][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:01,  1.53s/it]warmup run: 1it [00:01,  1.55s/it]warmup run: 1it [00:01,  1.50s/it]warmup run: 1it [00:01,  1.50s/it]warmup run: 1it [00:01,  1.50s/it]warmup run: 102it [00:01, 86.76it/s]warmup run: 96it [00:01, 80.75it/s]warmup run: 1it [00:01,  1.48s/it]warmup run: 92it [00:01, 79.57it/s]warmup run: 1it [00:01,  1.49s/it]warmup run: 101it [00:01, 87.33it/s]warmup run: 97it [00:01, 84.27it/s]warmup run: 204it [00:01, 188.03it/s]warmup run: 198it [00:01, 181.63it/s]warmup run: 98it [00:01, 85.71it/s]warmup run: 1it [00:01,  1.47s/it]warmup run: 185it [00:01, 173.21it/s]warmup run: 97it [00:01, 84.73it/s]warmup run: 203it [00:01, 189.99it/s]warmup run: 194it [00:01, 182.23it/s]warmup run: 306it [00:01, 299.38it/s]warmup run: 300it [00:01, 292.90it/s]warmup run: 194it [00:01, 183.03it/s]warmup run: 97it [00:01, 85.59it/s]warmup run: 271it [00:01, 266.15it/s]warmup run: 195it [00:01, 184.27it/s]warmup run: 305it [00:01, 302.51it/s]warmup run: 292it [00:01, 290.72it/s]warmup run: 408it [00:01, 414.85it/s]warmup run: 402it [00:01, 408.74it/s]warmup run: 290it [00:01, 289.39it/s]warmup run: 195it [00:01, 185.87it/s]warmup run: 348it [00:01, 347.18it/s]warmup run: 293it [00:01, 293.09it/s]warmup run: 406it [00:01, 416.80it/s]warmup run: 391it [00:01, 404.27it/s]warmup run: 509it [00:02, 525.07it/s]warmup run: 503it [00:02, 519.92it/s]warmup run: 388it [00:01, 401.95it/s]warmup run: 293it [00:01, 295.40it/s]warmup run: 447it [00:02, 467.80it/s]warmup run: 392it [00:01, 406.88it/s]warmup run: 507it [00:02, 527.64it/s]warmup run: 490it [00:01, 513.99it/s]warmup run: 611it [00:02, 628.53it/s]warmup run: 606it [00:02, 626.40it/s]warmup run: 483it [00:01, 505.48it/s]warmup run: 391it [00:01, 407.54it/s]warmup run: 547it [00:02, 580.39it/s]warmup run: 493it [00:01, 520.69it/s]warmup run: 590it [00:02, 616.69it/s]warmup run: 605it [00:02, 621.95it/s]warmup run: 713it [00:02, 718.56it/s]warmup run: 710it [00:02, 720.78it/s]warmup run: 577it [00:02, 597.38it/s]warmup run: 488it [00:01, 514.07it/s]warmup run: 649it [00:02, 681.36it/s]warmup run: 596it [00:02, 628.48it/s]warmup run: 690it [00:02, 705.19it/s]warmup run: 701it [00:02, 695.78it/s]warmup run: 815it [00:02, 792.53it/s]warmup run: 814it [00:02, 798.60it/s]warmup run: 675it [00:02, 686.47it/s]warmup run: 586it [00:02, 613.51it/s]warmup run: 751it [00:02, 763.81it/s]warmup run: 699it [00:02, 721.61it/s]warmup run: 790it [00:02, 778.27it/s]warmup run: 796it [00:02, 756.31it/s]warmup run: 916it [00:02, 848.79it/s]warmup run: 917it [00:02, 857.23it/s]warmup run: 773it [00:02, 759.37it/s]warmup run: 685it [00:02, 700.29it/s]warmup run: 850it [00:02, 821.33it/s]warmup run: 802it [00:02, 796.97it/s]warmup run: 890it [00:02, 834.95it/s]warmup run: 1017it [00:02, 892.42it/s]warmup run: 891it [00:02, 801.33it/s]warmup run: 1021it [00:02, 904.73it/s]warmup run: 877it [00:02, 831.75it/s]warmup run: 786it [00:02, 777.44it/s]warmup run: 947it [00:02, 851.94it/s]warmup run: 905it [00:02, 856.90it/s]warmup run: 989it [00:02, 877.04it/s]warmup run: 1119it [00:02, 927.15it/s]warmup run: 986it [00:02, 839.54it/s]warmup run: 1123it [00:02, 934.79it/s]warmup run: 977it [00:02, 877.60it/s]warmup run: 888it [00:02, 840.19it/s]warmup run: 1008it [00:02, 903.35it/s]warmup run: 1088it [00:02, 905.03it/s]warmup run: 1221it [00:02, 953.31it/s]warmup run: 1087it [00:02, 885.99it/s]warmup run: 1043it [00:02, 804.87it/s]warmup run: 1226it [00:02, 959.87it/s]warmup run: 1077it [00:02, 911.34it/s]warmup run: 990it [00:02, 887.99it/s]warmup run: 1112it [00:02, 940.47it/s]warmup run: 1187it [00:02, 925.69it/s]warmup run: 1324it [00:02, 975.17it/s]warmup run: 1189it [00:02, 922.22it/s]warmup run: 1132it [00:02, 820.70it/s]warmup run: 1329it [00:02, 979.36it/s]warmup run: 1176it [00:02, 930.32it/s]warmup run: 1094it [00:02, 928.81it/s]warmup run: 1217it [00:02, 971.43it/s]warmup run: 1288it [00:02, 948.26it/s]warmup run: 1428it [00:02, 992.63it/s]warmup run: 1291it [00:02, 949.28it/s]warmup run: 1235it [00:02, 877.30it/s]warmup run: 1432it [00:02, 990.23it/s]warmup run: 1275it [00:02, 937.13it/s]warmup run: 1197it [00:02, 956.77it/s]warmup run: 1321it [00:02, 989.14it/s]warmup run: 1392it [00:02, 974.23it/s]warmup run: 1531it [00:03, 1001.47it/s]warmup run: 1390it [00:02, 944.26it/s]warmup run: 1339it [00:02, 920.68it/s]warmup run: 1534it [00:03, 998.84it/s]warmup run: 1373it [00:02, 945.46it/s]warmup run: 1300it [00:02, 976.76it/s]warmup run: 1426it [00:02, 1004.26it/s]warmup run: 1497it [00:03, 993.80it/s]warmup run: 1634it [00:03, 1002.24it/s]warmup run: 1488it [00:03, 950.98it/s]warmup run: 1442it [00:03, 949.80it/s]warmup run: 1636it [00:03, 994.98it/s]warmup run: 1474it [00:02, 964.20it/s]warmup run: 1403it [00:02, 989.70it/s]warmup run: 1531it [00:02, 1016.09it/s]warmup run: 1601it [00:03, 1005.93it/s]warmup run: 1736it [00:03, 1002.62it/s]warmup run: 1587it [00:03, 960.55it/s]warmup run: 1544it [00:03, 970.09it/s]warmup run: 1737it [00:03, 995.44it/s]warmup run: 1574it [00:03, 973.08it/s]warmup run: 1506it [00:02, 1001.34it/s]warmup run: 1636it [00:03, 1024.90it/s]warmup run: 1704it [00:03, 1010.86it/s]warmup run: 1839it [00:03, 1008.99it/s]warmup run: 1686it [00:03, 968.96it/s]warmup run: 1647it [00:03, 986.54it/s]warmup run: 1838it [00:03, 990.21it/s]warmup run: 1675it [00:03, 981.61it/s]warmup run: 1609it [00:03, 1007.45it/s]warmup run: 1740it [00:03, 1028.63it/s]warmup run: 1807it [00:03, 1015.84it/s]warmup run: 1943it [00:03, 1015.64it/s]warmup run: 1784it [00:03, 969.54it/s]warmup run: 1747it [00:03, 986.81it/s]warmup run: 1776it [00:03, 989.27it/s]warmup run: 1938it [00:03, 980.23it/s]warmup run: 1712it [00:03, 1012.62it/s]warmup run: 1845it [00:03, 1032.62it/s]warmup run: 1911it [00:03, 1020.68it/s]warmup run: 2053it [00:03, 1039.46it/s]warmup run: 1887it [00:03, 986.14it/s]warmup run: 1847it [00:03, 973.02it/s]warmup run: 1881it [00:03, 1006.37it/s]warmup run: 2037it [00:03, 974.65it/s]warmup run: 1815it [00:03, 1015.71it/s]warmup run: 1949it [00:03, 1034.16it/s]warmup run: 2016it [00:03, 1027.13it/s]warmup run: 2173it [00:03, 1085.29it/s]warmup run: 1992it [00:03, 1002.32it/s]warmup run: 1945it [00:03, 971.67it/s]warmup run: 1987it [00:03, 1021.66it/s]warmup run: 2154it [00:03, 1030.72it/s]warmup run: 1918it [00:03, 1017.61it/s]warmup run: 2062it [00:03, 1062.30it/s]warmup run: 2137it [00:03, 1080.11it/s]warmup run: 2293it [00:03, 1118.41it/s]warmup run: 2113it [00:03, 1063.40it/s]warmup run: 2052it [00:03, 999.80it/s]warmup run: 2107it [00:03, 1073.68it/s]warmup run: 2275it [00:03, 1081.86it/s]warmup run: 2024it [00:03, 1029.86it/s]warmup run: 2183it [00:03, 1106.24it/s]warmup run: 2258it [00:03, 1117.09it/s]warmup run: 2413it [00:03, 1141.97it/s]warmup run: 2236it [00:03, 1110.42it/s]warmup run: 2173it [00:03, 1061.75it/s]warmup run: 2230it [00:03, 1119.42it/s]warmup run: 2397it [00:03, 1120.19it/s]warmup run: 2145it [00:03, 1081.54it/s]warmup run: 2304it [00:03, 1135.08it/s]warmup run: 2380it [00:03, 1145.75it/s]warmup run: 2533it [00:03, 1157.38it/s]warmup run: 2357it [00:03, 1139.29it/s]warmup run: 2293it [00:03, 1102.52it/s]warmup run: 2353it [00:03, 1150.06it/s]warmup run: 2517it [00:03, 1143.79it/s]warmup run: 2266it [00:03, 1118.38it/s]warmup run: 2425it [00:03, 1155.34it/s]warmup run: 2502it [00:03, 1166.55it/s]warmup run: 2652it [00:04, 1165.45it/s]warmup run: 2478it [00:03, 1158.72it/s]warmup run: 2414it [00:03, 1131.90it/s]warmup run: 2476it [00:03, 1171.91it/s]warmup run: 2636it [00:04, 1156.42it/s]warmup run: 2386it [00:03, 1142.66it/s]warmup run: 2545it [00:03, 1168.52it/s]warmup run: 2624it [00:04, 1180.71it/s]warmup run: 2772it [00:04, 1173.65it/s]warmup run: 2599it [00:04, 1172.65it/s]warmup run: 2534it [00:04, 1151.87it/s]warmup run: 2599it [00:04, 1187.26it/s]warmup run: 2753it [00:04, 1159.84it/s]warmup run: 2506it [00:03, 1159.27it/s]warmup run: 2665it [00:03, 1177.61it/s]warmup run: 2744it [00:04, 1186.30it/s]warmup run: 2892it [00:04, 1179.56it/s]warmup run: 2719it [00:04, 1179.68it/s]warmup run: 2652it [00:04, 1159.32it/s]warmup run: 2721it [00:04, 1195.47it/s]warmup run: 2873it [00:04, 1170.22it/s]warmup run: 2627it [00:03, 1168.52it/s]warmup run: 2784it [00:04, 1180.99it/s]warmup run: 2866it [00:04, 1194.24it/s]warmup run: 3000it [00:04, 690.66it/s] warmup run: 2840it [00:04, 1187.96it/s]warmup run: 2772it [00:04, 1168.90it/s]warmup run: 2841it [00:04, 1191.02it/s]warmup run: 2992it [00:04, 1175.62it/s]warmup run: 3000it [00:04, 683.39it/s] warmup run: 2748it [00:04, 1178.83it/s]warmup run: 2904it [00:04, 1185.50it/s]warmup run: 2988it [00:04, 1199.39it/s]warmup run: 2963it [00:04, 1198.71it/s]warmup run: 3000it [00:04, 693.09it/s] warmup run: 2891it [00:04, 1174.65it/s]warmup run: 3000it [00:04, 686.84it/s] warmup run: 2961it [00:04, 1182.16it/s]warmup run: 3000it [00:04, 700.14it/s] warmup run: 2868it [00:04, 1183.73it/s]warmup run: 3000it [00:04, 690.53it/s] warmup run: 3000it [00:04, 672.43it/s] warmup run: 2989it [00:04, 1189.92it/s]warmup run: 3000it [00:04, 697.45it/s] 

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]




warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1668.02it/s]warmup should be done:   5%|         | 162/3000 [00:00<00:01, 1613.42it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1633.44it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1634.08it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1625.00it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1621.66it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1642.07it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1660.84it/s]warmup should be done:  11%|         | 335/3000 [00:00<00:01, 1672.72it/s]warmup should be done:  11%|         | 329/3000 [00:00<00:01, 1641.96it/s]warmup should be done:  11%|         | 329/3000 [00:00<00:01, 1641.00it/s]warmup should be done:  11%|         | 328/3000 [00:00<00:01, 1637.08it/s]warmup should be done:  11%|         | 336/3000 [00:00<00:01, 1675.38it/s]warmup should be done:  11%|         | 326/3000 [00:00<00:01, 1623.71it/s]warmup should be done:  11%|         | 327/3000 [00:00<00:01, 1629.26it/s]warmup should be done:  11%|         | 331/3000 [00:00<00:01, 1649.34it/s]warmup should be done:  16%|        | 492/3000 [00:00<00:01, 1635.25it/s]warmup should be done:  17%|        | 496/3000 [00:00<00:01, 1647.89it/s]warmup should be done:  16%|        | 490/3000 [00:00<00:01, 1625.31it/s]warmup should be done:  16%|        | 494/3000 [00:00<00:01, 1636.66it/s]warmup should be done:  17%|        | 503/3000 [00:00<00:01, 1665.91it/s]warmup should be done:  16%|        | 494/3000 [00:00<00:01, 1635.71it/s]warmup should be done:  17%|        | 504/3000 [00:00<00:01, 1668.24it/s]warmup should be done:  16%|        | 489/3000 [00:00<00:01, 1616.40it/s]warmup should be done:  22%|       | 661/3000 [00:00<00:01, 1647.37it/s]warmup should be done:  22%|       | 656/3000 [00:00<00:01, 1633.07it/s]warmup should be done:  22%|       | 660/3000 [00:00<00:01, 1644.41it/s]warmup should be done:  22%|       | 670/3000 [00:00<00:01, 1664.57it/s]warmup should be done:  22%|       | 653/3000 [00:00<00:01, 1622.20it/s]warmup should be done:  22%|       | 659/3000 [00:00<00:01, 1638.09it/s]warmup should be done:  22%|       | 653/3000 [00:00<00:01, 1623.28it/s]warmup should be done:  22%|       | 671/3000 [00:00<00:01, 1663.22it/s]warmup should be done:  28%|       | 826/3000 [00:00<00:01, 1646.17it/s]warmup should be done:  27%|       | 823/3000 [00:00<00:01, 1637.11it/s]warmup should be done:  27%|       | 820/3000 [00:00<00:01, 1630.10it/s]warmup should be done:  28%|       | 837/3000 [00:00<00:01, 1662.89it/s]warmup should be done:  27%|       | 817/3000 [00:00<00:01, 1626.42it/s]warmup should be done:  27%|       | 816/3000 [00:00<00:01, 1618.66it/s]warmup should be done:  28%|       | 838/3000 [00:00<00:01, 1659.44it/s]warmup should be done:  28%|       | 825/3000 [00:00<00:01, 1634.90it/s]warmup should be done:  33%|      | 991/3000 [00:00<00:01, 1641.53it/s]warmup should be done:  33%|      | 987/3000 [00:00<00:01, 1632.95it/s]warmup should be done:  33%|      | 984/3000 [00:00<00:01, 1628.10it/s]warmup should be done:  33%|      | 980/3000 [00:00<00:01, 1622.25it/s]warmup should be done:  33%|      | 1004/3000 [00:00<00:01, 1657.93it/s]warmup should be done:  33%|      | 978/3000 [00:00<00:01, 1611.10it/s]warmup should be done:  33%|      | 1004/3000 [00:00<00:01, 1651.70it/s]warmup should be done:  33%|      | 989/3000 [00:00<00:01, 1601.58it/s]warmup should be done:  39%|      | 1156/3000 [00:00<00:01, 1642.65it/s]warmup should be done:  38%|      | 1152/3000 [00:00<00:01, 1636.56it/s]warmup should be done:  38%|      | 1143/3000 [00:00<00:01, 1624.24it/s]warmup should be done:  39%|      | 1170/3000 [00:00<00:01, 1658.19it/s]warmup should be done:  38%|      | 1147/3000 [00:00<00:01, 1620.49it/s]warmup should be done:  39%|      | 1170/3000 [00:00<00:01, 1650.71it/s]warmup should be done:  38%|      | 1140/3000 [00:00<00:01, 1604.06it/s]warmup should be done:  38%|      | 1151/3000 [00:00<00:01, 1604.51it/s]warmup should be done:  44%|     | 1321/3000 [00:00<00:01, 1643.14it/s]warmup should be done:  45%|     | 1336/3000 [00:00<00:01, 1658.73it/s]warmup should be done:  44%|     | 1306/3000 [00:00<00:01, 1624.58it/s]warmup should be done:  44%|     | 1317/3000 [00:00<00:01, 1638.00it/s]warmup should be done:  45%|     | 1337/3000 [00:00<00:01, 1655.58it/s]warmup should be done:  44%|     | 1310/3000 [00:00<00:01, 1614.46it/s]warmup should be done:  43%|     | 1301/3000 [00:00<00:01, 1603.49it/s]warmup should be done:  44%|     | 1312/3000 [00:00<00:01, 1599.11it/s]warmup should be done:  50%|     | 1486/3000 [00:00<00:00, 1642.53it/s]warmup should be done:  50%|     | 1502/3000 [00:00<00:00, 1658.65it/s]warmup should be done:  49%|     | 1482/3000 [00:00<00:00, 1640.31it/s]warmup should be done:  49%|     | 1469/3000 [00:00<00:00, 1619.24it/s]warmup should be done:  50%|     | 1504/3000 [00:00<00:00, 1659.83it/s]warmup should be done:  49%|     | 1473/3000 [00:00<00:00, 1617.77it/s]warmup should be done:  49%|     | 1462/3000 [00:00<00:00, 1604.55it/s]warmup should be done:  49%|     | 1474/3000 [00:00<00:00, 1603.04it/s]warmup should be done:  56%|    | 1668/3000 [00:01<00:00, 1658.10it/s]warmup should be done:  55%|    | 1651/3000 [00:01<00:00, 1641.37it/s]warmup should be done:  55%|    | 1647/3000 [00:01<00:00, 1636.16it/s]warmup should be done:  56%|    | 1672/3000 [00:01<00:00, 1663.17it/s]warmup should be done:  54%|    | 1631/3000 [00:01<00:00, 1612.61it/s]warmup should be done:  54%|    | 1623/3000 [00:01<00:00, 1605.01it/s]warmup should be done:  55%|    | 1636/3000 [00:01<00:00, 1619.29it/s]warmup should be done:  55%|    | 1636/3000 [00:01<00:00, 1605.96it/s]warmup should be done:  61%|    | 1834/3000 [00:01<00:00, 1657.24it/s]warmup should be done:  61%|    | 1816/3000 [00:01<00:00, 1641.30it/s]warmup should be done:  60%|    | 1812/3000 [00:01<00:00, 1638.77it/s]warmup should be done:  61%|   | 1840/3000 [00:01<00:00, 1665.84it/s]warmup should be done:  60%|    | 1793/3000 [00:01<00:00, 1612.10it/s]warmup should be done:  59%|    | 1784/3000 [00:01<00:00, 1605.36it/s]warmup should be done:  60%|    | 1799/3000 [00:01<00:00, 1621.37it/s]warmup should be done:  60%|    | 1798/3000 [00:01<00:00, 1609.02it/s]warmup should be done:  67%|   | 2000/3000 [00:01<00:00, 1656.58it/s]warmup should be done:  66%|   | 1981/3000 [00:01<00:00, 1640.16it/s]warmup should be done:  66%|   | 1977/3000 [00:01<00:00, 1639.84it/s]warmup should be done:  67%|   | 2007/3000 [00:01<00:00, 1666.49it/s]warmup should be done:  65%|   | 1945/3000 [00:01<00:00, 1604.91it/s]warmup should be done:  65%|   | 1962/3000 [00:01<00:00, 1620.83it/s]warmup should be done:  65%|   | 1955/3000 [00:01<00:00, 1609.89it/s]warmup should be done:  65%|   | 1960/3000 [00:01<00:00, 1610.25it/s]warmup should be done:  72%|  | 2166/3000 [00:01<00:00, 1655.48it/s]warmup should be done:  72%|  | 2146/3000 [00:01<00:00, 1639.42it/s]warmup should be done:  72%|  | 2174/3000 [00:01<00:00, 1666.35it/s]warmup should be done:  70%|   | 2106/3000 [00:01<00:00, 1604.13it/s]warmup should be done:  71%|  | 2141/3000 [00:01<00:00, 1630.98it/s]warmup should be done:  71%|   | 2125/3000 [00:01<00:00, 1621.95it/s]warmup should be done:  71%|   | 2116/3000 [00:01<00:00, 1603.21it/s]warmup should be done:  71%|   | 2122/3000 [00:01<00:00, 1612.03it/s]warmup should be done:  78%|  | 2332/3000 [00:01<00:00, 1647.94it/s]warmup should be done:  77%|  | 2310/3000 [00:01<00:00, 1634.47it/s]warmup should be done:  78%|  | 2341/3000 [00:01<00:00, 1663.42it/s]warmup should be done:  77%|  | 2305/3000 [00:01<00:00, 1631.93it/s]warmup should be done:  76%|  | 2288/3000 [00:01<00:00, 1622.34it/s]warmup should be done:  76%|  | 2267/3000 [00:01<00:00, 1597.48it/s]warmup should be done:  76%|  | 2277/3000 [00:01<00:00, 1600.48it/s]warmup should be done:  76%|  | 2284/3000 [00:01<00:00, 1610.67it/s]warmup should be done:  83%| | 2497/3000 [00:01<00:00, 1645.07it/s]warmup should be done:  84%| | 2508/3000 [00:01<00:00, 1665.15it/s]warmup should be done:  82%| | 2469/3000 [00:01<00:00, 1634.10it/s]warmup should be done:  82%| | 2474/3000 [00:01<00:00, 1625.19it/s]warmup should be done:  82%| | 2451/3000 [00:01<00:00, 1619.85it/s]warmup should be done:  81%|  | 2427/3000 [00:01<00:00, 1595.24it/s]warmup should be done:  81%| | 2438/3000 [00:01<00:00, 1595.51it/s]warmup should be done:  82%| | 2446/3000 [00:01<00:00, 1612.28it/s]warmup should be done:  89%| | 2664/3000 [00:01<00:00, 1650.13it/s]warmup should be done:  89%| | 2676/3000 [00:01<00:00, 1667.64it/s]warmup should be done:  88%| | 2634/3000 [00:01<00:00, 1636.86it/s]warmup should be done:  87%| | 2614/3000 [00:01<00:00, 1621.38it/s]warmup should be done:  88%| | 2637/3000 [00:01<00:00, 1622.24it/s]warmup should be done:  86%| | 2587/3000 [00:01<00:00, 1596.32it/s]warmup should be done:  87%| | 2599/3000 [00:01<00:00, 1599.43it/s]warmup should be done:  87%| | 2608/3000 [00:01<00:00, 1612.41it/s]warmup should be done:  94%|| 2831/3000 [00:01<00:00, 1654.92it/s]warmup should be done:  95%|| 2844/3000 [00:01<00:00, 1670.41it/s]warmup should be done:  93%|| 2799/3000 [00:01<00:00, 1639.23it/s]warmup should be done:  93%|| 2777/3000 [00:01<00:00, 1623.36it/s]warmup should be done:  93%|| 2800/3000 [00:01<00:00, 1622.29it/s]warmup should be done:  92%|| 2748/3000 [00:01<00:00, 1599.45it/s]warmup should be done:  92%|| 2761/3000 [00:01<00:00, 1602.95it/s]warmup should be done:  92%|| 2770/3000 [00:01<00:00, 1613.33it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1664.54it/s]warmup should be done: 100%|| 2999/3000 [00:01<00:00, 1660.17it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1657.46it/s]warmup should be done:  99%|| 2966/3000 [00:01<00:00, 1647.03it/s]warmup should be done:  98%|| 2942/3000 [00:01<00:00, 1628.75it/s]warmup should be done:  99%|| 2968/3000 [00:01<00:00, 1638.81it/s]warmup should be done:  97%|| 2911/3000 [00:01<00:00, 1606.96it/s]warmup should be done:  97%|| 2924/3000 [00:01<00:00, 1610.02it/s]warmup should be done:  98%|| 2934/3000 [00:01<00:00, 1618.33it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1638.60it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1638.21it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1624.44it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1614.88it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1612.45it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1607.37it/s]





warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 169/3000 [00:00<00:01, 1689.88it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1668.93it/s]warmup should be done:   6%|         | 170/3000 [00:00<00:01, 1697.45it/s]warmup should be done:   6%|         | 167/3000 [00:00<00:01, 1667.37it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1645.92it/s]warmup should be done:   6%|         | 171/3000 [00:00<00:01, 1704.19it/s]warmup should be done:   6%|         | 171/3000 [00:00<00:01, 1703.36it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1651.96it/s]warmup should be done:  11%|         | 335/3000 [00:00<00:01, 1674.61it/s]warmup should be done:  11%|        | 340/3000 [00:00<00:01, 1696.29it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1656.52it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1646.51it/s]warmup should be done:  11%|        | 339/3000 [00:00<00:01, 1690.62it/s]warmup should be done:  11%|        | 343/3000 [00:00<00:01, 1710.83it/s]warmup should be done:  11%|        | 343/3000 [00:00<00:01, 1709.01it/s]warmup should be done:  11%|         | 334/3000 [00:00<00:01, 1662.30it/s]warmup should be done:  17%|        | 510/3000 [00:00<00:01, 1696.23it/s]warmup should be done:  17%|        | 504/3000 [00:00<00:01, 1677.03it/s]warmup should be done:  17%|        | 510/3000 [00:00<00:01, 1697.58it/s]warmup should be done:  17%|        | 497/3000 [00:00<00:01, 1654.12it/s]warmup should be done:  17%|        | 515/3000 [00:00<00:01, 1712.55it/s]warmup should be done:  17%|        | 516/3000 [00:00<00:01, 1715.87it/s]warmup should be done:  17%|        | 501/3000 [00:00<00:01, 1654.17it/s]warmup should be done:  17%|        | 498/3000 [00:00<00:01, 1616.47it/s]warmup should be done:  23%|       | 680/3000 [00:00<00:01, 1695.97it/s]warmup should be done:  23%|       | 681/3000 [00:00<00:01, 1700.57it/s]warmup should be done:  23%|       | 687/3000 [00:00<00:01, 1714.63it/s]warmup should be done:  22%|       | 665/3000 [00:00<00:01, 1662.22it/s]warmup should be done:  23%|       | 688/3000 [00:00<00:01, 1715.32it/s]warmup should be done:  22%|       | 672/3000 [00:00<00:01, 1670.30it/s]warmup should be done:  22%|       | 667/3000 [00:00<00:01, 1646.70it/s]warmup should be done:  22%|       | 663/3000 [00:00<00:01, 1626.48it/s]warmup should be done:  28%|       | 851/3000 [00:00<00:01, 1698.86it/s]warmup should be done:  29%|       | 860/3000 [00:00<00:01, 1716.23it/s]warmup should be done:  28%|       | 853/3000 [00:00<00:01, 1703.74it/s]warmup should be done:  29%|       | 859/3000 [00:00<00:01, 1710.51it/s]warmup should be done:  28%|       | 832/3000 [00:00<00:01, 1657.77it/s]warmup should be done:  28%|       | 840/3000 [00:00<00:01, 1667.58it/s]warmup should be done:  28%|       | 832/3000 [00:00<00:01, 1642.11it/s]warmup should be done:  28%|       | 829/3000 [00:00<00:01, 1636.46it/s]warmup should be done:  34%|      | 1021/3000 [00:00<00:01, 1698.91it/s]warmup should be done:  34%|      | 1024/3000 [00:00<00:01, 1704.28it/s]warmup should be done:  34%|      | 1033/3000 [00:00<00:01, 1718.45it/s]warmup should be done:  34%|      | 1031/3000 [00:00<00:01, 1710.15it/s]warmup should be done:  34%|      | 1008/3000 [00:00<00:01, 1671.21it/s]warmup should be done:  33%|      | 998/3000 [00:00<00:01, 1645.68it/s]warmup should be done:  33%|      | 997/3000 [00:00<00:01, 1635.66it/s]warmup should be done:  33%|      | 996/3000 [00:00<00:01, 1644.86it/s]warmup should be done:  40%|      | 1191/3000 [00:00<00:01, 1696.19it/s]warmup should be done:  40%|      | 1205/3000 [00:00<00:01, 1717.88it/s]warmup should be done:  40%|      | 1195/3000 [00:00<00:01, 1702.43it/s]warmup should be done:  40%|      | 1203/3000 [00:00<00:01, 1710.08it/s]warmup should be done:  39%|      | 1176/3000 [00:00<00:01, 1672.77it/s]warmup should be done:  39%|      | 1166/3000 [00:00<00:01, 1653.81it/s]warmup should be done:  39%|      | 1161/3000 [00:00<00:01, 1632.74it/s]warmup should be done:  39%|      | 1162/3000 [00:00<00:01, 1649.01it/s]warmup should be done:  45%|     | 1362/3000 [00:00<00:00, 1698.42it/s]warmup should be done:  46%|     | 1378/3000 [00:00<00:00, 1720.73it/s]warmup should be done:  46%|     | 1367/3000 [00:00<00:00, 1705.41it/s]warmup should be done:  45%|     | 1344/3000 [00:00<00:00, 1674.60it/s]warmup should be done:  46%|     | 1375/3000 [00:00<00:00, 1712.03it/s]warmup should be done:  44%|     | 1333/3000 [00:00<00:01, 1658.43it/s]warmup should be done:  44%|     | 1328/3000 [00:00<00:01, 1650.53it/s]warmup should be done:  44%|     | 1325/3000 [00:00<00:01, 1629.10it/s]warmup should be done:  52%|    | 1551/3000 [00:00<00:00, 1721.24it/s]warmup should be done:  51%|     | 1532/3000 [00:00<00:00, 1696.03it/s]warmup should be done:  51%|    | 1538/3000 [00:00<00:00, 1706.38it/s]warmup should be done:  50%|     | 1512/3000 [00:00<00:00, 1674.07it/s]warmup should be done:  52%|    | 1547/3000 [00:00<00:00, 1708.00it/s]warmup should be done:  50%|     | 1501/3000 [00:00<00:00, 1663.62it/s]warmup should be done:  50%|     | 1494/3000 [00:00<00:00, 1652.67it/s]warmup should be done:  50%|     | 1488/3000 [00:00<00:00, 1628.40it/s]warmup should be done:  57%|    | 1724/3000 [00:01<00:00, 1721.60it/s]warmup should be done:  57%|    | 1710/3000 [00:01<00:00, 1707.81it/s]warmup should be done:  57%|    | 1702/3000 [00:01<00:00, 1690.81it/s]warmup should be done:  56%|    | 1680/3000 [00:01<00:00, 1673.41it/s]warmup should be done:  57%|    | 1718/3000 [00:01<00:00, 1704.07it/s]warmup should be done:  56%|    | 1670/3000 [00:01<00:00, 1669.60it/s]warmup should be done:  55%|    | 1661/3000 [00:01<00:00, 1654.92it/s]warmup should be done:  55%|    | 1651/3000 [00:01<00:00, 1620.18it/s]warmup should be done:  63%|   | 1897/3000 [00:01<00:00, 1721.44it/s]warmup should be done:  62%|   | 1873/3000 [00:01<00:00, 1693.49it/s]warmup should be done:  62%|   | 1849/3000 [00:01<00:00, 1675.96it/s]warmup should be done:  63%|   | 1881/3000 [00:01<00:00, 1699.65it/s]warmup should be done:  63%|   | 1890/3000 [00:01<00:00, 1707.06it/s]warmup should be done:  61%|   | 1839/3000 [00:01<00:00, 1673.95it/s]warmup should be done:  61%|    | 1827/3000 [00:01<00:00, 1653.64it/s]warmup should be done:  60%|    | 1814/3000 [00:01<00:00, 1597.32it/s]warmup should be done:  69%|   | 2070/3000 [00:01<00:00, 1721.08it/s]warmup should be done:  67%|   | 2017/3000 [00:01<00:00, 1675.93it/s]warmup should be done:  68%|   | 2044/3000 [00:01<00:00, 1696.10it/s]warmup should be done:  68%|   | 2051/3000 [00:01<00:00, 1695.92it/s]warmup should be done:  69%|   | 2062/3000 [00:01<00:00, 1708.38it/s]warmup should be done:  67%|   | 2008/3000 [00:01<00:00, 1678.11it/s]warmup should be done:  66%|   | 1993/3000 [00:01<00:00, 1653.32it/s]warmup should be done:  66%|   | 1977/3000 [00:01<00:00, 1605.02it/s]warmup should be done:  75%|  | 2243/3000 [00:01<00:00, 1720.39it/s]warmup should be done:  73%|  | 2185/3000 [00:01<00:00, 1676.15it/s]warmup should be done:  74%|  | 2214/3000 [00:01<00:00, 1696.32it/s]warmup should be done:  74%|  | 2233/3000 [00:01<00:00, 1707.78it/s]warmup should be done:  73%|  | 2177/3000 [00:01<00:00, 1680.09it/s]warmup should be done:  74%|  | 2221/3000 [00:01<00:00, 1690.47it/s]warmup should be done:  72%|  | 2159/3000 [00:01<00:00, 1653.75it/s]warmup should be done:  71%|  | 2140/3000 [00:01<00:00, 1611.99it/s]warmup should be done:  79%|  | 2384/3000 [00:01<00:00, 1696.89it/s]warmup should be done:  78%|  | 2354/3000 [00:01<00:00, 1677.39it/s]warmup should be done:  81%|  | 2416/3000 [00:01<00:00, 1715.49it/s]warmup should be done:  80%|  | 2404/3000 [00:01<00:00, 1707.25it/s]warmup should be done:  78%|  | 2346/3000 [00:01<00:00, 1681.67it/s]warmup should be done:  80%|  | 2391/3000 [00:01<00:00, 1687.17it/s]warmup should be done:  78%|  | 2326/3000 [00:01<00:00, 1656.82it/s]warmup should be done:  77%|  | 2304/3000 [00:01<00:00, 1619.78it/s]warmup should be done:  85%| | 2555/3000 [00:01<00:00, 1698.73it/s]warmup should be done:  84%| | 2523/3000 [00:01<00:00, 1678.49it/s]warmup should be done:  86%| | 2588/3000 [00:01<00:00, 1715.60it/s]warmup should be done:  84%| | 2516/3000 [00:01<00:00, 1685.62it/s]warmup should be done:  85%| | 2563/3000 [00:01<00:00, 1695.51it/s]warmup should be done:  83%| | 2493/3000 [00:01<00:00, 1660.33it/s]warmup should be done:  82%| | 2469/3000 [00:01<00:00, 1628.48it/s]warmup should be done:  86%| | 2575/3000 [00:01<00:00, 1572.55it/s]warmup should be done:  91%| | 2726/3000 [00:01<00:00, 1699.28it/s]warmup should be done:  90%| | 2691/3000 [00:01<00:00, 1678.29it/s]warmup should be done:  92%|| 2760/3000 [00:01<00:00, 1716.76it/s]warmup should be done:  90%| | 2686/3000 [00:01<00:00, 1687.80it/s]warmup should be done:  91%| | 2735/3000 [00:01<00:00, 1701.42it/s]warmup should be done:  89%| | 2660/3000 [00:01<00:00, 1658.91it/s]warmup should be done:  88%| | 2633/3000 [00:01<00:00, 1631.77it/s]warmup should be done:  91%| | 2737/3000 [00:01<00:00, 1585.88it/s]warmup should be done:  97%|| 2896/3000 [00:01<00:00, 1698.86it/s]warmup should be done:  95%|| 2859/3000 [00:01<00:00, 1676.65it/s]warmup should be done:  98%|| 2933/3000 [00:01<00:00, 1717.93it/s]warmup should be done:  95%|| 2855/3000 [00:01<00:00, 1687.38it/s]warmup should be done:  97%|| 2907/3000 [00:01<00:00, 1704.66it/s]warmup should be done:  94%|| 2826/3000 [00:01<00:00, 1657.53it/s]warmup should be done:  93%|| 2798/3000 [00:01<00:00, 1635.03it/s]warmup should be done:  97%|| 2906/3000 [00:01<00:00, 1615.33it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1717.46it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1700.43it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1696.80it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1675.02it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1674.50it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1669.57it/s]warmup should be done: 100%|| 2993/3000 [00:01<00:00, 1659.69it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1651.44it/s]warmup should be done:  99%|| 2964/3000 [00:01<00:00, 1639.57it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1630.58it/s]2022-12-12 07:37:57.184902: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fd4ef830710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:37:57.184977: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:37:58.281264: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fd4e7832d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:37:58.281328: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:37:58.281980: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fd4ef82ba70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:37:58.282026: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:37:58.297562: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fb5e002d1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:37:58.297627: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:37:58.305061: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x1d894050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:37:58.305112: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:37:58.429861: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fb53c02d1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:37:58.429940: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:37:58.477160: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fd4eb833700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:37:58.477225: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:37:58.570931: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7fd4ef82c440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 07:37:58.571011: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 07:37:59.446413: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:38:00.598040: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:38:00.614728: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:38:00.626569: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:38:00.629048: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:38:00.734269: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:38:00.748045: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:38:00.900599: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 07:38:02.305269: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:38:03.514040: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:38:03.608147: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:38:03.618404: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:38:03.637729: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:38:03.688608: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:38:03.688615: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 07:38:03.877696: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][07:38:26.753][ERROR][RK0][tid #140552662148864]: replica 5 reaches 1000, calling init pre replica
[HCTR][07:38:26.754][ERROR][RK0][tid #140552662148864]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:38:26.755][ERROR][RK0][main]: replica 2 reaches 1000, calling init pre replica
[HCTR][07:38:26.755][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:38:26.763][ERROR][RK0][main]: coll ps creation done
[HCTR][07:38:26.763][ERROR][RK0][main]: replica 2 waits for coll ps creation barrier
[HCTR][07:38:26.763][ERROR][RK0][tid #140552662148864]: coll ps creation done
[HCTR][07:38:26.763][ERROR][RK0][tid #140552662148864]: replica 5 waits for coll ps creation barrier
[HCTR][07:38:26.819][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][07:38:26.819][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:38:26.824][ERROR][RK0][main]: replica 7 reaches 1000, calling init pre replica
[HCTR][07:38:26.824][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:38:26.825][ERROR][RK0][main]: coll ps creation done
[HCTR][07:38:26.825][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][07:38:26.829][ERROR][RK0][tid #140552670541568]: replica 6 reaches 1000, calling init pre replica
[HCTR][07:38:26.829][ERROR][RK0][tid #140552670541568]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:38:26.830][ERROR][RK0][tid #140552603432704]: replica 4 reaches 1000, calling init pre replica
[HCTR][07:38:26.830][ERROR][RK0][tid #140552603432704]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:38:26.832][ERROR][RK0][main]: coll ps creation done
[HCTR][07:38:26.833][ERROR][RK0][main]: replica 7 waits for coll ps creation barrier
[HCTR][07:38:26.834][ERROR][RK0][tid #140552670541568]: coll ps creation done
[HCTR][07:38:26.834][ERROR][RK0][tid #140552670541568]: replica 6 waits for coll ps creation barrier
[HCTR][07:38:26.835][ERROR][RK0][tid #140552603432704]: coll ps creation done
[HCTR][07:38:26.835][ERROR][RK0][tid #140552603432704]: replica 4 waits for coll ps creation barrier
[HCTR][07:38:26.867][ERROR][RK0][main]: replica 0 reaches 1000, calling init pre replica
[HCTR][07:38:26.867][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:38:26.868][ERROR][RK0][main]: replica 1 reaches 1000, calling init pre replica
[HCTR][07:38:26.868][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][07:38:26.872][ERROR][RK0][main]: coll ps creation done
[HCTR][07:38:26.872][ERROR][RK0][main]: replica 0 waits for coll ps creation barrier
[HCTR][07:38:26.875][ERROR][RK0][main]: coll ps creation done
[HCTR][07:38:26.875][ERROR][RK0][main]: replica 1 waits for coll ps creation barrier
[HCTR][07:38:26.875][ERROR][RK0][main]: replica 0 preparing frequency
[HCTR][07:38:27.760][ERROR][RK0][main]: replica 0 preparing frequency done
[HCTR][07:38:27.822][ERROR][RK0][main]: replica 0 calling init per replica
[HCTR][07:38:27.822][ERROR][RK0][main]: replica 1 calling init per replica
[HCTR][07:38:27.822][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][07:38:27.822][ERROR][RK0][tid #140552603432704]: replica 4 calling init per replica
[HCTR][07:38:27.822][ERROR][RK0][main]: replica 2 calling init per replica
[HCTR][07:38:27.822][ERROR][RK0][tid #140552670541568]: replica 6 calling init per replica
[HCTR][07:38:27.822][ERROR][RK0][main]: replica 7 calling init per replica
[HCTR][07:38:27.822][ERROR][RK0][tid #140552662148864]: replica 5 calling init per replica
[HCTR][07:38:27.822][ERROR][RK0][main]: Calling build_v2
[HCTR][07:38:27.822][ERROR][RK0][main]: Calling build_v2
[HCTR][07:38:27.822][ERROR][RK0][main]: Calling build_v2
[HCTR][07:38:27.822][ERROR][RK0][tid #140552603432704]: Calling build_v2
[HCTR][07:38:27.822][ERROR][RK0][main]: Calling build_v2
[HCTR][07:38:27.822][ERROR][RK0][tid #140552670541568]: Calling build_v2
[HCTR][07:38:27.822][ERROR][RK0][main]: Calling build_v2
[HCTR][07:38:27.822][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:38:27.822][ERROR][RK0][tid #140552662148864]: Calling build_v2
[HCTR][07:38:27.822][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:38:27.822][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:38:27.822][ERROR][RK0][tid #140552603432704]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:38:27.822][ERROR][RK0][tid #140552670541568]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:38:27.822][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:38:27.822][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][07:38:27.822][ERROR][RK0][tid #140552662148864]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[[[[[[[[2022-12-12 07:38:272022-12-12 07:38:272022-12-12 07:38:272022-12-12 07:38:272022-12-12 07:38:272022-12-12 07:38:27.2022-12-12 07:38:27..2022-12-12 07:38:27...822403.822410822403.822410822410822415: 822411: : 822413: : : : E: EEEEEE E      /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc:/hugectr_dev/third_party/collcachelib/coll_cache_lib/run_config.cc::::::136:136136136136136136] 136] ] ] ] ] ] using concurrent impl MPS] using concurrent impl MPSusing concurrent impl MPSusing concurrent impl MPSusing concurrent impl MPSusing concurrent impl MPSusing concurrent impl MPS
using concurrent impl MPS






[2022-12-12 07:38:27.827879: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:178] v100x8, slow pcie
[2022-12-12 07:38:27.827920: [E2022-12-12 07:38:27 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc827923:: 196E]  assigning 8 to cpu/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
:178] v100x8, slow pcie
[[2022-12-12 07:38:272022-12-12 07:38:27..827978827974: : EE [ /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[2022-12-12 07:38:27/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:2022-12-12 07:38:27.:196.[828015178] 8280182022-12-12 07:38:27: ] assigning 8 to cpu: .Ev100x8, slow pcie
E828065 
[ [: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:38:27/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:38:27E:.:[. 212828116[1782022-12-12 07:38:27828141/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] : ] 2022-12-12 07:38:27.: :build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8Ev100x8, slow pcie.828158E178
 
828184: E ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[: [ [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccv100x8, slow pcie:2022-12-12 07:38:27E2022-12-12 07:38:27/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:38:27:
178. .:.196] 828271[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc828281212828291] v100x8, slow pcie: 2022-12-12 07:38:27:: ] : assigning 8 to cpu
E.178Ebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E
 828357[]  
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: 2022-12-12 07:38:27v100x8, slow pcie/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:E.[
[::178 8284342022-12-12 07:38:272022-12-12 07:38:27196213] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: ..] ] v100x8, slow pcie2022-12-12 07:38:27:E828482828487assigning 8 to cpuremote time is 8.68421
.196 : : 

828519] [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccEE: assigning 8 to cpu[2022-12-12 07:38:27:  E
2022-12-12 07:38:27.196/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[ .828604] ::2022-12-12 07:38:27/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[828627: assigning 8 to cpu213212.:2022-12-12 07:38:27: E
] ] 828666196.] E remote time is 8.68421build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8: 828717assigning 8 to cpu [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc

E: 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:38:27: [E:.[196/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:38:27 2148288022022-12-12 07:38:27] :./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] [: .assigning 8 to cpu212828822:cpu time is 97.05882022-12-12 07:38:27E828833
] : 212
. : build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8E] 828877/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE
 [build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8: : /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:38:27[
E212/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[:.2022-12-12 07:38:27 ] :2022-12-12 07:38:27214828979./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8213.] : 829010:
] 829063cpu time is 97.0588E: 212remote time is 8.68421: 
[ E] 
E2022-12-12 07:38:27/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8 [.:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 07:38:27829143212::.: ] 213[213829178Ebuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8] 2022-12-12 07:38:27] :  
remote time is 8.68421.remote time is 8.68421E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
829217
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[:: [:[2022-12-12 07:38:27213E2022-12-12 07:38:272142022-12-12 07:38:27.]  .] .829273remote time is 8.68421/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc829284cpu time is 97.0588829292: 
:: 
: E213E[E ]  2022-12-12 07:38:27 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:
:829372:213214: 214[] ] E] 2022-12-12 07:38:27remote time is 8.68421cpu time is 97.0588 cpu time is 97.0588.

/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
829434[:: 2022-12-12 07:38:27214E.]  829491cpu time is 97.0588/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: 
:E214 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cccpu time is 97.0588:
214] cpu time is 97.0588
[2022-12-12 07:39:47.488849: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-12 07:39:47.528886: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-12 07:39:47.528950: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 30000001
[2022-12-12 07:39:47.649851: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-12 07:39:47.649939: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-12 07:39:47.649971: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-12 07:39:47.650002: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-12 07:39:47.650477: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.651392: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.652053: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.665310: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 1 solved
[2022-12-12 07:39:47.665385: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 1 initing device 1
[2022-12-12 07:39:47.665811: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 07:39:47eager alloc mem 381.47 MB.
665818[: 2022-12-12 07:39:47E. 665837/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc: :E202 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc6 solved:
202] 7 solved[
2022-12-12 07:39:47.665937: [[E2022-12-12 07:39:472022-12-12 07:39:47 ../hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc665954[6659492022-12-12 07:39:47:: : .205EE665987]   : worker 0 thread 6 initing device 6/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.ccE
:: 205202/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc] ] :worker 0 thread 7 initing device 72 solved202

] 3 solved
[2022-12-12 07:39:47.666156[: 2022-12-12 07:39:47E. /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:666165205: ] Eworker 0 thread 2 initing device 2 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 3 initing device 3
[2022-12-12 07:39:47.666473: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.666526: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[[2022-12-12 07:39:472022-12-12 07:39:47..666594666596: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::19801980] ] eager alloc mem 381.47 MBeager alloc mem 381.47 MB

[2022-12-12 07:39:47.667120: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.669673: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.669794: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.669849: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.669915: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.669954: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.670020: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202[] 2022-12-12 07:39:475 solved.
670045: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc2022-12-12 07:39:47:.202670091] : 4 solvedE
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205[] 2022-12-12 07:39:47worker 0 thread 5 initing device 5.
670138: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 4 initing device 4
[2022-12-12 07:39:47.670526: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.670563: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.673826: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.674032: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.674085: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.674142: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.674703: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.674770: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.677886: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.677946: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 07:39:47.729718: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 07:39:47.730083: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 07:39:47.743711: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:39:47.743820: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 07:39:47.743865: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:39:47.756034: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:39:47.756891: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:47.758020: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:47.758112: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:39:47.758792: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:39:47.758833: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:39:47.758916: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[[:2022-12-12 07:39:472022-12-12 07:39:471980..[] 758954eager alloc mem 2.00 Bytes7589572022-12-12 07:39:47: 
: .EE758989  : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE:: 19801980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] ] :eager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes1980

] eager alloc mem 2.00 Bytes
[2022-12-12 07:39:47.759293: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[[2022-12-12 07:39:472022-12-12 07:39:47..[7593317593352022-12-12 07:39:47: : .EE759342  : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE:: 19801980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] ] :eager alloc mem 1024.00 Byteseager alloc mem 1024.00 Bytes1980

] eager alloc mem 1024.00 Bytes
[[[2022-12-12 07:39:472022-12-12 07:39:472022-12-12 07:39:47...763946763943763946: : : EEE   /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:::198019801980] ] ] eager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes


[[2022-12-12 07:39:47[2022-12-12 07:39:47.2022-12-12 07:39:47.764311.764311: 764316: E: E E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980:1980] 1980] eager alloc mem 1024.00 Bytes] eager alloc mem 1024.00 Bytes
eager alloc mem 1024.00 Bytes

[2022-12-12 07:39:47.812607: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:39:47.812680: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 07:39:47638.] 812678eager release cuda mem 2: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:39:47.812738: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 07:39:47638.] 812751eager release cuda mem 400000000: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 07:39:47eager release cuda mem 2.
812766: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:39:47.812815: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 07:39:47eager release cuda mem 400000000[.
2022-12-12 07:39:47812833.: 812827E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 2] 
eager release cuda mem 1024
[[2022-12-12 07:39:472022-12-12 07:39:47..812923812925: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::638638] ] eager release cuda mem 400000000eager release cuda mem 2

[2022-12-12 07:39:47[.2022-12-12 07:39:47812992.: 812973E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] 638eager release cuda mem 400000000] 
eager release cuda mem 1024
[2022-12-12 07:39:47.813100: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 07:39:47.813142: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:39:47.813229: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:39:47.813300: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 07:39:47.813343: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:39:47.817568: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 07:39:47.817634: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 07:39:47.817675: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 07:39:47.817881: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:39:47.818411: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:39:47.818915: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:39:47.819431: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:39:47.819952: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:39:47.820655: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:39:47.826956: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 114.82 MB
[2022-12-12 07:39:47.827540: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:47.827769: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 07:39:471980.] 827790eager alloc mem 611.00 KB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:47.827849: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:47.827933: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:47.827979: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:47.828123: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:47.828622: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:47.828711: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:39:47.828836: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:47.828875: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:47.828921[: 2022-12-12 07:39:47E. 828933/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: :E[1980 [2022-12-12 07:39:47] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 07:39:47.eager alloc mem 25.25 KB:.828956
638828960: ] : Eeager release cuda mem 625663E 
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::6381980] [] eager release cuda mem 6256632022-12-12 07:39:47eager alloc mem 25.25 KB
.
829061[: 2022-12-12 07:39:47E. 829098/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 625663:
[19802022-12-12 07:39:47] .eager alloc mem 25.25 KB829151: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[[2022-12-12 07:39:472022-12-12 07:39:47..829215829218: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::6381980] ] eager release cuda mem 625663eager alloc mem 25.25 KB

[2022-12-12 07:39:47.829326: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 07:39:47.829377: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:39:47.829419: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:39:47.829549: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:39:47.829589: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:39:47.829744: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:39:47.829783: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[2022-12-12 07:39:47.829830: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 07:39:47.[8298622022-12-12 07:39:47: .E829868 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] 2022-12-12 07:39:47:eager release cuda mem 25855.1980
829911] : eager alloc mem 14.31 GBE
[ 2022-12-12 07:39:47/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:829962638: ] Eeager release cuda mem 25855 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 07:39:471980.] 829996[eager alloc mem 14.31 GB: 2022-12-12 07:39:47
E. 830010/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager release cuda mem 25855:
1980] eager alloc mem 14.31 GB
[2022-12-12 07:39:47.830064: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 14.31 GB
[[[[[[[2022-12-12 07:39:51[2022-12-12 07:39:512022-12-12 07:39:512022-12-12 07:39:512022-12-12 07:39:512022-12-12 07:39:512022-12-12 07:39:512022-12-12 07:39:51........102232102232102268102230102230102232102230102242: : : : : : : : EEEEEEEE        /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:::1980::::198019801980] 1980198019801980] ] ] eager alloc mem 611.00 KB] ] ] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB
eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB






[[2022-12-12 07:39:51[2022-12-12 07:39:51[.2022-12-12 07:39:51[[.2022-12-12 07:39:51[103485.2022-12-12 07:39:51[2022-12-12 07:39:51103486.2022-12-12 07:39:51: 103489.2022-12-12 07:39:51.: 103495.E: 103499.103501E: 103513 E: 103525:  E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc E: E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc E:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc E :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc 638:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] 638:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:] 638:eager release cuda mem 625663] 638:638eager release cuda mem 625663] 638
eager release cuda mem 625663] 638] 
eager release cuda mem 625663] 
eager release cuda mem 625663] eager release cuda mem 625663
eager release cuda mem 625663
eager release cuda mem 625663


[2022-12-12 07:39:51.103878: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 07:39:51:.1980[103896] 2022-12-12 07:39:51: eager alloc mem 611.00 KB.E[[
[103908 [2022-12-12 07:39:51[2022-12-12 07:39:512022-12-12 07:39:51: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 07:39:51.2022-12-12 07:39:51..E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:.103930.103941103936:1980103938: 103935: : 1980] : E: EE] eager alloc mem 611.00 KBE E  eager alloc mem 611.00 KB
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:::1980:198019801980] 1980] ] ] eager alloc mem 611.00 KB] eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB
eager alloc mem 611.00 KB



[2022-12-12 07:39:51.104683: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.104755: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.104851: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 6256632022-12-12 07:39:51
.104869: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.104936: [E2022-12-12 07:39:51 .[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[[104944[2022-12-12 07:39:51:2022-12-12 07:39:512022-12-12 07:39:51: 2022-12-12 07:39:51.1980..[E2022-12-12 07:39:51.104954] 104955104958 .104958: eager alloc mem 611.00 KB: : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc104987: E
EE:: E   638E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc]  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:::eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:6381980638
638:] ] ] ] 638eager release cuda mem 625663eager alloc mem 611.00 KBeager release cuda mem 625663eager release cuda mem 625663] 



eager release cuda mem 625663[
2022-12-12 07:39:51.105231: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51[[.2022-12-12 07:39:512022-12-12 07:39:51105275..: 105280105283E: [:  E2022-12-12 07:39:51E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu . :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu105299/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980:: :] 1980E1980eager alloc mem 611.00 KB]  ] 
eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 611.00 KB
:
1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.105503: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.105572: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.105824: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.105896: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.105957: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.105993: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.106034: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.106071: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.106149: E[ 2022-12-12 07:39:51/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.[:1061612022-12-12 07:39:51638: .] E106170eager release cuda mem 625663 : 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 625663638] [
eager release cuda mem 6256632022-12-12 07:39:51
.[1062092022-12-12 07:39:51: .E106246 : [/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE2022-12-12 07:39:51[: .2022-12-12 07:39:51638/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu106282.[] :: 1062932022-12-12 07:39:51eager release cuda mem 6256631980E: .
]  E106320eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu : 
:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE1980: ] 1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager alloc mem 611.00 KB] :
[eager alloc mem 611.00 KB6382022-12-12 07:39:51
] .eager release cuda mem 625663106432
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.106529: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.106640: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.106711: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.106790: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.106826: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.106860: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.106895: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.107144: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.107176: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.107199: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 07:39:51eager release cuda mem 625663.
107218: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB[
2022-12-12 07:39:51.107247: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 611.00 KB2022-12-12 07:39:51[
[.2022-12-12 07:39:512022-12-12 07:39:51107264..: 107277107280E: :  EE/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc  :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638::] 1980638eager release cuda mem 625663] ] 
eager alloc mem 611.00 KBeager release cuda mem 625663

[2022-12-12 07:39:51.107463: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.107498[: 2022-12-12 07:39:51E. 107502/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: :E1980[]  2022-12-12 07:39:51eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.
:1075351980: ] Eeager alloc mem 611.00 KB 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.107611: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.107646: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.107683: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.107717: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.107978: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.108017: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.108054: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.108092: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.108179: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.108248: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.108279: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.[1083172022-12-12 07:39:51: .E108322 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[E:2022-12-12 07:39:51 638./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] 108349:eager release cuda mem 625663: 638
E]  eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
:1980] eager alloc mem 611.00 KB
[[2022-12-12 07:39:512022-12-12 07:39:51..108433108434: : [E[E2022-12-12 07:39:51 2022-12-12 07:39:51 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu108462:108470:: 638: 1980E] E]  eager release cuda mem 625663 eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
::1980638] ] eager alloc mem 611.00 KBeager release cuda mem 625663

[2022-12-12 07:39:51.108625: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.108655: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.108803: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.108839: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.108873: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.108905: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.108995: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.109070: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 07:39:51.109139: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.109179: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 120400004
[2022-12-12 07:39:51.109309: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.109347: [E 2022-12-12 07:39:51/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:109351638: ] [Eeager release cuda mem 1204000042022-12-12 07:39:51 
./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[109379:2022-12-12 07:39:51: 638.E] 109407 eager release cuda mem 625663: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
E: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 625663638
] eager release cuda mem 625663
[2022-12-12 07:39:51.[1095212022-12-12 07:39:51: .[E1095272022-12-12 07:39:51 : ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE109536: : 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE] : eager release cuda mem 120400004638[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
] 2022-12-12 07:39:51:eager release cuda mem 120400004[.1980
2022-12-12 07:39:51109620] .: eager alloc mem 611.00 KB109650E
:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638:] [638eager release cuda mem 6256632022-12-12 07:39:51] 
.eager release cuda mem 625663109724
: [E2022-12-12 07:39:51 [./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 07:39:51109772:.: 1793109785E] : [ Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.4432 secs E2022-12-12 07:39:51/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
 .:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc109825638:: ] 638Eeager release cuda mem 120400004]  
eager release cuda mem 120400004/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 625663
[2022-12-12 07:39:51.109910: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 120400004
[2022-12-12 07:39:51.110167: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.44358 secs 
[2022-12-12 07:39:51.110453: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 07:39:51.110527: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 120400004
[2022-12-12 07:39:51.110988: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.4444 secs 
[2022-12-12 07:39:51.111342: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.44079 secs 
[2022-12-12 07:39:51.111635: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.46116 secs 
[2022-12-12 07:39:51.111844: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.44538 secs 
[2022-12-12 07:39:51.112663: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.44686 secs 
[2022-12-12 07:39:51.113424: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 20.94 GB
[2022-12-12 07:39:51.113852: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 30000001 / 100000000 nodes ( 30.00 %~30.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 69999999 / 100000000 nodes ( 70.00 %) | 14.31 GB | 3.44333 secs 
[2022-12-12 07:39:52.768127: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 21.21 GB
[2022-12-12 07:39:52.768562: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 21.21 GB
[2022-12-12 07:39:52.770266: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 21.21 GB
[2022-12-12 07:39:54.249008: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 21.47 GB
[2022-12-12 07:39:54.249947: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 21.47 GB
[2022-12-12 07:39:54.251090: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 21.47 GB
[2022-12-12 07:39:55.505116: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 21.69 GB
[2022-12-12 07:39:55.505248: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 21.69 GB
[2022-12-12 07:39:55.505536: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 21.69 GB
[2022-12-12 07:39:57.798430: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 21.90 GB
[2022-12-12 07:39:57.799064: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 21.90 GB
[2022-12-12 07:39:57.804422: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 21.90 GB
[2022-12-12 07:39:59.821181: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 22.36 GB
[2022-12-12 07:39:59.823435: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 22.36 GB
[2022-12-12 07:39:59.824265: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2060] before create ctx, mem is 22.36 GB
[2022-12-12 07:40:01.557142: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2066] after create ctx, mem is 22.56 GB
[2022-12-12 07:40:01.557328: W /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:2073] after create stream, mem is 22.56 GB
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier
[HCTR][07:40:01.665][ERROR][RK0][tid #140552603432704]: replica 4 calling init per replica done, doing barrier
[HCTR][07:40:01.665][ERROR][RK0][tid #140552670541568]: replica 6 calling init per replica done, doing barrier
[HCTR][07:40:01.665][ERROR][RK0][tid #140552662148864]: replica 5 calling init per replica done, doing barrier
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier
[HCTR][07:40:01.665][ERROR][RK0][tid #140552670541568]: replica 6 calling init per replica done, doing barrier done
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 0 calling init per replica done, doing barrier done
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 2 calling init per replica done, doing barrier done
[HCTR][07:40:01.665][ERROR][RK0][tid #140552603432704]: replica 4 calling init per replica done, doing barrier done
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 7 calling init per replica done, doing barrier done
[HCTR][07:40:01.665][ERROR][RK0][main]: replica 1 calling init per replica done, doing barrier done
[HCTR][07:40:01.665][ERROR][RK0][tid #140552662148864]: replica 5 calling init per replica done, doing barrier done
[HCTR][07:40:01.665][ERROR][RK0][tid #140552670541568]: init per replica done
[HCTR][07:40:01.665][ERROR][RK0][main]: init per replica done
[HCTR][07:40:01.665][ERROR][RK0][main]: init per replica done
[HCTR][07:40:01.665][ERROR][RK0][tid #140552603432704]: init per replica done
[HCTR][07:40:01.665][ERROR][RK0][main]: init per replica done
[HCTR][07:40:01.665][ERROR][RK0][main]: init per replica done
[HCTR][07:40:01.665][ERROR][RK0][tid #140552662148864]: init per replica done
[HCTR][07:40:01.669][ERROR][RK0][main]: init per replica done
[HCTR][07:40:01.672][ERROR][RK0][main]: 2 allocated 3276800 at 0x7fbe77920000
[HCTR][07:40:01.672][ERROR][RK0][main]: 2 allocated 6553600 at 0x7fd6e5000000
[HCTR][07:40:01.672][ERROR][RK0][main]: 2 allocated 3276800 at 0x7fd6e5640000
[HCTR][07:40:01.672][ERROR][RK0][main]: 2 allocated 6553600 at 0x7fd6e5960000
[HCTR][07:40:01.672][ERROR][RK0][main]: 1 allocated 3276800 at 0x7fbe73920000
[HCTR][07:40:01.672][ERROR][RK0][main]: 1 allocated 6553600 at 0x7fd6e5000000
[HCTR][07:40:01.672][ERROR][RK0][main]: 1 allocated 3276800 at 0x7fd6e5640000
[HCTR][07:40:01.672][ERROR][RK0][main]: 1 allocated 6553600 at 0x7fd6e5960000
[HCTR][07:40:01.672][ERROR][RK0][main]: 7 allocated 3276800 at 0x7fbe77920000
[HCTR][07:40:01.672][ERROR][RK0][main]: 7 allocated 6553600 at 0x7fd6e3000000
[HCTR][07:40:01.672][ERROR][RK0][main]: 6 allocated 3276800 at 0x7fbe73920000
[HCTR][07:40:01.672][ERROR][RK0][main]: 7 allocated 3276800 at 0x7fd6e3640000
[HCTR][07:40:01.672][ERROR][RK0][main]: 3 allocated 3276800 at 0x7fbe73920000
[HCTR][07:40:01.672][ERROR][RK0][main]: 7 allocated 6553600 at 0x7fd6e3960000
[HCTR][07:40:01.672][ERROR][RK0][main]: 6 allocated 6553600 at 0x7fd6e3000000
[HCTR][07:40:01.672][ERROR][RK0][main]: 3 allocated 6553600 at 0x7fd6e5000000
[HCTR][07:40:01.672][ERROR][RK0][main]: 6 allocated 3276800 at 0x7fd6e3640000
[HCTR][07:40:01.672][ERROR][RK0][main]: 3 allocated 3276800 at 0x7fd6e5640000
[HCTR][07:40:01.672][ERROR][RK0][main]: 6 allocated 6553600 at 0x7fd6e3960000
[HCTR][07:40:01.672][ERROR][RK0][main]: 3 allocated 6553600 at 0x7fd6e5960000
[HCTR][07:40:01.672][ERROR][RK0][main]: 4 allocated 3276800 at 0x7fbe73920000
[HCTR][07:40:01.672][ERROR][RK0][main]: 4 allocated 6553600 at 0x7fd6e5000000
[HCTR][07:40:01.672][ERROR][RK0][main]: 4 allocated 3276800 at 0x7fd6e5640000
[HCTR][07:40:01.672][ERROR][RK0][main]: 4 allocated 6553600 at 0x7fd6e5960000
[HCTR][07:40:01.672][ERROR][RK0][main]: 5 allocated 3276800 at 0x7fbe73920000
[HCTR][07:40:01.672][ERROR][RK0][main]: 5 allocated 6553600 at 0x7fd6e3000000
[HCTR][07:40:01.672][ERROR][RK0][main]: 5 allocated 3276800 at 0x7fd6e3640000
[HCTR][07:40:01.672][ERROR][RK0][main]: 5 allocated 6553600 at 0x7fd6e3960000
[HCTR][07:40:01.675][ERROR][RK0][main]: 0 allocated 3276800 at 0x7fd6e6f20000
[HCTR][07:40:01.675][ERROR][RK0][main]: 0 allocated 6553600 at 0x7fd6e7400000
[HCTR][07:40:01.675][ERROR][RK0][main]: 0 allocated 3276800 at 0x7fd6e810e800
[HCTR][07:40:01.675][ERROR][RK0][main]: 0 allocated 6553600 at 0x7fd6e842e800








