2022-12-12 01:10:36.048032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.055302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.061964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.068300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.074231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.085663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.093386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.096991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.153965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.159777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.163620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.164259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.164835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.166046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.166252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.167652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.167781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.169335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.169391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.171112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.171240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.172629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.173008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.174074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.174661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.175529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.176308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.177139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.178824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.179976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.181035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.182117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.183926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.185155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.186180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.187221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.188252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.189292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.190304: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.191355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.196755: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:10:36.197424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.198956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.199659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.200252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.201251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.201848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.202866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.203372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.204376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.204917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.205704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.205883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.206841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.208020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.208405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.209498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.210743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.211271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.211331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.214188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.214288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.214596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.216905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.217221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.219081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.219471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.221175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.221648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.223101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.223327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.224060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.225953: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.226361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.227337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.229215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.229791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.230004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.230715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.232363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.233521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.234046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.234163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.234870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.236144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.236805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.237055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.245134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.245834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.245859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.247382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.247732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.247835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.249902: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.250261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.257404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.260882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.277544: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.280875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.284896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.288087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.288662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.288702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.288717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.288791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.288841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.289573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.293483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.293605: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.293778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.293798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.293796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.293823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.294437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.299452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.299497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.299595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.299639: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.299733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.300419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.303347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.303601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.303653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.303690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.303888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.307389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.307433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.307599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.307613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.307713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.311291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.311422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.311575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.311597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.311763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.314790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.315010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.315222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.315286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.315422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.318420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.318503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.318739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.318831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.319669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.321654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.321743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.321970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.322432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.323536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.326226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.326498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.326530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.327188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.329105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.330580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.330677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.330718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.330845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.332784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.334451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.334535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.334587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.334695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.336503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.337907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.338120: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.338167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.338394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.340479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.341401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.341600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.341703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.341922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.344141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.344366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.344862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.344954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.345197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.345701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.348758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.348903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.349062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.350613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.351443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.351466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.351634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.353601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.353905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.354582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.355647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.355698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.355936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.357135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.357357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.357976: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:10:36.358446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.359068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.359298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.359393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.360752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.361033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.362298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.362891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.363047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.363262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.364619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.364798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.366410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.366941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.367348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.367715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.368378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.370324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.370736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.372218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.372312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.372923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.373393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.373484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.375070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.375152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.376868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.377003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.377392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.377879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.378591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.379912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.380117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.381837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.382325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.382938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.383715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.384379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.384697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.388674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.389187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.390626: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:10:36.390633: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:10:36.390633: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:10:36.391057: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:10:36.392022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.392268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.395078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.395183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.397415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.397500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.399834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.399877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.399935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.399952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.400303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.400334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.405597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.405714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.406042: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.406069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.406363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.406530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.410295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.410665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.410816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.411112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.411219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.411255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.415484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.415837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.452613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.453003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.457524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.457883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.463774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.464284: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.496846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.499156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.503998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.504443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.510876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.511358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.516485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.520890: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:10:36.524456: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-12-12 01:10:36.529760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.533245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.545530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.545806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.549964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:36.550225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.521554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.522509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.523048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.523525: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:10:37.523582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 01:10:37.541763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.542401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.543063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.543655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.544180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.544656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0
2022-12-12 01:10:37.590753: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.590977: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.644573: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12340
2022-12-12 01:10:37.770310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.770938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.771484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.771962: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:10:37.772017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 01:10:37.789999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.790699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.791405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.791989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.792764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.793232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:1/device:GPU:0 with 30914 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0a.0, compute capability: 7.0
2022-12-12 01:10:37.837179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.837794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.838311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.838782: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:10:37.838833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 01:10:37.841267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.841894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.842414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.842886: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:10:37.842938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 01:10:37.844430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.845019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.845575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.846052: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:10:37.846098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 01:10:37.846380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.847010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.847553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.848030: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:10:37.848079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 01:10:37.856574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.857224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.858248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.858829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.859363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.859354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.860518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:5/device:GPU:0 with 30914 MB memory:  -> device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0e.0, compute capability: 7.0
2022-12-12 01:10:37.860729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.861277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.861868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.862407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.863302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.863308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:2/device:GPU:0 with 30914 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0b.0, compute capability: 7.0
2022-12-12 01:10:37.863900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.864417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.864985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.865495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.865502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.866455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:4/device:GPU:0 with 30914 MB memory:  -> device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0d.0, compute capability: 7.0
2022-12-12 01:10:37.866578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.867113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.867700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.868219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.868685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:3/device:GPU:0 with 30914 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0c.0, compute capability: 7.0
2022-12-12 01:10:37.881743: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.881931: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.883888: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12341
2022-12-12 01:10:37.899892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.899893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.901372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.901376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.902380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.902426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.903348: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:10:37.903383: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-12-12 01:10:37.903404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 01:10:37.903433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 01:10:37.905257: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.905432: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.908050: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12345
2022-12-12 01:10:37.912022: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.912205: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.914032: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.914073: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12344
2022-12-12 01:10:37.914169: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.915883: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12343
2022-12-12 01:10:37.921112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.921251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.922301: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.922414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.923341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.923459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.924503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.924584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.925580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.925664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:991] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-12-12 01:10:37.926595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:7/device:GPU:0 with 30914 MB memory:  -> device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:10.0, compute capability: 7.0
2022-12-12 01:10:37.926676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:worker/replica:0/task:6/device:GPU:0 with 30914 MB memory:  -> device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:0f.0, compute capability: 7.0
2022-12-12 01:10:37.963533: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.963745: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.965552: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12342
2022-12-12 01:10:37.972595: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.972781: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.972958: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.973109: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:272] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12340, 1 -> localhost:12341, 2 -> localhost:12342, 3 -> localhost:12343, 4 -> localhost:12344, 5 -> localhost:12345, 6 -> localhost:12346, 7 -> localhost:12347}
2022-12-12 01:10:37.974543: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12346
2022-12-12 01:10:37.974923: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:438] Started server with target: grpc://localhost:12347
[HCTR][01:10:39.246][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:10:39.247][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:10:39.247][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:10:39.247][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:10:39.247][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:10:39.247][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:10:39.247][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
[HCTR][01:10:39.247][ERROR][RK0][main]: using mock embedding with 100000000 * 128 elements
warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 0it [00:00, ?it/s]warmup run: 1it [00:01,  1.56s/it]warmup run: 95it [00:01, 79.36it/s]warmup run: 191it [00:01, 173.44it/s]warmup run: 1it [00:01,  1.54s/it]warmup run: 1it [00:01,  1.54s/it]warmup run: 288it [00:01, 278.57it/s]warmup run: 1it [00:01,  1.53s/it]warmup run: 1it [00:01,  1.56s/it]warmup run: 1it [00:01,  1.55s/it]warmup run: 1it [00:01,  1.47s/it]warmup run: 1it [00:01,  1.57s/it]warmup run: 100it [00:01, 84.56it/s]warmup run: 96it [00:01, 81.08it/s]warmup run: 384it [00:01, 386.62it/s]warmup run: 99it [00:01, 84.35it/s]warmup run: 97it [00:01, 81.18it/s]warmup run: 94it [00:01, 79.09it/s]warmup run: 99it [00:01, 87.41it/s]warmup run: 100it [00:01, 83.37it/s]warmup run: 199it [00:01, 182.29it/s]warmup run: 192it [00:01, 175.84it/s]warmup run: 480it [00:02, 492.18it/s]warmup run: 182it [00:01, 165.48it/s]warmup run: 192it [00:01, 174.18it/s]warmup run: 188it [00:01, 171.70it/s]warmup run: 198it [00:01, 188.70it/s]warmup run: 202it [00:01, 183.27it/s]warmup run: 298it [00:01, 289.87it/s]warmup run: 287it [00:01, 278.97it/s]warmup run: 574it [00:02, 585.32it/s]warmup run: 281it [00:01, 276.22it/s]warmup run: 288it [00:01, 278.26it/s]warmup run: 284it [00:01, 276.59it/s]warmup run: 298it [00:01, 300.41it/s]warmup run: 304it [00:01, 293.79it/s]warmup run: 399it [00:01, 405.02it/s]warmup run: 369it [00:01, 361.58it/s]warmup run: 667it [00:02, 663.90it/s]warmup run: 381it [00:01, 392.51it/s]warmup run: 385it [00:01, 388.05it/s]warmup run: 379it [00:01, 384.18it/s]warmup run: 398it [00:01, 415.47it/s]warmup run: 407it [00:01, 410.48it/s]warmup run: 500it [00:02, 517.14it/s]warmup run: 468it [00:02, 476.78it/s]warmup run: 762it [00:02, 733.04it/s]warmup run: 481it [00:02, 505.71it/s]warmup run: 482it [00:02, 494.88it/s]warmup run: 475it [00:02, 491.18it/s]warmup run: 497it [00:01, 524.44it/s]warmup run: 510it [00:02, 524.89it/s]warmup run: 603it [00:02, 623.64it/s]warmup run: 569it [00:02, 587.61it/s]warmup run: 856it [00:02, 786.89it/s]warmup run: 582it [00:02, 611.10it/s]warmup run: 571it [00:02, 589.32it/s]warmup run: 582it [00:02, 599.47it/s]warmup run: 598it [00:02, 627.82it/s]warmup run: 615it [00:02, 633.45it/s]warmup run: 706it [00:02, 716.54it/s]warmup run: 668it [00:02, 679.63it/s]warmup run: 950it [00:02, 828.33it/s]warmup run: 678it [00:02, 690.21it/s]warmup run: 676it [00:02, 676.53it/s]warmup run: 668it [00:02, 675.42it/s]warmup run: 700it [00:02, 718.53it/s]warmup run: 720it [00:02, 727.78it/s]warmup run: 805it [00:02, 775.02it/s]warmup run: 769it [00:02, 760.48it/s]warmup run: 1046it [00:02, 863.05it/s]warmup run: 764it [00:02, 745.62it/s]warmup run: 801it [00:02, 789.68it/s]warmup run: 770it [00:02, 710.32it/s]warmup run: 773it [00:02, 713.14it/s]warmup run: 823it [00:02, 801.84it/s]warmup run: 906it [00:02, 835.09it/s]warmup run: 868it [00:02, 818.46it/s]warmup run: 1142it [00:02, 887.96it/s]warmup run: 901it [00:02, 844.92it/s]warmup run: 858it [00:02, 768.74it/s]warmup run: 871it [00:02, 785.32it/s]warmup run: 873it [00:02, 783.35it/s]warmup run: 926it [00:02, 859.39it/s]warmup run: 1006it [00:02, 878.75it/s]warmup run: 965it [00:02, 858.71it/s]warmup run: 1000it [00:02, 884.28it/s]warmup run: 1237it [00:02, 859.85it/s]warmup run: 964it [00:02, 823.52it/s]warmup run: 973it [00:02, 838.18it/s]warmup run: 949it [00:02, 776.62it/s]warmup run: 1029it [00:02, 904.10it/s]warmup run: 1106it [00:02, 911.92it/s]warmup run: 1062it [00:02, 886.07it/s]warmup run: 1099it [00:02, 908.60it/s]warmup run: 1060it [00:02, 856.88it/s]warmup run: 1073it [00:02, 880.69it/s]warmup run: 1327it [00:02, 844.07it/s]warmup run: 1049it [00:02, 834.71it/s]warmup run: 1133it [00:02, 941.29it/s]warmup run: 1208it [00:02, 940.47it/s]warmup run: 1159it [00:02, 906.95it/s]warmup run: 1198it [00:02, 925.65it/s]warmup run: 1156it [00:02, 884.32it/s]warmup run: 1173it [00:02, 913.97it/s]warmup run: 1424it [00:03, 878.29it/s]warmup run: 1149it [00:02, 878.90it/s]warmup run: 1236it [00:02, 960.95it/s]warmup run: 1311it [00:02, 963.94it/s]warmup run: 1256it [00:02, 923.43it/s]warmup run: 1298it [00:02, 946.89it/s]warmup run: 1254it [00:02, 910.27it/s]warmup run: 1273it [00:02, 937.55it/s]warmup run: 1522it [00:03, 905.23it/s]warmup run: 1251it [00:02, 916.99it/s]warmup run: 1338it [00:02, 975.80it/s]warmup run: 1412it [00:02, 974.39it/s]warmup run: 1353it [00:02, 931.29it/s]warmup run: 1398it [00:02, 961.13it/s]warmup run: 1354it [00:02, 935.59it/s]warmup run: 1374it [00:02, 956.25it/s]warmup run: 1620it [00:03, 925.05it/s]warmup run: 1351it [00:02, 940.45it/s]warmup run: 1441it [00:02, 991.36it/s]warmup run: 1513it [00:03, 977.62it/s]warmup run: 1450it [00:03, 939.97it/s]warmup run: 1497it [00:02, 967.21it/s]warmup run: 1455it [00:03, 955.57it/s]warmup run: 1476it [00:03, 973.29it/s]warmup run: 1716it [00:03, 933.91it/s]warmup run: 1450it [00:03, 954.29it/s]warmup run: 1544it [00:03, 1002.39it/s]warmup run: 1616it [00:03, 991.73it/s]warmup run: 1546it [00:03, 945.78it/s]warmup run: 1596it [00:03, 963.99it/s]warmup run: 1555it [00:03, 966.24it/s]warmup run: 1577it [00:03, 983.54it/s]warmup run: 1820it [00:03, 964.50it/s]warmup run: 1550it [00:03, 967.37it/s]warmup run: 1647it [00:03, 1009.41it/s]warmup run: 1720it [00:03, 1003.91it/s]warmup run: 1648it [00:03, 967.51it/s]warmup run: 1694it [00:03, 962.07it/s]warmup run: 1655it [00:03, 973.85it/s]warmup run: 1678it [00:03, 990.40it/s]warmup run: 1924it [00:03, 985.48it/s]warmup run: 1651it [00:03, 977.74it/s]warmup run: 1750it [00:03, 1012.52it/s]warmup run: 1822it [00:03, 1002.59it/s]warmup run: 1749it [00:03, 979.82it/s]warmup run: 1794it [00:03, 970.96it/s]warmup run: 1780it [00:03, 998.50it/s]warmup run: 1754it [00:03, 966.48it/s]warmup run: 2031it [00:03, 1009.59it/s]warmup run: 1751it [00:03, 982.85it/s]warmup run: 1854it [00:03, 1018.29it/s]warmup run: 1852it [00:03, 994.00it/s]warmup run: 1923it [00:03, 998.41it/s] warmup run: 1892it [00:03, 964.54it/s]warmup run: 1883it [00:03, 1005.11it/s]warmup run: 1855it [00:03, 976.68it/s]warmup run: 2150it [00:03, 1062.87it/s]warmup run: 1852it [00:03, 988.06it/s]warmup run: 1958it [00:03, 1023.18it/s]warmup run: 1955it [00:03, 1003.94it/s]warmup run: 2027it [00:03, 1009.20it/s]warmup run: 1989it [00:03, 951.88it/s]warmup run: 1985it [00:03, 1003.70it/s]warmup run: 1956it [00:03, 984.70it/s]warmup run: 2270it [00:03, 1101.61it/s]warmup run: 2071it [00:03, 1054.06it/s]warmup run: 1952it [00:03, 977.39it/s]warmup run: 2067it [00:03, 1036.20it/s]warmup run: 2149it [00:03, 1070.36it/s]warmup run: 2102it [00:03, 1002.07it/s]warmup run: 2101it [00:03, 1049.08it/s]warmup run: 2390it [00:04, 1130.16it/s]warmup run: 2067it [00:03, 1020.80it/s]warmup run: 2063it [00:03, 1015.76it/s]warmup run: 2191it [00:03, 1095.82it/s]warmup run: 2188it [00:03, 1086.95it/s]warmup run: 2272it [00:03, 1115.27it/s]warmup run: 2218it [00:03, 1048.61it/s]warmup run: 2221it [00:03, 1091.38it/s]warmup run: 2510it [00:04, 1150.40it/s]warmup run: 2187it [00:03, 1073.29it/s]warmup run: 2185it [00:03, 1076.18it/s]warmup run: 2311it [00:03, 1125.66it/s]warmup run: 2309it [00:03, 1122.71it/s]warmup run: 2394it [00:03, 1146.40it/s]warmup run: 2334it [00:03, 1080.93it/s]warmup run: 2340it [00:03, 1120.44it/s]warmup run: 2307it [00:03, 1110.32it/s]warmup run: 2629it [00:04, 1159.63it/s]warmup run: 2307it [00:03, 1118.53it/s]warmup run: 2431it [00:03, 1146.90it/s]warmup run: 2431it [00:03, 1149.53it/s]warmup run: 2516it [00:03, 1168.10it/s]warmup run: 2450it [00:03, 1103.09it/s]warmup run: 2459it [00:03, 1138.76it/s]warmup run: 2427it [00:03, 1135.63it/s]warmup run: 2749it [00:04, 1170.24it/s]warmup run: 2429it [00:03, 1148.74it/s]warmup run: 2551it [00:03, 1161.72it/s]warmup run: 2553it [00:04, 1169.29it/s]warmup run: 2637it [00:04, 1179.78it/s]warmup run: 2566it [00:03, 1119.91it/s]warmup run: 2577it [00:04, 1150.90it/s]warmup run: 2547it [00:04, 1153.04it/s]warmup run: 2869it [00:04, 1178.06it/s]warmup run: 2551it [00:04, 1169.79it/s]warmup run: 2671it [00:04, 1172.75it/s]warmup run: 2675it [00:04, 1181.94it/s]warmup run: 2759it [00:04, 1191.74it/s]warmup run: 2682it [00:04, 1129.26it/s]warmup run: 2694it [00:04, 1156.18it/s]warmup run: 2989it [00:04, 1183.42it/s]warmup run: 2666it [00:04, 1161.97it/s]warmup run: 2672it [00:04, 1180.09it/s]warmup run: 2789it [00:04, 1173.99it/s]warmup run: 3000it [00:04, 663.64it/s] warmup run: 2797it [00:04, 1192.41it/s]warmup run: 2881it [00:04, 1197.87it/s]warmup run: 2799it [00:04, 1140.90it/s]warmup run: 2810it [00:04, 1156.97it/s]warmup run: 2785it [00:04, 1170.23it/s]warmup run: 2794it [00:04, 1191.63it/s]warmup run: 2907it [00:04, 1173.59it/s]warmup run: 2920it [00:04, 1201.81it/s]warmup run: 3000it [00:04, 686.75it/s] warmup run: 3000it [00:04, 687.27it/s] warmup run: 2918it [00:04, 1153.06it/s]warmup run: 2926it [00:04, 1157.12it/s]warmup run: 2904it [00:04, 1174.27it/s]warmup run: 2916it [00:04, 1198.70it/s]warmup run: 3000it [00:04, 675.84it/s] warmup run: 3000it [00:04, 676.36it/s] warmup run: 3000it [00:04, 685.15it/s] warmup run: 3000it [00:04, 671.05it/s] warmup run: 3000it [00:04, 669.20it/s] 



warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]

warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1649.79it/s]warmup should be done:   5%|         | 160/3000 [00:00<00:01, 1597.84it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1635.73it/s]warmup should be done:   5%|         | 161/3000 [00:00<00:01, 1605.41it/s]warmup should be done:   5%|         | 161/3000 [00:00<00:01, 1607.01it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1642.79it/s]warmup should be done:   5%|         | 158/3000 [00:00<00:01, 1574.49it/s]warmup should be done:   5%|         | 161/3000 [00:00<00:01, 1602.85it/s]warmup should be done:  11%|         | 331/3000 [00:00<00:01, 1655.08it/s]warmup should be done:  11%|         | 323/3000 [00:00<00:01, 1612.02it/s]warmup should be done:  11%|         | 322/3000 [00:00<00:01, 1605.15it/s]warmup should be done:  11%|         | 316/3000 [00:00<00:01, 1574.06it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1642.84it/s]warmup should be done:  11%|         | 324/3000 [00:00<00:01, 1615.14it/s]warmup should be done:  11%|         | 322/3000 [00:00<00:01, 1602.68it/s]warmup should be done:  11%|         | 328/3000 [00:00<00:01, 1625.70it/s]warmup should be done:  17%|        | 497/3000 [00:00<00:01, 1651.56it/s]warmup should be done:  16%|        | 476/3000 [00:00<00:01, 1584.26it/s]warmup should be done:  16%|        | 483/3000 [00:00<00:01, 1601.77it/s]warmup should be done:  16%|        | 491/3000 [00:00<00:01, 1625.63it/s]warmup should be done:  16%|        | 486/3000 [00:00<00:01, 1610.75it/s]warmup should be done:  16%|        | 495/3000 [00:00<00:01, 1638.74it/s]warmup should be done:  16%|        | 485/3000 [00:00<00:01, 1605.45it/s]warmup should be done:  16%|        | 483/3000 [00:00<00:01, 1591.44it/s]warmup should be done:  21%|        | 637/3000 [00:00<00:01, 1592.72it/s]warmup should be done:  22%|       | 663/3000 [00:00<00:01, 1648.76it/s]warmup should be done:  22%|       | 655/3000 [00:00<00:01, 1627.42it/s]warmup should be done:  22%|       | 659/3000 [00:00<00:01, 1635.80it/s]warmup should be done:  22%|       | 648/3000 [00:00<00:01, 1608.76it/s]warmup should be done:  22%|       | 646/3000 [00:00<00:01, 1600.83it/s]warmup should be done:  21%|       | 644/3000 [00:00<00:01, 1590.03it/s]warmup should be done:  21%|       | 643/3000 [00:00<00:01, 1588.89it/s]warmup should be done:  27%|       | 797/3000 [00:00<00:01, 1594.48it/s]warmup should be done:  27%|       | 818/3000 [00:00<00:01, 1626.32it/s]warmup should be done:  28%|       | 828/3000 [00:00<00:01, 1643.93it/s]warmup should be done:  27%|       | 809/3000 [00:00<00:01, 1606.37it/s]warmup should be done:  27%|       | 823/3000 [00:00<00:01, 1632.01it/s]warmup should be done:  27%|       | 807/3000 [00:00<00:01, 1595.73it/s]warmup should be done:  27%|       | 802/3000 [00:00<00:01, 1582.67it/s]warmup should be done:  27%|       | 804/3000 [00:00<00:01, 1584.94it/s]warmup should be done:  32%|      | 958/3000 [00:00<00:01, 1597.81it/s]warmup should be done:  33%|      | 981/3000 [00:00<00:01, 1622.29it/s]warmup should be done:  33%|      | 993/3000 [00:00<00:01, 1636.88it/s]warmup should be done:  32%|      | 970/3000 [00:00<00:01, 1599.62it/s]warmup should be done:  33%|      | 987/3000 [00:00<00:01, 1626.91it/s]warmup should be done:  32%|      | 968/3000 [00:00<00:01, 1597.40it/s]warmup should be done:  32%|      | 961/3000 [00:00<00:01, 1580.20it/s]warmup should be done:  32%|      | 963/3000 [00:00<00:01, 1579.88it/s]warmup should be done:  37%|      | 1118/3000 [00:00<00:01, 1592.40it/s]warmup should be done:  38%|      | 1144/3000 [00:00<00:01, 1623.10it/s]warmup should be done:  39%|      | 1158/3000 [00:00<00:01, 1638.33it/s]warmup should be done:  38%|      | 1150/3000 [00:00<00:01, 1625.47it/s]warmup should be done:  38%|      | 1131/3000 [00:00<00:01, 1606.10it/s]warmup should be done:  38%|      | 1130/3000 [00:00<00:01, 1595.38it/s]warmup should be done:  37%|      | 1120/3000 [00:00<00:01, 1576.58it/s]warmup should be done:  37%|      | 1121/3000 [00:00<00:01, 1575.81it/s]warmup should be done:  43%|     | 1278/3000 [00:00<00:01, 1590.10it/s]warmup should be done:  44%|     | 1307/3000 [00:00<00:01, 1623.11it/s]warmup should be done:  44%|     | 1323/3000 [00:00<00:01, 1640.32it/s]warmup should be done:  44%|     | 1313/3000 [00:00<00:01, 1625.33it/s]warmup should be done:  43%|     | 1294/3000 [00:00<00:01, 1612.19it/s]warmup should be done:  43%|     | 1290/3000 [00:00<00:01, 1594.49it/s]warmup should be done:  43%|     | 1282/3000 [00:00<00:01, 1584.93it/s]warmup should be done:  43%|     | 1279/3000 [00:00<00:01, 1577.76it/s]warmup should be done:  48%|     | 1438/3000 [00:00<00:00, 1589.64it/s]warmup should be done:  49%|     | 1470/3000 [00:00<00:00, 1619.83it/s]warmup should be done:  50%|     | 1488/3000 [00:00<00:00, 1640.68it/s]warmup should be done:  49%|     | 1457/3000 [00:00<00:00, 1615.03it/s]warmup should be done:  48%|     | 1450/3000 [00:00<00:00, 1595.12it/s]warmup should be done:  49%|     | 1476/3000 [00:00<00:00, 1617.47it/s]warmup should be done:  48%|     | 1445/3000 [00:00<00:00, 1596.77it/s]warmup should be done:  48%|     | 1438/3000 [00:00<00:00, 1579.30it/s]warmup should be done:  53%|    | 1598/3000 [00:01<00:00, 1590.24it/s]warmup should be done:  54%|    | 1632/3000 [00:01<00:00, 1617.81it/s]warmup should be done:  55%|    | 1653/3000 [00:01<00:00, 1641.25it/s]warmup should be done:  54%|    | 1610/3000 [00:01<00:00, 1595.42it/s]warmup should be done:  54%|    | 1619/3000 [00:01<00:00, 1612.27it/s]warmup should be done:  55%|    | 1639/3000 [00:01<00:00, 1620.84it/s]warmup should be done:  54%|    | 1607/3000 [00:01<00:00, 1602.49it/s]warmup should be done:  53%|    | 1596/3000 [00:01<00:00, 1574.40it/s]warmup should be done:  59%|    | 1758/3000 [00:01<00:00, 1589.15it/s]warmup should be done:  59%|    | 1770/3000 [00:01<00:00, 1596.67it/s]warmup should be done:  61%|    | 1818/3000 [00:01<00:00, 1641.19it/s]warmup should be done:  60%|    | 1794/3000 [00:01<00:00, 1613.18it/s]warmup should be done:  60%|    | 1802/3000 [00:01<00:00, 1623.22it/s]warmup should be done:  59%|    | 1769/3000 [00:01<00:00, 1604.86it/s]warmup should be done:  58%|    | 1755/3000 [00:01<00:00, 1577.64it/s]warmup should be done:  59%|    | 1781/3000 [00:01<00:00, 1598.49it/s]warmup should be done:  64%|   | 1918/3000 [00:01<00:00, 1590.11it/s]warmup should be done:  64%|   | 1930/3000 [00:01<00:00, 1596.99it/s]warmup should be done:  66%|   | 1983/3000 [00:01<00:00, 1639.97it/s]warmup should be done:  66%|   | 1965/3000 [00:01<00:00, 1623.72it/s]warmup should be done:  65%|   | 1956/3000 [00:01<00:00, 1608.94it/s]warmup should be done:  64%|   | 1931/3000 [00:01<00:00, 1606.44it/s]warmup should be done:  64%|   | 1914/3000 [00:01<00:00, 1579.87it/s]warmup should be done:  65%|   | 1941/3000 [00:01<00:00, 1580.78it/s]warmup should be done:  70%|   | 2090/3000 [00:01<00:00, 1597.85it/s]warmup should be done:  69%|   | 2078/3000 [00:01<00:00, 1589.38it/s]warmup should be done:  71%|   | 2128/3000 [00:01<00:00, 1625.57it/s]warmup should be done:  72%|  | 2148/3000 [00:01<00:00, 1641.05it/s]warmup should be done:  71%|   | 2117/3000 [00:01<00:00, 1608.68it/s]warmup should be done:  70%|   | 2093/3000 [00:01<00:00, 1608.42it/s]warmup should be done:  69%|   | 2073/3000 [00:01<00:00, 1582.14it/s]warmup should be done:  70%|   | 2100/3000 [00:01<00:00, 1583.45it/s]warmup should be done:  75%|  | 2251/3000 [00:01<00:00, 1599.77it/s]warmup should be done:  76%|  | 2279/3000 [00:01<00:00, 1610.71it/s]warmup should be done:  76%|  | 2291/3000 [00:01<00:00, 1622.33it/s]warmup should be done:  75%|  | 2237/3000 [00:01<00:00, 1582.08it/s]warmup should be done:  77%|  | 2313/3000 [00:01<00:00, 1638.87it/s]warmup should be done:  75%|  | 2254/3000 [00:01<00:00, 1608.45it/s]warmup should be done:  74%|  | 2232/3000 [00:01<00:00, 1574.10it/s]warmup should be done:  75%|  | 2259/3000 [00:01<00:00, 1582.64it/s]warmup should be done:  80%|  | 2413/3000 [00:01<00:00, 1603.72it/s]warmup should be done:  83%| | 2477/3000 [00:01<00:00, 1639.12it/s]warmup should be done:  81%| | 2442/3000 [00:01<00:00, 1614.86it/s]warmup should be done:  82%| | 2454/3000 [00:01<00:00, 1623.27it/s]warmup should be done:  80%|  | 2396/3000 [00:01<00:00, 1578.76it/s]warmup should be done:  80%|  | 2415/3000 [00:01<00:00, 1606.07it/s]warmup should be done:  80%|  | 2390/3000 [00:01<00:00, 1575.72it/s]warmup should be done:  81%|  | 2418/3000 [00:01<00:00, 1582.19it/s]warmup should be done:  86%| | 2575/3000 [00:01<00:00, 1608.16it/s]warmup should be done:  88%| | 2642/3000 [00:01<00:00, 1641.50it/s]warmup should be done:  87%| | 2618/3000 [00:01<00:00, 1625.45it/s]warmup should be done:  85%| | 2554/3000 [00:01<00:00, 1576.52it/s]warmup should be done:  86%| | 2576/3000 [00:01<00:00, 1606.53it/s]warmup should be done:  87%| | 2604/3000 [00:01<00:00, 1604.58it/s]warmup should be done:  85%| | 2548/3000 [00:01<00:00, 1576.00it/s]warmup should be done:  86%| | 2577/3000 [00:01<00:00, 1578.84it/s]warmup should be done:  91%|| 2739/3000 [00:01<00:00, 1617.54it/s]warmup should be done:  94%|| 2807/3000 [00:01<00:00, 1641.90it/s]warmup should be done:  93%|| 2781/3000 [00:01<00:00, 1626.51it/s]warmup should be done:  90%| | 2712/3000 [00:01<00:00, 1576.51it/s]warmup should be done:  91%|| 2738/3000 [00:01<00:00, 1609.37it/s]warmup should be done:  92%|| 2767/3000 [00:01<00:00, 1609.39it/s]warmup should be done:  90%| | 2706/3000 [00:01<00:00, 1577.03it/s]warmup should be done:  91%| | 2735/3000 [00:01<00:00, 1577.60it/s]warmup should be done:  97%|| 2903/3000 [00:01<00:00, 1622.79it/s]warmup should be done:  98%|| 2944/3000 [00:01<00:00, 1624.61it/s]warmup should be done:  99%|| 2972/3000 [00:01<00:00, 1637.97it/s]warmup should be done:  96%|| 2871/3000 [00:01<00:00, 1579.52it/s]warmup should be done:  97%|| 2902/3000 [00:01<00:00, 1615.82it/s]warmup should be done:  98%|| 2931/3000 [00:01<00:00, 1616.93it/s]warmup should be done:  96%|| 2866/3000 [00:01<00:00, 1582.26it/s]warmup should be done:  97%|| 2896/3000 [00:01<00:00, 1587.19it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1640.92it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1625.93it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1617.22it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1605.89it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1602.36it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1594.11it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1585.13it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1581.22it/s]






warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]
warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   0%|          | 0/3000 [00:00<?, ?it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1659.41it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1657.74it/s]warmup should be done:   6%|         | 166/3000 [00:00<00:01, 1657.73it/s]warmup should be done:   5%|         | 163/3000 [00:00<00:01, 1627.44it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1635.09it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1633.91it/s]warmup should be done:   6%|         | 165/3000 [00:00<00:01, 1641.52it/s]warmup should be done:   5%|         | 164/3000 [00:00<00:01, 1630.27it/s]warmup should be done:  11%|         | 333/3000 [00:00<00:01, 1662.25it/s]warmup should be done:  11%|         | 332/3000 [00:00<00:01, 1655.79it/s]warmup should be done:  11%|         | 330/3000 [00:00<00:01, 1646.36it/s]warmup should be done:  11%|         | 329/3000 [00:00<00:01, 1641.01it/s]warmup should be done:  11%|         | 334/3000 [00:00<00:01, 1666.10it/s]warmup should be done:  11%|         | 327/3000 [00:00<00:01, 1630.96it/s]warmup should be done:  11%|         | 329/3000 [00:00<00:01, 1637.17it/s]warmup should be done:  11%|         | 328/3000 [00:00<00:01, 1627.13it/s]warmup should be done:  17%|        | 500/3000 [00:00<00:01, 1664.60it/s]warmup should be done:  16%|        | 495/3000 [00:00<00:01, 1646.69it/s]warmup should be done:  17%|        | 502/3000 [00:00<00:01, 1670.78it/s]warmup should be done:  17%|        | 499/3000 [00:00<00:01, 1657.80it/s]warmup should be done:  16%|        | 495/3000 [00:00<00:01, 1645.65it/s]warmup should be done:  16%|        | 491/3000 [00:00<00:01, 1630.59it/s]warmup should be done:  16%|        | 494/3000 [00:00<00:01, 1640.43it/s]warmup should be done:  16%|        | 492/3000 [00:00<00:01, 1628.38it/s]warmup should be done:  22%|       | 667/3000 [00:00<00:01, 1665.93it/s]warmup should be done:  22%|       | 668/3000 [00:00<00:01, 1669.83it/s]warmup should be done:  22%|       | 670/3000 [00:00<00:01, 1670.37it/s]warmup should be done:  22%|       | 660/3000 [00:00<00:01, 1643.87it/s]warmup should be done:  22%|       | 656/3000 [00:00<00:01, 1635.13it/s]warmup should be done:  22%|       | 660/3000 [00:00<00:01, 1639.60it/s]warmup should be done:  22%|       | 656/3000 [00:00<00:01, 1630.36it/s]warmup should be done:  22%|       | 659/3000 [00:00<00:01, 1637.24it/s]warmup should be done:  28%|       | 834/3000 [00:00<00:01, 1662.67it/s]warmup should be done:  28%|       | 838/3000 [00:00<00:01, 1677.17it/s]warmup should be done:  27%|       | 821/3000 [00:00<00:01, 1637.71it/s]warmup should be done:  28%|       | 838/3000 [00:00<00:01, 1668.62it/s]warmup should be done:  27%|       | 824/3000 [00:00<00:01, 1636.27it/s]warmup should be done:  28%|       | 825/3000 [00:00<00:01, 1639.68it/s]warmup should be done:  27%|       | 823/3000 [00:00<00:01, 1637.06it/s]warmup should be done:  27%|       | 820/3000 [00:00<00:01, 1632.03it/s]warmup should be done:  34%|      | 1007/3000 [00:00<00:01, 1681.27it/s]warmup should be done:  33%|      | 1001/3000 [00:00<00:01, 1662.47it/s]warmup should be done:  33%|      | 985/3000 [00:00<00:01, 1636.27it/s]warmup should be done:  33%|      | 988/3000 [00:00<00:01, 1636.94it/s]warmup should be done:  34%|      | 1006/3000 [00:00<00:01, 1669.64it/s]warmup should be done:  33%|      | 988/3000 [00:00<00:01, 1640.34it/s]warmup should be done:  33%|      | 991/3000 [00:00<00:01, 1643.57it/s]warmup should be done:  33%|      | 984/3000 [00:00<00:01, 1628.88it/s]warmup should be done:  39%|      | 1176/3000 [00:00<00:01, 1681.44it/s]warmup should be done:  38%|      | 1152/3000 [00:00<00:01, 1637.32it/s]warmup should be done:  39%|      | 1168/3000 [00:00<00:01, 1660.01it/s]warmup should be done:  38%|      | 1150/3000 [00:00<00:01, 1637.52it/s]warmup should be done:  39%|      | 1174/3000 [00:00<00:01, 1670.13it/s]warmup should be done:  39%|      | 1157/3000 [00:00<00:01, 1648.19it/s]warmup should be done:  39%|      | 1156/3000 [00:00<00:01, 1650.37it/s]warmup should be done:  38%|      | 1148/3000 [00:00<00:01, 1630.04it/s]warmup should be done:  45%|     | 1346/3000 [00:00<00:00, 1684.19it/s]warmup should be done:  44%|     | 1316/3000 [00:00<00:01, 1635.90it/s]warmup should be done:  44%|     | 1314/3000 [00:00<00:01, 1637.65it/s]warmup should be done:  45%|     | 1342/3000 [00:00<00:00, 1672.34it/s]warmup should be done:  44%|     | 1335/3000 [00:00<00:01, 1659.40it/s]warmup should be done:  44%|     | 1323/3000 [00:00<00:01, 1655.23it/s]warmup should be done:  44%|     | 1322/3000 [00:00<00:01, 1646.34it/s]warmup should be done:  44%|     | 1312/3000 [00:00<00:01, 1627.79it/s]warmup should be done:  49%|     | 1479/3000 [00:00<00:00, 1641.39it/s]warmup should be done:  50%|     | 1515/3000 [00:00<00:00, 1683.41it/s]warmup should be done:  49%|     | 1481/3000 [00:00<00:00, 1638.36it/s]warmup should be done:  50%|     | 1510/3000 [00:00<00:00, 1673.05it/s]warmup should be done:  50%|     | 1491/3000 [00:00<00:00, 1661.44it/s]warmup should be done:  50%|     | 1488/3000 [00:00<00:00, 1648.13it/s]warmup should be done:  49%|     | 1476/3000 [00:00<00:00, 1631.17it/s]warmup should be done:  50%|     | 1501/3000 [00:00<00:00, 1575.46it/s]warmup should be done:  55%|    | 1644/3000 [00:01<00:00, 1642.97it/s]warmup should be done:  56%|    | 1685/3000 [00:01<00:00, 1685.80it/s]warmup should be done:  56%|    | 1678/3000 [00:01<00:00, 1673.86it/s]warmup should be done:  55%|    | 1659/3000 [00:01<00:00, 1666.62it/s]warmup should be done:  55%|    | 1646/3000 [00:01<00:00, 1639.35it/s]warmup should be done:  55%|    | 1655/3000 [00:01<00:00, 1651.77it/s]warmup should be done:  55%|    | 1641/3000 [00:01<00:00, 1633.91it/s]warmup should be done:  56%|    | 1665/3000 [00:01<00:00, 1593.03it/s]warmup should be done:  60%|    | 1809/3000 [00:01<00:00, 1641.53it/s]warmup should be done:  62%|   | 1855/3000 [00:01<00:00, 1687.76it/s]warmup should be done:  60%|    | 1810/3000 [00:01<00:00, 1638.59it/s]warmup should be done:  61%|    | 1827/3000 [00:01<00:00, 1668.10it/s]warmup should be done:  62%|   | 1846/3000 [00:01<00:00, 1672.33it/s]warmup should be done:  61%|    | 1822/3000 [00:01<00:00, 1654.29it/s]warmup should be done:  60%|    | 1805/3000 [00:01<00:00, 1597.87it/s]warmup should be done:  61%|    | 1835/3000 [00:01<00:00, 1622.32it/s]warmup should be done:  67%|   | 2024/3000 [00:01<00:00, 1687.63it/s]warmup should be done:  66%|   | 1994/3000 [00:01<00:00, 1667.54it/s]warmup should be done:  66%|   | 1974/3000 [00:01<00:00, 1636.04it/s]warmup should be done:  67%|   | 2014/3000 [00:01<00:00, 1671.36it/s]warmup should be done:  66%|   | 1974/3000 [00:01<00:00, 1636.23it/s]warmup should be done:  66%|   | 1988/3000 [00:01<00:00, 1653.15it/s]warmup should be done:  66%|   | 1968/3000 [00:01<00:00, 1607.11it/s]warmup should be done:  67%|   | 2004/3000 [00:01<00:00, 1641.92it/s]warmup should be done:  72%|  | 2161/3000 [00:01<00:00, 1667.91it/s]warmup should be done:  73%|  | 2193/3000 [00:01<00:00, 1685.83it/s]warmup should be done:  71%|  | 2138/3000 [00:01<00:00, 1636.36it/s]warmup should be done:  73%|  | 2182/3000 [00:01<00:00, 1670.58it/s]warmup should be done:  71%|  | 2138/3000 [00:01<00:00, 1633.97it/s]warmup should be done:  72%|  | 2154/3000 [00:01<00:00, 1650.87it/s]warmup should be done:  71%|   | 2132/3000 [00:01<00:00, 1614.02it/s]warmup should be done:  72%|  | 2173/3000 [00:01<00:00, 1656.08it/s]warmup should be done:  79%|  | 2362/3000 [00:01<00:00, 1686.08it/s]warmup should be done:  78%|  | 2329/3000 [00:01<00:00, 1669.65it/s]warmup should be done:  77%|  | 2303/3000 [00:01<00:00, 1638.25it/s]warmup should be done:  78%|  | 2350/3000 [00:01<00:00, 1672.00it/s]warmup should be done:  77%|  | 2302/3000 [00:01<00:00, 1634.35it/s]warmup should be done:  77%|  | 2320/3000 [00:01<00:00, 1648.41it/s]warmup should be done:  77%|  | 2296/3000 [00:01<00:00, 1621.64it/s]warmup should be done:  78%|  | 2343/3000 [00:01<00:00, 1667.68it/s]warmup should be done:  84%| | 2531/3000 [00:01<00:00, 1686.79it/s]warmup should be done:  83%| | 2497/3000 [00:01<00:00, 1670.69it/s]warmup should be done:  82%| | 2467/3000 [00:01<00:00, 1637.14it/s]warmup should be done:  84%| | 2518/3000 [00:01<00:00, 1673.37it/s]warmup should be done:  82%| | 2466/3000 [00:01<00:00, 1630.58it/s]warmup should be done:  83%| | 2485/3000 [00:01<00:00, 1647.70it/s]warmup should be done:  82%| | 2459/3000 [00:01<00:00, 1623.93it/s]warmup should be done:  84%| | 2513/3000 [00:01<00:00, 1676.40it/s]warmup should be done:  90%| | 2700/3000 [00:01<00:00, 1687.46it/s]warmup should be done:  89%| | 2665/3000 [00:01<00:00, 1668.93it/s]warmup should be done:  88%| | 2631/3000 [00:01<00:00, 1633.77it/s]warmup should be done:  90%| | 2686/3000 [00:01<00:00, 1673.38it/s]warmup should be done:  88%| | 2651/3000 [00:01<00:00, 1648.99it/s]warmup should be done:  88%| | 2630/3000 [00:01<00:00, 1627.46it/s]warmup should be done:  87%| | 2622/3000 [00:01<00:00, 1624.70it/s]warmup should be done:  89%| | 2683/3000 [00:01<00:00, 1680.96it/s]warmup should be done:  96%|| 2869/3000 [00:01<00:00, 1687.07it/s]warmup should be done:  94%|| 2832/3000 [00:01<00:00, 1668.11it/s]warmup should be done:  95%|| 2854/3000 [00:01<00:00, 1672.32it/s]warmup should be done:  93%|| 2795/3000 [00:01<00:00, 1631.73it/s]warmup should be done:  94%|| 2817/3000 [00:01<00:00, 1650.71it/s]warmup should be done:  93%|| 2794/3000 [00:01<00:00, 1628.56it/s]warmup should be done:  93%|| 2786/3000 [00:01<00:00, 1628.26it/s]warmup should be done:  95%|| 2853/3000 [00:01<00:00, 1684.75it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1682.44it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1671.31it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1670.31it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1659.87it/s]warmup should be done:  99%|| 2962/3000 [00:01<00:00, 1641.52it/s]warmup should be done:  99%|| 2984/3000 [00:01<00:00, 1655.88it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1657.55it/s]warmup should be done:  99%|| 2958/3000 [00:01<00:00, 1630.53it/s]warmup should be done:  98%|| 2951/3000 [00:01<00:00, 1632.36it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1649.09it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1638.12it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1633.84it/s]warmup should be done: 100%|| 3000/3000 [00:01<00:00, 1625.08it/s]2022-12-12 01:12:13.404025: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4aeb82f7c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:12:13.404085: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:12:13.945846: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4ae3833480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:12:13.945905: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:12:14.466549: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f2ed802d410 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:12:14.466614: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:12:14.514150: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4ae7795eb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:12:14.514215: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:12:14.753399: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4aeb82fc20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:12:14.753472: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:12:14.760452: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4aeb82c0d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:12:14.760516: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:12:14.802451: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4ad3833640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:12:14.802522: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:12:14.834901: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x7f4aeb82bc20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-12-12 01:12:14.834975: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-12-12 01:12:15.645031: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:12:16.186001: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:12:16.764874: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:12:16.835090: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:12:17.021390: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:12:17.102450: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:12:17.125834: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:12:17.138412: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-12-12 01:12:18.577825: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:12:19.025991: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:12:19.612893: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:12:19.771047: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:12:19.892695: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:12:20.004492: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:12:20.046969: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-12-12 01:12:20.057275: I tensorflow/compiler/jit/xla_compilation_cache.cc:481] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
[HCTR][01:12:53.400][ERROR][RK0][tid #139960451569408]: replica 7 reaches 1000, calling init pre replica
[HCTR][01:12:53.400][ERROR][RK0][tid #139960451569408]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:12:53.407][ERROR][RK0][tid #139960451569408]: coll ps creation done
[HCTR][01:12:53.407][ERROR][RK0][tid #139960451569408]: replica 7 waits for coll ps creation barrier
[HCTR][01:12:53.461][ERROR][RK0][main]: replica 6 reaches 1000, calling init pre replica
[HCTR][01:12:53.462][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:12:53.471][ERROR][RK0][main]: coll ps creation done
[HCTR][01:12:53.471][ERROR][RK0][main]: replica 6 waits for coll ps creation barrier
[HCTR][01:12:53.585][ERROR][RK0][main]: replica 3 reaches 1000, calling init pre replica
[HCTR][01:12:53.585][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:12:53.595][ERROR][RK0][main]: coll ps creation done
[HCTR][01:12:53.595][ERROR][RK0][main]: replica 3 waits for coll ps creation barrier
[HCTR][01:12:53.603][ERROR][RK0][tid #139959897945856]: replica 1 reaches 1000, calling init pre replica
[HCTR][01:12:53.604][ERROR][RK0][tid #139959897945856]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:12:53.608][ERROR][RK0][tid #139959897945856]: coll ps creation done
[HCTR][01:12:53.608][ERROR][RK0][tid #139959897945856]: replica 1 waits for coll ps creation barrier
[HCTR][01:12:53.654][ERROR][RK0][tid #139960434816768]: replica 0 reaches 1000, calling init pre replica
[HCTR][01:12:53.654][ERROR][RK0][tid #139960434816768]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:12:53.659][ERROR][RK0][tid #139960434816768]: coll ps creation done
[HCTR][01:12:53.659][ERROR][RK0][tid #139960434816768]: replica 0 waits for coll ps creation barrier
[HCTR][01:12:53.661][ERROR][RK0][tid #139959830836992]: replica 2 reaches 1000, calling init pre replica
[HCTR][01:12:53.661][ERROR][RK0][tid #139959830836992]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:12:53.665][ERROR][RK0][tid #139959830836992]: coll ps creation done
[HCTR][01:12:53.665][ERROR][RK0][tid #139959830836992]: replica 2 waits for coll ps creation barrier
[HCTR][01:12:53.770][ERROR][RK0][main]: replica 5 reaches 1000, calling init pre replica
[HCTR][01:12:53.770][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:12:53.775][ERROR][RK0][main]: coll ps creation done
[HCTR][01:12:53.775][ERROR][RK0][main]: replica 5 waits for coll ps creation barrier
[HCTR][01:12:53.826][ERROR][RK0][main]: replica 4 reaches 1000, calling init pre replica
[HCTR][01:12:53.826][ERROR][RK0][main]: coll ps creation, with 8 devices, using policy rep_cache
[HCTR][01:12:53.833][ERROR][RK0][main]: coll ps creation done
[HCTR][01:12:53.833][ERROR][RK0][main]: replica 4 waits for coll ps creation barrier
[HCTR][01:12:53.833][ERROR][RK0][tid #139960434816768]: replica 0 preparing frequency
[HCTR][01:12:54.701][ERROR][RK0][tid #139960434816768]: replica 0 preparing frequency done
[HCTR][01:12:54.743][ERROR][RK0][tid #139960434816768]: replica 0 calling init per replica
[HCTR][01:12:54.743][ERROR][RK0][tid #139959830836992]: replica 2 calling init per replica
[HCTR][01:12:54.743][ERROR][RK0][main]: replica 5 calling init per replica
[HCTR][01:12:54.743][ERROR][RK0][main]: replica 3 calling init per replica
[HCTR][01:12:54.743][ERROR][RK0][tid #139959897945856]: replica 1 calling init per replica
[HCTR][01:12:54.743][ERROR][RK0][main]: replica 6 calling init per replica
[HCTR][01:12:54.743][ERROR][RK0][main]: replica 4 calling init per replica
[HCTR][01:12:54.743][ERROR][RK0][tid #139960451569408]: replica 7 calling init per replica
[HCTR][01:12:54.743][ERROR][RK0][tid #139960434816768]: Calling build_v2
[HCTR][01:12:54.743][ERROR][RK0][tid #139959830836992]: Calling build_v2
[HCTR][01:12:54.743][ERROR][RK0][main]: Calling build_v2
[HCTR][01:12:54.743][ERROR][RK0][main]: Calling build_v2
[HCTR][01:12:54.743][ERROR][RK0][tid #139959897945856]: Calling build_v2
[HCTR][01:12:54.744][ERROR][RK0][tid #139959830836992]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:12:54.743][ERROR][RK0][main]: Calling build_v2
[HCTR][01:12:54.744][ERROR][RK0][main]: Calling build_v2
[HCTR][01:12:54.744][ERROR][RK0][tid #139960434816768]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:12:54.744][ERROR][RK0][tid #139960451569408]: Calling build_v2
[HCTR][01:12:54.744][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:12:54.744][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:12:54.744][ERROR][RK0][tid #139959897945856]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:12:54.744][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:12:54.744][ERROR][RK0][main]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[HCTR][01:12:54.744][ERROR][RK0][tid #139960451569408]: cudaDevAttrCanUseHostPointerForRegisteredMem is 1
[2022-12-12 01:12:54.748232: E [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:12:54:.178748273] : v100x8, slow pcieE
 [/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:[1782022-12-12 01:12:54] .2022-12-12 01:12:54v100x8, slow pcie748338.
: 748317E:  E[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc 2022-12-12 01:12:54[:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.196:748370] 2022-12-12 01:12:54178: assigning 0 to cpu.] E
748364v100x8, slow pcie [: 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE: 1962022-12-12 01:12:54/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[] .:2022-12-12 01:12:54assigning 0 to cpu748408178.
: ] 748444v100x8, slow pcieE[: [
 2022-12-12 01:12:54E/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc. [:748475/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[2022-12-12 01:12:54178: :2022-12-12 01:12:54.] E2022-12-12 01:12:54196.748500v100x8, slow pcie .] 748508: [
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc748469assigning 0 to cpu: E:: 
2022-12-12 01:12:54E[ [212E. 2022-12-12 01:12:54/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc]  2022-12-12 01:12:54748523/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.:build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.[: :748575196
:7485642022-12-12 01:12:54E212: ] 178: . ] Eassigning 0 to cpu[] E748643/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8 
2022-12-12 01:12:54v100x8, slow pcie : :
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE178:748701: [[[] 196v100x8, slow pcie: 178/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:12:542022-12-12 01:12:542022-12-12 01:12:54] 
E] :...assigning 0 to cpu [v100x8, slow pcie212748784748783748785
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:12:54
] : : : :.build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8EEE[213748856
   2022-12-12 01:12:54[] : /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[.2022-12-12 01:12:54remote time is 8.68421E:::2022-12-12 01:12:54748911.
 212213196.: 748935/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] ] [] 748958E: :build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8remote time is 8.684212022-12-12 01:12:54assigning 0 to cpu:  E196

.
E[/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc ] 749026 [2022-12-12 01:12:54:/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccassigning 0 to cpu: /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:12:54.196:
E:.[749106] 212 2137491082022-12-12 01:12:54: assigning 0 to cpu] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[] : .E
build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8:2022-12-12 01:12:54remote time is 8.68421E749156 
214.
 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc] 749214/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[E[:[cpu time is 97.0588: :2022-12-12 01:12:54 2022-12-12 01:12:542142022-12-12 01:12:54
E213./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.] . ] 749269:749272cpu time is 97.0588749274/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421: 212: 
: :
E] EE212 [build asymm link desc with 8X Tesla V100-SXM2-32GB out of 8  ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:12:54
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccbuild asymm link desc with 8X Tesla V100-SXM2-32GB out of 8:.[::
2137494252022-12-12 01:12:54212214] : .] [] remote time is 8.68421E749482build asymm link desc with 8X Tesla V100-SXM2-32GB out of 82022-12-12 01:12:54cpu time is 97.0588
 : 
.
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccE[749519: [2022-12-12 01:12:54: 214/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-12 01:12:54.E ] :.749568/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cccpu time is 97.0588213749585: :
] : E213remote time is 8.68421E ] 
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 8.68421/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:
:[[2142132022-12-12 01:12:542022-12-12 01:12:54] ] ..cpu time is 97.0588remote time is 8.68421749735749755

: : E[E 2022-12-12 01:12:54 /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc./hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:749829:214: 214] E] cpu time is 97.0588 cpu time is 97.0588
/hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
:214] cpu time is 97.0588
[2022-12-12 01:14:13.960507: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-12 01:14:14.  1127: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-12 01:14:14.  1194: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:919] num_cached_nodes = 5000000
[2022-12-12 01:14:14.131249: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-12 01:14:14.131339: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-12 01:14:14.191908: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-12 01:14:14.191947: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-12 01:14:14.192406: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.193259: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.193922: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.207062: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 3 solved
[2022-12-12 01:14:14.207145: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 3 initing device 3
[2022-12-12 01:14:14.207308: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:202] 6 solved
[2022-12-12 01:14:14.207371[: 2022-12-12 01:14:14E. 207366/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc: :E205 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.ccworker 0 thread 6 initing device 6:
202] 7 solved
[2022-12-12 01:14:14.207442: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 7 initing device 7
[2022-12-12 01:14:14.207566: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.207789: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.207851: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14[.2022-12-12 01:14:14208309.: 208331E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc202:] 202] 5 solved4 solved

[[2022-12-12 01:14:142022-12-12 01:14:14..208433208436: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::205205] ] worker 0 thread 5 initing device 5worker 0 thread 4 initing device 4

[2022-12-12 01:14:14.208877: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 01:14:14eager alloc mem 381.47 MB.
208898: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[[2022-12-12 01:14:142022-12-12 01:14:14..210123210126: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::202202] ] 1 solved2 solved

[[2022-12-12 01:14:142022-12-12 01:14:14..210230210232: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/facade.cc::205205] ] worker 0 thread 1 initing device 1worker 0 thread 2 initing device 2

[2022-12-12 01:14:14.[2106572022-12-12 01:14:14: .E210670 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE: [1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 01:14:14] :[.eager alloc mem 381.47 MB19802022-12-12 01:14:14210695
] .: eager alloc mem 381.47 MB210705E
:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980:] 1980eager alloc mem 381.47 MB] 
eager alloc mem 381.47 MB
[2022-12-12 01:14:14.210925: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.210983: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.212392: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.214985: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.215056: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.215091: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.215298: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.215333: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.215390: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.216308: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.219470: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.219705: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 381.47 MB
[2022-12-12 01:14:14.274713: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 01:14:14.275100: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 01:14:14.291062: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:14:14.291155: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:14:14.291202: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:14:14.292035: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:14:14.292710: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.293691: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.293779: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:14:14.294453: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:14:14.294492: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:14:14.299278: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 01:14:14.299590: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 01:14:14.304397: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:14:14.304460: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:14:14.304501: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:14:14.304791: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[2022-12-12 01:14:14.305094: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[2022-12-12 01:14:14.305276: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:14:14.305691: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.306642: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.306723: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:14:14.307396: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:14:14.307436: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:14:14.308047: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.00 Bytes
[[[[2022-12-12 01:14:142022-12-12 01:14:142022-12-12 01:14:142022-12-12 01:14:14....308117308117308117308117: : : : EEEE    /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::::1980198019801980] ] ] ] eager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Byteseager alloc mem 2.00 Bytes



[2022-12-12 01:14:14.308377: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 1024.00 Bytes
[[[2022-12-12 01:14:14[2022-12-12 01:14:142022-12-12 01:14:14.2022-12-12 01:14:14..308501.308502308502: 308505: E: E:  E E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980:1980:] 1980] 1980eager alloc mem 1024.00 Bytes] eager alloc mem 1024.00 Bytes] 
eager alloc mem 1024.00 Bytes
eager alloc mem 1024.00 Bytes

[2022-12-12 01:14:14.312394: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:14:14.312462: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:14:14.312503: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:14:14.323731: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:14:14.324148: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.324379: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:14:14.324456: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:14:14.324501: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:14:14.324525: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:14:14.324597: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2[
2022-12-12 01:14:14.324605: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:14:14.324648: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:14:14.324672: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 01:14:14638.] 324675eager release cuda mem 2: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:14:14.324735: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:[6382022-12-12 01:14:14] .eager release cuda mem 400000000324750
: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:14:14.324806: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:14:14.324935: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 1024
[2022-12-12 01:14:14.325001: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 2
[2022-12-12 01:14:14.325045: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 400000000
[2022-12-12 01:14:14.325108: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.325194: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:14:14.325323: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:14:14.325861: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:14:14.325903: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:14:14.326242: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:14:14.326990: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:14:14.330251: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:14:14.330767: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 19.45 MB
[2022-12-12 01:14:14.331263: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.331815: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.331977: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.332033: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.332086: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.332229: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.332325: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:14:14.332766: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.332847: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:14:14.332933: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[[2022-12-12 01:14:142022-12-12 01:14:14..332991332992: : EE[  2022-12-12 01:14:14/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.::333016638638: ] ] [Eeager release cuda mem 625663eager release cuda mem 258552022-12-12 01:14:14 

./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu333043:: 1980E]  eager alloc mem 25.25 KB[/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
2022-12-12 01:14:14:.638333082] : eager release cuda mem 625663E
 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 01:14:14eager alloc mem 2.38 GB.
333118: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:14:14.333166: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 25.25 KB
[2022-12-12 01:14:14.333523: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[2022-12-12 01:14:14.333569: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:14:14.333747: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 25855
[[2022-12-12 01:14:142022-12-12 01:14:14..333788333789: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::1980638] ] eager alloc mem 2.38 GBeager release cuda mem 25855

[2022-12-12 01:14:14.333834: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[:2022-12-12 01:14:14638.] 333853eager release cuda mem 25855: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[2022-12-12 01:14:14.333890: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 2.38 GB
[[[[[[[2022-12-12 01:14:14[2022-12-12 01:14:142022-12-12 01:14:142022-12-12 01:14:142022-12-12 01:14:142022-12-12 01:14:142022-12-12 01:14:14.2022-12-12 01:14:14......806235.806251806235806235806235806251806253: 806264: : : : : : E: EEEEEE E      /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
::::::1980198019801980198019801980] ] ] ] ] ] ] eager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KBeager alloc mem 611.00 KB






[2022-12-12 01:14:14.807323: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.807410: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14[.2022-12-12 01:14:14[807535.2022-12-12 01:14:14: [807540.E2022-12-12 01:14:14: 807545 [.[E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc2022-12-12 01:14:14807553[2022-12-12 01:14:14 E:.: 2022-12-12 01:14:14./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc 638807566E.807566:/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :  807586: 638:eager release cuda mem 625663E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: E] 638
 :E eager release cuda mem 625663] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638 /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
eager release cuda mem 625663:] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:
638eager release cuda mem 625663:[638] 
6382022-12-12 01:14:14] eager release cuda mem 625663[] .eager release cuda mem 625663
2022-12-12 01:14:14eager release cuda mem 625663807777
[.
: 2022-12-12 01:14:14[807812E.2022-12-12 01:14:14:  807841.E/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: 807864 :[E: /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu19802022-12-12 01:14:14[ E:] .2022-12-12 01:14:14[/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 1980eager alloc mem 611.00 KB807895.2022-12-12 01:14:14:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] 
: 807912.1980:eager alloc mem 611.00 KBE: 807928] 1980
 E: eager alloc mem 611.00 KB] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu E
eager alloc mem 611.00 KB:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu 
1980:/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] 1980:eager alloc mem 611.00 KB] 1980
eager alloc mem 611.00 KB] 
eager alloc mem 611.00 KB
[2022-12-12 01:14:14.808165: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.808239: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.808702: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.808738: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.[8087652022-12-12 01:14:14: .E[808771 2022-12-12 01:14:14: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.E:[808782 [638[2022-12-12 01:14:14: [/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 01:14:14] 2022-12-12 01:14:14.E2022-12-12 01:14:14:.eager release cuda mem 625663.808796 .1980808803
808808: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc808813] : : E:: eager alloc mem 611.00 KBEE 638E
[  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc]  2022-12-12 01:14:14/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.[::638
:8089472022-12-12 01:14:146381980] 638: .] ] eager release cuda mem 625663] E[808994eager release cuda mem 625663eager alloc mem 611.00 KB
eager release cuda mem 625663 2022-12-12 01:14:14: 


/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.E:809083 1980: /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] E:eager alloc mem 611.00 KB 638[
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu] 2022-12-12 01:14:14[:eager release cuda mem 625663[.2022-12-12 01:14:141980
2022-12-12 01:14:14809145.] .: 809160eager alloc mem 611.00 KB809168E: 
:  EE/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu [ :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu2022-12-12 01:14:14/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu1980:.:] 19808092381980eager alloc mem 611.00 KB] : ] 
eager alloc mem 611.00 KBEeager alloc mem 611.00 KB
 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.809693: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.809771: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.809846: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.809885: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.809914: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[[2022-12-12 01:14:142022-12-12 01:14:14..809952809954: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc::1980638] ] eager alloc mem 611.00 KBeager release cuda mem 625663

[2022-12-12 01:14:14.810026: E[ 2022-12-12 01:14:14/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc[.:[2022-12-12 01:14:14810039638[2022-12-12 01:14:14.: ] 2022-12-12 01:14:14.810047Eeager release cuda mem 625663.810049:  
810058: E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: E :E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638 /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[eager release cuda mem 625663:1980] 2022-12-12 01:14:14
638] eager release cuda mem 625663.] eager alloc mem 611.00 KB
810159eager release cuda mem 625663
: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 01:14:141980.] 810233eager alloc mem 611.00 KB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu[:2022-12-12 01:14:141980.] 810257eager alloc mem 611.00 KB[: 
2022-12-12 01:14:14E. 810270/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: :E1980 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cueager alloc mem 611.00 KB:
1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.810517: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.810588: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.810664: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[[2022-12-12 01:14:142022-12-12 01:14:14..810727810729: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::6381980] ] eager release cuda mem 625663eager alloc mem 611.00 KB

[2022-12-12 01:14:14.810817: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.810945: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.810974: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[[2022-12-12 01:14:142022-12-12 01:14:14..811012811014: : EE[  2022-12-12 01:14:14/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.::[[81104319806382022-12-12 01:14:142022-12-12 01:14:14: ] ] ..Eeager alloc mem 611.00 KBeager release cuda mem 625663811075811066 

: : /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuEE:  1980/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] ::[eager alloc mem 611.00 KB6386382022-12-12 01:14:14
] ] .eager release cuda mem 625663eager release cuda mem 625663811209

: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.[8113072022-12-12 01:14:14: .E811313[ : 2022-12-12 01:14:14/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cuE.: 8113311980/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu: ] :Eeager alloc mem 611.00 KB1980 
] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager alloc mem 611.00 KB:
638] eager release cuda mem 625663
[2022-12-12 01:14:14.811480: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.811504: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14[.2022-12-12 01:14:14811569.: 811574E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638:] 1980eager release cuda mem 625663] 
eager alloc mem 611.00 KB
[2022-12-12 01:14:14.811658: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.811888: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.811956: E[ 2022-12-12 01:14:14/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.:8119631980: ] Eeager alloc mem 611.00 KB[ 
2022-12-12 01:14:14/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc.:812003638: ] Eeager release cuda mem 625663 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.812087: E[ 2022-12-12 01:14:14/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu.:8120971980: ] Eeager alloc mem 611.00 KB 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.812135: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663[
2022-12-12 01:14:14.812159: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.812210: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] [eager alloc mem 611.00 KB2022-12-12 01:14:14[
.2022-12-12 01:14:14812230.: 812235E:  E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc :/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu638:] 1980eager release cuda mem 625663] 
eager alloc mem 611.00 KB
[[2022-12-12 01:14:142022-12-12 01:14:14..812346812348: : EE  /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu::6381980] ] eager release cuda mem 625663eager alloc mem 611.00 KB

[2022-12-12 01:14:14.812403: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.812435: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.812466: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.812749: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.812815: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980] eager alloc mem 611.00 KB
[2022-12-12 01:14:14.812849: [E2022-12-12 01:14:14 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc812860:: 638E]  eager release cuda mem 625663/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 625663
[2022-12-12 01:14:14.812933: [E2022-12-12 01:14:14 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu812941:: 1980E]  eager alloc mem 611.00 KB/hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu
[:2022-12-12 01:14:141980.] 812971eager alloc mem 611.00 KB: 
E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.813033: [E2022-12-12 01:14:14 ./hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc813038:: 638E]  eager release cuda mem 20400000/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc
:638] eager release cuda mem 625663
[2022-12-12 01:14:14.813120: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638[] 2022-12-12 01:14:14eager release cuda mem 625663.
813144: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1980[] 2022-12-12 01:14:14[eager alloc mem 611.00 KB.2022-12-12 01:14:14
813176.: 813182E[:  2022-12-12 01:14:14E/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc. :813211/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc638: :] E638eager release cuda mem 20400000 ] 
/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 625663:
638] eager release cuda mem 625663
[2022-12-12 01:14:14.813274[: 2022-12-12 01:14:14E. 813281/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc: :E638 ] /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cceager release cuda mem 20400000:
638] eager release cuda mem 20400000
[2022-12-12 01:14:14.813563: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.813599: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:14:14.813700: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.[8137322022-12-12 01:14:14: .E813738 : /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.ccE: 638/hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc] :eager release cuda mem 625663638
] eager release cuda mem 20400000
[2022-12-12 01:14:14.813789: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 20400000
[2022-12-12 01:14:14.813930: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] eager release cuda mem 625663
[2022-12-12 01:14:14.813967: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/common.cc:638] [eager release cuda mem 204000002022-12-12 01:14:14
.813977: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.606134 secs 
[2022-12-12 01:14:14.814587: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.607043 secs 
[2022-12-12 01:14:14.814998: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.607222 secs 
[2022-12-12 01:14:14.815099: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.60444 secs 
[2022-12-12 01:14:14.815920: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.607053 secs 
[2022-12-12 01:14:14.816351: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.607465 secs 
[2022-12-12 01:14:14.816774: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.606091 secs 
[2022-12-12 01:14:14.817187: E /hugectr_dev/third_party/collcachelib/coll_cache_lib/cache_context.cu:1793] Collaborative GPU cache (policy: rep_cache) | local 5000000 / 100000000 nodes ( 5.00 %~5.00 %) | remote 0 / 100000000 nodes ( 0.00 %) | cpu 95000000 / 100000000 nodes ( 95.00 %) | 2.38 GB | 0.624797 secs 
[HCTR][01:14:14.817][ERROR][RK0][tid #139959830836992]: replica 2 calling init per replica done, doing barrier
[HCTR][01:14:14.817][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier
[HCTR][01:14:14.817][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier
[HCTR][01:14:14.817][ERROR][RK0][tid #139960451569408]: replica 7 calling init per replica done, doing barrier
[HCTR][01:14:14.817][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier
[HCTR][01:14:14.817][ERROR][RK0][tid #139959897945856]: replica 1 calling init per replica done, doing barrier
[HCTR][01:14:14.817][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier
[HCTR][01:14:14.817][ERROR][RK0][tid #139960434816768]: replica 0 calling init per replica done, doing barrier
[HCTR][01:14:14.817][ERROR][RK0][main]: replica 4 calling init per replica done, doing barrier done
[HCTR][01:14:14.817][ERROR][RK0][tid #139959897945856]: replica 1 calling init per replica done, doing barrier done
[HCTR][01:14:14.817][ERROR][RK0][main]: replica 3 calling init per replica done, doing barrier done
[HCTR][01:14:14.817][ERROR][RK0][tid #139960434816768]: replica 0 calling init per replica done, doing barrier done
[HCTR][01:14:14.817][ERROR][RK0][main]: replica 6 calling init per replica done, doing barrier done
[HCTR][01:14:14.817][ERROR][RK0][tid #139959830836992]: replica 2 calling init per replica done, doing barrier done
[HCTR][01:14:14.817][ERROR][RK0][main]: replica 5 calling init per replica done, doing barrier done
[HCTR][01:14:14.817][ERROR][RK0][tid #139960451569408]: replica 7 calling init per replica done, doing barrier done
[HCTR][01:14:14.817][ERROR][RK0][main]: init per replica done
[HCTR][01:14:14.817][ERROR][RK0][tid #139959897945856]: init per replica done
[HCTR][01:14:14.817][ERROR][RK0][main]: init per replica done
[HCTR][01:14:14.817][ERROR][RK0][main]: init per replica done
[HCTR][01:14:14.817][ERROR][RK0][main]: init per replica done
[HCTR][01:14:14.817][ERROR][RK0][tid #139959830836992]: init per replica done
[HCTR][01:14:14.817][ERROR][RK0][tid #139960451569408]: init per replica done
[HCTR][01:14:14.819][ERROR][RK0][tid #139960434816768]: init per replica done








